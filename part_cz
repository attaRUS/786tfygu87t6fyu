GJEC5A=
golang.org/x/net v0.0.0-20200625001655-4c5254603344/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=
golang.org/x/net v0.0.0-20200707034311-ab3426394381/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=
golang.org/x/net v0.0.0-20200822124328-c89045814202/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=
golang.org/x/net v0.0.0-20201021035429-f5854403a974/go.mod h1:sp8m0HH+o8qH0wwXwYZr8TS3Oi6o0r6Gce1SSxlDquU=
golang.org/x/net v0.0.0-20201031054903-ff519b6c9102/go.mod h1:sp8m0HH+o8qH0wwXwYZr8TS3Oi6o0r6Gce1SSxlDquU=
golang.org/x/net v0.0.0-20201110031124-69a78807bb2b/go.mod h1:sp8m0HH+o8qH0wwXwYZr8TS3Oi6o0r6Gce1SSxlDquU=
golang.org/x/net v0.0.0-20201209123823-ac852fbbde11/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=
golang.org/x/net v0.0.0-20201224014010-6772e930b67b/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=
golang.org/x/net v0.0.0-20210119194325-5f4716e94777/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=
golang.org/x/net v0.0.0-20210226172049-e18ecbb05110/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=
golang.org/x/net v0.0.0-20210316092652-d523dce5a7f4/go.mod h1:RBQZq4jEuRlivfhVLdyRGr576XBO4/greRjx4P4O3yc=
golang.org/x/net v0.0.0-20210405180319-a5a99cb37ef4/go.mod h1:p54w0d4576C0XHj96bSt6lcn1PtDYWL6XObtHCRCNQM=
golang.org/x/net v0.0.0-20210503060351-7fd8e65b6420/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=
golang.org/x/net v0.0.0-20210813160813-60bc85c4be6d/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=
golang.org/x/net v0.0.0-20211015210444-4f30a5c0130f/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=
golang.org/x/net v0.0.0-20211112202133-69e39bad7dc2/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=
golang.org/x/net v0.0.0-20220127200216-cd36cc0744dd/go.mod h1:CfG3xpIq0wQ8r1q4Su4UZFWDARRcnwPjda9FqA0JpMk=
golang.org/x/net v0.0.0-20220225172249-27dd8689420f/go.mod h1:CfG3xpIq0wQ8r1q4Su4UZFWDARRcnwPjda9FqA0JpMk=
golang.org/x/net v0.0.0-20220325170049-de3da57026de/go.mod h1:CfG3xpIq0wQ8r1q4Su4UZFWDARRcnwPjda9FqA0JpMk=
golang.org/x/net v0.0.0-20220412020605-290c469a71a5/go.mod h1:CfG3xpIq0wQ8r1q4Su4UZFWDARRcnwPjda9FqA0JpMk=
golang.org/x/net v0.0.0-20220425223048-2871e0cb64e4/go.mod h1:CfG3xpIq0wQ8r1q4Su4UZFWDARRcnwPjda9FqA0JpMk=
golang.org/x/net v0.0.0-20220607020251-c690dde0001d/go.mod h1:XRhObCWvk6IyKnWLug+ECip1KBveYUHfp+8e9klMJ9c=
golang.org/x/net v0.0.0-20220617184016-355a448f1bc9/go.mod h1:XRhObCWvk6IyKnWLug+ECip1KBveYUHfp+8e9klMJ9c=
golang.org/x/net v0.0.0-20220624214902-1bab6f366d9e/go.mod h1:XRhObCWvk6IyKnWLug+ECip1KBveYUHfp+8e9klMJ9c=
golang.org/x/net v0.0.0-20220722155237-a158d28d115b/go.mod h1:XRhObCWvk6IyKnWLug+ECip1KBveYUHfp+8e9klMJ9c=
golang.org/x/net v0.0.0-20220909164309-bea034e7d591/go.mod h1:YDH+HFinaLZZlnHAfSS6ZXJJ9M9t4Dl22yv3iI2vPwk=
golang.org/x/net v0.0.0-20221012135044-0b7e1fb9d458/go.mod h1:YDH+HFinaLZZlnHAfSS6ZXJJ9M9t4Dl22yv3iI2vPwk=
golang.org/x/net v0.0.0-20221014081412-f15817d10f9b/go.mod h1:YDH+HFinaLZZlnHAfSS6ZXJJ9M9t4Dl22yv3iI2vPwk=
golang.org/x/net v0.1.0/go.mod h1:Cx3nUiGt4eDBEyega/BKRp+/AlGL8hYe7U9odMt2Cco=
golang.org/x/net v0.2.0/go.mod h1:KqCZLdyyvdV855qA2rE3GC2aiw5xGR5TEjj8smXukLY=
golang.org/x/net v0.4.0/go.mod h1:MBQ8lrhLObU/6UmLb4fmbmk5OcyYmqtbGd/9yIeKjEE=
golang.org/x/net v0.5.0/go.mod h1:DivGGAXEgPSlEBzxGzZI+ZLohi+xUj054jfeKui00ws=
golang.org/x/net v0.6.0/go.mod h1:2Tu9+aMcznHK/AK1HMvgo6xiTLG5rD5rZLDS+rp2Bjs=
golang.org/x/net v0.7.0/go.mod h1:2Tu9+aMcznHK/AK1HMvgo6xiTLG5rD5rZLDS+rp2Bjs=
golang.org/x/net v0.8.0/go.mod h1:QVkue5JL9kW//ek3r6jTKnTFis1tRmNAW2P1shuFdJc=
golang.org/x/net v0.9.0/go.mod h1:d48xBJpPfHeWQsugry2m+kC02ZBRGRgulfHnEXEuWns=
golang.org/x/net v0.10.0/go.mod h1:0qNGK6F8kojg2nk9dLZ2mShWaEBan6FAoqfSigmmuDg=
golang.org/x/net v0.11.0/go.mod h1:2L/ixqYpgIVXmeoSA/4Lu7BzTG4KIyPIryS4IsOd1oQ=
golang.org/x/net v0.12.0/go.mod h1:zEVYFnQC7m/vmpQFELhcD1EWkZlX69l4oqgmer6hfKA=
golang.org/x/net v0.14.0/go.mod h1:PpSgVXXLK0OxS0F31C1/tv6XNguvCrnXIDrFMspZIUI=
golang.org/x/net v0.16.0/go.mod h1:NxSsAGuq816PNPmqtQdLE42eU2Fs7NoRIZrHJAlaCOE=
golang.org/x/net v0.17.0/go.mod h1:NxSsAGuq816PNPmqtQdLE42eU2Fs7NoRIZrHJAlaCOE=
golang.org/x/net v0.18.0/go.mod h1:/czyP5RqHAH4odGYxBJ1qz0+CE5WZ+2j1YgoEo8F2jQ=
golang.org/x/net v0.20.0 h1:aCL9BSgETF1k+blQaYUBx9hJ9LOGP3gAVemcZlf1Kpo=
golang.org/x/net v0.20.0/go.mod h1:z8BVo6PvndSri0LbOE3hAn0apkU+1YvI6E70E9jsnvY=
golang.org/x/oauth2 v0.0.0-20180821212333-d2e6202438be/go.mod h1:N/0e6XlmueqKjAGxoOufVs8QHGRruUQn6yWY3a++T0U=
golang.org/x/oauth2 v0.0.0-20190226205417-e64efc72b421/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=
golang.org/x/oauth2 v0.0.0-20190604053449-0f29369cfe45/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=
golang.org/x/oauth2 v0.0.0-20191202225959-858c2ad4c8b6/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=
golang.org/x/oauth2 v0.0.0-20200107190931-bf48bf16ab8d/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=
golang.org/x/oauth2 v0.0.0-20200902213428-5d25da1a8d43/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=
golang.org/x/oauth2 v0.0.0-20201109201403-9fd604954f58/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=
golang.org/x/oauth2 v0.0.0-20201208152858-08078c50e5b5/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=
golang.org/x/oauth2 v0.0.0-20210218202405-ba52d332ba99/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=
golang.org/x/oauth2 v0.0.0-20210220000619-9bb904979d93/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=
golang.org/x/oauth2 v0.0.0-20210313182246-cd4f82c27b84/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=
golang.org/x/oauth2 v0.0.0-20210514164344-f6687ab2804c/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=
golang.org/x/oauth2 v0.0.0-20210628180205-a41e5a781914/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=
golang.org/x/oauth2 v0.0.0-20210805134026-6f1e6394065a/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=
golang.org/x/oauth2 v0.0.0-20210819190943-2bc19b11175f/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=
golang.org/x/oauth2 v0.0.0-20211104180415-d3ed0bb246c8/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=
golang.org/x/oauth2 v0.0.0-20220223155221-ee480838109b/go.mod h1:DAh4E804XQdzx2j+YRIaUnCqCV2RuMz24cGBJ5QYIrc=
golang.org/x/oauth2 v0.0.0-20220309155454-6242fa91716a/go.mod h1:DAh4E804XQdzx2j+YRIaUnCqCV2RuMz24cGBJ5QYIrc=
golang.org/x/oauth2 v0.0.0-20220411215720-9780585627b5/go.mod h1:DAh4E804XQdzx2j+YRIaUnCqCV2RuMz24cGBJ5QYIrc=
golang.org/x/oauth2 v0.0.0-20220608161450-d0670ef3b1eb/go.mod h1:jaDAt6Dkxork7LmZnYtzbRWj0W47D86a3TGe0YHBvmE=
golang.org/x/oauth2 v0.0.0-20220622183110-fd043fe589d2/go.mod h1:jaDAt6Dkxork7LmZnYtzbRWj0W47D86a3TGe0YHBvmE=
golang.org/x/oauth2 v0.0.0-20220822191816-0ebed06d0094/go.mod h1:h4gKUeWbJ4rQPri7E0u6Gs4e9Ri2zaLxzw5DI5XGrYg=
golang.org/x/oauth2 v0.0.0-20220909003341-f21342109be1/go.mod h1:h4gKUeWbJ4rQPri7E0u6Gs4e9Ri2zaLxzw5DI5XGrYg=
golang.org/x/oauth2 v0.0.0-20221006150949-b44042a4b9c1/go.mod h1:h4gKUeWbJ4rQPri7E0u6Gs4e9Ri2zaLxzw5DI5XGrYg=
golang.org/x/oauth2 v0.0.0-20221014153046-6fdb5e3db783/go.mod h1:h4gKUeWbJ4rQPri7E0u6Gs4e9Ri2zaLxzw5DI5XGrYg=
golang.org/x/oauth2 v0.4.0/go.mod h1:RznEsdpjGAINPTOF0UH/t+xJ75L18YO3Ho6Pyn+uRec=
golang.org/x/oauth2 v0.5.0/go.mod h1:9/XBHVqLaWO3/BRHs5jbpYCnOZVjj5V0ndyaAM7KB4I=
golang.org/x/oauth2 v0.6.0/go.mod h1:ycmewcwgD4Rpr3eZJLSB4Kyyljb3qDh40vJ8STE5HKw=
golang.org/x/oauth2 v0.7.0/go.mod h1:hPLQkd9LyjfXTiRohC/41GhcFqxisoUQ99sCUOHO9x4=
golang.org/x/oauth2 v0.8.0/go.mod h1:yr7u4HXZRm1R1kBWqr/xKNqewf0plRYoB7sla+BCIXE=
golang.org/x/oauth2 v0.10.0/go.mod h1:kTpgurOux7LqtuxjuyZa4Gj2gdezIt/jQtGnNFfypQI=
golang.org/x/oauth2 v0.11.0/go.mod h1:LdF7O/8bLR/qWK9DrpXmbHLTouvRHK0SgJl0GmDBchk=
golang.org/x/oauth2 v0.13.0/go.mod h1:/JMhi4ZRXAf4HG9LiNmxvk+45+96RUlVThiH8FzNBn0=
golang.org/x/oauth2 v0.14.0/go.mod h1:lAtNWgaWfL4cm7j2OV8TxGi9Qb7ECORx8DktCY74OwM=
golang.org/x/sync v0.0.0-20180314180146-1d60e4601c6f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
golang.org/x/sync v0.0.0-20181108010431-42b317875d0f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
golang.org/x/sync v0.0.0-20181221193216-37e7f081c4d4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
golang.org/x/sync v0.0.0-20190227155943-e225da77a7e6/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
golang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
golang.org/x/sync v0.0.0-20190911185100-cd5d95a43a6e/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
golang.org/x/sync v0.0.0-20200317015054-43a5402ce75a/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
golang.org/x/sync v0.0.0-20200625203802-6e8e738ad208/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
golang.org/x/sync v0.0.0-20201020160332-67f06af15bc9/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
golang.org/x/sync v0.0.0-20201207232520-09787c993a3a/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
golang.org/x/sync v0.0.0-20210220032951-036812b2e83c/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
golang.org/x/sync v0.0.0-20220601150217-0de741cfad7f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
golang.org/x/sync v0.0.0-20220722155255-886fb9371eb4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
golang.org/x/sync v0.0.0-20220819030929-7fc1605a5dde/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
golang.org/x/sync v0.0.0-20220929204114-8fcdb60fdcc0/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
golang.org/x/sync v0.1.0/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
golang.org/x/sync v0.2.0/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
golang.org/x/sync v0.3.0/go.mod h1:FU7BRWz2tNW+3quACPkgCx/L+uEAv1htQ0V83Z9Rj+Y=
golang.org/x/sync v0.4.0/go.mod h1:FU7BRWz2tNW+3quACPkgCx/L+uEAv1htQ0V83Z9Rj+Y=
golang.org/x/sync v0.5.0/go.mod h1:Czt+wKu1gCyEFDUtn0jG5QVvpJ6rzVqr5aXyt9drQfk=
golang.org/x/sys v0.0.0-20180830151530-49385e6e1522/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=
golang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=
golang.org/x/sys v0.0.0-20190312061237-fead79001313/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20190502145724-3ef323f4f1fd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20190507160741-ecd444e8653b/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20190606165138-5da285871e9c/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20190624142023-c5567b49c5d0/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20190726091711-fc99dfbffb4e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20191001151750-bb3f8db39f24/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20191204072324-ce4227a45e2e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20191228213918-04cbcbbfeed8/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20200113162924-86b910548bc1/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20200116001909-b77594299b42/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20200122134326-e047566fdf82/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20200202164722-d101bd2416d5/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20200212091648-12a6c2dcc1e4/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20200223170610-d5e6a3e2c0ae/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20200302150141-5c8b2ff67527/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20200323222414-85ca7c5b95cd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20200331124033-c3d80250170d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20200501052902-10377860bb8e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20200511232937-7e40ca221e25/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20200515095857-1151b9dac4a9/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20200523222454-059865788121/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20200803210538-64077c9b5642/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20200905004654-be1d3432aa8f/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20200930185726-fdedc70b468f/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20201201145000-ef89a241ccb3/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20210104204734-6f8348627aad/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20210119212857-b64e53b001e4/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20210220050731-9a76102bfb43/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20210225134936-a50acf3fe073/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20210304124612-50617c2ba197/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20210305230114-8fe3ee5dd75b/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20210315160823-c6e025ad8005/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20210320140829-1e4c9ba3b0c4/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20210330210617-4fbd30eecc44/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20210423082822-04245dca01da/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20210423185535-09eb48e85fd7/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20210510120138-977fb7262007/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20210514084401-e8d321eab015/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20210603125802-9665404d3644/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20210615035016-665e8c7367d1/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20210616094352-59db8d763f22/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20210630005230-0f9fa26af87c/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20210806184541-e5e7981a1069/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20210816183151-1e6c022a8912/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20210823070655-63515b42dcdf/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20210908233432-aa78b53d3365/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20211007075335-d3039528d8ac/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20211019181941-9d821ace8654/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20211124211545-fe61309f8881/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20211210111614-af8b64212486/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20211216021012-1d35b9e2eb4e/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20220128215802-99c3d69c2c27/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20220209214540-3681064d5158/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20220227234510-4e6760a101f9/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20220328115105-d36c6a25d886/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20220412211240-33da011f77ad/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20220502124256-b6088ccd6cba/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20220503163025-988cb79eb6c6/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20220520151302-bc2c85ada10a/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20220610221304-9f5ed59c137d/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20220615213510-4f61da869c0c/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20220624220833-87e55d714810/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20220722155257-8c9f86f7a55f/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20220728004956-3c1f35247d10/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20220811171246-fbc7d0a398ab/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20220829200755-d48e67d00261/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.1.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.2.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.3.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.4.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.5.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.6.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.7.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.8.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.9.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.10.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.11.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.12.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.13.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.14.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=
golang.org/x/sys v0.16.0 h1:xWw16ngr6ZMtmxDyKyIgsE93KNKz5HKmMa3b8ALHidU=
golang.org/x/sys v0.16.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=
golang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=
golang.org/x/term v0.0.0-20210927222741-03fcf44c2211/go.mod h1:jbD1KX2456YbFQfuXm/mYQcufACuNUgVhRMnK/tPxf8=
golang.org/x/term v0.1.0/go.mod h1:jbD1KX2456YbFQfuXm/mYQcufACuNUgVhRMnK/tPxf8=
golang.org/x/term v0.2.0/go.mod h1:TVmDHMZPmdnySmBfhjOoOdhjzdE1h4u1VwSiw2l1Nuc=
golang.org/x/term v0.3.0/go.mod h1:q750SLmJuPmVoN1blW3UFBPREJfb1KmY3vwxfr+nFDA=
golang.org/x/term v0.4.0/go.mod h1:9P2UbLfCdcvo3p/nzKvsmas4TnlujnuoV9hGgYzW1lQ=
golang.org/x/term v0.5.0/go.mod h1:jMB1sMXY+tzblOD4FWmEbocvup2/aLOaQEp7JmGp78k=
golang.org/x/term v0.6.0/go.mod h1:m6U89DPEgQRMq3DNkDClhWw02AUbt2daBVO4cn4Hv9U=
golang.org/x/term v0.7.0/go.mod h1:P32HKFT3hSsZrRxla30E9HqToFYAQPCMs/zFMBUFqPY=
golang.org/x/term v0.8.0/go.mod h1:xPskH00ivmX89bAKVGSKKtLOWNx2+17Eiy94tnKShWo=
golang.org/x/term v0.9.0/go.mod h1:M6DEAAIenWoTxdKrOltXcmDY3rSplQUkrvaDU5FcQyo=
golang.org/x/term v0.10.0/go.mod h1:lpqdcUyK/oCiQxvxVrppt5ggO2KCZ5QblwqPnfZ6d5o=
golang.org/x/term v0.11.0/go.mod h1:zC9APTIj3jG3FdV/Ons+XE1riIZXG4aZ4GTHiPZJPIU=
golang.org/x/term v0.12.0/go.mod h1:owVbMEjm3cBLCHdkQu9b1opXd4ETQWc3BhuQGKgXgvU=
golang.org/x/term v0.13.0/go.mod h1:LTmsnFJwVN6bCy1rVCoS+qHT1HhALEFxKncY3WNNh4U=
golang.org/x/term v0.14.0/go.mod h1:TySc+nGkYR6qt8km8wUhuFRTVSMIX3XPR58y2lC8vww=
golang.org/x/term v0.16.0/go.mod h1:yn7UURbUtPyrVJPGPq404EukNFxcm/foM+bV/bfcDsY=
golang.org/x/text v0.0.0-20170915032832-14c0d48ead0c/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=
golang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=
golang.org/x/text v0.3.1-0.20180807135948-17ff2d5776d2/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=
golang.org/x/text v0.3.2/go.mod h1:bEr9sfX3Q8Zfm5fL9x+3itogRgK3+ptLWKqgva+5dAk=
golang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=
golang.org/x/text v0.3.4/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=
golang.org/x/text v0.3.5/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=
golang.org/x/text v0.3.6/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=
golang.org/x/text v0.3.7/go.mod h1:u+2+/6zg+i71rQMx5EYifcz6MCKuco9NR6JIITiCfzQ=
golang.org/x/text v0.3.8/go.mod h1:E6s5w1FMmriuDzIBO73fBruAKo1PCIq6d2Q6DHfQ8WQ=
golang.org/x/text v0.4.0/go.mod h1:mrYo+phRRbMaCq/xk9113O4dZlRixOauAjOtrjsXDZ8=
golang.org/x/text v0.5.0/go.mod h1:mrYo+phRRbMaCq/xk9113O4dZlRixOauAjOtrjsXDZ8=
golang.org/x/text v0.6.0/go.mod h1:mrYo+phRRbMaCq/xk9113O4dZlRixOauAjOtrjsXDZ8=
golang.org/x/text v0.7.0/go.mod h1:mrYo+phRRbMaCq/xk9113O4dZlRixOauAjOtrjsXDZ8=
golang.org/x/text v0.8.0/go.mod h1:e1OnstbJyHTd6l/uOt8jFFHp6TRDWZR/bV3emEE/zU8=
golang.org/x/text v0.9.0/go.mod h1:e1OnstbJyHTd6l/uOt8jFFHp6TRDWZR/bV3emEE/zU8=
golang.org/x/text v0.10.0/go.mod h1:TvPlkZtksWOMsz7fbANvkp4WM8x/WCo/om8BMLbz+aE=
golang.org/x/text v0.11.0/go.mod h1:TvPlkZtksWOMsz7fbANvkp4WM8x/WCo/om8BMLbz+aE=
golang.org/x/text v0.12.0/go.mod h1:TvPlkZtksWOMsz7fbANvkp4WM8x/WCo/om8BMLbz+aE=
golang.org/x/text v0.13.0/go.mod h1:TvPlkZtksWOMsz7fbANvkp4WM8x/WCo/om8BMLbz+aE=
golang.org/x/text v0.14.0 h1:ScX5w1eTa3QqT8oi6+ziP7dTV1S2+ALU0bI+0zXKWiQ=
golang.org/x/text v0.14.0/go.mod h1:18ZOQIKpY8NJVqYksKHtTdi31H5itFRjB5/qKTNYzSU=
golang.org/x/time v0.0.0-20181108054448-85acf8d2951c/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=
golang.org/x/time v0.0.0-20190308202827-9d24e82272b4/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=
golang.org/x/time v0.0.0-20191024005414-555d28b269f0/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=
golang.org/x/time v0.0.0-20220922220347-f3bd1da661af/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=
golang.org/x/time v0.1.0/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=
golang.org/x/time v0.3.0/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=
golang.org/x/tools v0.0.0-20180525024113-a5b4c53f6e8b/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=
golang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=
golang.org/x/tools v0.0.0-20190114222345-bf090417da8b/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=
golang.org/x/tools v0.0.0-20190206041539-40960b6deb8e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=
golang.org/x/tools v0.0.0-20190226205152-f727befe758c/go.mod h1:9Yl7xja0Znq3iFh3HoIrodX9oNMXvdceNzlUR8zjMvY=
golang.org/x/tools v0.0.0-20190311212946-11955173bddd/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=
golang.org/x/tools v0.0.0-20190312151545-0bb0c0a6e846/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=
golang.org/x/tools v0.0.0-20190312170243-e65039ee4138/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=
golang.org/x/tools v0.0.0-20190425150028-36563e24a262/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=
golang.org/x/tools v0.0.0-20190506145303-2d16b83fe98c/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=
golang.org/x/tools v0.0.0-20190524140312-2c0ae7006135/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=
golang.org/x/tools v0.0.0-20190606124116-d0a3d012864b/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=
golang.org/x/tools v0.0.0-20190621195816-6e04913cbbac/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=
golang.org/x/tools v0.0.0-20190628153133-6cdbf07be9d0/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=
golang.org/x/tools v0.0.0-20190816200558-6889da9d5479/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
golang.org/x/tools v0.0.0-20190911174233-4f2ddba30aff/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
golang.org/x/tools v0.0.0-20190927191325-030b2cf1153e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
golang.org/x/tools v0.0.0-20191012152004-8de300cfc20a/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
golang.org/x/tools v0.0.0-20191113191852-77e3bb0ad9e7/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
golang.org/x/tools v0.0.0-20191115202509-3a792d9c32b2/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
golang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
golang.org/x/tools v0.0.0-20191125144606-a911d9008d1f/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
golang.org/x/tools v0.0.0-20191130070609-6e064ea0cf2d/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
golang.org/x/tools v0.0.0-20191216173652-a0e659d51361/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=
golang.org/x/tools v0.0.0-20191227053925-7b8e75db28f4/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=
golang.org/x/tools v0.0.0-20200117161641-43d50277825c/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=
golang.org/x/tools v0.0.0-20200122220014-bf1340f18c4a/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=
golang.org/x/tools v0.0.0-20200130002326-2f3ba24bd6e7/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=
golang.org/x/tools v0.0.0-20200204074204-1cc6d1ef6c74/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=
golang.org/x/tools v0.0.0-20200207183749-b753a1ba74fa/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=
golang.org/x/tools v0.0.0-20200212150539-ea181f53ac56/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=
golang.org/x/tools v0.0.0-20200224181240-023911ca70b2/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=
golang.org/x/tools v0.0.0-20200227222343-706bc42d1f0d/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=
golang.org/x/tools v0.0.0-20200304193943-95d2e580d8eb/go.mod h1:o4KQGtdN14AW+yjsvvwRTJJuXz8XRtIHtEnmAXLyFUw=
golang.org/x/tools v0.0.0-20200312045724-11d5b4c81c7d/go.mod h1:o4KQGtdN14AW+yjsvvwRTJJuXz8XRtIHtEnmAXLyFUw=
golang.org/x/tools v0.0.0-20200331025713-a30bf2db82d4/go.mod h1:Sl4aGygMT6LrqrWclx+PTx3U+LnKx/seiNR+3G19Ar8=
golang.org/x/tools v0.0.0-20200501065659-ab2804fb9c9d/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=
golang.org/x/tools v0.0.0-20200512131952-2bc93b1c0c88/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=
golang.org/x/tools v0.0.0-20200515010526-7d3b6ebf133d/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=
golang.org/x/tools v0.0.0-20200618134242-20370b0cb4b2/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=
golang.org/x/tools v0.0.0-20200729194436-6467de6f59a7/go.mod h1:njjCfa9FT2d7l9Bc6FUM5FLjQPp3cFF28FI3qnDFljA=
golang.org/x/tools v0.0.0-20200804011535-6c149bb5ef0d/go.mod h1:njjCfa9FT2d7l9Bc6FUM5FLjQPp3cFF28FI3qnDFljA=
golang.org/x/tools v0.0.0-20200825202427-b303f430e36d/go.mod h1:njjCfa9FT2d7l9Bc6FUM5FLjQPp3cFF28FI3qnDFljA=
golang.org/x/tools v0.0.0-20200904185747-39188db58858/go.mod h1:Cj7w3i3Rnn0Xh82ur9kSqwfTHTeVxaDqrfMjpcNT6bE=
golang.org/x/tools v0.0.0-20201110124207-079ba7bd75cd/go.mod h1:emZCQorbCU4vsT4fOWvOPXz4eW1wZW4PmDk9uLelYpA=
golang.org/x/tools v0.0.0-20201124115921-2c860bdd6e78/go.mod h1:emZCQorbCU4vsT4fOWvOPXz4eW1wZW4PmDk9uLelYpA=
golang.org/x/tools v0.0.0-20201201161351-ac6f37ff4c2a/go.mod h1:emZCQorbCU4vsT4fOWvOPXz4eW1wZW4PmDk9uLelYpA=
golang.org/x/tools v0.0.0-20201208233053-a543418bbed2/go.mod h1:emZCQorbCU4vsT4fOWvOPXz4eW1wZW4PmDk9uLelYpA=
golang.org/x/tools v0.0.0-20210105154028-b0ab187a4818/go.mod h1:emZCQorbCU4vsT4fOWvOPXz4eW1wZW4PmDk9uLelYpA=
golang.org/x/tools v0.0.0-20210108195828-e2f9c7f1fc8e/go.mod h1:emZCQorbCU4vsT4fOWvOPXz4eW1wZW4PmDk9uLelYpA=
golang.org/x/tools v0.1.0/go.mod h1:xkSsbof2nBLbhDlRMhhhyNLN/zl3eTqcnHD5viDpcZ0=
golang.org/x/tools v0.1.1/go.mod h1:o0xws9oXOQQZyjljx8fwUC0k7L1pTE6eaCbjGeHmOkk=
golang.org/x/tools v0.1.2/go.mod h1:o0xws9oXOQQZyjljx8fwUC0k7L1pTE6eaCbjGeHmOkk=
golang.org/x/tools v0.1.3/go.mod h1:o0xws9oXOQQZyjljx8fwUC0k7L1pTE6eaCbjGeHmOkk=
golang.org/x/tools v0.1.4/go.mod h1:o0xws9oXOQQZyjljx8fwUC0k7L1pTE6eaCbjGeHmOkk=
golang.org/x/tools v0.1.5/go.mod h1:o0xws9oXOQQZyjljx8fwUC0k7L1pTE6eaCbjGeHmOkk=
golang.org/x/tools v0.1.9/go.mod h1:nABZi5QlRsZVlzPpHl034qft6wpY4eDcsTt5AaioBiU=
golang.org/x/tools v0.1.12/go.mod h1:hNGJHUnrk76NpqgfD5Aqm5Crs+Hm0VOH/i9J2+nxYbc=
golang.org/x/tools v0.3.0/go.mod h1:/rWhSS2+zyEVwoJf8YAX6L2f0ntZ7Kn/mGgAWcipA5k=
golang.org/x/tools v0.6.0/go.mod h1:Xwgl3UAJ/d3gWutnCtw505GrjyAbvKui8lOU390QaIU=
golang.org/x/tools v0.7.0/go.mod h1:4pg6aUX35JBAogB10C9AtvVL+qowtN4pT3CGSQex14s=
golang.org/x/tools v0.8.0/go.mod h1:JxBZ99ISMI5ViVkT1tr6tdNmXeTrcpVSD3vZ1RsRdN4=
golang.org/x/tools v0.9.1/go.mod h1:owI94Op576fPu3cIGQeHs3joujW/2Oc6MtlxbF5dfNc=
golang.org/x/tools v0.10.0/go.mod h1:UJwyiVBsOA2uwvK/e5OY3GTpDUJriEd+/YlqAwLPmyM=
golang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=
golang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=
golang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=
golang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=
golang.org/x/xerrors v0.0.0-20220411194840-2f41105eb62f/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=
golang.org/x/xerrors v0.0.0-20220517211312-f3a8303e98df/go.mod h1:K8+ghG5WaK9qNqU5K3HdILfMLy1f3aNYFI/wnl100a8=
golang.org/x/xerrors v0.0.0-20220609144429-65e65417b02f/go.mod h1:K8+ghG5WaK9qNqU5K3HdILfMLy1f3aNYFI/wnl100a8=
golang.org/x/xerrors v0.0.0-20220907171357-04be3eba64a2/go.mod h1:K8+ghG5WaK9qNqU5K3HdILfMLy1f3aNYFI/wnl100a8=
gonum.org/v1/gonum v0.0.0-20180816165407-929014505bf4/go.mod h1:Y+Yx5eoAFn32cQvJDxZx5Dpnq+c3wtXuadVZAcxbbBo=
gonum.org/v1/gonum v0.8.2/go.mod h1:oe/vMfY3deqTw+1EZJhuvEW2iwGF1bW9wwu7XCu0+v0=
gonum.org/v1/gonum v0.9.3/go.mod h1:TZumC3NeyVQskjXqmyWt4S3bINhy7B4eYwW69EbyX+0=
gonum.org/v1/gonum v0.11.0/go.mod h1:fSG4YDCxxUZQJ7rKsQrj0gMOg00Il0Z96/qMA4bVQhA=
gonum.org/v1/netlib v0.0.0-20190313105609-8cb42192e0e0/go.mod h1:wa6Ws7BG/ESfp6dHfk7C6KdzKA7wR7u/rKwOGE66zvw=
gonum.org/v1/plot v0.0.0-20190515093506-e2840ee46a6b/go.mod h1:Wt8AAjI+ypCyYX3nZBvf6cAIx93T+c/OS2HFAYskSZc=
gonum.org/v1/plot v0.9.0/go.mod h1:3Pcqqmp6RHvJI72kgb8fThyUnav364FOsdDo2aGW5lY=
gonum.org/v1/plot v0.10.1/go.mod h1:VZW5OlhkL1mysU9vaqNHnsy86inf6Ot+jB3r+BczCEo=
google.golang.org/api v0.4.0/go.mod h1:8k5glujaEP+g9n7WNsDg8QP6cUVNI86fCNMcbazEtwE=
google.golang.org/api v0.7.0/go.mod h1:WtwebWUNSVBH/HAw79HIFXZNqEvBhG+Ra+ax0hx3E3M=
google.golang.org/api v0.8.0/go.mod h1:o4eAsZoiT+ibD93RtjEohWalFOjRDx6CVaqeizhEnKg=
google.golang.org/api v0.9.0/go.mod h1:o4eAsZoiT+ibD93RtjEohWalFOjRDx6CVaqeizhEnKg=
google.golang.org/api v0.13.0/go.mod h1:iLdEw5Ide6rF15KTC1Kkl0iskquN2gFfn9o9XIsbkAI=
google.golang.org/api v0.14.0/go.mod h1:iLdEw5Ide6rF15KTC1Kkl0iskquN2gFfn9o9XIsbkAI=
google.golang.org/api v0.15.0/go.mod h1:iLdEw5Ide6rF15KTC1Kkl0iskquN2gFfn9o9XIsbkAI=
google.golang.org/api v0.17.0/go.mod h1:BwFmGc8tA3vsd7r/7kR8DY7iEEGSU04BFxCo5jP/sfE=
google.golang.org/api v0.18.0/go.mod h1:BwFmGc8tA3vsd7r/7kR8DY7iEEGSU04BFxCo5jP/sfE=
google.golang.org/api v0.19.0/go.mod h1:BwFmGc8tA3vsd7r/7kR8DY7iEEGSU04BFxCo5jP/sfE=
google.golang.org/api v0.20.0/go.mod h1:BwFmGc8tA3vsd7r/7kR8DY7iEEGSU04BFxCo5jP/sfE=
google.golang.org/api v0.22.0/go.mod h1:BwFmGc8tA3vsd7r/7kR8DY7iEEGSU04BFxCo5jP/sfE=
google.golang.org/api v0.24.0/go.mod h1:lIXQywCXRcnZPGlsd8NbLnOjtAoL6em04bJ9+z0MncE=
google.golang.org/api v0.28.0/go.mod h1:lIXQywCXRcnZPGlsd8NbLnOjtAoL6em04bJ9+z0MncE=
google.golang.org/api v0.29.0/go.mod h1:Lcubydp8VUV7KeIHD9z2Bys/sm/vGKnG1UHuDBSrHWM=
google.golang.org/api v0.30.0/go.mod h1:QGmEvQ87FHZNiUVJkT14jQNYJ4ZJjdRF23ZXz5138Fc=
google.golang.org/api v0.35.0/go.mod h1:/XrVsuzM0rZmrsbjJutiuftIzeuTQcEeaYcSk/mQ1dg=
google.golang.org/api v0.36.0/go.mod h1:+z5ficQTmoYpPn8LCUNVpK5I7hwkpjbcgqA7I34qYtE=
google.golang.org/api v0.40.0/go.mod h1:fYKFpnQN0DsDSKRVRcQSDQNtqWPfM9i+zNPxepjRCQ8=
google.golang.org/api v0.41.0/go.mod h1:RkxM5lITDfTzmyKFPt+wGrCJbVfniCr2ool8kTBzRTU=
google.golang.org/api v0.43.0/go.mod h1:nQsDGjRXMo4lvh5hP0TKqF244gqhGcr/YSIykhUk/94=
google.golang.org/api v0.47.0/go.mod h1:Wbvgpq1HddcWVtzsVLyfLp8lDg6AA241LmgIL59tHXo=
google.golang.org/api v0.48.0/go.mod h1:71Pr1vy+TAZRPkPs/xlCf5SsU8WjuAWv1Pfjbtukyy4=
google.golang.org/api v0.50.0/go.mod h1:4bNT5pAuq5ji4SRZm+5QIkjny9JAyVD/3gaSihNefaw=
google.golang.org/api v0.51.0/go.mod h1:t4HdrdoNgyN5cbEfm7Lum0lcLDLiise1F8qDKX00sOU=
google.golang.org/api v0.54.0/go.mod h1:7C4bFFOvVDGXjfDTAsgGwDgAxRDeQ4X8NvUedIt6z3k=
google.golang.org/api v0.55.0/go.mod h1:38yMfeP1kfjsl8isn0tliTjIb1rJXcQi4UXlbqivdVE=
google.golang.org/api v0.56.0/go.mod h1:38yMfeP1kfjsl8isn0tliTjIb1rJXcQi4UXlbqivdVE=
google.golang.org/api v0.57.0/go.mod h1:dVPlbZyBo2/OjBpmvNdpn2GRm6rPy75jyU7bmhdrMgI=
google.golang.org/api v0.61.0/go.mod h1:xQRti5UdCmoCEqFxcz93fTl338AVqDgyaDRuOZ3hg9I=
google.golang.org/api v0.63.0/go.mod h1:gs4ij2ffTRXwuzzgJl/56BdwJaA194ijkfn++9tDuPo=
google.golang.org/api v0.67.0/go.mod h1:ShHKP8E60yPsKNw/w8w+VYaj9H6buA5UqDp8dhbQZ6g=
google.golang.org/api v0.70.0/go.mod h1:Bs4ZM2HGifEvXwd50TtW70ovgJffJYw2oRCOFU/SkfA=
google.golang.org/api v0.71.0/go.mod h1:4PyU6e6JogV1f9eA4voyrTY2batOLdgZ5qZ5HOCc4j8=
google.golang.org/api v0.74.0/go.mod h1:ZpfMZOVRMywNyvJFeqL9HRWBgAuRfSjJFpe9QtRRyDs=
google.golang.org/api v0.75.0/go.mod h1:pU9QmyHLnzlpar1Mjt4IbapUCy8J+6HD6GeELN69ljA=
google.golang.org/api v0.77.0/go.mod h1:pU9QmyHLnzlpar1Mjt4IbapUCy8J+6HD6GeELN69ljA=
google.golang.org/api v0.78.0/go.mod h1:1Sg78yoMLOhlQTeF+ARBoytAcH1NNyyl390YMy6rKmw=
google.golang.org/api v0.80.0/go.mod h1:xY3nI94gbvBrE0J6NHXhxOmW97HG7Khjkku6AFB3Hyg=
google.golang.org/api v0.84.0/go.mod h1:NTsGnUFJMYROtiquksZHBWtHfeMC7iYthki7Eq3pa8o=
google.golang.org/api v0.85.0/go.mod h1:AqZf8Ep9uZ2pyTvgL+x0D3Zt0eoT9b5E8fmzfu6FO2g=
google.golang.org/api v0.90.0/go.mod h1:+Sem1dnrKlrXMR/X0bPnMWyluQe4RsNoYfmNLhOIkzw=
google.golang.org/api v0.93.0/go.mod h1:+Sem1dnrKlrXMR/X0bPnMWyluQe4RsNoYfmNLhOIkzw=
google.golang.org/api v0.95.0/go.mod h1:eADj+UBuxkh5zlrSntJghuNeg8HwQ1w5lTKkuqaETEI=
google.golang.org/api v0.96.0/go.mod h1:w7wJQLTM+wvQpNf5JyEcBoxK0RH7EDrh/L4qfsuJ13s=
google.golang.org/api v0.97.0/go.mod h1:w7wJQLTM+wvQpNf5JyEcBoxK0RH7EDrh/L4qfsuJ13s=
google.golang.org/api v0.98.0/go.mod h1:w7wJQLTM+wvQpNf5JyEcBoxK0RH7EDrh/L4qfsuJ13s=
google.golang.org/api v0.99.0/go.mod h1:1YOf74vkVndF7pG6hIHuINsM7eWwpVTAfNMNiL91A08=
google.golang.org/api v0.100.0/go.mod h1:ZE3Z2+ZOr87Rx7dqFsdRQkRBk36kDtp/h+QpHbB7a70=
google.golang.org/api v0.102.0/go.mod h1:3VFl6/fzoA+qNuS1N1/VfXY4LjoXN/wzeIp7TweWwGo=
google.golang.org/api v0.103.0/go.mod h1:hGtW6nK1AC+d9si/UBhw8Xli+QMOf6xyNAyJw4qU9w0=
google.golang.org/api v0.106.0/go.mod h1:2Ts0XTHNVWxypznxWOYUeI4g3WdP9Pk2Qk58+a/O9MY=
google.golang.org/api v0.107.0/go.mod h1:2Ts0XTHNVWxypznxWOYUeI4g3WdP9Pk2Qk58+a/O9MY=
google.golang.org/api v0.108.0/go.mod h1:2Ts0XTHNVWxypznxWOYUeI4g3WdP9Pk2Qk58+a/O9MY=
google.golang.org/api v0.110.0/go.mod h1:7FC4Vvx1Mooxh8C5HWjzZHcavuS2f6pmJpZx60ca7iI=
google.golang.org/api v0.111.0/go.mod h1:qtFHvU9mhgTJegR31csQ+rwxyUTHOKFqCKWp1J0fdw0=
google.golang.org/api v0.114.0/go.mod h1:ifYI2ZsFK6/uGddGfAD5BMxlnkBqCmqHSDUVi45N5Yg=
google.golang.org/api v0.118.0/go.mod h1:76TtD3vkgmZ66zZzp72bUUklpmQmKlhh6sYtIjYK+5E=
google.golang.org/api v0.122.0/go.mod h1:gcitW0lvnyWjSp9nKxAbdHKIZ6vF4aajGueeslZOyms=
google.golang.org/api v0.124.0/go.mod h1:xu2HQurE5gi/3t1aFCvhPD781p0a3p11sdunTJ2BlP4=
google.golang.org/api v0.125.0/go.mod h1:mBwVAtz+87bEN6CbA1GtZPDOqY2R5ONPqJeIlvyo4Aw=
google.golang.org/api v0.126.0/go.mod h1:mBwVAtz+87bEN6CbA1GtZPDOqY2R5ONPqJeIlvyo4Aw=
google.golang.org/api v0.128.0/go.mod h1:Y611qgqaE92On/7g65MQgxYul3c0rEB894kniWLY750=
google.golang.org/api v0.139.0/go.mod h1:CVagp6Eekz9CjGZ718Z+sloknzkDJE7Vc1Ckj9+viBk=
google.golang.org/api v0.149.0/go.mod h1:Mwn1B7JTXrzXtnvmzQE2BD6bYZQ8DShKZDZbeN9I7qI=
google.golang.org/appengine v1.1.0/go.mod h1:EbEs0AVv82hx2wNQdGPgUI5lhzA/G0D9YwlJXL52JkM=
google.golang.org/appengine v1.4.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=
google.golang.org/appengine v1.5.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=
google.golang.org/appengine v1.6.1/go.mod h1:i06prIuMbXzDqacNJfV5OdTW448YApPu5ww/cMBSeb0=
google.golang.org/appengine v1.6.5/go.mod h1:8WjMMxjGQR8xUklV/ARdw2HLXBOI7O7uCIDZVag1xfc=
google.golang.org/appengine v1.6.6/go.mod h1:8WjMMxjGQR8xUklV/ARdw2HLXBOI7O7uCIDZVag1xfc=
google.golang.org/appengine v1.6.7/go.mod h1:8WjMMxjGQR8xUklV/ARdw2HLXBOI7O7uCIDZVag1xfc=
google.golang.org/appengine v1.6.8/go.mod h1:1jJ3jBArFh5pcgW8gCtRJnepW8FzD1V44FJffLiz/Ds=
google.golang.org/genproto v0.0.0-20180817151627-c66870c02cf8/go.mod h1:JiN7NxoALGmiZfu7CAH4rXhgtRTLTxftemlI0sWmxmc=
google.golang.org/genproto v0.0.0-20190307195333-5fe7a883aa19/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=
google.golang.org/genproto v0.0.0-20190418145605-e7d98fc518a7/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=
google.golang.org/genproto v0.0.0-20190425155659-357c62f0e4bb/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=
google.golang.org/genproto v0.0.0-20190502173448-54afdca5d873/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=
google.golang.org/genproto v0.0.0-20190801165951-fa694d86fc64/go.mod h1:DMBHOl98Agz4BDEuKkezgsaosCRResVns1a3J2ZsMNc=
google.golang.org/genproto v0.0.0-20190819201941-24fa4b261c55/go.mod h1:DMBHOl98Agz4BDEuKkezgsaosCRResVns1a3J2ZsMNc=
google.golang.org/genproto v0.0.0-20190911173649-1774047e7e51/go.mod h1:IbNlFCBrqXvoKpeg0TB2l7cyZUmoaFKYIwrEpbDKLA8=
google.golang.org/genproto v0.0.0-20191108220845-16a3f7862a1a/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=
google.golang.org/genproto v0.0.0-20191115194625-c23dd37a84c9/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=
google.golang.org/genproto v0.0.0-20191216164720-4f79533eabd1/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=
google.golang.org/genproto v0.0.0-20191230161307-f3c370f40bfb/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=
google.golang.org/genproto v0.0.0-20200115191322-ca5a22157cba/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=
google.golang.org/genproto v0.0.0-20200122232147-0452cf42e150/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=
google.golang.org/genproto v0.0.0-20200204135345-fa8e72b47b90/go.mod h1:GmwEX6Z4W5gMy59cAlVYjN9JhxgbQH6Gn+gFDQe2lzA=
google.golang.org/genproto v0.0.0-20200212174721-66ed5ce911ce/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=
google.golang.org/genproto v0.0.0-20200224152610-e50cd9704f63/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=
google.golang.org/genproto v0.0.0-20200228133532-8c2c7df3a383/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=
google.golang.org/genproto v0.0.0-20200305110556-506484158171/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=
google.golang.org/genproto v0.0.0-20200312145019-da6875a35672/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=
google.golang.org/genproto v0.0.0-20200331122359-1ee6d9798940/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=
google.golang.org/genproto v0.0.0-20200430143042-b979b6f78d84/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=
google.golang.org/genproto v0.0.0-20200511104702-f5ebc3bea380/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=
google.golang.org/genproto v0.0.0-20200513103714-09dca8ec2884/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=
google.golang.org/genproto v0.0.0-20200515170657-fc4c6c6a6587/go.mod h1:YsZOwe1myG/8QRHRsmBRE1LrgQY60beZKjly0O1fX9U=
google.golang.org/genproto v0.0.0-20200526211855-cb27e3aa2013/go.mod h1:NbSheEEYHJ7i3ixzK3sjbqSGDJWnxyFXZblF3eUsNvo=
google.golang.org/genproto v0.0.0-20200618031413-b414f8b61790/go.mod h1:jDfRM7FcilCzHH/e9qn6dsT145K34l5v+OpcnNgKAAA=
google.golang.org/genproto v0.0.0-20200729003335-053ba62fc06f/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=
google.golang.org/genproto v0.0.0-20200804131852-c06518451d9c/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=
google.golang.org/genproto v0.0.0-20200825200019-8632dd797987/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=
google.golang.org/genproto v0.0.0-20200904004341-0bd0a958aa1d/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=
google.golang.org/genproto v0.0.0-20201109203340-2640f1f9cdfb/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=
google.golang.org/genproto v0.0.0-20201201144952-b05cb90ed32e/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=
google.golang.org/genproto v0.0.0-20201210142538-e3217bee35cc/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=
google.golang.org/genproto v0.0.0-20201214200347-8c77b98c765d/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=
google.golang.org/genproto v0.0.0-20210108203827-ffc7fda8c3d7/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=
google.golang.org/genproto v0.0.0-20210222152913-aa3ee6e6a81c/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=
google.golang.org/genproto v0.0.0-20210226172003-ab064af71705/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=
google.golang.org/genproto v0.0.0-20210303154014-9728d6b83eeb/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=
google.golang.org/genproto v0.0.0-20210310155132-4ce2db91004e/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=
google.golang.org/genproto v0.0.0-20210319143718-93e7006c17a6/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=
google.golang.org/genproto v0.0.0-20210329143202-679c6ae281ee/go.mod h1:9lPAdzaEmUacj36I+k7YKbEc5CXzPIeORRgDAUOu28A=
google.golang.org/genproto v0.0.0-20210402141018-6c239bbf2bb1/go.mod h1:9lPAdzaEmUacj36I+k7YKbEc5CXzPIeORRgDAUOu28A=
google.golang.org/genproto v0.0.0-20210513213006-bf773b8c8384/go.mod h1:P3QM42oQyzQSnHPnZ/vqoCdDmzH28fzWByN9asMeM8A=
google.golang.org/genproto v0.0.0-20210602131652-f16073e35f0c/go.mod h1:UODoCrxHCcBojKKwX1terBiRUaqAsFqJiF615XL43r0=
google.golang.org/genproto v0.0.0-20210604141403-392c879c8b08/go.mod h1:UODoCrxHCcBojKKwX1terBiRUaqAsFqJiF615XL43r0=
google.golang.org/genproto v0.0.0-20210608205507-b6d2f5bf0d7d/go.mod h1:UODoCrxHCcBojKKwX1terBiRUaqAsFqJiF615XL43r0=
google.golang.org/genproto v0.0.0-20210624195500-8bfb893ecb84/go.mod h1:SzzZ/N+nwJDaO1kznhnlzqS8ocJICar6hYhVyhi++24=
google.golang.org/genproto v0.0.0-20210713002101-d411969a0d9a/go.mod h1:AxrInvYm1dci+enl5hChSFPOmmUF1+uAa/UsgNRWd7k=
google.golang.org/genproto v0.0.0-20210716133855-ce7ef5c701ea/go.mod h1:AxrInvYm1dci+enl5hChSFPOmmUF1+uAa/UsgNRWd7k=
google.golang.org/genproto v0.0.0-20210728212813-7823e685a01f/go.mod h1:ob2IJxKrgPT52GcgX759i1sleT07tiKowYBGbczaW48=
google.golang.org/genproto v0.0.0-20210805201207-89edb61ffb67/go.mod h1:ob2IJxKrgPT52GcgX759i1sleT07tiKowYBGbczaW48=
google.golang.org/genproto v0.0.0-20210813162853-db860fec028c/go.mod h1:cFeNkxwySK631ADgubI+/XFU/xp8FD5KIVV4rj8UC5w=
google.golang.org/genproto v0.0.0-20210821163610-241b8fcbd6c8/go.mod h1:eFjDcFEctNawg4eG61bRv87N7iHBWyVhJu7u1kqDUXY=
google.golang.org/genproto v0.0.0-20210828152312-66f60bf46e71/go.mod h1:eFjDcFEctNawg4eG61bRv87N7iHBWyVhJu7u1kqDUXY=
google.golang.org/genproto v0.0.0-20210831024726-fe130286e0e2/go.mod h1:eFjDcFEctNawg4eG61bRv87N7iHBWyVhJu7u1kqDUXY=
google.golang.org/genproto v0.0.0-20210903162649-d08c68adba83/go.mod h1:eFjDcFEctNawg4eG61bRv87N7iHBWyVhJu7u1kqDUXY=
google.golang.org/genproto v0.0.0-20210909211513-a8c4777a87af/go.mod h1:eFjDcFEctNawg4eG61bRv87N7iHBWyVhJu7u1kqDUXY=
google.golang.org/genproto v0.0.0-20210924002016-3dee208752a0/go.mod h1:5CzLGKJ67TSI2B9POpiiyGha0AjJvZIUgRMt1dSmuhc=
google.golang.org/genproto v0.0.0-20211118181313-81c1377c94b1/go.mod h1:5CzLGKJ67TSI2B9POpiiyGha0AjJvZIUgRMt1dSmuhc=
google.golang.org/genproto v0.0.0-20211206160659-862468c7d6e0/go.mod h1:5CzLGKJ67TSI2B9POpiiyGha0AjJvZIUgRMt1dSmuhc=
google.golang.org/genproto v0.0.0-20211208223120-3a66f561d7aa/go.mod h1:5CzLGKJ67TSI2B9POpiiyGha0AjJvZIUgRMt1dSmuhc=
google.golang.org/genproto v0.0.0-20211221195035-429b39de9b1c/go.mod h1:5CzLGKJ67TSI2B9POpiiyGha0AjJvZIUgRMt1dSmuhc=
google.golang.org/genproto v0.0.0-20220126215142-9970aeb2e350/go.mod h1:5CzLGKJ67TSI2B9POpiiyGha0AjJvZIUgRMt1dSmuhc=
google.golang.org/genproto v0.0.0-20220207164111-0872dc986b00/go.mod h1:5CzLGKJ67TSI2B9POpiiyGha0AjJvZIUgRMt1dSmuhc=
google.golang.org/genproto v0.0.0-20220218161850-94dd64e39d7c/go.mod h1:kGP+zUP2Ddo0ayMi4YuN7C3WZyJvGLZRh8Z5wnAqvEI=
google.golang.org/genproto v0.0.0-20220222213610-43724f9ea8cf/go.mod h1:kGP+zUP2Ddo0ayMi4YuN7C3WZyJvGLZRh8Z5wnAqvEI=
google.golang.org/genproto v0.0.0-20220304144024-325a89244dc8/go.mod h1:kGP+zUP2Ddo0ayMi4YuN7C3WZyJvGLZRh8Z5wnAqvEI=
google.golang.org/genproto v0.0.0-20220310185008-1973136f34c6/go.mod h1:kGP+zUP2Ddo0ayMi4YuN7C3WZyJvGLZRh8Z5wnAqvEI=
google.golang.org/genproto v0.0.0-20220324131243-acbaeb5b85eb/go.mod h1:hAL49I2IFola2sVEjAn7MEwsja0xp51I0tlGAf9hz4E=
google.golang.org/genproto v0.0.0-20220329172620-7be39ac1afc7/go.mod h1:8w6bsBMX6yCPbAVTeqQHvzxW0EIFigd5lZyahWgyfDo=
google.golang.org/genproto v0.0.0-20220407144326-9054f6ed7bac/go.mod h1:8w6bsBMX6yCPbAVTeqQHvzxW0EIFigd5lZyahWgyfDo=
google.golang.org/genproto v0.0.0-20220413183235-5e96e2839df9/go.mod h1:8w6bsBMX6yCPbAVTeqQHvzxW0EIFigd5lZyahWgyfDo=
google.golang.org/genproto v0.0.0-20220414192740-2d67ff6cf2b4/go.mod h1:8w6bsBMX6yCPbAVTeqQHvzxW0EIFigd5lZyahWgyfDo=
google.golang.org/genproto v0.0.0-20220421151946-72621c1f0bd3/go.mod h1:8w6bsBMX6yCPbAVTeqQHvzxW0EIFigd5lZyahWgyfDo=
google.golang.org/genproto v0.0.0-20220429170224-98d788798c3e/go.mod h1:8w6bsBMX6yCPbAVTeqQHvzxW0EIFigd5lZyahWgyfDo=
google.golang.org/genproto v0.0.0-20220502173005-c8bf987b8c21/go.mod h1:RAyBrSAP7Fh3Nc84ghnVLDPuV51xc9agzmm4Ph6i0Q4=
google.golang.org/genproto v0.0.0-20220505152158-f39f71e6c8f3/go.mod h1:RAyBrSAP7Fh3Nc84ghnVLDPuV51xc9agzmm4Ph6i0Q4=
google.golang.org/genproto v0.0.0-20220518221133-4f43b3371335/go.mod h1:RAyBrSAP7Fh3Nc84ghnVLDPuV51xc9agzmm4Ph6i0Q4=
google.golang.org/genproto v0.0.0-20220523171625-347a074981d8/go.mod h1:RAyBrSAP7Fh3Nc84ghnVLDPuV51xc9agzmm4Ph6i0Q4=
google.golang.org/genproto v0.0.0-20220608133413-ed9918b62aac/go.mod h1:KEWEmljWE5zPzLBa/oHl6DaEt9LmfH6WtH1OHIvleBA=
google.golang.org/genproto v0.0.0-20220616135557-88e70c0c3a90/go.mod h1:KEWEmljWE5zPzLBa/oHl6DaEt9LmfH6WtH1OHIvleBA=
google.golang.org/genproto v0.0.0-20220617124728-180714bec0ad/go.mod h1:KEWEmljWE5zPzLBa/oHl6DaEt9LmfH6WtH1OHIvleBA=
google.golang.org/genproto v0.0.0-20220624142145-8cd45d7dbd1f/go.mod h1:KEWEmljWE5zPzLBa/oHl6DaEt9LmfH6WtH1OHIvleBA=
google.golang.org/genproto v0.0.0-20220628213854-d9e0b6570c03/go.mod h1:KEWEmljWE5zPzLBa/oHl6DaEt9LmfH6WtH1OHIvleBA=
google.golang.org/genproto v0.0.0-20220722212130-b98a9ff5e252/go.mod h1:GkXuJDJ6aQ7lnJcRF+SJVgFdQhypqgl3LB1C9vabdRE=
google.golang.org/genproto v0.0.0-20220801145646-83ce21fca29f/go.mod h1:iHe1svFLAZg9VWz891+QbRMwUv9O/1Ww+/mngYeThbc=
google.golang.org/genproto v0.0.0-20220815135757-37a418bb8959/go.mod h1:dbqgFATTzChvnt+ujMdZwITVAJHFtfyN1qUhDqEiIlk=
google.golang.org/genproto v0.0.0-20220817144833-d7fd3f11b9b1/go.mod h1:dbqgFATTzChvnt+ujMdZwITVAJHFtfyN1qUhDqEiIlk=
google.golang.org/genproto v0.0.0-20220822174746-9e6da59bd2fc/go.mod h1:dbqgFATTzChvnt+ujMdZwITVAJHFtfyN1qUhDqEiIlk=
google.golang.org/genproto v0.0.0-20220829144015-23454907ede3/go.mod h1:dbqgFATTzChvnt+ujMdZwITVAJHFtfyN1qUhDqEiIlk=
google.golang.org/genproto v0.0.0-20220829175752-36a9c930ecbf/go.mod h1:dbqgFATTzChvnt+ujMdZwITVAJHFtfyN1qUhDqEiIlk=
google.golang.org/genproto v0.0.0-20220913154956-18f8339a66a5/go.mod h1:0Nb8Qy+Sk5eDzHnzlStwW3itdNaWoZA5XeSG+R3JHSo=
google.golang.org/genproto v0.0.0-20220914142337-ca0e39ece12f/go.mod h1:0Nb8Qy+Sk5eDzHnzlStwW3itdNaWoZA5XeSG+R3JHSo=
google.golang.org/genproto v0.0.0-20220915135415-7fd63a7952de/go.mod h1:0Nb8Qy+Sk5eDzHnzlStwW3itdNaWoZA5XeSG+R3JHSo=
google.golang.org/genproto v0.0.0-20220916172020-2692e8806bfa/go.mod h1:0Nb8Qy+Sk5eDzHnzlStwW3itdNaWoZA5XeSG+R3JHSo=
google.golang.org/genproto v0.0.0-20220919141832-68c03719ef51/go.mod h1:0Nb8Qy+Sk5eDzHnzlStwW3itdNaWoZA5XeSG+R3JHSo=
google.golang.org/genproto v0.0.0-20220920201722-2b89144ce006/go.mod h1:ht8XFiar2npT/g4vkk7O0WYS1sHOHbdujxbEp7CJWbw=
google.golang.org/genproto v0.0.0-20220926165614-551eb538f295/go.mod h1:woMGP53BroOrRY3xTxlbr8Y3eB/nzAvvFM83q7kG2OI=
google.golang.org/genproto v0.0.0-20220926220553-6981cbe3cfce/go.mod h1:woMGP53BroOrRY3xTxlbr8Y3eB/nzAvvFM83q7kG2OI=
google.golang.org/genproto v0.0.0-20221010155953-15ba04fc1c0e/go.mod h1:3526vdqwhZAwq4wsRUaVG555sVgsNmIjRtO7t/JH29U=
google.golang.org/genproto v0.0.0-20221014173430-6e2ab493f96b/go.mod h1:1vXfmgAz9N9Jx0QA82PqRVauvCz1SGSz739p0f183jM=
google.golang.org/genproto v0.0.0-20221014213838-99cd37c6964a/go.mod h1:1vXfmgAz9N9Jx0QA82PqRVauvCz1SGSz739p0f183jM=
google.golang.org/genproto v0.0.0-20221024153911-1573dae28c9c/go.mod h1:9qHF0xnpdSfF6knlcsnpzUu5y+rpwgbvsyGAZPBMg4s=
google.golang.org/genproto v0.0.0-20221024183307-1bc688fe9f3e/go.mod h1:9qHF0xnpdSfF6knlcsnpzUu5y+rpwgbvsyGAZPBMg4s=
google.golang.org/genproto v0.0.0-20221027153422-115e99e71e1c/go.mod h1:CGI5F/G+E5bKwmfYo09AXuVN4dD894kIKUFmVbP2/Fo=
google.golang.org/genproto v0.0.0-20221109142239-94d6d90a7d66/go.mod h1:rZS5c/ZVYMaOGBfO68GWtjOw/eLaZM1X6iVtgjZ+EWg=
google.golang.org/genproto v0.0.0-20221114212237-e4508ebdbee1/go.mod h1:rZS5c/ZVYMaOGBfO68GWtjOw/eLaZM1X6iVtgjZ+EWg=
google.golang.org/genproto v0.0.0-20221117204609-8f9c96812029/go.mod h1:rZS5c/ZVYMaOGBfO68GWtjOw/eLaZM1X6iVtgjZ+EWg=
google.golang.org/genproto v0.0.0-20221118155620-16455021b5e6/go.mod h1:rZS5c/ZVYMaOGBfO68GWtjOw/eLaZM1X6iVtgjZ+EWg=
google.golang.org/genproto v0.0.0-20221201164419-0e50fba7f41c/go.mod h1:rZS5c/ZVYMaOGBfO68GWtjOw/eLaZM1X6iVtgjZ+EWg=
google.golang.org/genproto v0.0.0-20221201204527-e3fa12d562f3/go.mod h1:rZS5c/ZVYMaOGBfO68GWtjOw/eLaZM1X6iVtgjZ+EWg=
google.golang.org/genproto v0.0.0-20221202195650-67e5cbc046fd/go.mod h1:cTsE614GARnxrLsqKREzmNYJACSWWpAWdNMwnD7c2BE=
google.golang.org/genproto v0.0.0-20221227171554-f9683d7f8bef/go.mod h1:RGgjbofJ8xD9Sq1VVhDM1Vok1vRONV+rg+CjzG4SZKM=
google.golang.org/genproto v0.0.0-20230110181048-76db0878b65f/go.mod h1:RGgjbofJ8xD9Sq1VVhDM1Vok1vRONV+rg+CjzG4SZKM=
google.golang.org/genproto v0.0.0-20230112194545-e10362b5ecf9/go.mod h1:RGgjbofJ8xD9Sq1VVhDM1Vok1vRONV+rg+CjzG4SZKM=
google.golang.org/genproto v0.0.0-20230113154510-dbe35b8444a5/go.mod h1:RGgjbofJ8xD9Sq1VVhDM1Vok1vRONV+rg+CjzG4SZKM=
google.golang.org/genproto v0.0.0-20230123190316-2c411cf9d197/go.mod h1:RGgjbofJ8xD9Sq1VVhDM1Vok1vRONV+rg+CjzG4SZKM=
google.golang.org/genproto v0.0.0-20230124163310-31e0e69b6fc2/go.mod h1:RGgjbofJ8xD9Sq1VVhDM1Vok1vRONV+rg+CjzG4SZKM=
google.golang.org/genproto v0.0.0-20230125152338-dcaf20b6aeaa/go.mod h1:RGgjbofJ8xD9Sq1VVhDM1Vok1vRONV+rg+CjzG4SZKM=
google.golang.org/genproto v0.0.0-20230127162408-596548ed4efa/go.mod h1:RGgjbofJ8xD9Sq1VVhDM1Vok1vRONV+rg+CjzG4SZKM=
google.golang.org/genproto v0.0.0-20230209215440-0dfe4f8abfcc/go.mod h1:RGgjbofJ8xD9Sq1VVhDM1Vok1vRONV+rg+CjzG4SZKM=
google.golang.org/genproto v0.0.0-20230216225411-c8e22ba71e44/go.mod h1:8B0gmkoRebU8ukX6HP+4wrVQUY1+6PkQ44BSyIlflHA=
google.golang.org/genproto v0.0.0-20230222225845-10f96fb3dbec/go.mod h1:3Dl5ZL0q0isWJt+FVcfpQyirqemEuLAK/iFvg1UP1Hw=
google.golang.org/genproto v0.0.0-20230223222841-637eb2293923/go.mod h1:3Dl5ZL0q0isWJt+FVcfpQyirqemEuLAK/iFvg1UP1Hw=
google.golang.org/genproto v0.0.0-20230303212802-e74f57abe488/go.mod h1:TvhZT5f700eVlTNwND1xoEZQeWTB2RY/65kplwl/bFA=
google.golang.org/genproto v0.0.0-20230306155012-7f2fa6fef1f4/go.mod h1:NWraEVixdDnqcqQ30jipen1STv2r/n24Wb7twVTGR4s=
google.golang.org/genproto v0.0.0-20230320184635-7606e756e683/go.mod h1:NWraEVixdDnqcqQ30jipen1STv2r/n24Wb7twVTGR4s=
google.golang.org/genproto v0.0.0-20230323212658-478b75c54725/go.mod h1:UUQDJDOlWu4KYeJZffbWgBkS1YFobzKbLVfK69pe0Ak=
google.golang.org/genproto v0.0.0-20230330154414-c0448cd141ea/go.mod h1:UUQDJDOlWu4KYeJZffbWgBkS1YFobzKbLVfK69pe0Ak=
google.golang.org/genproto v0.0.0-20230331144136-dcfb400f0633/go.mod h1:UUQDJDOlWu4KYeJZffbWgBkS1YFobzKbLVfK69pe0Ak=
google.golang.org/genproto v0.0.0-20230403163135-c38d8f061ccd/go.mod h1:UUQDJDOlWu4KYeJZffbWgBkS1YFobzKbLVfK69pe0Ak=
google.golang.org/genproto v0.0.0-20230410155749-daa745c078e1/go.mod h1:nKE/iIaLqn2bQwXBg8f1g2Ylh6r5MN5CmZvuzZCgsCU=
google.golang.org/genproto v0.0.0-20230525234025-438c736192d0/go.mod h1:9ExIQyXL5hZrHzQceCwuSYwZZ5QZBazOcprJ5rgs3lY=
google.golang.org/genproto v0.0.0-20230526161137-0005af68ea54/go.mod h1:zqTuNwFlFRsw5zIts5VnzLQxSRqh+CGOTVMlYbY0Eyk=
google.golang.org/genproto v0.0.0-20230526203410-71b5a4ffd15e/go.mod h1:zqTuNwFlFRsw5zIts5VnzLQxSRqh+CGOTVMlYbY0Eyk=
google.golang.org/genproto v0.0.0-20230530153820-e85fd2cbaebc/go.mod h1:xZnkP7mREFX5MORlOPEzLMr+90PPZQ2QWzrVTWfAq64=
google.golang.org/genproto v0.0.0-20230629202037-9506855d4529/go.mod h1:xZnkP7mREFX5MORlOPEzLMr+90PPZQ2QWzrVTWfAq64=
google.golang.org/genproto v0.0.0-20230706204954-ccb25ca9f130/go.mod h1:O9kGHb51iE/nOGvQaDUuadVYqovW56s5emA88lQnj6Y=
google.golang.org/genproto v0.0.0-20230711160842-782d3b101e98/go.mod h1:S7mY02OqCJTD0E1OiQy1F72PWFB4bZJ87cAtLPYgDR0=
google.golang.org/genproto v0.0.0-20230726155614-23370e0ffb3e/go.mod h1:0ggbjUrZYpy1q+ANUS30SEoGZ53cdfwtbuG7Ptgy108=
google.golang.org/genproto v0.0.0-20230803162519-f966b187b2e5/go.mod h1:oH/ZOT02u4kWEp7oYBGYFFkCdKS/uYR9Z7+0/xuuFp8=
google.golang.org/genproto v0.0.0-20230821184602-ccc8af3d0e93/go.mod h1:yZTlhN0tQnXo3h00fuXNCxJdLdIdnVFVBaRJ5LWBbw4=
google.golang.org/genproto v0.0.0-20230822172742-b8732ec3820d/go.mod h1:yZTlhN0tQnXo3h00fuXNCxJdLdIdnVFVBaRJ5LWBbw4=
google.golang.org/genproto v0.0.0-20230913181813-007df8e322eb/go.mod h1:yZTlhN0tQnXo3h00fuXNCxJdLdIdnVFVBaRJ5LWBbw4=
google.golang.org/genproto v0.0.0-20230920204549-e6e6cdab5c13/go.mod h1:CCviP9RmpZ1mxVr8MUjCnSiY09IbAXZxhLE6EhHIdPU=
google.golang.org/genproto v0.0.0-20231002182017-d307bd883b97/go.mod h1:t1VqOqqvce95G3hIDCT5FeO3YUc6Q4Oe24L/+rNMxRk=
google.golang.org/genproto v0.0.0-20231012201019-e917dd12ba7a/go.mod h1:EMfReVxb80Dq1hhioy0sOsY9jCE46YDgHlJ7fWVUWRE=
google.golang.org/genproto v0.0.0-20231016165738-49dd2c1f3d0b/go.mod h1:CgAqfJo+Xmu0GwA0411Ht3OU3OntXwsGmrmjI8ioGXI=
google.golang.org/genproto v0.0.0-20231030173426-d783a09b4405/go.mod h1:3WDQMjmJk36UQhjQ89emUzb1mdaHcPeeAh4SCBKznB4=
google.golang.org/genproto v0.0.0-20231106174013-bbf56f31fb17 h1:wpZ8pe2x1Q3f2KyT5f8oP/fa9rHAKgFPr/HZdNuS+PQ=
google.golang.org/genproto v0.0.0-20231106174013-bbf56f31fb17/go.mod h1:J7XzRzVy1+IPwWHZUzoD0IccYZIrXILAQpc+Qy9CMhY=
google.golang.org/genproto/googleapis/api v0.0.0-20230525234020-1aefcd67740a/go.mod h1:ts19tUU+Z0ZShN1y3aPyq2+O3d5FUNNgT6FtOzmrNn8=
google.golang.org/genproto/googleapis/api v0.0.0-20230525234035-dd9d682886f9/go.mod h1:vHYtlOoi6TsQ3Uk2yxR7NI5z8uoV+3pZtR4jmHIkRig=
google.golang.org/genproto/googleapis/api v0.0.0-20230526203410-71b5a4ffd15e/go.mod h1:vHYtlOoi6TsQ3Uk2yxR7NI5z8uoV+3pZtR4jmHIkRig=
google.golang.org/genproto/googleapis/api v0.0.0-20230530153820-e85fd2cbaebc/go.mod h1:vHYtlOoi6TsQ3Uk2yxR7NI5z8uoV+3pZtR4jmHIkRig=
google.golang.org/genproto/googleapis/api v0.0.0-20230629202037-9506855d4529/go.mod h1:vHYtlOoi6TsQ3Uk2yxR7NI5z8uoV+3pZtR4jmHIkRig=
google.golang.org/genproto/googleapis/api v0.0.0-20230706204954-ccb25ca9f130/go.mod h1:mPBs5jNgx2GuQGvFwUvVKqtn6HsUw9nP64BedgvqEsQ=
google.golang.org/genproto/googleapis/api v0.0.0-20230711160842-782d3b101e98/go.mod h1:rsr7RhLuwsDKL7RmgDDCUc6yaGr1iqceVb5Wv6f6YvQ=
google.golang.org/genproto/googleapis/api v0.0.0-20230726155614-23370e0ffb3e/go.mod h1:rsr7RhLuwsDKL7RmgDDCUc6yaGr1iqceVb5Wv6f6YvQ=
google.golang.org/genproto/googleapis/api v0.0.0-20230803162519-f966b187b2e5/go.mod h1:5DZzOUPCLYL3mNkQ0ms0F3EuUNZ7py1Bqeq6sxzI7/Q=
google.golang.org/genproto/googleapis/api v0.0.0-20230822172742-b8732ec3820d/go.mod h1:KjSP20unUpOx5kyQUFa7k4OJg0qeJ7DEZflGDu2p6Bk=
google.golang.org/genproto/googleapis/api v0.0.0-20230913181813-007df8e322eb/go.mod h1:KjSP20unUpOx5kyQUFa7k4OJg0qeJ7DEZflGDu2p6Bk=
google.golang.org/genproto/googleapis/api v0.0.0-20230920204549-e6e6cdab5c13/go.mod h1:RdyHbowztCGQySiCvQPgWQWgWhGnouTdCflKoDBt32U=
google.golang.org/genproto/googleapis/api v0.0.0-20231002182017-d307bd883b97/go.mod h1:iargEX0SFPm3xcfMI0d1domjg0ZF4Aa0p2awqyxhvF0=
google.golang.org/genproto/googleapis/api v0.0.0-20231012201019-e917dd12ba7a/go.mod h1:SUBoKXbI1Efip18FClrQVGjWcyd0QZd8KkvdP34t7ww=
google.golang.org/genproto/googleapis/api v0.0.0-20231016165738-49dd2c1f3d0b/go.mod h1:IBQ646DjkDkvUIsVq/cc03FUFQ9wbZu7yE396YcL870=
google.golang.org/genproto/googleapis/api v0.0.0-20231030173426-d783a09b4405/go.mod h1:oT32Z4o8Zv2xPQTg0pbVaPr0MPOH6f14RgXt7zfIpwg=
google.golang.org/genproto/googleapis/api v0.0.0-20231106174013-bbf56f31fb17/go.mod h1:0xJLfVdJqpAPl8tDg1ujOCGzx6LFLttXT5NhllGOXY4=
google.golang.org/genproto/googleapis/bytestream v0.0.0-20230530153820-e85fd2cbaebc/go.mod h1:ylj+BE99M198VPbBh6A8d9n3w8fChvyLK3wwBOjXBFA=
google.golang.org/genproto/googleapis/bytestream v0.0.0-20230807174057-1744710a1577/go.mod h1:NjCQG/D8JandXxM57PZbAJL1DCNL6EypA0vPPwfsc7c=
google.golang.org/genproto/googleapis/bytestream v0.0.0-20231030173426-d783a09b4405/go.mod h1:GRUCuLdzVqZte8+Dl/D4N25yLzcGqqWaYkeVOwulFqw=
google.golang.org/genproto/googleapis/rpc v0.0.0-20230525234015-3fc162c6f38a/go.mod h1:xURIpW9ES5+/GZhnV6beoEtxQrnkRGIfP5VQG2tCBLc=
google.golang.org/genproto/googleapis/rpc v0.0.0-20230525234030-28d5490b6b19/go.mod h1:66JfowdXAEgad5O9NnYcsNPLCPZJD++2L9X0PCMODrA=
google.golang.org/genproto/googleapis/rpc v0.0.0-20230526203410-71b5a4ffd15e/go.mod h1:66JfowdXAEgad5O9NnYcsNPLCPZJD++2L9X0PCMODrA=
google.golang.org/genproto/googleapis/rpc v0.0.0-20230530153820-e85fd2cbaebc/go.mod h1:66JfowdXAEgad5O9NnYcsNPLCPZJD++2L9X0PCMODrA=
google.golang.org/genproto/googleapis/rpc v0.0.0-20230629202037-9506855d4529/go.mod h1:66JfowdXAEgad5O9NnYcsNPLCPZJD++2L9X0PCMODrA=
google.golang.org/genproto/googleapis/rpc v0.0.0-20230706204954-ccb25ca9f130/go.mod h1:8mL13HKkDa+IuJ8yruA3ci0q+0vsUz4m//+ottjwS5o=
google.golang.org/genproto/googleapis/rpc v0.0.0-20230711160842-782d3b101e98/go.mod h1:TUfxEVdsvPg18p6AslUXFoLdpED4oBnGwyqk3dV1XzM=
google.golang.org/genproto/googleapis/rpc v0.0.0-20230731190214-cbb8c96f2d6d/go.mod h1:TUfxEVdsvPg18p6AslUXFoLdpED4oBnGwyqk3dV1XzM=
google.golang.org/genproto/googleapis/rpc v0.0.0-20230803162519-f966b187b2e5/go.mod h1:zBEcrKX2ZOcEkHWxBPAIvYUWOKKMIhYcmNiUIu2ji3I=
google.golang.org/genproto/googleapis/rpc v0.0.0-20230822172742-b8732ec3820d/go.mod h1:+Bk1OCOj40wS2hwAMA+aCW9ypzm63QTBBHp6lQ3p+9M=
google.golang.org/genproto/googleapis/rpc v0.0.0-20230920183334-c177e329c48b/go.mod h1:+Bk1OCOj40wS2hwAMA+aCW9ypzm63QTBBHp6lQ3p+9M=
google.golang.org/genproto/googleapis/rpc v0.0.0-20230920204549-e6e6cdab5c13/go.mod h1:KSqppvjFjtoCI+KGd4PELB0qLNxdJHRGqRI09mB6pQA=
google.golang.org/genproto/googleapis/rpc v0.0.0-20231002182017-d307bd883b97/go.mod h1:v7nGkzlmW8P3n/bKmWBn2WpBjpOEx8Q6gMueudAmKfY=
google.golang.org/genproto/googleapis/rpc v0.0.0-20231012201019-e917dd12ba7a/go.mod h1:4cYg8o5yUbm77w8ZX00LhMVNl/YVBFJRYWDc0uYWMs0=
google.golang.org/genproto/googleapis/rpc v0.0.0-20231016165738-49dd2c1f3d0b/go.mod h1:swOH3j0KzcDDgGUWr+SNpyTen5YrXjS3eyPzFYKc6lc=
google.golang.org/genproto/googleapis/rpc v0.0.0-20231030173426-d783a09b4405/go.mod h1:67X1fPuzjcrkymZzZV1vvkFeTn2Rvc6lYF9MYFGCcwE=
google.golang.org/genproto/googleapis/rpc v0.0.0-20231106174013-bbf56f31fb17 h1:Jyp0Hsi0bmHXG6k9eATXoYtjd6e2UzZ1SCn/wIupY14=
google.golang.org/genproto/googleapis/rpc v0.0.0-20231106174013-bbf56f31fb17/go.mod h1:oQ5rr10WTTMvP4A36n8JpR1OrO1BEiV4f78CneXZxkA=
google.golang.org/grpc v1.19.0/go.mod h1:mqu4LbDTu4XGKhr4mRzUsmM4RtVoemTSY81AxZiDr8c=
google.golang.org/grpc v1.20.1/go.mod h1:10oTOabMzJvdu6/UiuZezV6QK5dSlG84ov/aaiqXj38=
google.golang.org/grpc v1.21.1/go.mod h1:oYelfM1adQP15Ek0mdvEgi9Df8B9CZIaU1084ijfRaM=
google.golang.org/grpc v1.23.0/go.mod h1:Y5yQAOtifL1yxbo5wqy6BxZv8vAUGQwXBOALyacEbxg=
google.golang.org/grpc v1.25.1/go.mod h1:c3i+UQWmh7LiEpx4sFZnkU36qjEYZ0imhYfXVyQciAY=
google.golang.org/grpc v1.26.0/go.mod h1:qbnxyOmOxrQa7FizSgH+ReBfzJrCY1pSN7KXBS8abTk=
google.golang.org/grpc v1.27.0/go.mod h1:qbnxyOmOxrQa7FizSgH+ReBfzJrCY1pSN7KXBS8abTk=
google.golang.org/grpc v1.27.1/go.mod h1:qbnxyOmOxrQa7FizSgH+ReBfzJrCY1pSN7KXBS8abTk=
google.golang.org/grpc v1.28.0/go.mod h1:rpkK4SK4GF4Ach/+MFLZUBavHOvF2JJB5uozKKal+60=
google.golang.org/grpc v1.29.1/go.mod h1:itym6AZVZYACWQqET3MqgPpjcuV5QH3BxFS3IjizoKk=
google.golang.org/grpc v1.30.0/go.mod h1:N36X2cJ7JwdamYAgDz+s+rVMFjt3numwzf/HckM8pak=
google.golang.org/grpc v1.31.0/go.mod h1:N36X2cJ7JwdamYAgDz+s+rVMFjt3numwzf/HckM8pak=
google.golang.org/grpc v1.31.1/go.mod h1:N36X2cJ7JwdamYAgDz+s+rVMFjt3numwzf/HckM8pak=
google.golang.org/grpc v1.33.1/go.mod h1:fr5YgcSWrqhRRxogOsw7RzIpsmvOZ6IcH4kBYTpR3n0=
google.golang.org/grpc v1.33.2/go.mod h1:JMHMWHQWaTccqQQlmk3MJZS+GWXOdAesneDmEnv2fbc=
google.golang.org/grpc v1.34.0/go.mod h1:WotjhfgOW/POjDeRt8vscBtXq+2VjORFy659qA51WJ8=
google.golang.org/grpc v1.35.0/go.mod h1:qjiiYl8FncCW8feJPdyg3v6XW24KsRHe+dy9BAGRRjU=
google.golang.org/grpc v1.36.0/go.mod h1:qjiiYl8FncCW8feJPdyg3v6XW24KsRHe+dy9BAGRRjU=
google.golang.org/grpc v1.36.1/go.mod h1:qjiiYl8FncCW8feJPdyg3v6XW24KsRHe+dy9BAGRRjU=
google.golang.org/grpc v1.37.0/go.mod h1:NREThFqKR1f3iQ6oBuvc5LadQuXVGo9rkm5ZGrQdJfM=
google.golang.org/grpc v1.37.1/go.mod h1:NREThFqKR1f3iQ6oBuvc5LadQuXVGo9rkm5ZGrQdJfM=
google.golang.org/grpc v1.38.0/go.mod h1:NREThFqKR1f3iQ6oBuvc5LadQuXVGo9rkm5ZGrQdJfM=
google.golang.org/grpc v1.39.0/go.mod h1:PImNr+rS9TWYb2O4/emRugxiyHZ5JyHW5F+RPnDzfrE=
google.golang.org/grpc v1.39.1/go.mod h1:PImNr+rS9TWYb2O4/emRugxiyHZ5JyHW5F+RPnDzfrE=
google.golang.org/grpc v1.40.0/go.mod h1:ogyxbiOoUXAkP+4+xa6PZSE9DZgIHtSpzjDTB9KAK34=
google.golang.org/grpc v1.40.1/go.mod h1:ogyxbiOoUXAkP+4+xa6PZSE9DZgIHtSpzjDTB9KAK34=
google.golang.org/grpc v1.42.0/go.mod h1:k+4IHHFw41K8+bbowsex27ge2rCb65oeWqe4jJ590SU=
google.golang.org/grpc v1.44.0/go.mod h1:k+4IHHFw41K8+bbowsex27ge2rCb65oeWqe4jJ590SU=
google.golang.org/grpc v1.45.0/go.mod h1:lN7owxKUQEqMfSyQikvvk5tf/6zMPsrK+ONuO11+0rQ=
google.golang.org/grpc v1.46.0/go.mod h1:vN9eftEi1UMyUsIF80+uQXhHjbXYbm0uXoFCACuMGWk=
google.golang.org/grpc v1.46.2/go.mod h1:vN9eftEi1UMyUsIF80+uQXhHjbXYbm0uXoFCACuMGWk=
google.golang.org/grpc v1.47.0/go.mod h1:vN9eftEi1UMyUsIF80+uQXhHjbXYbm0uXoFCACuMGWk=
google.golang.org/grpc v1.48.0/go.mod h1:vN9eftEi1UMyUsIF80+uQXhHjbXYbm0uXoFCACuMGWk=
google.golang.org/grpc v1.49.0/go.mod h1:ZgQEeidpAuNRZ8iRrlBKXZQP1ghovWIVhdJRyCDK+GI=
google.golang.org/grpc v1.50.0/go.mod h1:ZgQEeidpAuNRZ8iRrlBKXZQP1ghovWIVhdJRyCDK+GI=
google.golang.org/grpc v1.50.1/go.mod h1:ZgQEeidpAuNRZ8iRrlBKXZQP1ghovWIVhdJRyCDK+GI=
google.golang.org/grpc v1.51.0/go.mod h1:wgNDFcnuBGmxLKI/qn4T+m5BtEBYXJPvibbUPsAIPww=
google.golang.org/grpc v1.52.0/go.mod h1:pu6fVzoFb+NBYNAvQL08ic+lvB2IojljRYuun5vorUY=
google.golang.org/grpc v1.52.3/go.mod h1:pu6fVzoFb+NBYNAvQL08ic+lvB2IojljRYuun5vorUY=
google.golang.org/grpc v1.53.0/go.mod h1:OnIrk0ipVdj4N5d9IUoFUx72/VlD7+jUsHwZgwSMQpw=
google.golang.org/grpc v1.54.0/go.mod h1:PUSEXI6iWghWaB6lXM4knEgpJNu2qUcKfDtNci3EC2g=
google.golang.org/grpc v1.55.0/go.mod h1:iYEXKGkEBhg1PjZQvoYEVPTDkHo1/bjTnfwTeGONTY8=
google.golang.org/grpc v1.56.1/go.mod h1:I9bI3vqKfayGqPUAwGdOSu7kt6oIJLixfffKrpXqQ9s=
google.golang.org/grpc v1.56.2/go.mod h1:I9bI3vqKfayGqPUAwGdOSu7kt6oIJLixfffKrpXqQ9s=
google.golang.org/grpc v1.57.0/go.mod h1:Sd+9RMTACXwmub0zcNY2c4arhtrbBYD1AUHI/dt16Mo=
google.golang.org/grpc v1.58.2/go.mod h1:tgX3ZQDlNJGU96V6yHh1T/JeoBQ2TXdr43YbYSsCJk0=
google.golang.org/grpc v1.58.3/go.mod h1:tgX3ZQDlNJGU96V6yHh1T/JeoBQ2TXdr43YbYSsCJk0=
google.golang.org/grpc v1.59.0/go.mod h1:aUPDwccQo6OTjy7Hct4AfBPD1GptF4fyUjIkQ9YtF98=
google.golang.org/grpc v1.61.0 h1:TOvOcuXn30kRao+gfcvsebNEa5iZIiLkisYEkf7R7o0=
google.golang.org/grpc v1.61.0/go.mod h1:VUbo7IFqmF1QtCAstipjG0GIoq49KvMe9+h1jFLBNJs=
google.golang.org/grpc/cmd/protoc-gen-go-grpc v1.1.0/go.mod h1:6Kw0yEErY5E/yWrBtf03jp27GLLJujG4z/JK95pnjjw=
google.golang.org/protobuf v0.0.0-20200109180630-ec00e32a8dfd/go.mod h1:DFci5gLYBciE7Vtevhsrf46CRTquxDuWsQurQQe4oz8=
google.golang.org/protobuf v0.0.0-20200221191635-4d8936d0db64/go.mod h1:kwYJMbMJ01Woi6D6+Kah6886xMZcty6N08ah7+eCXa0=
google.golang.org/protobuf v0.0.0-20200228230310-ab0ca4ff8a60/go.mod h1:cfTl7dwQJ+fmap5saPgwCLgHXTUD7jkjRqWcaiX5VyM=
google.golang.org/protobuf v1.20.1-0.20200309200217-e05f789c0967/go.mod h1:A+miEFZTKqfCUM6K7xSMQL9OKL/b6hQv+e19PK+JZNE=
google.golang.org/protobuf v1.21.0/go.mod h1:47Nbq4nVaFHyn7ilMalzfO3qCViNmqZ2kzikPIcrTAo=
google.golang.org/protobuf v1.22.0/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=
google.golang.org/protobuf v1.23.0/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=
google.golang.org/protobuf v1.23.1-0.20200526195155-81db48ad09cc/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=
google.golang.org/protobuf v1.24.0/go.mod h1:r/3tXBNzIEhYS9I1OUVjXDlt8tc493IdKGjtUeSXeh4=
google.golang.org/protobuf v1.25.0/go.mod h1:9JNX74DMeImyA3h4bdi1ymwjUzf21/xIlbajtzgsN7c=
google.golang.org/protobuf v1.26.0-rc.1/go.mod h1:jlhhOSvTdKEhbULTjvd4ARK9grFBp09yW+WbY/TyQbw=
google.golang.org/protobuf v1.26.0/go.mod h1:9q0QmTI4eRPtz6boOQmLYwt+qCgq0jsYwAQnmE0givc=
google.golang.org/protobuf v1.27.1/go.mod h1:9q0QmTI4eRPtz6boOQmLYwt+qCgq0jsYwAQnmE0givc=
google.golang.org/protobuf v1.28.0/go.mod h1:HV8QOd/L58Z+nl8r43ehVNZIU/HEI6OcFqwMG9pJV4I=
google.golang.org/protobuf v1.28.1/go.mod h1:HV8QOd/L58Z+nl8r43ehVNZIU/HEI6OcFqwMG9pJV4I=
google.golang.org/protobuf v1.29.1/go.mod h1:HV8QOd/L58Z+nl8r43ehVNZIU/HEI6OcFqwMG9pJV4I=
google.golang.org/protobuf v1.30.0/go.mod h1:HV8QOd/L58Z+nl8r43ehVNZIU/HEI6OcFqwMG9pJV4I=
google.golang.org/protobuf v1.31.0 h1:g0LDEJHgrBl9N9r17Ru3sqWhkIx2NB67okBHPwC7hs8=
google.golang.org/protobuf v1.31.0/go.mod h1:HV8QOd/L58Z+nl8r43ehVNZIU/HEI6OcFqwMG9pJV4I=
gopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=
gopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=
gopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c/go.mod h1:JHkPIbrfpd72SG/EVd6muEfDQjcINNoR0C8j2r3qZ4Q=
gopkg.in/errgo.v2 v2.1.0/go.mod h1:hNsd1EY+bozCKY1Ytp96fpM3vjJbqLJn88ws8XvfDNI=
gopkg.in/yaml.v2 v2.2.2/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=
gopkg.in/yaml.v2 v2.2.3/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=
gopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=
gopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=
honnef.co/go/tools v0.0.0-20190102054323-c2f93a96b099/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=
honnef.co/go/tools v0.0.0-20190106161140-3f1c8253044a/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=
honnef.co/go/tools v0.0.0-20190418001031-e561f6794a2a/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=
honnef.co/go/tools v0.0.0-20190523083050-ea95bdfd59fc/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=
honnef.co/go/tools v0.0.1-2019.2.3/go.mod h1:a3bituU0lyd329TUQxRnasdCoJDkEUEAqEt0JzvZhAg=
honnef.co/go/tools v0.0.1-2020.1.3/go.mod h1:X/FiERA/W4tHapMX5mGpAtMSVEeEUOyHaw9vFzvIQ3k=
honnef.co/go/tools v0.0.1-2020.1.4/go.mod h1:X/FiERA/W4tHapMX5mGpAtMSVEeEUOyHaw9vFzvIQ3k=
honnef.co/go/tools v0.1.3/go.mod h1:NgwopIslSNH47DimFoV78dnkksY2EFtX0ajyb3K/las=
lukechampine.com/uint128 v1.1.1/go.mod h1:c4eWIwlEGaxC/+H1VguhU4PHXNWDCDMUlWdIWl2j1gk=
lukechampine.com/uint128 v1.2.0/go.mod h1:c4eWIwlEGaxC/+H1VguhU4PHXNWDCDMUlWdIWl2j1gk=
modernc.org/cc/v3 v3.36.0/go.mod h1:NFUHyPn4ekoC/JHeZFfZurN6ixxawE1BnVonP/oahEI=
modernc.org/cc/v3 v3.36.2/go.mod h1:NFUHyPn4ekoC/JHeZFfZurN6ixxawE1BnVonP/oahEI=
modernc.org/cc/v3 v3.36.3/go.mod h1:NFUHyPn4ekoC/JHeZFfZurN6ixxawE1BnVonP/oahEI=
modernc.org/cc/v3 v3.37.0/go.mod h1:vtL+3mdHx/wcj3iEGz84rQa8vEqR6XM84v5Lcvfph20=
modernc.org/cc/v3 v3.40.0/go.mod h1:/bTg4dnWkSXowUO6ssQKnOV0yMVxDYNIsIrzqTFDGH0=
modernc.org/ccgo/v3 v3.0.0-20220428102840-41399a37e894/go.mod h1:eI31LL8EwEBKPpNpA4bU1/i+sKOwOrQy8D87zWUcRZc=
modernc.org/ccgo/v3 v3.0.0-20220430103911-bc99d88307be/go.mod h1:bwdAnOoaIt8Ax9YdWGjxWsdkPcZyRPHqrOvJxaKAKGw=
modernc.org/ccgo/v3 v3.0.0-20220904174949-82d86e1b6d56/go.mod h1:YSXjPL62P2AMSxBphRHPn7IkzhVHqkvOnRKAKh+W6ZI=
modernc.org/ccgo/v3 v3.16.4/go.mod h1:tGtX0gE9Jn7hdZFeU88slbTh1UtCYKusWOoCJuvkWsQ=
modernc.org/ccgo/v3 v3.16.6/go.mod h1:tGtX0gE9Jn7hdZFeU88slbTh1UtCYKusWOoCJuvkWsQ=
modernc.org/ccgo/v3 v3.16.8/go.mod h1:zNjwkizS+fIFDrDjIAgBSCLkWbJuHF+ar3QRn+Z9aws=
modernc.org/ccgo/v3 v3.16.9/go.mod h1:zNMzC9A9xeNUepy6KuZBbugn3c0Mc9TeiJO4lgvkJDo=
modernc.org/ccgo/v3 v3.16.13-0.20221017192402-261537637ce8/go.mod h1:fUB3Vn0nVPReA+7IG7yZDfjv1TMWjhQP8gCxrFAtL5g=
modernc.org/ccgo/v3 v3.16.13/go.mod h1:2Quk+5YgpImhPjv2Qsob1DnZ/4som1lJTodubIcoUkY=
modernc.org/ccorpus v1.11.6/go.mod h1:2gEUTrWqdpH2pXsmTM1ZkjeSrUWDpjMu2T6m29L/ErQ=
modernc.org/httpfs v1.0.6/go.mod h1:7dosgurJGp0sPaRanU53W4xZYKh14wfzX420oZADeHM=
modernc.org/libc v0.0.0-20220428101251-2d5f3daf273b/go.mod h1:p7Mg4+koNjc8jkqwcoFBJx7tXkpj00G77X7A72jXPXA=
modernc.org/libc v1.16.0/go.mod h1:N4LD6DBE9cf+Dzf9buBlzVJndKr/iJHG97vGLHYnb5A=
modernc.org/libc v1.16.1/go.mod h1:JjJE0eu4yeK7tab2n4S1w8tlWd9MxXLRzheaRnAKymU=
modernc.org/libc v1.16.17/go.mod h1:hYIV5VZczAmGZAnG15Vdngn5HSF5cSkbvfz2B7GRuVU=
modernc.org/libc v1.16.19/go.mod h1:p7Mg4+koNjc8jkqwcoFBJx7tXkpj00G77X7A72jXPXA=
modernc.org/libc v1.17.0/go.mod h1:XsgLldpP4aWlPlsjqKRdHPqCxCjISdHfM/yeWC5GyW0=
modernc.org/libc v1.17.1/go.mod h1:FZ23b+8LjxZs7XtFMbSzL/EhPxNbfZbErxEHc7cbD9s=
modernc.org/libc v1.17.4/go.mod h1:WNg2ZH56rDEwdropAJeZPQkXmDwh+JCA1s/htl6r2fA=
modernc.org/libc v1.18.0/go.mod h1:vj6zehR5bfc98ipowQOM2nIDUZnVew/wNC/2tOGS+q0=
modernc.org/libc v1.20.3/go.mod h1:ZRfIaEkgrYgZDl6pa4W39HgN5G/yDW+NRmNKZBDFrk0=
modernc.org/libc v1.21.4/go.mod h1:przBsL5RDOZajTVslkugzLBj1evTue36jEomFQOoYuI=
modernc.org/libc v1.22.2/go.mod h1:uvQavJ1pZ0hIoC/jfqNoMLURIMhKzINIWypNM17puug=
modernc.org/mathutil v1.2.2/go.mod h1:mZW8CKdRPY1v87qxC/wUdX5O1qDzXMP5TH3wjfpga6E=
modernc.org/mathutil v1.4.1/go.mod h1:mZW8CKdRPY1v87qxC/wUdX5O1qDzXMP5TH3wjfpga6E=
modernc.org/mathutil v1.5.0/go.mod h1:mZW8CKdRPY1v87qxC/wUdX5O1qDzXMP5TH3wjfpga6E=
modernc.org/memory v1.1.1/go.mod h1:/0wo5ibyrQiaoUoH7f9D8dnglAmILJ5/cxZlRECf+Nw=
modernc.org/memory v1.2.0/go.mod h1:/0wo5ibyrQiaoUoH7f9D8dnglAmILJ5/cxZlRECf+Nw=
modernc.org/memory v1.2.1/go.mod h1:PkUhL0Mugw21sHPeskwZW4D6VscE/GQJOnIpCnW6pSU=
modernc.org/memory v1.3.0/go.mod h1:PkUhL0Mugw21sHPeskwZW4D6VscE/GQJOnIpCnW6pSU=
modernc.org/memory v1.4.0/go.mod h1:PkUhL0Mugw21sHPeskwZW4D6VscE/GQJOnIpCnW6pSU=
modernc.org/memory v1.5.0/go.mod h1:PkUhL0Mugw21sHPeskwZW4D6VscE/GQJOnIpCnW6pSU=
modernc.org/opt v0.1.1/go.mod h1:WdSiB5evDcignE70guQKxYUl14mgWtbClRi5wmkkTX0=
modernc.org/opt v0.1.3/go.mod h1:WdSiB5evDcignE70guQKxYUl14mgWtbClRi5wmkkTX0=
modernc.org/sqlite v1.18.1/go.mod h1:6ho+Gow7oX5V+OiOQ6Tr4xeqbx13UZ6t+Fw9IRUG4d4=
modernc.org/sqlite v1.18.2/go.mod h1:kvrTLEWgxUcHa2GfHBQtanR1H9ht3hTJNtKpzH9k1u0=
modernc.org/strutil v1.1.1/go.mod h1:DE+MQQ/hjKBZS2zNInV5hhcipt5rLPWkmpbGeW5mmdw=
modernc.org/strutil v1.1.3/go.mod h1:MEHNA7PdEnEwLvspRMtWTNnp2nnyvMfkimT1NKNAGbw=
modernc.org/tcl v1.13.1/go.mod h1:XOLfOwzhkljL4itZkK6T72ckMgvj0BDsnKNdZVUOecw=
modernc.org/tcl v1.13.2/go.mod h1:7CLiGIPo1M8Rv1Mitpv5akc2+8fxUd2y2UzC/MfMzy0=
modernc.org/token v1.0.0/go.mod h1:UGzOrNV1mAFSEB63lOFHIpNRUVMvYTc6yu1SMY/XTDM=
modernc.org/token v1.0.1/go.mod h1:UGzOrNV1mAFSEB63lOFHIpNRUVMvYTc6yu1SMY/XTDM=
modernc.org/token v1.1.0/go.mod h1:UGzOrNV1mAFSEB63lOFHIpNRUVMvYTc6yu1SMY/XTDM=
modernc.org/z v1.5.1/go.mod h1:eWFB510QWW5Th9YGZT81s+LwvaAs3Q2yr4sP0rmLkv8=
rsc.io/binaryregexp v0.2.0/go.mod h1:qTv7/COck+e2FymRvadv62gMdZztPaShugOCi3I+8D8=
rsc.io/pdf v0.1.1/go.mod h1:n8OzWcQ6Sp37PL01nO98y4iUCRdTGarVfzxY20ICaU4=
rsc.io/quote/v3 v3.1.0/go.mod h1:yEA65RcK8LyAZtP9Kv3t0HmxON59tX3rD+tICJqUlj0=
rsc.io/sampler v1.3.0/go.mod h1:T1hPZKmBbMNahiBKFy5HrXp6adAjACjK9JXDnKaTXpA=
static_resources:
  listeners:
  - address:
      socket_address:
        address: 0.0.0.0
        port_value: 8811
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          codec_type: AUTO
          stat_prefix: ingress_http
          access_log:
          - name: envoy.access_loggers.stdout
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.access_loggers.stream.v3.StdoutAccessLog
          route_config:
            name: local_route
            virtual_hosts:
            - name: backend
              domains:
              - "*"
              routes:
              - match:
                  prefix: "/"
                  grpc: {}
                route:
                  cluster: backend_grpc_service
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
  clusters:
  - name: backend_grpc_service
    type: STRICT_DNS
    lb_policy: ROUND_ROBIN
    typed_extension_protocol_options:
      envoy.extensions.upstreams.http.v3.HttpProtocolOptions:
        "@type": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions
        explicit_http_config:
          http2_protocol_options: {}
    load_assignment:
      cluster_name: backend_grpc_service
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: grpc-server
                port_value: 8081
services:

  # $ docker run -ti -v $(pwd):/protos -v $(pwd)/stubs:/stubs grpc/go protoc --go_out=plugins=grpc:/stubs -I/protos /protos/kv.proto
  stubs_go:
    build:
      context: .
      dockerfile: Dockerfile-grpc-go
    command: protoc --go_out=plugins=grpc:/stubs -I/protos /protos/kv.proto
    volumes:
    - ./protos:/protos
    - ./server/kv:/stubs

  # $ docker run -ti -v $(pwd):/protos -v $(pwd)/stubs:/stubs grpc/python python -m grpc.tools.protoc --python_out=/stubs --grpc_python_out=/stubs -I/protos /protos/kv.proto
  stubs_python:
    build:
      context: .
      dockerfile: Dockerfile-grpc-python
    command: python -m grpc.tools.protoc --python_out=/stubs --grpc_python_out=/stubs -I/protos /protos/kv.proto
    volumes:
    - ./protos:/protos
    - ./client/kv:/stubs
To learn about this sandbox and for instructions on how to run it please head over
to the [envoy docs](https://www.envoyproxy.io/docs/envoy/latest/start/sandboxes/grpc_bridge)

# gRPC HTTP/1.1 to HTTP/2 bridge

This is an example of a key-value store where a client CLI, written in Python, updates a remote store, written in Go, using the stubs generated for both languages.

Running clients that uses gRPC stubs and sends messages through a proxy
that upgrades the HTTP requests from http/1.1 to http/2. This is a more detailed
implementation of the Envoy documentation at https://www.envoyproxy.io/docs/envoy/latest/start/sandboxes/grpc_bridge

* Client: talks in python and sends HTTP/1.1 requests (gRPC stubs)
  * Client-Proxy: Envoy setup that acts as an egress and converts the HTTP/1.1 call to HTTP/2.
* Server: talks in golang and receives HTTP/2 requests (gRPC stubs)
  * Server-Proxy: Envoy setup that acts as an ingress and receives the HTTP/2 calls

`[client](http/1.1) -> [client-egress-proxy](http/2) -> [server-ingress-proxy](http/2) -> [server]`

# Running in 3 Steps

* Generate Stubs: both the `client` and `server` stubs in `python` and `go` respectively to be used by each server.
* Start Both Client and Server Servers and Proxies: `
* Use the Client CLI to make calls to the kv server.

## Generate Stubs

* Uses the `protos` dir and generates the stubs for both `client` and `server`
* Inspect the file `docker-compose-protos.yaml` with the gRPC protoc commands to generate the stubs.

```console
$ docker-compose -f docker-compose-protos.yaml up --remove-orphans
Starting grpc-bridge_stubs_python_1 ... done
Starting grpc-bridge_stubs_go_1     ... done
Attaching to grpc-bridge_stubs_go_1, grpc-bridge_stubs_python_1
grpc-bridge_stubs_go_1 exited with code 0
grpc-bridge_stubs_python_1 exited with code 0
```

* The files created were the `kv` modules for both the client and server respective dir.
  * Note that both stubs are their respective languages.
  * For each language, use its ways to include the stubs as an external module.

```console
$ ls -la client/kv/kv_pb2.py
-rw-r--r--  1 mdesales  CORP\Domain Users  9527 Nov  6 21:59 client/kv/kv_pb2.py

$ ls -la server/kv/kv.pb.go
-rw-r--r--  1 mdesales  CORP\Domain Users  9994 Nov  6 21:59 server/kv/kv.pb.go
```

## Start Both Client and Server and Proxies

* After the stubs are in place, start the containers described in `docker-compose.yaml`.

```console
$ docker-compose up --build
```

* Inspect the files `client/envoy-proxy.yaml` and `server/envoy-proxy.yaml`, as they define configs for their respective container, comparing port numbers and other specific settings.

Notice that you will be interacting with the client container, which hosts
the client python CLI. The port numbers for the proxies and the containers are displayed
by the `docker-compose ps`, so it's easier to compare with the `\*/envoy-proxy.yaml` config files for each
of the containers how they match.

Note that the client container to use is `grpc-bridge_grpc-client_1` and binds to no port
as it will use the `python` CLI.

```console
$ docker-compose ps
             Name                            Command               State                             Ports
------------------------------------------------------------------------------------------------------------------------------------
grpc-bridge_grpc-client-proxy_1   /docker-entrypoint.sh /usr ... Up      10000/tcp, 0.0.0.0:9911->9911/tcp, 0.0.0.0:9991->9991/tcp
grpc-bridge_grpc-client_1         /bin/sh -c tail -f /dev/null     Up
grpc-bridge_grpc-server-proxy_1   /docker-entrypoint.sh /usr ... Up      10000/tcp, 0.0.0.0:8811->8811/tcp, 0.0.0.0:8881->8881/tcp
grpc-bridge_grpc-server_1         /bin/sh -c /bin/server           Up      0.0.0.0:8081->8081/tcp
```

## Use the Client CLI

* Since the containers are running, you can use the client container to interact with the gRPC server through the proxies
* The client has the methods `set key value` and `get key` to use the in-memory key-value store.

```console
$ docker-compose exec grpc-client /client/grpc-kv-client.py set foo bar
setf foo to bar
```

> NOTE: You could also run docker instead of docker-compose `docker exec -ti grpc-bridge_grpc-client_1 /client/grpc-kv-client.py set foo bar`

* The server will display the gRPC call received by the server, and then the access logs from the proxy for the SET method.
  * Note that the proxy is propagating the headers of the request

```console
grpc-server_1        | 2019/11/07 16:33:58 set: foo = bar
grpc-server-proxy_1  | [2019-11-07T16:33:58.856Z] "POST /kv.KV/Set HTTP/1.1" 200 - 15 7 3 1 "172.24.0.3" "python-requests/2.22.0" "c11cf735-0647-4e67-965c-5b1e362a5532" "grpc" "172.24.0.2:8081"
grpc-client-proxy_1  | [2019-11-07T16:33:58.855Z] "POST /kv.KV/Set HTTP/1.1" 200 - 15 7 5 3 "172.24.0.3" "python-requests/2.22.0" "c11cf735-0647-4e67-965c-5b1e362a5532" "grpc" "172.24.0.5:8811"
```

* Getting the value is no different

```console
$ docker-compose exec grpc-client /client/grpc-kv-client.py get foo
bar
```

> NOTE: You could also run docker instead of docker-compose `docker exec -ti grpc-bridge_grpc-client_1 /client/grpc-kv-client.py get foo`

* The logs in the server will show the same for the GET method.
  * Note that again the request ID is proxied through

```console
grpc-server_1        | 2019/11/07 16:34:50 get: foo
grpc-server-proxy_1  | [2019-11-07T16:34:50.456Z] "POST /kv.KV/Get HTTP/1.1" 200 - 10 10 2 1 "172.24.0.3" "python-requests/2.22.0" "727d4dcd-a276-4bb2-b4cc-494ae7119c24" "grpc" "172.24.0.2:8081"
grpc-client-proxy_1  | [2019-11-07T16:34:50.455Z] "POST /kv.KV/Get HTTP/1.1" 200 - 10 10 3 2 "172.24.0.3" "python-requests/2.22.0" "727d4dcd-a276-4bb2-b4cc-494ae7119c24" "grpc" "172.24.0.5:8811"
```

# Troubleshooting

* Errors building the `client` or `server` are related to the missing gRPC stubs.
* Make sure to produce the stubs before building
  * The error below is when the server is missing the stubs in the kv dir.

```console
$ go build -o server
go: finding github.com/envoyproxy/envoy/examples/grpc-bridge latest
go: finding github.com/envoyproxy/envoy/examples latest
go: finding github.com/envoyproxy/envoy/examples/grpc-bridge/server/kv latest
go: finding github.com/envoyproxy/envoy/examples/grpc-bridge/server latest
build github.com/envoyproxy/envoy: cannot load github.com/envoyproxy/envoy/examples/grpc-bridge/server/kv: no matching versions for query "latest"
```
.idea
server/kv/kv.pb.go
client/kv/kv_pb2.py
FROM grpc/go@sha256:0d3bb1fbfab306680ebaf751992bd2db2a0322106e4b389e85028a027242c2bc
#
# This file is autogenerated by pip-compile with Python 3.11
# by the following command:
#
#    pip-compile --allow-unsafe --generate-hashes requirements.in
#
certifi==2023.7.22 \
    --hash=sha256:539cc1d13202e33ca466e88b2807e29f4c13049d6d87031a3c110744495cb082 \
    --hash=sha256:92d6037539857d8206b8f6ae472e8b77db8058fec5937a1ef3f54304089edbb9
    # via requests
charset-normalizer==3.3.0 \
    --hash=sha256:02673e456dc5ab13659f85196c534dc596d4ef260e4d86e856c3b2773ce09843 \
    --hash=sha256:02af06682e3590ab952599fbadac535ede5d60d78848e555aa58d0c0abbde786 \
    --hash=sha256:03680bb39035fbcffe828eae9c3f8afc0428c91d38e7d61aa992ef7a59fb120e \
    --hash=sha256:0570d21da019941634a531444364f2482e8db0b3425fcd5ac0c36565a64142c8 \
    --hash=sha256:09c77f964f351a7369cc343911e0df63e762e42bac24cd7d18525961c81754f4 \
    --hash=sha256:0d3d5b7db9ed8a2b11a774db2bbea7ba1884430a205dbd54a32d61d7c2a190fa \
    --hash=sha256:1063da2c85b95f2d1a430f1c33b55c9c17ffaf5e612e10aeaad641c55a9e2b9d \
    --hash=sha256:12ebea541c44fdc88ccb794a13fe861cc5e35d64ed689513a5c03d05b53b7c82 \
    --hash=sha256:153e7b6e724761741e0974fc4dcd406d35ba70b92bfe3fedcb497226c93b9da7 \
    --hash=sha256:15b26ddf78d57f1d143bdf32e820fd8935d36abe8a25eb9ec0b5a71c82eb3895 \
    --hash=sha256:1872d01ac8c618a8da634e232f24793883d6e456a66593135aeafe3784b0848d \
    --hash=sha256:187d18082694a29005ba2944c882344b6748d5be69e3a89bf3cc9d878e548d5a \
    --hash=sha256:1b2919306936ac6efb3aed1fbf81039f7087ddadb3160882a57ee2ff74fd2382 \
    --hash=sha256:232ac332403e37e4a03d209a3f92ed9071f7d3dbda70e2a5e9cff1c4ba9f0678 \
    --hash=sha256:23e8565ab7ff33218530bc817922fae827420f143479b753104ab801145b1d5b \
    --hash=sha256:24817cb02cbef7cd499f7c9a2735286b4782bd47a5b3516a0e84c50eab44b98e \
    --hash=sha256:249c6470a2b60935bafd1d1d13cd613f8cd8388d53461c67397ee6a0f5dce741 \
    --hash=sha256:24a91a981f185721542a0b7c92e9054b7ab4fea0508a795846bc5b0abf8118d4 \
    --hash=sha256:2502dd2a736c879c0f0d3e2161e74d9907231e25d35794584b1ca5284e43f596 \
    --hash=sha256:250c9eb0f4600361dd80d46112213dff2286231d92d3e52af1e5a6083d10cad9 \
    --hash=sha256:278c296c6f96fa686d74eb449ea1697f3c03dc28b75f873b65b5201806346a69 \
    --hash=sha256:2935ffc78db9645cb2086c2f8f4cfd23d9b73cc0dc80334bc30aac6f03f68f8c \
    --hash=sha256:2f4a0033ce9a76e391542c182f0d48d084855b5fcba5010f707c8e8c34663d77 \
    --hash=sha256:30a85aed0b864ac88309b7d94be09f6046c834ef60762a8833b660139cfbad13 \
    --hash=sha256:380c4bde80bce25c6e4f77b19386f5ec9db230df9f2f2ac1e5ad7af2caa70459 \
    --hash=sha256:3ae38d325b512f63f8da31f826e6cb6c367336f95e418137286ba362925c877e \
    --hash=sha256:3b447982ad46348c02cb90d230b75ac34e9886273df3a93eec0539308a6296d7 \
    --hash=sha256:3debd1150027933210c2fc321527c2299118aa929c2f5a0a80ab6953e3bd1908 \
    --hash=sha256:4162918ef3098851fcd8a628bf9b6a98d10c380725df9e04caf5ca6dd48c847a \
    --hash=sha256:468d2a840567b13a590e67dd276c570f8de00ed767ecc611994c301d0f8c014f \
    --hash=sha256:4cc152c5dd831641e995764f9f0b6589519f6f5123258ccaca8c6d34572fefa8 \
    --hash=sha256:542da1178c1c6af8873e143910e2269add130a299c9106eef2594e15dae5e482 \
    --hash=sha256:557b21a44ceac6c6b9773bc65aa1b4cc3e248a5ad2f5b914b91579a32e22204d \
    --hash=sha256:5707a746c6083a3a74b46b3a631d78d129edab06195a92a8ece755aac25a3f3d \
    --hash=sha256:588245972aca710b5b68802c8cad9edaa98589b1b42ad2b53accd6910dad3545 \
    --hash=sha256:5adf257bd58c1b8632046bbe43ee38c04e1038e9d37de9c57a94d6bd6ce5da34 \
    --hash=sha256:619d1c96099be5823db34fe89e2582b336b5b074a7f47f819d6b3a57ff7bdb86 \
    --hash=sha256:63563193aec44bce707e0c5ca64ff69fa72ed7cf34ce6e11d5127555756fd2f6 \
    --hash=sha256:67b8cc9574bb518ec76dc8e705d4c39ae78bb96237cb533edac149352c1f39fe \
    --hash=sha256:6a685067d05e46641d5d1623d7c7fdf15a357546cbb2f71b0ebde91b175ffc3e \
    --hash=sha256:70f1d09c0d7748b73290b29219e854b3207aea922f839437870d8cc2168e31cc \
    --hash=sha256:750b446b2ffce1739e8578576092179160f6d26bd5e23eb1789c4d64d5af7dc7 \
    --hash=sha256:7966951325782121e67c81299a031f4c115615e68046f79b85856b86ebffc4cd \
    --hash=sha256:7b8b8bf1189b3ba9b8de5c8db4d541b406611a71a955bbbd7385bbc45fcb786c \
    --hash=sha256:7f5d10bae5d78e4551b7be7a9b29643a95aded9d0f602aa2ba584f0388e7a557 \
    --hash=sha256:805dfea4ca10411a5296bcc75638017215a93ffb584c9e344731eef0dcfb026a \
    --hash=sha256:81bf654678e575403736b85ba3a7867e31c2c30a69bc57fe88e3ace52fb17b89 \
    --hash=sha256:82eb849f085624f6a607538ee7b83a6d8126df6d2f7d3b319cb837b289123078 \
    --hash=sha256:85a32721ddde63c9df9ebb0d2045b9691d9750cb139c161c80e500d210f5e26e \
    --hash=sha256:86d1f65ac145e2c9ed71d8ffb1905e9bba3a91ae29ba55b4c46ae6fc31d7c0d4 \
    --hash=sha256:86f63face3a527284f7bb8a9d4f78988e3c06823f7bea2bd6f0e0e9298ca0403 \
    --hash=sha256:8eaf82f0eccd1505cf39a45a6bd0a8cf1c70dcfc30dba338207a969d91b965c0 \
    --hash=sha256:93aa7eef6ee71c629b51ef873991d6911b906d7312c6e8e99790c0f33c576f89 \
    --hash=sha256:96c2b49eb6a72c0e4991d62406e365d87067ca14c1a729a870d22354e6f68115 \
    --hash=sha256:9cf3126b85822c4e53aa28c7ec9869b924d6fcfb76e77a45c44b83d91afd74f9 \
    --hash=sha256:9fe359b2e3a7729010060fbca442ca225280c16e923b37db0e955ac2a2b72a05 \
    --hash=sha256:a0ac5e7015a5920cfce654c06618ec40c33e12801711da6b4258af59a8eff00a \
    --hash=sha256:a3f93dab657839dfa61025056606600a11d0b696d79386f974e459a3fbc568ec \
    --hash=sha256:a4b71f4d1765639372a3b32d2638197f5cd5221b19531f9245fcc9ee62d38f56 \
    --hash=sha256:aae32c93e0f64469f74ccc730a7cb21c7610af3a775157e50bbd38f816536b38 \
    --hash=sha256:aaf7b34c5bc56b38c931a54f7952f1ff0ae77a2e82496583b247f7c969eb1479 \
    --hash=sha256:abecce40dfebbfa6abf8e324e1860092eeca6f7375c8c4e655a8afb61af58f2c \
    --hash=sha256:abf0d9f45ea5fb95051c8bfe43cb40cda383772f7e5023a83cc481ca2604d74e \
    --hash=sha256:ac71b2977fb90c35d41c9453116e283fac47bb9096ad917b8819ca8b943abecd \
    --hash=sha256:ada214c6fa40f8d800e575de6b91a40d0548139e5dc457d2ebb61470abf50186 \
    --hash=sha256:b09719a17a2301178fac4470d54b1680b18a5048b481cb8890e1ef820cb80455 \
    --hash=sha256:b1121de0e9d6e6ca08289583d7491e7fcb18a439305b34a30b20d8215922d43c \
    --hash=sha256:b3b2316b25644b23b54a6f6401074cebcecd1244c0b8e80111c9a3f1c8e83d65 \
    --hash=sha256:b3d9b48ee6e3967b7901c052b670c7dda6deb812c309439adaffdec55c6d7b78 \
    --hash=sha256:b5bcf60a228acae568e9911f410f9d9e0d43197d030ae5799e20dca8df588287 \
    --hash=sha256:b8f3307af845803fb0b060ab76cf6dd3a13adc15b6b451f54281d25911eb92df \
    --hash=sha256:c2af80fb58f0f24b3f3adcb9148e6203fa67dd3f61c4af146ecad033024dde43 \
    --hash=sha256:c350354efb159b8767a6244c166f66e67506e06c8924ed74669b2c70bc8735b1 \
    --hash=sha256:c5a74c359b2d47d26cdbbc7845e9662d6b08a1e915eb015d044729e92e7050b7 \
    --hash=sha256:c71f16da1ed8949774ef79f4a0260d28b83b3a50c6576f8f4f0288d109777989 \
    --hash=sha256:d47ecf253780c90ee181d4d871cd655a789da937454045b17b5798da9393901a \
    --hash=sha256:d7eff0f27edc5afa9e405f7165f85a6d782d308f3b6b9d96016c010597958e63 \
    --hash=sha256:d97d85fa63f315a8bdaba2af9a6a686e0eceab77b3089af45133252618e70884 \
    --hash=sha256:db756e48f9c5c607b5e33dd36b1d5872d0422e960145b08ab0ec7fd420e9d649 \
    --hash=sha256:dc45229747b67ffc441b3de2f3ae5e62877a282ea828a5bdb67883c4ee4a8810 \
    --hash=sha256:e0fc42822278451bc13a2e8626cf2218ba570f27856b536e00cfa53099724828 \
    --hash=sha256:e39c7eb31e3f5b1f88caff88bcff1b7f8334975b46f6ac6e9fc725d829bc35d4 \
    --hash=sha256:e46cd37076971c1040fc8c41273a8b3e2c624ce4f2be3f5dfcb7a430c1d3acc2 \
    --hash=sha256:e5c1502d4ace69a179305abb3f0bb6141cbe4714bc9b31d427329a95acfc8bdd \
    --hash=sha256:edfe077ab09442d4ef3c52cb1f9dab89bff02f4524afc0acf2d46be17dc479f5 \
    --hash=sha256:effe5406c9bd748a871dbcaf3ac69167c38d72db8c9baf3ff954c344f31c4cbe \
    --hash=sha256:f0d1e3732768fecb052d90d62b220af62ead5748ac51ef61e7b32c266cac9293 \
    --hash=sha256:f5969baeaea61c97efa706b9b107dcba02784b1601c74ac84f2a532ea079403e \
    --hash=sha256:f8888e31e3a85943743f8fc15e71536bda1c81d5aa36d014a3c0c44481d7db6e \
    --hash=sha256:fc52b79d83a3fe3a360902d3f5d79073a993597d48114c29485e9431092905d8
    # via requests
grpcio==1.60.0 \
    --hash=sha256:073f959c6f570797272f4ee9464a9997eaf1e98c27cb680225b82b53390d61e6 \
    --hash=sha256:0fd3b3968ffe7643144580f260f04d39d869fcc2cddb745deef078b09fd2b328 \
    --hash=sha256:1434ca77d6fed4ea312901122dc8da6c4389738bf5788f43efb19a838ac03ead \
    --hash=sha256:1c30bb23a41df95109db130a6cc1b974844300ae2e5d68dd4947aacba5985aa5 \
    --hash=sha256:20e7a4f7ded59097c84059d28230907cd97130fa74f4a8bfd1d8e5ba18c81491 \
    --hash=sha256:2199165a1affb666aa24adf0c97436686d0a61bc5fc113c037701fb7c7fceb96 \
    --hash=sha256:297eef542156d6b15174a1231c2493ea9ea54af8d016b8ca7d5d9cc65cfcc444 \
    --hash=sha256:2aef56e85901c2397bd557c5ba514f84de1f0ae5dd132f5d5fed042858115951 \
    --hash=sha256:30943b9530fe3620e3b195c03130396cd0ee3a0d10a66c1bee715d1819001eaf \
    --hash=sha256:3b36a2c6d4920ba88fa98075fdd58ff94ebeb8acc1215ae07d01a418af4c0253 \
    --hash=sha256:428d699c8553c27e98f4d29fdc0f0edc50e9a8a7590bfd294d2edb0da7be3629 \
    --hash=sha256:43e636dc2ce9ece583b3e2ca41df5c983f4302eabc6d5f9cd04f0562ee8ec1ae \
    --hash=sha256:452ca5b4afed30e7274445dd9b441a35ece656ec1600b77fff8c216fdf07df43 \
    --hash=sha256:467a7d31554892eed2aa6c2d47ded1079fc40ea0b9601d9f79204afa8902274b \
    --hash=sha256:4b44d7e39964e808b071714666a812049765b26b3ea48c4434a3b317bac82f14 \
    --hash=sha256:4c86343cf9ff7b2514dd229bdd88ebba760bd8973dac192ae687ff75e39ebfab \
    --hash=sha256:5208a57eae445ae84a219dfd8b56e04313445d146873117b5fa75f3245bc1390 \
    --hash=sha256:5ff21e000ff2f658430bde5288cb1ac440ff15c0d7d18b5fb222f941b46cb0d2 \
    --hash=sha256:675997222f2e2f22928fbba640824aebd43791116034f62006e19730715166c0 \
    --hash=sha256:676e4a44e740deaba0f4d95ba1d8c5c89a2fcc43d02c39f69450b1fa19d39590 \
    --hash=sha256:6e306b97966369b889985a562ede9d99180def39ad42c8014628dd3cc343f508 \
    --hash=sha256:6fd9584bf1bccdfff1512719316efa77be235469e1e3295dce64538c4773840b \
    --hash=sha256:705a68a973c4c76db5d369ed573fec3367d7d196673fa86614b33d8c8e9ebb08 \
    --hash=sha256:74d7d9fa97809c5b892449b28a65ec2bfa458a4735ddad46074f9f7d9550ad13 \
    --hash=sha256:77c8a317f0fd5a0a2be8ed5cbe5341537d5c00bb79b3bb27ba7c5378ba77dbca \
    --hash=sha256:79a050889eb8d57a93ed21d9585bb63fca881666fc709f5d9f7f9372f5e7fd03 \
    --hash=sha256:7db16dd4ea1b05ada504f08d0dca1cd9b926bed3770f50e715d087c6f00ad748 \
    --hash=sha256:83f2292ae292ed5a47cdcb9821039ca8e88902923198f2193f13959360c01860 \
    --hash=sha256:87c9224acba0ad8bacddf427a1c2772e17ce50b3042a789547af27099c5f751d \
    --hash=sha256:8a97a681e82bc11a42d4372fe57898d270a2707f36c45c6676e49ce0d5c41353 \
    --hash=sha256:9073513ec380434eb8d21970e1ab3161041de121f4018bbed3146839451a6d8e \
    --hash=sha256:90bdd76b3f04bdb21de5398b8a7c629676c81dfac290f5f19883857e9371d28c \
    --hash=sha256:91229d7203f1ef0ab420c9b53fe2ca5c1fbeb34f69b3bc1b5089466237a4a134 \
    --hash=sha256:92f88ca1b956eb8427a11bb8b4a0c0b2b03377235fc5102cb05e533b8693a415 \
    --hash=sha256:95ae3e8e2c1b9bf671817f86f155c5da7d49a2289c5cf27a319458c3e025c320 \
    --hash=sha256:9e30be89a75ee66aec7f9e60086fadb37ff8c0ba49a022887c28c134341f7179 \
    --hash=sha256:a48edde788b99214613e440fce495bbe2b1e142a7f214cce9e0832146c41e324 \
    --hash=sha256:a7152fa6e597c20cb97923407cf0934e14224af42c2b8d915f48bc3ad2d9ac18 \
    --hash=sha256:a9c7b71211f066908e518a2ef7a5e211670761651039f0d6a80d8d40054047df \
    --hash=sha256:b0571a5aef36ba9177e262dc88a9240c866d903a62799e44fd4aae3f9a2ec17e \
    --hash=sha256:b0fb2d4801546598ac5cd18e3ec79c1a9af8b8f2a86283c55a5337c5aeca4b1b \
    --hash=sha256:b10241250cb77657ab315270b064a6c7f1add58af94befa20687e7c8d8603ae6 \
    --hash=sha256:b87efe4a380887425bb15f220079aa8336276398dc33fce38c64d278164f963d \
    --hash=sha256:b98f43fcdb16172dec5f4b49f2fece4b16a99fd284d81c6bbac1b3b69fcbe0ff \
    --hash=sha256:c193109ca4070cdcaa6eff00fdb5a56233dc7610216d58fb81638f89f02e4968 \
    --hash=sha256:c826f93050c73e7769806f92e601e0efdb83ec8d7c76ddf45d514fee54e8e619 \
    --hash=sha256:d020cfa595d1f8f5c6b343530cd3ca16ae5aefdd1e832b777f9f0eb105f5b139 \
    --hash=sha256:d6a478581b1a1a8fdf3318ecb5f4d0cda41cacdffe2b527c23707c9c1b8fdb55 \
    --hash=sha256:de2ad69c9a094bf37c1102b5744c9aec6cf74d2b635558b779085d0263166454 \
    --hash=sha256:e278eafb406f7e1b1b637c2cf51d3ad45883bb5bd1ca56bc05e4fc135dfdaa65 \
    --hash=sha256:e381fe0c2aa6c03b056ad8f52f8efca7be29fb4d9ae2f8873520843b6039612a \
    --hash=sha256:e61e76020e0c332a98290323ecfec721c9544f5b739fab925b6e8cbe1944cf19 \
    --hash=sha256:f897c3b127532e6befdcf961c415c97f320d45614daf84deba0a54e64ea2457b \
    --hash=sha256:fb464479934778d7cc5baf463d959d361954d6533ad34c3a4f1d267e86ee25fd
    # via
    #   -r requirements.in
    #   grpcio-tools
grpcio-tools==1.60.0 \
    --hash=sha256:081336d8258f1a56542aa8a7a5dec99a2b38d902e19fbdd744594783301b0210 \
    --hash=sha256:1748893efd05cf4a59a175d7fa1e4fbb652f4d84ccaa2109f7869a2be48ed25e \
    --hash=sha256:17a32b3da4fc0798cdcec0a9c974ac2a1e98298f151517bf9148294a3b1a5742 \
    --hash=sha256:18976684a931ca4bcba65c78afa778683aefaae310f353e198b1823bf09775a0 \
    --hash=sha256:1b93ae8ffd18e9af9a965ebca5fa521e89066267de7abdde20721edc04e42721 \
    --hash=sha256:1fbb9554466d560472f07d906bfc8dcaf52f365c2a407015185993e30372a886 \
    --hash=sha256:24c4ead4a03037beaeb8ef2c90d13d70101e35c9fae057337ed1a9144ef10b53 \
    --hash=sha256:2a8a758701f3ac07ed85f5a4284c6a9ddefcab7913a8e552497f919349e72438 \
    --hash=sha256:2dd01257e4feff986d256fa0bac9f56de59dc735eceeeb83de1c126e2e91f653 \
    --hash=sha256:2e00de389729ca8d8d1a63c2038703078a887ff738dc31be640b7da9c26d0d4f \
    --hash=sha256:2fb4cf74bfe1e707cf10bc9dd38a1ebaa145179453d150febb121c7e9cd749bf \
    --hash=sha256:2fd1671c52f96e79a2302c8b1c1f78b8a561664b8b3d6946f20d8f1cc6b4225a \
    --hash=sha256:321b18f42a70813545e416ddcb8bf20defa407a8114906711c9710a69596ceda \
    --hash=sha256:3456df087ea61a0972a5bc165aed132ed6ddcc63f5749e572f9fff84540bdbad \
    --hash=sha256:4041538f55aad5b3ae7e25ab314d7995d689e968bfc8aa169d939a3160b1e4c6 \
    --hash=sha256:559ce714fe212aaf4abbe1493c5bb8920def00cc77ce0d45266f4fd9d8b3166f \
    --hash=sha256:5a907a4f1ffba86501b2cdb8682346249ea032b922fc69a92f082ba045cca548 \
    --hash=sha256:5ce6bbd4936977ec1114f2903eb4342781960d521b0d82f73afedb9335251f6f \
    --hash=sha256:6170873b1e5b6580ebb99e87fb6e4ea4c48785b910bd7af838cc6e44b2bccb04 \
    --hash=sha256:6192184b1f99372ff1d9594bd4b12264e3ff26440daba7eb043726785200ff77 \
    --hash=sha256:6807b7a3f3e6e594566100bd7fe04a2c42ce6d5792652677f1aaf5aa5adaef3d \
    --hash=sha256:687f576d7ff6ce483bc9a196d1ceac45144e8733b953620a026daed8e450bc38 \
    --hash=sha256:74025fdd6d1cb7ba4b5d087995339e9a09f0c16cf15dfe56368b23e41ffeaf7a \
    --hash=sha256:7a5263a0f2ddb7b1cfb2349e392cfc4f318722e0f48f886393e06946875d40f3 \
    --hash=sha256:7a6fe752205caae534f29fba907e2f59ff79aa42c6205ce9a467e9406cbac68c \
    --hash=sha256:7c1cde49631732356cb916ee1710507967f19913565ed5f9991e6c9cb37e3887 \
    --hash=sha256:811abb9c4fb6679e0058dfa123fb065d97b158b71959c0e048e7972bbb82ba0f \
    --hash=sha256:857c5351e9dc33a019700e171163f94fcc7e3ae0f6d2b026b10fda1e3c008ef1 \
    --hash=sha256:87cf439178f3eb45c1a889b2e4a17cbb4c450230d92c18d9c57e11271e239c55 \
    --hash=sha256:9970d384fb0c084b00945ef57d98d57a8d32be106d8f0bd31387f7cbfe411b5b \
    --hash=sha256:9ee35234f1da8fba7ddbc544856ff588243f1128ea778d7a1da3039be829a134 \
    --hash=sha256:addc9b23d6ff729d9f83d4a2846292d4c84f5eb2ec38f08489a6a0d66ac2b91e \
    --hash=sha256:b22b1299b666eebd5752ba7719da536075eae3053abcf2898b65f763c314d9da \
    --hash=sha256:b8f7a5094adb49e85db13ea3df5d99a976c2bdfd83b0ba26af20ebb742ac6786 \
    --hash=sha256:b96981f3a31b85074b73d97c8234a5ed9053d65a36b18f4a9c45a2120a5b7a0a \
    --hash=sha256:bbf0ed772d2ae7e8e5d7281fcc00123923ab130b94f7a843eee9af405918f924 \
    --hash=sha256:bd2a17b0193fbe4793c215d63ce1e01ae00a8183d81d7c04e77e1dfafc4b2b8a \
    --hash=sha256:c771b19dce2bfe06899247168c077d7ab4e273f6655d8174834f9a6034415096 \
    --hash=sha256:d941749bd8dc3f8be58fe37183143412a27bec3df8482d5abd6b4ec3f1ac2924 \
    --hash=sha256:dba6e32c87b4af29b5f475fb2f470f7ee3140bfc128644f17c6c59ddeb670680 \
    --hash=sha256:dd1e68c232fe01dd5312a8dbe52c50ecd2b5991d517d7f7446af4ba6334ba872 \
    --hash=sha256:e5614cf0960456d21d8a0f4902e3e5e3bcacc4e400bf22f196e5dd8aabb978b7 \
    --hash=sha256:e5c519a0d4ba1ab44a004fa144089738c59278233e2010b2cf4527dc667ff297 \
    --hash=sha256:e68dc4474f30cad11a965f0eb5d37720a032b4720afa0ec19dbcea2de73b5aae \
    --hash=sha256:e70d867c120d9849093b0ac24d861e378bc88af2552e743d83b9f642d2caa7c2 \
    --hash=sha256:e87cabac7969bdde309575edc2456357667a1b28262b2c1f12580ef48315b19d \
    --hash=sha256:eae27f9b16238e2aaee84c77b5923c6924d6dccb0bdd18435bf42acc8473ae1a \
    --hash=sha256:ec0e401e9a43d927d216d5169b03c61163fb52b665c5af2fed851357b15aef88 \
    --hash=sha256:ed30499340228d733ff69fcf4a66590ed7921f94eb5a2bf692258b1280b9dac7 \
    --hash=sha256:f10ef47460ce3c6fd400f05fe757b90df63486c9b84d1ecad42dcc5f80c8ac14 \
    --hash=sha256:f3d916606dcf5610d4367918245b3d9d8cd0d2ec0b7043d1bbb8c50fe9815c3a \
    --hash=sha256:f610384dee4b1ca705e8da66c5b5fe89a2de3d165c5282c3d1ddf40cb18924e4 \
    --hash=sha256:fb4df80868b3e397d5fbccc004c789d2668b622b51a9d2387b4c89c80d31e2c5 \
    --hash=sha256:fc01bc1079279ec342f0f1b6a107b3f5dc3169c33369cf96ada6e2e171f74e86
    # via -r requirements.in
idna==3.4 \
    --hash=sha256:814f528e8dead7d329833b91c5faa87d60bf71824cd12a7530b5526063d02cb4 \
    --hash=sha256:90b77e79eaa3eba6de819a0c442c0b4ceefc341a7a2ab77d7562bf49f425c5c2
    # via requests
protobuf==4.25.2 \
    --hash=sha256:10894a2885b7175d3984f2be8d9850712c57d5e7587a2410720af8be56cdaf62 \
    --hash=sha256:2db9f8fa64fbdcdc93767d3cf81e0f2aef176284071507e3ede160811502fd3d \
    --hash=sha256:33a1aeef4b1927431d1be780e87b641e322b88d654203a9e9d93f218ee359e61 \
    --hash=sha256:47f3de503fe7c1245f6f03bea7e8d3ec11c6c4a2ea9ef910e3221c8a15516d62 \
    --hash=sha256:5e5c933b4c30a988b52e0b7c02641760a5ba046edc5e43d3b94a74c9fc57c1b3 \
    --hash=sha256:8f62574857ee1de9f770baf04dde4165e30b15ad97ba03ceac65f760ff018ac9 \
    --hash=sha256:a8b7a98d4ce823303145bf3c1a8bdb0f2f4642a414b196f04ad9853ed0c8f830 \
    --hash=sha256:b50c949608682b12efb0b2717f53256f03636af5f60ac0c1d900df6213910fd6 \
    --hash=sha256:d66a769b8d687df9024f2985d5137a337f957a0916cf5464d1513eee96a63ff0 \
    --hash=sha256:fc381d1dd0516343f1440019cedf08a7405f791cd49eef4ae1ea06520bc1c020 \
    --hash=sha256:fe599e175cb347efc8ee524bcd4b902d11f7262c0e569ececcb89995c15f0a5e
    # via
    #   -r requirements.in
    #   grpcio-tools
requests==2.31.0 \
    --hash=sha256:58cd2187c01e70e6e26505bca751777aa9f2ee0b7f4300988b709f44e013003f \
    --hash=sha256:942c5a758f98d790eaed1a29cb6eefc7ffb0d1cf7af05c3d2791656dbd6ad1e1
    # via -r requirements.in
urllib3==2.0.7 \
    --hash=sha256:c97dfde1f7bd43a71c8d2a58e369e9b2bf692d1334ea9f9cae55add7d0dd0f84 \
    --hash=sha256:fdb6d215c776278489906c2f8916e6e7d4f5a9b602ccbcfdf7f016fc8da0596e
    # via requests

# The following packages are considered to be unsafe in a requirements file:
setuptools==68.2.2 \
    --hash=sha256:4ac1475276d2f1c48684874089fefcd83bd7162ddaafb81fac866ba0db282a87 \
    --hash=sha256:b454a35605876da60632df1a60f736524eb73cc47bbc9f3f1ef1b644de74fd2a
    # via grpcio-tools
#!/usr/bin/env python

import requests, sys
import os

# Stubs generated by protoc
from kv import kv_pb2 as kv

from struct import pack

HOST = os.getenv('CLIENT_PROXY', "http://localhost:9001")
HEADERS = {'content-type': 'application/grpc', 'Host': 'grpc'}
USAGE = """
grpc-client usage [{host}]:
  ./client.py set <key> <value> - sets the <key> and <value>
  ./client.py get <key>         - gets the value for <key>

  Set env var CLIENT_PROXY to change to a different host
  """.format(host=HOST)


class KVClient:

    def get(self, key):
        r = kv.GetRequest(key=key)

        # Build the gRPC frame
        data = r.SerializeToString()
        data = pack('!cI', b'\0', len(data)) + data

        resp = requests.post(HOST + "/kv.KV/Get", data=data, headers=HEADERS)

        return kv.GetResponse().FromString(resp.content[5:])

    def set(self, key, value):
        r = kv.SetRequest(key=key, value=value)
        data = r.SerializeToString()
        data = pack('!cI', b'\0', len(data)) + data

        return requests.post(HOST + "/kv.KV/Set", data=data, headers=HEADERS)


def main():
    if len(sys.argv) == 1:
        print(USAGE)

        sys.exit(0)

    cmd = sys.argv[1]

    client = KVClient()

    if cmd == "get":
        # ensure a key was provided
        if len(sys.argv) != 3:
            print(USAGE)
            sys.exit(1)

        # get the key to fetch
        key = sys.argv[2]

        # send the request to the server
        response = client.get(key)

        print(response.value)
        sys.exit(0)

    elif cmd == "set":
        # ensure a key and value were provided
        if len(sys.argv) < 4:
            print(USAGE)
            sys.exit(1)

        # get the key and the full text of value
        key = sys.argv[2]
        value = " ".join(sys.argv[3:])

        # send the request to the server
        response = client.set(key, value)

        print("setf %s to %s" % (key, value))


if __name__ == '__main__':
    main()
static_resources:
  listeners:
  - address:
      socket_address:
        address: 0.0.0.0
        port_value: 9911
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          codec_type: AUTO
          add_user_agent: true
          access_log:
          - name: envoy.access_loggers.stdout
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.access_loggers.stream.v3.StdoutAccessLog
          stat_prefix: egress_http
          common_http_protocol_options:
            idle_timeout: 0.840s
          use_remote_address: true
          route_config:
            name: local_route
            virtual_hosts:
            - name: backend
              domains:
              - grpc
              routes:
              - match:
                  prefix: "/"
                route:
                  cluster: backend-proxy
          http_filters:
          - name: envoy.filters.http.grpc_http1_bridge
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.grpc_http1_bridge.v3.Config
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
  clusters:
  - name: backend-proxy
    type: LOGICAL_DNS
    dns_lookup_family: V4_ONLY
    lb_policy: ROUND_ROBIN
    typed_extension_protocol_options:
      envoy.extensions.upstreams.http.v3.HttpProtocolOptions:
        "@type": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions
        explicit_http_config:
          http_protocol_options: {}
    load_assignment:
      cluster_name: backend-proxy
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: grpc-server-proxy
                port_value: 8811
requests>=2.22.0
grpcio
grpcio-tools
protobuf>=3.18.0
#!/usr/bin/env bash
set -ex

rm /srv/runtime/v1/envoy/fault/http/delay/fixed_delay_percent
rm /srv/runtime/v1/envoy/fault/http/delay/fixed_duration_ms

pushd /srv/runtime
ln -s /srv/runtime/v1 new && mv -Tf new current
popd
services:
  envoy:
    build:
      context: .
      dockerfile: ../shared/envoy/Dockerfile
      target: envoy-fault-injection
    volumes:
    - ./runtime:/srv/runtime
    ports:
    - 9211:9211

  backend:
    build:
      context: .
      dockerfile: Dockerfile-backend
    ports:
    - ${PORT_PROXY:-8080}:80
static_resources:
  listeners:
  - address:
      socket_address:
        address: 0.0.0.0
        port_value: 9211
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          codec_type: AUTO
          stat_prefix: ingress_http
          access_log:
          - name: envoy.access_loggers.stdout
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.access_loggers.stream.v3.StdoutAccessLog
          route_config:
            name: local_route
            virtual_hosts:
            - name: service
              domains:
              - "*"
              routes:
              - match:
                  prefix: /
                route:
                  cluster: local_service
          http_filters:
          - name: envoy.filters.http.fault
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.fault.v3.HTTPFault
              abort:
                http_status: 503
                percentage:
                  numerator: 0
                  denominator: HUNDRED
              delay:
                fixed_delay: 3s
                percentage:
                  numerator: 0
                  denominator: HUNDRED
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
  clusters:
  - name: local_service
    type: STRICT_DNS
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: local_service
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: backend
                port_value: 80
layered_runtime:
  layers:
  - name: disk_layer_0
    disk_layer:
      symlink_root: /srv/runtime/current
      subdirectory: envoy
#!/usr/bin/env bash
set -ex

rm /srv/runtime/v1/envoy/fault/http/abort/abort_percent
rm /srv/runtime/v1/envoy/fault/http/abort/http_status

pushd /srv/runtime
ln -s /srv/runtime/v1 new && mv -Tf new current
popd
#!/bin/bash -e

export NAME=fault-injection
export PORT_PROXY="${FAULT_INJECTION_PORT_PROXY:-10610}"

# shellcheck source=examples/verify-common.sh
. "$(dirname "${BASH_SOURCE[0]}")/../verify-common.sh"


run_log "Send requests for 20 seconds"
"${DOCKER_COMPOSE[@]}" exec -T envoy bash -c \
               "bash send_request.sh & export pid=\$! && sleep 20 && kill \$pid" \
    &> /dev/null

run_log "Check logs"
"${DOCKER_COMPOSE[@]}" logs | grep "HTTP/1.1\" 200"


_fault_injection_test () {
    local action code existing_200s existing_codes
    action="$1"
    code="$2"
    existing_codes=0

    # enable fault injection and check for http hits of type $code
    existing_codes=$("${DOCKER_COMPOSE[@]}" logs | grep -c "HTTP/1.1\" ${code}" || :)
    run_log "Enable ${action} fault injection"
    "${DOCKER_COMPOSE[@]}" exec -T envoy bash "enable_${action}_fault_injection.sh"
    run_log "Send requests for 20 seconds"
    "${DOCKER_COMPOSE[@]}" exec -T envoy bash -c \
                   "bash send_request.sh & export pid=\$! && sleep 20 && kill \$pid" \
        &> /dev/null
    run_log "Check logs again"
    new_codes=$("${DOCKER_COMPOSE[@]}" logs | grep -c "HTTP/1.1\" ${code}")
    if [[ "$new_codes" -le "$existing_codes" ]]; then
        echo "ERROR: expected to find new logs with response code $code" >&2
        return 1
    fi

    # disable fault injection and check for http hits of type 200
    existing_200s=$("${DOCKER_COMPOSE[@]}" logs | grep -c "HTTP/1.1\" 200")
    run_log "Disable ${action} fault injection"
    "${DOCKER_COMPOSE[@]}" exec -T envoy bash "disable_${action}_fault_injection.sh"
    run_log "Send requests for 20 seconds"
    "${DOCKER_COMPOSE[@]}" exec -T envoy bash -c \
                   "bash send_request.sh & export pid=\$! && sleep 20 && kill \$pid" \
        &> /dev/null
    run_log "Check logs again"
    new_200s=$("${DOCKER_COMPOSE[@]}" logs | grep -c "HTTP/1.1\" 200")
    if [[ "$new_200s" -le "$existing_200s" ]]; then
        echo "ERROR: expected to find new logs with response code 200" >&2
        return 1
    fi
}

_fault_injection_test abort 503
_fault_injection_test delay 200

run_log "Check tree"
"${DOCKER_COMPOSE[@]}" exec -T envoy tree /srv/runtime
To learn about this sandbox and for instructions on how to run it please head over
to the [Envoy docs](https://www.envoyproxy.io/docs/envoy/latest/start/sandboxes/fault_injection.html).
#!/usr/bin/env bash
set -ex

mkdir -p /srv/runtime/v1/envoy/fault/http/abort
echo '100' > /srv/runtime/v1/envoy/fault/http/abort/abort_percent
echo '503' > /srv/runtime/v1/envoy/fault/http/abort/http_status

pushd /srv/runtime
ln -s /srv/runtime/v1 new && mv -Tf new current
popd
/runtime/
#!/usr/bin/env bash
set -ex

mkdir -p /srv/runtime/v1/envoy/fault/http/delay
echo '50' > /srv/runtime/v1/envoy/fault/http/delay/fixed_delay_percent
echo '3000' > /srv/runtime/v1/envoy/fault/http/delay/fixed_duration_ms

pushd /srv/runtime
ln -s /srv/runtime/v1 new && mv -Tf new current
popd
FROM kennethreitz/httpbin@sha256:599fe5e5073102dbb0ee3dbb65f049dab44fa9fc251f6835c9990f8fb196a72b
#!/usr/bin/env bash
set -ex

while :; do
  curl -v localhost:9211/status/200
  sleep 1
done
import logging
import os

from aiohttp import web

routes = web.RouteTableDef()
healthy = True


@routes.get("/")
async def get(request):
    global healthy
    if healthy:
        return web.Response(text=f"Hello from {os.environ['HOST']}!\n")
    else:
        raise web.HTTPServiceUnavailable(reason="Unhealthy")


@routes.get("/healthy")
async def healthy(request):
    global healthy
    healthy = True
    return web.Response(text=f"[{os.environ['HOST']}] Set to healthy\n", status=201)


@routes.get("/unhealthy")
async def unhealthy(request):
    global healthy
    healthy = False
    return web.Response(text=f"[{os.environ['HOST']}] Set to unhealthy\n", status=201)


if __name__ == "__main__":
    app = web.Application()
    logging.basicConfig(level=logging.DEBUG)
    app.add_routes(routes)
    web.run_app(app, host='0.0.0.0', port=8080)
services:

  client-envoy:
    build:
      context: .
      dockerfile: ../shared/envoy/Dockerfile
      target: envoy-load-balancing
    depends_on:
      backend-local-1:
        condition: service_healthy
      backend-local-2:
        condition: service_healthy
      backend-remote-1:
        condition: service_healthy
      backend-remote-2:
        condition: service_healthy

  backend-local-1:
    build:
      context: ../shared/python
      target: aiohttp-service
    volumes:
    - ./service.py:/code/service.py
    environment:
    - HOST=backend-local-1

  backend-local-2:
    build:
      context: ../shared/python
      target: aiohttp-service
    volumes:
    - ./service.py:/code/service.py
    environment:
    - HOST=backend-local-2

  backend-remote-1:
    build:
      context: ../shared/python
      target: aiohttp-service
    volumes:
    - ./service.py:/code/service.py
    environment:
    - HOST=backend-remote-1

  backend-remote-2:
    build:
      context: ../shared/python
      target: aiohttp-service
    volumes:
    - ./service.py:/code/service.py
    environment:
    - HOST=backend-remote-2
admin:
  address:
    socket_address:
      address: 0.0.0.0
      port_value: 8001
static_resources:
  listeners:
  - name: backend
    address:
      socket_address:
        address: 0.0.0.0
        port_value: 3000
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          codec_type: AUTO
          stat_prefix: ingress_http
          route_config:
            name: local_route
            virtual_hosts:
            - name: backend
              domains:
              - "*"
              routes:
              - match:
                  prefix: "/"
                route:
                  cluster: backend
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
  clusters:
  - name: backend
    type: STRICT_DNS
    lb_policy: ROUND_ROBIN
    common_lb_config:
      locality_weighted_lb_config: {}
    health_checks:
    - interval: 2s
      timeout: 3s
      no_traffic_interval: 4s
      no_traffic_healthy_interval: 4s
      unhealthy_threshold: 1
      healthy_threshold: 1
      http_health_check:
        path: "/"
    load_assignment:
      cluster_name: backend
      endpoints:
      - locality:
          region: local
          zone: zone-1
        load_balancing_weight: 1
        priority: 0  # highest
        lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: backend-local-1
                port_value: 8080
            health_check_config:
              port_value: 8080
            hostname: backend-local-1
      - locality:
          region: local
          zone: zone-2
        load_balancing_weight: 1
        priority: 1
        lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: backend-local-2
                port_value: 8080
            health_check_config:
              port_value: 8080
            hostname: backend-local-2
      - locality:
          region: remote
          zone: zone-1
        load_balancing_weight: 1
        priority: 1
        lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: backend-remote-1
                port_value: 8080
            health_check_config:
              port_value: 8080
            hostname: backend-remote-1
      - locality:
          region: remote
          zone: zone-2
        load_balancing_weight: 1
        priority: 2
        lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: backend-remote-2
                port_value: 8080
            health_check_config:
              port_value: 8080
            hostname: backend-remote-2
import sys
import urllib.request
from collections import Counter

url, n_requests = sys.argv[1], int(sys.argv[2])

count = Counter()
count_fail = 0

for i in range(n_requests):
    try:
        with urllib.request.urlopen(url) as resp:
            content = resp.read().decode("utf-8").strip()
            count[content] += 1
    except:
        count_fail += 1

for k in count:
    print(f"{k}: actual weight {count[k] / n_requests * 100}%")
print(f"Failed: {count_fail}")
#!/bin/bash -e

export NAME=locality-load-balancing


# shellcheck source=examples/verify-common.sh
. "$(dirname "${BASH_SOURCE[0]}")/../verify-common.sh"


dump_clusters () {
    "${DOCKER_COMPOSE[@]}" exec -T client-envoy curl -s "localhost:8001/clusters"
}

check_health() {
    local ip_address
    ip_address="$(docker inspect --format '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' "${NAME}-${1}")"
    dump_clusters  | grep "backend::${ip_address}:8080::health_flags::${2}"
}

check_backend() {
    output=$("${DOCKER_COMPOSE[@]}" exec -T client-envoy python3 client.py http://localhost:3000/ 100)
    echo "$output"
    for expected in "$@"; do
        count=$(echo "$output" | grep -c "$expected" | xargs)
        if [ "$count" -eq 0 ]; then
            echo "Test fail: locality $expected is expected to be routed to."
            return 1
        fi
    done
}

make_healthy() {
    "${DOCKER_COMPOSE[@]}" exec -T client-envoy curl -s "${NAME}-${1}:8080/healthy"
    wait_for 5 check_health "${1}" healthy
}

make_unhealthy() {
    "${DOCKER_COMPOSE[@]}" exec -T client-envoy curl -s "${NAME}-${1}:8080/unhealthy"
    wait_for 5 check_health "${1}" /failed_active_hc
}

run_log "Wait for backend clusters to become healthy."
wait_for 5 check_health backend-local-1-1 healthy
wait_for 5 check_health backend-local-2-1 healthy
wait_for 5 check_health backend-remote-1-1 healthy
wait_for 5 check_health backend-remote-2-1 healthy

run_log "Dump configured Envoy clusters"
dump_clusters

run_log "=== Demo setup
client  -> backend-local-1      [priority: 0, weight: 1]
        -> backend-local-2      [priority: 1, weight: 1]
        -> backend-remote-1     [priority: 1, weight: 1]
        -> backend-remote-2     [priority: 2, weight: 1]
"

run_log "=== Scenario 1: one replica in the highest priority locality"

run_log "Send requests to backend."
wait_for 5 check_health backend-local-1-1 healthy
check_backend backend-local-1

run_log "Bring down backend-local-1. Priority 0 locality is 0% healthy."
make_unhealthy backend-local-1-1

run_log "Send requests to backend."
check_backend backend-local-2 backend-remote-1

run_log "Bring down backend-local-2. Priority 1 locality is 50% healthy."
make_unhealthy backend-local-2-1

run_log "Traffic is load balanced goes to remote only."
check_backend backend-remote-1 backend-remote-2

run_log "=== Scenario 2: multiple replica in the highest priority locality"
run_log "Recover local-1 and local-2"
make_healthy backend-local-1-1
make_healthy backend-local-2-1

run_log "Scale backend-local-1 to 5 replicas."
"${DOCKER_COMPOSE[@]}" -p "${NAME}" up --scale backend-local-1=5 -d --build
wait_for 5 check_health backend-local-1-2 healthy
wait_for 5 check_health backend-local-1-3 healthy
wait_for 5 check_health backend-local-1-4 healthy
wait_for 5 check_health backend-local-1-5 healthy

run_log "Bring down 4 replicas in backend-local-1. Priority 0 locality is 20% healthy."
make_unhealthy backend-local-1-2
make_unhealthy backend-local-1-3
make_unhealthy backend-local-1-4
make_unhealthy backend-local-1-5

run_log "Send requests to backend."
check_backend backend-local-1 backend-local-2 backend-remote-1

run_log "Bring down all endpoints of priority 1. Priority 1 locality is 0% healthy."
make_unhealthy backend-local-2-1
make_unhealthy backend-remote-1-1

run_log "Send requests to backend."
check_backend backend-local-1 backend-remote-2
# The Google Python styles can be found here: https://github.com/google/styleguide/blob/gh-pages/pyguide.md
# TODO: Look into enforcing single vs double quote.
[style]
based_on_style=Google
indent_width=4
column_limit=100
split_before_first_argument=True
coalesce_brackets=True
split_before_logical_operator=True
split_complex_comprehension=True
split_before_expression_after_opening_paren=True
split_before_dict_set_generator=True
split_before_arithmetic_operator=True
split_before_bitwise_operator=True
# blank_line_before_nested_def_
--- rust/private/rustc.bzl
+++ rust/private/rustc.bzl
@@ -1451,7 +1451,7 @@ def rustc_compile_action(
         })
         crate_info = rust_common.create_crate_info(**crate_info_dict)
 
-    if crate_info.type in ["staticlib", "cdylib"]:
+    if crate_info.type in ["staticlib", "cdylib"] and not out_binary:
         # These rules are not supposed to be depended on by other rust targets, and
         # as such they shouldn't provide a CrateInfo. However, one may still want to
         # write a rust_test for them, so we provide the CrateInfo wrapped in a provider
# DO NOT LOAD THIS FILE. Load envoy_build_system.bzl instead.
# Envoy binary targets
load(
    ":envoy_internal.bzl",
    "envoy_copts",
    "envoy_dbg_linkopts",
    "envoy_exported_symbols_input",
    "envoy_external_dep_path",
    "envoy_select_exported_symbols",
    "envoy_stdlib_deps",
    "tcmalloc_external_dep",
)

# Envoy C++ binary targets should be specified with this function.
def envoy_cc_binary(
        name,
        srcs = [],
        data = [],
        testonly = 0,
        visibility = None,
        external_deps = [],
        repository = "",
        stamp = 1,
        stamped = False,
        deps = [],
        linkopts = [],
        tags = [],
        features = []):
    linker_inputs = envoy_exported_symbols_input()

    if not linkopts:
        linkopts = _envoy_linkopts()
    if stamped:
        linkopts = linkopts + _envoy_stamped_linkopts()
        deps = deps + _envoy_stamped_deps()
    linkopts += envoy_dbg_linkopts()
    deps = deps + [envoy_external_dep_path(dep) for dep in external_deps] + envoy_stdlib_deps()
    native.cc_binary(
        name = name,
        srcs = srcs,
        data = data,
        additional_linker_inputs = linker_inputs,
        copts = envoy_copts(repository),
        linkopts = linkopts,
        testonly = testonly,
        linkstatic = 1,
        visibility = visibility,
        malloc = tcmalloc_external_dep(repository),
        stamp = stamp,
        deps = deps,
        tags = tags,
        features = features,
    )

# Compute the final linkopts based on various options.
def _envoy_linkopts():
    return select({
        "@envoy//bazel:apple": [
            # https://github.com/envoyproxy/envoy/issues/24782
            "-Wl,-framework,CoreFoundation",
            # https://github.com/bazelbuild/bazel/pull/16414
            "-Wl,-undefined,error",
        ],
        "@envoy//bazel:windows_opt_build": [
            "-DEFAULTLIB:ws2_32.lib",
            "-DEFAULTLIB:iphlpapi.lib",
            "-DEFAULTLIB:shell32.lib",
            "-DEBUG:FULL",
            "-WX",
        ],
        "@envoy//bazel:windows_x86_64": [
            "-DEFAULTLIB:ws2_32.lib",
            "-DEFAULTLIB:iphlpapi.lib",
            "-DEFAULTLIB:shell32.lib",
            "-WX",
        ],
        "//conditions:default": [
            "-pthread",
            "-lrt",
            "-ldl",
            "-Wl,-z,relro,-z,now",
            "-Wl,--hash-style=gnu",
        ],
    }) + select({
        "@envoy//bazel:apple": [],
        "@envoy//bazel:boringssl_fips": [],
        "@envoy//bazel:windows_x86_64": [],
        "//conditions:default": ["-pie"],
    }) + envoy_select_exported_symbols(["-Wl,-E"])

def _envoy_stamped_deps():
    return select({
        "@envoy//bazel:windows_x86_64": [],
        "@envoy//bazel:apple": [
            "@envoy//bazel:raw_build_id.ldscript",
        ],
        "//conditions:default": [
            "@envoy//bazel:gnu_build_id.ldscript",
        ],
    })

def _envoy_stamped_linkopts():
    return select({
        # Coverage builds in CI are failing to link when setting a build ID.
        #
        # /usr/bin/ld.gold: internal error in write_build_id, at ../../gold/layout.cc:5419
        "@envoy//bazel:coverage_build": [],
        "@envoy//bazel:windows_x86_64": [],

        # macOS doesn't have an official equivalent to the `.note.gnu.build-id`
        # ELF section, so just stuff the raw ID into a new text section.
        "@envoy//bazel:apple": [
            "-sectcreate __TEXT __build_id",
            "$(location @envoy//bazel:raw_build_id.ldscript)",
        ],

        # Note: assumes GNU GCC (or compatible) handling of `--build-id` flag.
        "//conditions:default": [
            "-Wl,@$(location @envoy//bazel:gnu_build_id.ldscript)",
        ],
    })
diff --git a/BUILD b/BUILD
index 69c9bda..d293092 100644
--- a/BUILD
+++ b/BUILD
@@ -88,7 +88,7 @@ cc_library(
         ":headers",
     ] + select({
         "//bazel:crypto_system": [],
-        "//conditions:default": ["@boringssl//:crypto"],
+        "//conditions:default": ["@envoy//bazel:boringcrypto"],
     }),
     alwayslink = 1,
 )
def _default_envoy_api_impl(ctx):
    ctx.file("WORKSPACE", "")
    api_dirs = [
        "BUILD",
        "bazel",
        "envoy",
        "examples",
        "test",
        "tools",
        "versioning",
        "contrib",
        "buf.yaml",
    ]
    for d in api_dirs:
        ctx.symlink(ctx.path(ctx.attr.envoy_root).dirname.get_child(ctx.attr.reldir).get_child(d), d)

_default_envoy_api = repository_rule(
    implementation = _default_envoy_api_impl,
    attrs = {
        "envoy_root": attr.label(default = "@envoy//:BUILD"),
        "reldir": attr.string(),
    },
)

def envoy_api_binding():
    # Treat the data plane API as an external repo, this simplifies exporting
    # the API to https://github.com/envoyproxy/data-plane-api.
    if "envoy_api" not in native.existing_rules().keys():
        _default_envoy_api(name = "envoy_api", reldir = "api")

    # TODO(https://github.com/envoyproxy/envoy/issues/7719) need to remove both bindings and use canonical rules
    native.bind(
        name = "api_httpbody_protos",
        actual = "@com_google_googleapis//google/api:httpbody_cc_proto",
    )
    native.bind(
        name = "http_api_protos",
        actual = "@com_google_googleapis//google/api:annotations_cc_proto",
    )
#!/bin/bash

# This file was imported from https://github.com/bazelbuild/bazel at d6fec93.

# This script will be run bazel when building process starts to
# generate key-value information that represents the status of the
# workspace. The output should be like
#
# KEY1 VALUE1
# KEY2 VALUE2
#
# If the script exits with non-zero code, it's considered as a failure
# and the output will be discarded.

# For Envoy in particular, we want to force binaries to relink when the Git
# SHA changes (https://github.com/envoyproxy/envoy/issues/2551). This can be
# done by prefixing keys with "STABLE_". To avoid breaking compatibility with
# other status scripts, this one still echos the non-stable ("volatile") names.

# If this SOURCE_VERSION file exists then it must have been placed here by a
# distribution doing a non-git, source build.
# Distributions would be expected to echo the commit/tag as BUILD_SCM_REVISION
if [ -f SOURCE_VERSION ]
then
    echo "BUILD_SCM_REVISION $(cat SOURCE_VERSION)"
    echo "ENVOY_BUILD_SCM_REVISION $(cat SOURCE_VERSION)"
    echo "STABLE_BUILD_SCM_REVISION $(cat SOURCE_VERSION)"
    echo "BUILD_SCM_STATUS Distribution"
    exit 0
fi

if [[ -n "$BAZEL_FAKE_SCM_REVISION" ]]; then
    echo "BUILD_SCM_REVISION $BAZEL_FAKE_SCM_REVISION"
    echo "ENVOY_BUILD_SCM_REVISION $BAZEL_FAKE_SCM_REVISION"
    echo "STABLE_BUILD_SCM_REVISION $BAZEL_FAKE_SCM_REVISION"
else
    # The code below presents an implementation that works for git repository
    git_rev=$(git rev-parse HEAD) || exit 1
    echo "BUILD_SCM_REVISION ${git_rev}"
    echo "ENVOY_BUILD_SCM_REVISION ${git_rev}"
    echo "STABLE_BUILD_SCM_REVISION ${git_rev}"
fi

# If BAZEL_VOLATILE_DIRTY is set then stamped builds will rebuild uncached when
# either a tracked file changes or an untracked file is added or removed.
# Otherwise this just tracks changes to tracked files.
tracked_hash="$(git ls-files -s | sha256sum | head -c 40)"
if [[ -n "$BAZEL_VOLATILE_DIRTY" ]]; then
    porcelain_status="$(git status --porcelain | sha256sum)"
    diff_status="$(git --no-pager diff | sha256sum)"
    tree_hash="$(echo "${tracked_hash}:${porcelain_status}:${diff_status}" | sha256sum | head -c 40)"
    echo "BUILD_SCM_HASH ${tree_hash}"
else
    echo "BUILD_SCM_HASH ${tracked_hash}"
fi

# Check whether there are any uncommitted changes
tree_status="Clean"
git diff-index --quiet HEAD -- || {
    tree_status="Modified"
}

echo "BUILD_SCM_STATUS ${tree_status}"
echo "STABLE_BUILD_SCM_STATUS ${tree_status}"

git_branch=$(git rev-parse --abbrev-ref HEAD)
echo "BUILD_SCM_BRANCH ${git_branch}"

git_remote=$(git remote get-url origin)
if [[ -n "$git_remote" ]]; then
    echo "BUILD_SCM_REMOTE ${git_remote}"
fi
load("@aspect_bazel_lib//lib:repositories.bzl", "aspect_bazel_lib_dependencies")
load("@com_github_rules_proto_grpc//:repositories.bzl", "rules_proto_grpc_toolchains")
load("@emsdk//:deps.bzl", emsdk_deps = "deps")
load("@proxy_wasm_cpp_host//bazel/cargo/wasmtime:crates.bzl", "wasmtime_fetch_remote_crates")
load("@rules_python//python:repositories.bzl", "py_repositories", "python_register_toolchains")
load("//bazel/external/cargo:crates.bzl", "raze_fetch_remote_crates")

def _python_minor_version(python_version):
    return "_".join(python_version.split(".")[:-1])

# Python version for `rules_python`
PYTHON_VERSION = "3.11.3"
PYTHON_MINOR_VERSION = _python_minor_version(PYTHON_VERSION)

# Envoy deps that rely on a first stage of dependency loading in envoy_dependencies().
def envoy_dependencies_extra(
        python_version = PYTHON_VERSION,
        ignore_root_user_error = False):
    emsdk_deps()
    raze_fetch_remote_crates()
    wasmtime_fetch_remote_crates()
    rules_proto_grpc_toolchains()
    py_repositories()

    # Registers underscored Python minor version - eg `python3_10`
    python_register_toolchains(
        name = "python%s" % _python_minor_version(python_version),
        python_version = python_version,
        ignore_root_user_error = ignore_root_user_error,
    )

    aspect_bazel_lib_dependencies()
#!/bin/bash

# Used in a genrule to wrap sh_test script for execution in
# //test/coverage:coverage_tests single binary.

# Do not generate test suites for empty source files.
if [ -z "$1" ]; then
  exit 0
fi

RAW_TEST_NAME="$(basename "$1")"
# Normalize to something we can use in a TEST(ShTest, ...) name
TEST_NAME="${RAW_TEST_NAME//./_}"

EXEC_ARGS="\"$1\""
shift
for a in "$@"
do
  EXEC_ARGS="${EXEC_ARGS}, \"$a\""
done

(
  cat << EOF
#include "test/test_common/environment.h"

#include "gtest/gtest.h"

TEST(ShTest, ${TEST_NAME}) {
  Envoy::TestEnvironment::exec({${EXEC_ARGS}});
}
EOF
)
   Bud1                                                                       r a g edscl                                           c o v e r a g edsclbool     e x t e r n a ldsclbool                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        @                                              @                                                @                                                @                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   E                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          DSDB                                 `                                                   @                                                @                                                @                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              diff --git a/BUILD.bazel b/BUILD.bazel
index 8099642a85..3598661079 100644
--- a/BUILD.bazel
+++ b/BUILD.bazel
@@ -40,7 +40,7 @@ exports_files(["LICENSE"])

 config_setting(
     name = "windows",
-    constraint_values = ["@bazel_tools//platforms:windows"],
+    constraint_values = ["@platforms//os:windows"],
 )

 config_setting(
--- pkg/private/BUILD
+++ pkg/private/BUILD
@@ -55,6 +55,9 @@ exports_files(
 config_setting(
     name = "private_stamp_detect",
     values = {"stamp": "1"},
+    # When --incompatible_config_setting_private_default_visibility is set, this fails unless this is public.
+    # TODO: refactor to clear up confusion that this is a "private" target with public access.
+    visibility = ["//visibility:public"],
 )

 py_library(
#!/bin/bash

set -ex

# Clear existing tap directory if previous run wasn't in sandbox
rm -rf tap

mkdir -p tap
TAP_TMP="$(realpath tap)"

TAP_PATH="${TAP_TMP}/tap" "$@"

# TODO(htuch): Check for pcap, now CI (with or without RBE) does have
# enough capabilities.
# Verify that some pb_text files have been created.
ls -l "${TAP_TMP}"/tap_*.pb_text > /dev/null
licenses(["notice"])  # Apache 2

exports_files(["verify_tap_test.sh"])
# Proxy-Wasm tests

WebAssembly tests are built using [Proxy-Wasm C++ SDK] and [Proxy-Wasm Rust SDK],
as such, they bring their own set of dependencies.

## Cargo dependencies.

In order to update Cargo dependencies, please make sure that Rust and Cargo
are installed, and run this tool:

```
bash tools/update_crates.sh
```

which will regenerate Bazel rules in `bazel/external/cargo/`.


[Proxy-Wasm C++ SDK]: https://github.com/proxy-wasm/proxy-wasm-cpp-sdk
[Proxy-Wasm Rust SDK]: https://github.com/proxy-wasm/proxy-wasm-rust-sdk
#
# Bazel RBE on Windows GCP workers currently will not invoke cmd.exe batch files correctly
#
# Symptom is program not found 'bazel-out', because of the way that the CreateProcess command
# is constructed by bazel with actions.run with forward slashes, e.g. the command
#   cmd.exe /c "bazel-out/host/bin/external/go_sdk/builder.exe.bat"
# where cmd.exe on GCP is treating 'bazel-out' as the target, and /host as a command line switch.
# This problem was not observed on Azure CI pipelines or locally by the developers. The eventual
# fix is not specific to rules_go; this patch simply addresses immediate breakage and can be removed
# once the underlying issue within Bazel/RBE is fixed.
# See:
# - https://github.com/bazelbuild/rules_go/pull/2542
# - https://github.com/envoyproxy/envoy/issues/11657
#
diff --git a/go/private/rules/binary.bzl b/go/private/rules/binary.bzl
index 91748eda..c1aeb91e 100644
--- a/go/private/rules/binary.bzl
+++ b/go/private/rules/binary.bzl
@@ -443,8 +443,9 @@ def _go_tool_binary_impl(ctx):
             content = cmd,
         )
         ctx.actions.run(
-            executable = bat,
-            inputs = sdk.headers + sdk.tools + sdk.srcs + ctx.files.srcs + [sdk.go],
+            executable = "cmd.exe",
+            arguments = ["/S", "/C", bat.path.replace("/", "\\")],
+            inputs = sdk.headers + sdk.tools + sdk.srcs + ctx.files.srcs + [sdk.go, bat],
             outputs = [out, gopath, gocache],
             mnemonic = "GoToolchainBinaryBuild",
         )
#!/bin/bash -e

BAZELRC_FILE="${BAZELRC_FILE:-./clang.bazelrc}"

LLVM_PREFIX=$1

if [[ ! -e "${LLVM_PREFIX}/bin/llvm-config" ]]; then
  echo "Error: cannot find local llvm-config in ${LLVM_PREFIX}."
  exit 1
fi

PATH="$("${LLVM_PREFIX}"/bin/llvm-config --bindir):${PATH}"
export PATH

LLVM_VERSION="$(llvm-config --version)"
LLVM_LIBDIR="$(llvm-config --libdir)"
LLVM_TARGET="$(llvm-config --host-target)"

RT_LIBRARY_PATH="${LLVM_LIBDIR}/clang/${LLVM_VERSION}/lib/${LLVM_TARGET}"

echo "# Generated file, do not edit. If you want to disable clang, just delete this file.
build:clang --action_env='PATH=${PATH}' --host_action_env='PATH=${PATH}'
build:clang --action_env=CC=clang --host_action_env=CC=clang
build:clang --action_env=CXX=clang++ --host_action_env=CXX=clang++
build:clang --action_env='LLVM_CONFIG=${LLVM_PREFIX}/bin/llvm-config' --host_action_env='LLVM_CONFIG=${LLVM_PREFIX}/bin/llvm-config'
build:clang --repo_env='LLVM_CONFIG=${LLVM_PREFIX}/bin/llvm-config'
build:clang --linkopt='-L$(llvm-config --libdir)'
build:clang --linkopt='-Wl,-rpath,$(llvm-config --libdir)'

build:clang-asan --action_env=ENVOY_UBSAN_VPTR=1
build:clang-asan --copt=-fsanitize=vptr,function
build:clang-asan --linkopt=-fsanitize=vptr,function
build:clang-asan --linkopt='-L${RT_LIBRARY_PATH}'
build:clang-asan --linkopt=-l:libclang_rt.ubsan_standalone.a
build:clang-asan --linkopt=-l:libclang_rt.ubsan_standalone_cxx.a
" >"${BAZELRC_FILE}"
diff --git a/BUILD b/BUILD
index 206786442..c0b3de699 100644
--- a/BUILD
+++ b/BUILD
@@ -140,6 +140,7 @@ cc_library(
         "@platforms//os:windows": ["-defaultlib:advapi32.lib"],
         "//conditions:default": ["-pthread"],
     }),
+    linkstatic = True,
     visibility = ["//visibility:public"],
 )
 
@@ -149,6 +150,7 @@ cc_library(
     hdrs = ssl_headers,
     copts = boringssl_copts_cxx,
     includes = ["src/include"],
+    linkstatic = True,
     visibility = ["//visibility:public"],
     deps = [
         ":crypto",
#!/bin/bash

# Set the benchmark time to 0 to just verify that the benchmark runs to
# completion.  We're interacting with two different flag parsers, so the order
# of flags and the -- matters.
"${TEST_SRCDIR}/envoy/${1}" "${@:2}" --skip_expensive_benchmarks -- --benchmark_min_time=0
# Choosing tarballs

Where the dependency maintainer provides a tarball, prefer that over the
automatically generated Github tarball. Github generated tarball SHA256
values can change when Github change their tar/gzip libraries breaking
builds. Maintainer provided tarballs are more stable and the maintainer
can provide the SHA256.

# Adding external dependencies to Envoy (C++)

## Native Bazel

This is the preferred style of adding dependencies that use Bazel for their
build process.

1. Define a new Bazel repository in [`bazel/repositories.bzl`](repositories.bzl),
   in the `envoy_dependencies()` function.
2. Reference your new external dependency in some `envoy_cc_library` via the
   `external_deps` attribute.
3. `bazel test //test/...`

## External CMake (preferred)

This is the preferred style of adding dependencies that use CMake for their build system.

1. Define a the source Bazel repository in [`bazel/repositories.bzl`](repositories.bzl), in the
   `envoy_dependencies()` function.
2. Add an `envoy_cmake` rule to [`bazel/foreign_cc/BUILD`](foreign_cc/BUILD). This will reference
   the source repository in step 1.
3. Reference your new external dependency in some `envoy_cc_library` via the name bound in step 1
   `external_deps` attribute.
4. `bazel test //test/...`

# Adding external dependencies to Envoy (Python)

Python dependencies should be added via `pip` and `rules_python`. The process
is:

1. Define a `pip_install()` pointing at your target `requirements.txt` in
   [`bazel/repositories_extra.bzl`](repositories_extra.bzl)

2. Add a `requirements("<package name>")` in the `BUILD` file that depends on
   this package.

You can use [`tools/config_validation/BUILD`](../tools/config_validation/BUILD) as an example
for this flow. See also the [`rules_python`](https://github.com/bazelbuild/rules_python)
documentation for further references.

# Updating an external dependency version

1. Update the corresponding entry in
[the repository locations file.](https://github.com/envoyproxy/envoy/blob/main/bazel/repository_locations.bzl)
2. `bazel test //test/...`

# Overriding an external dependency temporarily

An external dependency built by genrule repository or native Bazel could be overridden by
specifying Bazel option
[`--override_repository`](https://docs.bazel.build/versions/master/command-line-reference.html)
to point to a local copy. The option can used multiple times to override multiple dependencies.
The name of the dependency can be found in
[the repository locations file.](https://github.com/envoyproxy/envoy/blob/main/bazel/repository_locations.bzl)
The path of the local copy has to be absolute path.

For repositories built by `envoy_cmake()` in `bazel/foreign_cc/BUILD`,
it is necessary to populate the local copy with some additional Bazel machinery
to support `--override_repository`:
1. Place an empty `WORKSPACE` in the root.
2. Place a `BUILD` file with `filegroup(name = "all", srcs = glob(["**"]), visibility = ["//visibility:public"])`
   in the root.

# Debugging external dependencies

For all external dependencies, overriding with a local copy as described in the
previous section is a useful tool.

Below we describe specific tips for obtaining additional debug for specific
dependencies:

* `libevent`: add `"EVENT__ENABLE_VERBOSE_DEBUG": "on",` to `cache_entries`
  in the `event` target in `bazel/foreign_cc/BUILD` for verbose tracing of
  libevent processing.

* `nghttp2`: set `ENVOY_NGHTTP2_TRACE` in the environment and run at `-l trace`.

* `QUICHE`: set `ENVOY_QUICHE_VERBOSITY=n` in the environment to display
  verbose logs up to level `n`.

# Distdir - prefetching dependencies

Usually Bazel downloads all dependencies during build time. But there is a
possibility to prefetch dependencies and point Bazel to them by using `--distdir`
option and providing a path to directory which contains tarballs with exactly
the same name and the same SHA256 sum that are defined in repositories
definitions.

For example, let's assume that your distdir location is `$HOME/envoy_distdir`.
To prefetch `boringssl` which is defined in `bazel/repository_locations.bzl` as:

```
boringssl = dict(
    # Use commits from branch "chromium-stable-with-bazel"
    sha256 = "d1700e0455f5f918f8a85ff3ce6cd684d05c766200ba6bdb18c77d5dcadc05a1",
    strip_prefix = "boringssl-060e9a583976e73d1ea8b2bfe8b9cab33c62fa17",
    # chromium-70.0.3538.67
    urls = ["https://github.com/google/boringssl/archive/060e9a583976e73d1ea8b2bfe8b9cab33c62fa17.tar.gz"],
),
```

`$HOME/envoy_distdir` needs to contain `060e9a583976e73d1ea8b2bfe8b9cab33c62fa17.tar.gz`
file.

Then Envoy needs to be built with the following command:

```
bazel build --distdir=$HOME/envoy_distdir //source/exe:envoy
```
# fix include types for late clang (15.0.7) / gcc (13.2.1)
# for Arch linux / Fedora, like in
#     In file included from external/v8/src/torque/torque.cc:5:
#     In file included from external/v8/src/torque/source-positions.h:10:
#     In file included from external/v8/src/torque/contextual.h:10:
#     In file included from external/v8/src/base/macros.h:12:
#     external/v8/src/base/logging.h:154:26: error: use of undeclared identifier 'uint16_t'

diff --git a/src/base/logging.h b/src/base/logging.h
--- a/src/base/logging.h
+++ b/src/base/logging.h
@@ -5,6 +5,7 @@
 #ifndef V8_BASE_LOGGING_H_
 #define V8_BASE_LOGGING_H_
 
+#include <cstdint>
 #include <cstring>
 #include <sstream>
 #include <string>
diff --git a/src/base/macros.h b/src/base/macros.h
--- a/src/base/macros.h
+++ b/src/base/macros.h
@@ -5,6 +5,7 @@
 #ifndef V8_BASE_MACROS_H_
 #define V8_BASE_MACROS_H_

+#include <cstdint>
 #include <limits>
 #include <type_traits>

diff --git a/src/inspector/v8-string-conversions.h b/src/inspector/v8-string-conversions.h
--- a/src/inspector/v8-string-conversions.h
+++ b/src/inspector/v8-string-conversions.h
@@ -5,6 +5,7 @@
 #ifndef V8_INSPECTOR_V8_STRING_CONVERSIONS_H_
 #define V8_INSPECTOR_V8_STRING_CONVERSIONS_H_
 
+#include <cstdint>
 #include <string>
 
 // Conversion routines between UT8 and UTF16, used by string-16.{h,cc}. You may
# DO NOT LOAD THIS FILE. Load envoy_build_system.bzl instead.
# Envoy library targets
load(
    ":envoy_internal.bzl",
    "envoy_copts",
    "envoy_external_dep_path",
    "envoy_linkstatic",
)
load(":pch.bzl", "pch")

def envoy_pch_deps(repository, target):
    return select({
        repository + "//bazel:clang_pch_build": [repository + target],
        "//conditions:default": [],
    })

def envoy_pch_copts(repository, target):
    return select({
        repository + "//bazel:clang_pch_build": [
            "-include-pch",
            "$(location {}{})".format(repository, target),
        ],
        "//conditions:default": [],
    })

def envoy_pch_library(
        name,
        includes,
        deps,
        external_deps,
        visibility,
        testonly = False,
        repository = ""):
    native.cc_library(
        name = name + "_libs",
        visibility = ["//visibility:private"],
        copts = envoy_copts(repository),
        deps = deps + [envoy_external_dep_path(dep) for dep in external_deps],
        alwayslink = 1,
        testonly = testonly,
        linkstatic = envoy_linkstatic(),
    )

    pch(
        name = name,
        deps = [name + "_libs"],
        includes = includes,
        visibility = visibility,
        testonly = testonly,
        tags = ["no-remote"],
        enabled = select({
            repository + "//bazel:clang_pch_build": True,
            "//conditions:default": False,
        }),
    )
diff --git a/upb/message/tagged_ptr.h b/upb/message/tagged_ptr.h
index 64602923..ae44146a 100644
--- a/upb/message/tagged_ptr.h
+++ b/upb/message/tagged_ptr.h
@@ -37,7 +37,14 @@
 extern "C" {
 #endif
 
+#ifdef __clang__
+#pragma GCC diagnostic push
+#pragma GCC diagnostic ignored "-Wtypedef-redefinition"
+#endif
 typedef void upb_Message;
+#ifdef __clang__
+#pragma GCC diagnostic pop
+#endif
 
 // When a upb_Message* is stored in a message, array, or map, it is stored in a
 // tagged form.  If the tag bit is set, the referenced upb_Message is of type
diff --git a/upb/mini_table/internal/message.h b/upb/mini_table/internal/message.h
index 7e928d52..c652077a 100644
--- a/upb/mini_table/internal/message.h
+++ b/upb/mini_table/internal/message.h
@@ -33,7 +33,14 @@
 // Must be last.
 #include "upb/port/def.inc"
 
+#ifdef __clang__
+#pragma GCC diagnostic push
+#pragma GCC diagnostic ignored "-Wtypedef-redefinition"
+#endif
 typedef void upb_Message;
+#ifdef __clang__
+#pragma GCC diagnostic pop
+#endif
 
 struct upb_Decoder;
 typedef const char* _upb_FieldParser(struct upb_Decoder* d, const char* ptr,
# This should match the schema defined in external_deps.bzl.

PROTOBUF_VERSION = "23.4"

# These names of these deps *must* match the names used in `/bazel/protobuf.patch`,
# and both must match the names from the protobuf releases (see
# https://github.com/protocolbuffers/protobuf/releases).
# The names change in upcoming versions.
# The shas are calculated from the downloads on the releases page.
PROTOC_VERSIONS = dict(
    linux_aarch_64 = "1c7750b6e038305b5a7fc3d0cda1ebefdf106a4f30a787bf826ed2fc47c3967d",
    linux_x86_64 = "0502f286ac9ed860b629a7965a14527b1f2dd131e4283fa23c2d7f184672aa9a",
    osx_aarch_64 = "8c7afae8626b6811e7b5897d16d940c2dbf50b1e135ed958a01db6566bdda726",
    osx_x86_64 = "07e5fdcf1b0708d3367dc5e6eb8d135de7e407d75316c93155cfd8ab362eec80",
    win64 = "a309c39442fb75f0db343cb22c111a00f91cdf0767f332e170644b9378e2bcc6",
)

REPOSITORY_LOCATIONS_SPEC = dict(
    bazel_compdb = dict(
        project_name = "bazel-compilation-database",
        project_desc = "Clang JSON compilation database support for Bazel",
        project_url = "https://github.com/grailbio/bazel-compilation-database",
        version = "40864791135333e1446a04553b63cbe744d358d0",
        sha256 = "acd2a9eaf49272bb1480c67d99b82662f005b596a8c11739046a4220ec73c4da",
        strip_prefix = "bazel-compilation-database-{version}",
        urls = ["https://github.com/grailbio/bazel-compilation-database/archive/{version}.tar.gz"],
        release_date = "2022-09-06",
        use_category = ["build"],
        license = "Apache-2.0",
        license_url = "https://github.com/grailbio/bazel-compilation-database/blob/{version}/LICENSE",
    ),
    bazel_gazelle = dict(
        project_name = "Gazelle",
        project_desc = "Bazel BUILD file generator for Go projects",
        project_url = "https://github.com/bazelbuild/bazel-gazelle",
        version = "0.31.1",
        sha256 = "b8b6d75de6e4bf7c41b7737b183523085f56283f6db929b86c5e7e1f09cf59c9",
        urls = ["https://github.com/bazelbuild/bazel-gazelle/releases/download/v{version}/bazel-gazelle-v{version}.tar.gz"],
        release_date = "2023-06-13",
        use_category = ["build"],
        license = "Apache-2.0",
        license_url = "https://github.com/bazelbuild/bazel-gazelle/blob/v{version}/LICENSE",
    ),
    bazel_toolchains = dict(
        project_name = "bazel-toolchains",
        project_desc = "Bazel toolchain configs for RBE",
        project_url = "https://github.com/bazelbuild/bazel-toolchains",
        version = "5.1.2",
        sha256 = "02e4f3744f1ce3f6e711e261fd322916ddd18cccd38026352f7a4c0351dbda19",
        strip_prefix = "bazel-toolchains-{version}",
        urls = [
            "https://github.com/bazelbuild/bazel-toolchains/archive/v{version}.tar.gz",
        ],
        release_date = "2022-08-09",
        use_category = ["build"],
        license = "Apache-2.0",
        license_url = "https://github.com/bazelbuild/bazel-toolchains/blob/v{version}/LICENSE",
    ),
    build_bazel_rules_apple = dict(
        project_name = "Apple Rules for Bazel",
        project_desc = "Bazel rules for Apple platforms",
        project_url = "https://github.com/bazelbuild/rules_apple",
        version = "3.1.1",
        sha256 = "34c41bfb59cdaea29ac2df5a2fa79e5add609c71bb303b2ebb10985f93fa20e7",
        urls = ["https://github.com/bazelbuild/rules_apple/releases/download/{version}/rules_apple.{version}.tar.gz"],
        release_date = "2023-10-19",
        use_category = ["build"],
        license = "Apache-2.0",
        license_url = "https://github.com/bazelbuild/rules_apple/blob/{version}/LICENSE",
    ),
    com_github_bazelbuild_buildtools = dict(
        project_name = "Bazel build tools",
        project_desc = "Developer tools for working with Google's bazel buildtool.",
        project_url = "https://github.com/bazelbuild/buildtools",
        version = "6.4.0",
        sha256 = "05c3c3602d25aeda1e9dbc91d3b66e624c1f9fdadf273e5480b489e744ca7269",
        release_date = "2023-11-15",
        strip_prefix = "buildtools-{version}",
        urls = ["https://github.com/bazelbuild/buildtools/archive/v{version}.tar.gz"],
        use_category = ["test_only"],
    ),
    rules_fuzzing = dict(
        project_name = "Fuzzing Rules for Bazel",
        project_desc = "Bazel rules for fuzz tests",
        project_url = "https://github.com/bazelbuild/rules_fuzzing",
        # Patch contains workaround for https://github.com/bazelbuild/rules_python/issues/1221
        version = "0.4.1",
        sha256 = "f6f3f42c48576acd5653bf07637deee2ae4ebb77ccdb0dacc67c184508bedc8c",
        strip_prefix = "rules_fuzzing-{version}",
        urls = ["https://github.com/bazelbuild/rules_fuzzing/archive/v{version}.tar.gz"],
        release_date = "2023-10-19",
        use_category = ["test_only"],
        implied_untracked_deps = [
            # This is a repository rule generated to define an OSS-Fuzz fuzzing
            # engine target from the CFLAGS/CXXFLAGS environment.
            "rules_fuzzing_oss_fuzz",
        ],
        license = "Apache-2.0",
        license_url = "https://github.com/bazelbuild/rules_fuzzing/blob/v{version}/LICENSE",
    ),
    envoy_build_tools = dict(
        project_name = "envoy-build-tools",
        project_desc = "Common build tools shared by the Envoy/UDPA ecosystem",
        project_url = "https://github.com/envoyproxy/envoy-build-tools",
        version = "7cd964feb564419532ec8a825031e4e1b7b6974f",
        sha256 = "74182edc4c40a4d3b775598cdcf7f88000a96cc8753ffbd6d94083fb403f5e78",
        strip_prefix = "envoy-build-tools-{version}",
        urls = ["https://github.com/envoyproxy/envoy-build-tools/archive/{version}.tar.gz"],
        release_date = "2024-01-08",
        use_category = ["build"],
        license = "Apache-2.0",
        license_url = "https://github.com/envoyproxy/envoy-build-tools/blob/{version}/LICENSE",
    ),
    boringssl = dict(
        project_name = "BoringSSL",
        project_desc = "Minimal OpenSSL fork",
        project_url = "https://github.com/google/boringssl",
        # To update BoringSSL, which tracks Chromium releases:
        # 1. Open https://omahaproxy.appspot.com/ and note <current_version> of linux/beta release.
        # 2. Open https://chromium.googlesource.com/chromium/src/+/refs/tags/<current_version>/DEPS and note <boringssl_revision>.
        # 3. Find a commit in BoringSSL's "master-with-bazel" branch that merges <boringssl_revision>.
        #
        # chromium-118.0.5993.54 (linux/beta)
        version = "45cf810dbdbd767f09f8cb0b0fcccd342c39041f",
        sha256 = "f1f421738e9ba39dd88daf8cf3096ddba9c53e2b6b41b32fff5a3ff82f4cd162",
        strip_prefix = "boringssl-{version}",
        urls = ["https://github.com/google/boringssl/archive/{version}.tar.gz"],
        use_category = ["controlplane", "dataplane_core"],
        release_date = "2023-08-28",
        cpe = "cpe:2.3:a:google:boringssl:*",
        license = "Mixed",
        license_url = "https://github.com/google/boringssl/blob/{version}/LICENSE",
    ),
    boringssl_fips = dict(
        project_name = "BoringSSL (FIPS)",
        project_desc = "FIPS compliant BoringSSL",
        project_url = "https://boringssl.googlesource.com/boringssl/+/master/crypto/fipsmodule/FIPS.md",
        # When this is updated to a revision newer than 2022-08-12,
        # CertValidatorUtil::setIgnoreCertificateExpiration can be simplified.
        version = "fips-20210429",
        sha256 = "a4d069ccef6f3c7bc0c68de82b91414f05cb817494cd1ab483dcf3368883c7c2",
        urls = ["https://commondatastorage.googleapis.com/chromium-boringssl-fips/boringssl-853ca1ea1168dff08011e5d42d94609cc0ca2e27.tar.xz"],
        use_category = ["controlplane", "dataplane_core"],
        release_date = "2021-04-29",
        cpe = "cpe:2.3:a:google:boringssl:*",
    ),
    aspect_bazel_lib = dict(
        project_name = "Aspect Bazel helpers",
        project_desc = "Base Starlark libraries and basic Bazel rules which are useful for constructing rulesets and BUILD files",
        project_url = "https://github.com/aspect-build/bazel-lib",
        version = "2.3.0",
        sha256 = "bda4a69fa50411b5feef473b423719d88992514d259dadba7d8218a1d02c7883",
        strip_prefix = "bazel-lib-{version}",
        urls = ["https://github.com/aspect-build/bazel-lib/archive/v{version}.tar.gz"],
        use_category = ["build"],
        release_date = "2024-01-10",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/aspect-build/bazel-lib/blob/v{version}/LICENSE",
    ),
    com_google_absl = dict(
        project_name = "Abseil",
        project_desc = "Open source collection of C++ libraries drawn from the most fundamental pieces of Googles internal codebase",
        project_url = "https://abseil.io/",
        version = "20230802.1",
        sha256 = "987ce98f02eefbaf930d6e38ab16aa05737234d7afbab2d5c4ea7adbe50c28ed",
        strip_prefix = "abseil-cpp-{version}",
        urls = ["https://github.com/abseil/abseil-cpp/archive/{version}.tar.gz"],
        use_category = ["dataplane_core", "controlplane"],
        release_date = "2023-09-18",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/abseil/abseil-cpp/blob/{version}/LICENSE",
    ),
    com_github_aignas_rules_shellcheck = dict(
        project_name = "Shellcheck rules for bazel",
        project_desc = "Now you do not need to depend on the system shellcheck version in your bazel-managed (mono)repos.",
        project_url = "https://github.com/aignas/rules_shellcheck",
        version = "0.3.2",
        sha256 = "798c7ff488a949e51d7d41d853d79164ce5c5335364ba32f972b79df8dd6be62",
        strip_prefix = "rules_shellcheck-{version}",
        urls = ["https://github.com/aignas/rules_shellcheck/archive/{version}.tar.gz"],
        release_date = "2024-01-10",
        use_category = ["build"],
        cpe = "N/A",
        license = "MIT",
        license_url = "https://github.com/aignas/rules_shellcheck/blob/v{version}/LICENSE",
    ),
    com_github_axboe_liburing = dict(
        project_name = "liburing",
        project_desc = "C helpers to set up and tear down io_uring instances",
        project_url = "https://github.com/axboe/liburing",
        version = "2.3",
        sha256 = "60b367dbdc6f2b0418a6e0cd203ee0049d9d629a36706fcf91dfb9428bae23c8",
        strip_prefix = "liburing-liburing-{version}",
        urls = ["https://github.com/axboe/liburing/archive/liburing-{version}.tar.gz"],
        use_category = ["dataplane_core", "controlplane"],
        release_date = "2022-10-26",
        cpe = "N/A",
    ),
    # This dependency is built only when performance tracing is enabled with the
    # option --define=perf_tracing=enabled. It's never built for releases.
    com_github_google_perfetto = dict(
        project_name = "Perfetto",
        project_desc = "Perfetto Tracing SDK",
        project_url = "https://perfetto.dev/",
        version = "41.0",
        sha256 = "4c8fe8a609fcc77ca653ec85f387ab6c3a048fcd8df9275a1aa8087984b89db8",
        strip_prefix = "perfetto-{version}/sdk",
        urls = ["https://github.com/google/perfetto/archive/v{version}.tar.gz"],
        use_category = ["dataplane_core", "controlplane"],
        release_date = "2024-01-11",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/google/perfetto/blob/v{version}/LICENSE",
    ),
    com_github_c_ares_c_ares = dict(
        project_name = "c-ares",
        project_desc = "C library for asynchronous DNS requests",
        project_url = "https://c-ares.haxx.se/",
        version = "1.19.1",
        sha256 = "321700399b72ed0e037d0074c629e7741f6b2ec2dda92956abe3e9671d3e268e",
        strip_prefix = "c-ares-{version}",
        urls = ["https://github.com/c-ares/c-ares/releases/download/cares-{underscore_version}/c-ares-{version}.tar.gz"],
        use_category = ["dataplane_core", "controlplane"],
        release_date = "2023-05-22",
        cpe = "cpe:2.3:a:c-ares_project:c-ares:*",
        license = "c-ares",
        license_url = "https://github.com/c-ares/c-ares/blob/cares-{underscore_version}/LICENSE.md",
    ),
    com_github_openhistogram_libcircllhist = dict(
        project_name = "libcircllhist",
        project_desc = "An implementation of OpenHistogram log-linear histograms",
        project_url = "https://github.com/openhistogram/libcircllhist",
        version = "39f9db724a81ba78f5d037f1cae79c5a07107c8e",
        sha256 = "fd2492f6cc1f8734f8f57be8c2e7f2907e94ee2a4c02445ce59c4241fece144b",
        strip_prefix = "libcircllhist-{version}",
        urls = ["https://github.com/openhistogram/libcircllhist/archive/{version}.tar.gz"],
        use_category = ["controlplane", "observability_core", "dataplane_core"],
        release_date = "2019-05-21",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/openhistogram/libcircllhist/blob/{version}/LICENSE",
    ),
    com_github_cyan4973_xxhash = dict(
        project_name = "xxHash",
        project_desc = "Extremely fast hash algorithm",
        project_url = "https://github.com/Cyan4973/xxHash",
        version = "0.8.2",
        sha256 = "baee0c6afd4f03165de7a4e67988d16f0f2b257b51d0e3cb91909302a26a79c4",
        strip_prefix = "xxHash-{version}",
        urls = ["https://github.com/Cyan4973/xxHash/archive/v{version}.tar.gz"],
        use_category = ["dataplane_core", "controlplane"],
        release_date = "2023-07-21",
        cpe = "N/A",
        license = "BSD-2-Clause",
        license_url = "https://github.com/Cyan4973/xxHash/blob/v{version}/LICENSE",
    ),
    com_github_envoyproxy_sqlparser = dict(
        project_name = "C++ SQL Parser Library",
        project_desc = "Forked from Hyrise SQL Parser",
        project_url = "https://github.com/envoyproxy/sql-parser",
        version = "3b40ba2d106587bdf053a292f7e3bb17e818a57f",
        sha256 = "96c10c8e950a141a32034f19b19cdeb1da48fe859cf96ae5e19f894f36c62c71",
        strip_prefix = "sql-parser-{version}",
        urls = ["https://github.com/envoyproxy/sql-parser/archive/{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        extensions = [
            "envoy.filters.network.mysql_proxy",
            "envoy.filters.network.postgres_proxy",
        ],
        release_date = "2020-06-10",
        cpe = "N/A",
        license = "MIT",
        license_url = "https://github.com/envoyproxy/sql-parser/blob/{version}/LICENSE",
    ),
    com_github_mirror_tclap = dict(
        project_name = "tclap",
        project_desc = "Small, flexible library that provides a simple interface for defining and accessing command line arguments",
        project_url = "http://tclap.sourceforge.net",
        version = "1.2.5",
        sha256 = "7e87d13734076fa4f626f6144ce9a02717198b3f054341a6886e2107b048b235",
        strip_prefix = "tclap-{version}",
        urls = ["https://github.com/mirror/tclap/archive/v{version}.tar.gz"],
        release_date = "2021-11-01",
        use_category = ["other"],
        cpe = "cpe:2.3:a:tclap_project:tclap:*",
        license = "MIT",
        license_url = "https://github.com/mirror/tclap/blob/v{version}/COPYING",
    ),
    com_github_fmtlib_fmt = dict(
        project_name = "fmt",
        project_desc = "{fmt} is an open-source formatting library providing a fast and safe alternative to C stdio and C++ iostreams",
        project_url = "https://fmt.dev",
        version = "9.1.0",
        sha256 = "cceb4cb9366e18a5742128cb3524ce5f50e88b476f1e54737a47ffdf4df4c996",
        strip_prefix = "fmt-{version}",
        urls = ["https://github.com/fmtlib/fmt/releases/download/{version}/fmt-{version}.zip"],
        use_category = ["dataplane_core", "controlplane"],
        release_date = "2022-08-27",
        cpe = "cpe:2.3:a:fmt:fmt:*",
        license = "fmt",
        license_url = "https://github.com/fmtlib/fmt/blob/{version}/LICENSE.rst",
    ),
    com_github_gabime_spdlog = dict(
        project_name = "spdlog",
        project_desc = "Very fast, header-only/compiled, C++ logging library",
        project_url = "https://github.com/gabime/spdlog",
        version = "1.13.0",
        sha256 = "534f2ee1a4dcbeb22249856edfb2be76a1cf4f708a20b0ac2ed090ee24cfdbc9",
        strip_prefix = "spdlog-{version}",
        urls = ["https://github.com/gabime/spdlog/archive/v{version}.tar.gz"],
        use_category = ["dataplane_core", "controlplane"],
        release_date = "2024-01-12",
        cpe = "N/A",
        license = "MIT",
        license_url = "https://github.com/gabime/spdlog/blob/v{version}/LICENSE",
    ),
    com_github_google_libprotobuf_mutator = dict(
        project_name = "libprotobuf-mutator",
        project_desc = "Library to randomly mutate protobuffers",
        project_url = "https://github.com/google/libprotobuf-mutator",
        version = "3b28530531b154a748fe9884bc9219b4966f0754",
        sha256 = "21bfdfef25554fa2e30aec2a9f9b58f4a17c1d8c8593763fa94a6dd74b226594",
        strip_prefix = "libprotobuf-mutator-{version}",
        urls = ["https://github.com/google/libprotobuf-mutator/archive/{version}.tar.gz"],
        release_date = "2023-04-25",
        use_category = ["test_only"],
        license = "Apache-2.0",
        license_url = "https://github.com/google/libprotobuf-mutator/blob/v{version}/LICENSE",
    ),
    com_github_google_libsxg = dict(
        project_name = "libsxg",
        project_desc = "Signed HTTP Exchange library",
        project_url = "https://github.com/google/libsxg",
        version = "beaa3939b76f8644f6833267e9f2462760838f18",
        sha256 = "082bf844047a9aeec0d388283d5edc68bd22bcf4d32eb5a566654ae89956ad1f",
        strip_prefix = "libsxg-{version}",
        urls = ["https://github.com/google/libsxg/archive/{version}.tar.gz"],
        use_category = ["other"],
        extensions = ["envoy.filters.http.sxg"],
        release_date = "2021-07-08",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/google/libsxg/blob/{version}/LICENSE",
    ),
    com_github_google_tcmalloc = dict(
        project_name = "tcmalloc",
        project_desc = "Fast, multi-threaded malloc implementation",
        project_url = "https://github.com/google/tcmalloc",
        version = "e33c7bc60415127c104006d3301c96902f98d42a",
        sha256 = "14a2c91b71d6719558768a79671408c9acd8284b418e80386c5888047e2c15aa",
        strip_prefix = "tcmalloc-{version}",
        urls = ["https://github.com/google/tcmalloc/archive/{version}.tar.gz"],
        use_category = ["dataplane_core", "controlplane"],
        release_date = "2022-10-24",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/google/tcmalloc/blob/{version}/LICENSE",
    ),
    com_github_gperftools_gperftools = dict(
        project_name = "gperftools",
        project_desc = "tcmalloc and profiling libraries",
        project_url = "https://github.com/gperftools/gperftools",
        version = "2.10",
        sha256 = "83e3bfdd28b8bcf53222c3798d4d395d52dadbbae59e8730c4a6d31a9c3732d8",
        strip_prefix = "gperftools-{version}",
        urls = ["https://github.com/gperftools/gperftools/releases/download/gperftools-{version}/gperftools-{version}.tar.gz"],
        release_date = "2022-05-31",
        use_category = ["dataplane_core", "controlplane"],
        cpe = "cpe:2.3:a:gperftools_project:gperftools:*",
        license = "BSD-3-Clause",
        license_url = "https://github.com/gperftools/gperftools/blob/gperftools-{version}/COPYING",
    ),
    com_github_grpc_grpc = dict(
        project_name = "gRPC",
        project_desc = "gRPC C core library",
        project_url = "https://grpc.io",
        version = "1.59.3",
        sha256 = "ea281bb3489520ad4fb96ae84b45ed194a1f0b944d3e74f925f5e019d31ecd0f",
        strip_prefix = "grpc-{version}",
        urls = ["https://github.com/grpc/grpc/archive/v{version}.tar.gz"],
        use_category = ["dataplane_core", "controlplane"],
        release_date = "2023-11-17",
        cpe = "cpe:2.3:a:grpc:grpc:*",
        license = "Apache-2.0",
        license_url = "https://github.com/grpc/grpc/blob/v{version}/LICENSE",
    ),
    com_github_rules_proto_grpc = dict(
        project_name = "Protobuf and gRPC rules for Bazel",
        project_desc = "Bazel rules for building Protobuf and gRPC code and libraries from proto_library targets",
        project_url = "https://github.com/rules-proto-grpc/rules_proto_grpc",
        version = "4.6.0",
        sha256 = "2a0860a336ae836b54671cbbe0710eec17c64ef70c4c5a88ccfd47ea6e3739bd",
        strip_prefix = "rules_proto_grpc-{version}",
        urls = ["https://github.com/rules-proto-grpc/rules_proto_grpc/releases/download/{version}/rules_proto_grpc-{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        extensions = ["envoy.transport_sockets.alts"],
        release_date = "2023-12-14",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/rules-proto-grpc/rules_proto_grpc/blob/{version}/LICENSE",
    ),
    com_github_unicode_org_icu = dict(
        project_name = "ICU Library",
        project_desc = "Development files for International Components for Unicode",
        project_url = "https://github.com/unicode-org/icu",
        # When this is updated, make sure to update the icu.patch patch file and remove
        # all remaining Bazel build artifacts (for example WORKSPACE and BUILD.bazel files)
        # from the icu source code, to prevent Bazel from treating the foreign library
        # as a Bazel project.
        # https://github.com/envoyproxy/envoy/issues/26395
        version = "72-1",
        sha256 = "43cbad628d98f37a3f95f6c34579f9144ef4bde60248fa6004a4f006d7487e69",
        strip_prefix = "icu-release-{version}",
        urls = ["https://github.com/unicode-org/icu/archive/release-{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        extensions = ["envoy.filters.http.language"],
        release_date = "2022-10-18",
        cpe = "N/A",
        license = "ICU",
        license_url = "https://github.com/unicode-org/icu/blob/release-{version}/icu4c/LICENSE",
    ),
    com_github_intel_ipp_crypto_crypto_mb = dict(
        project_name = "libipp-crypto",
        project_desc = "Intel Integrated Performance Primitives Cryptography",
        project_url = "https://github.com/intel/ipp-crypto",
        version = "2021.6",
        sha256 = "632cc5ba54413eeab575682619c05d247e9b7f2fc58ea3e5f4a02bdcab3e6b78",
        strip_prefix = "ipp-crypto-ippcp_{version}",
        urls = ["https://github.com/intel/ipp-crypto/archive/ippcp_{version}.tar.gz"],
        release_date = "2022-08-09",
        use_category = ["dataplane_ext"],
        extensions = ["envoy.tls.key_providers.cryptomb"],
        cpe = "cpe:2.3:a:intel:cryptography_for_intel_integrated_performance_primitives:*",
        license = "Apache-2.0",
        license_url = "https://github.com/intel/ipp-crypto/blob/ippcp_{version}/LICENSE",
    ),
    com_github_intel_qatlib = dict(
        project_name = "qatlib",
        project_desc = "Intel QuickAssist Technology Library",
        project_url = "https://github.com/intel/qatlib",
        version = "23.11.0",
        sha256 = "f649613c243df98c2b005e58af7e0c9bb6d9638e0a12d2757d18d4930bf893cd",
        strip_prefix = "qatlib-{version}",
        urls = ["https://github.com/intel/qatlib/archive/refs/tags/{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        release_date = "2023-11-15",
        extensions = ["envoy.tls.key_providers.qat", "envoy.compression.qatzip.compressor"],
        cpe = "N/A",
        license = "BSD-3-Clause",
        license_url = "https://github.com/intel/qatlib/blob/{version}/LICENSE",
    ),
    com_github_intel_qatzip = dict(
        project_name = "qatzip",
        project_desc = "Intel QuickAssist Technology QATzip Library",
        project_url = "https://github.com/intel/qatzip",
        version = "1.1.2",
        sha256 = "31419fa4b42d217b3e55a70a34545582cbf401a4f4d44738d21b4a3944b1e1ef",
        strip_prefix = "QATzip-{version}",
        urls = ["https://github.com/intel/QATzip/archive/v{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        release_date = "2023-03-24",
        extensions = ["envoy.compression.qatzip.compressor"],
        cpe = "N/A",
        license = "BSD-3-Clause",
        license_url = "https://github.com/intel/QATzip/blob/{version}/LICENSE",
    ),
    com_github_luajit_luajit = dict(
        project_name = "LuaJIT",
        project_desc = "Just-In-Time compiler for Lua",
        project_url = "https://luajit.org",
        # LuaJIT only provides rolling releases
        version = "1c279127050e86e99970100e9c42e0f09cd54ab7",
        sha256 = "c62f6e6d5bff89e4718709841cd6be71ad419ac9fa780c91abf1635cda923f8f",
        strip_prefix = "LuaJIT-{version}",
        urls = ["https://github.com/LuaJIT/LuaJIT/archive/{version}.tar.gz"],
        release_date = "2023-04-16",
        use_category = ["dataplane_ext"],
        extensions = [
            "envoy.filters.http.lua",
            "envoy.router.cluster_specifier_plugin.lua",
        ],
        cpe = "cpe:2.3:a:luajit:luajit:*",
        license = "MIT",
        license_url = "https://github.com/LuaJIT/LuaJIT/blob/{version}/COPYRIGHT",
    ),
    com_github_nghttp2_nghttp2 = dict(
        project_name = "Nghttp2",
        project_desc = "Implementation of HTTP/2 and its header compression algorithm HPACK in C",
        project_url = "https://nghttp2.org",
        version = "1.59.0",
        sha256 = "90fd27685120404544e96a60ed40398a3457102840c38e7215dc6dec8684470f",
        strip_prefix = "nghttp2-{version}",
        urls = ["https://github.com/nghttp2/nghttp2/releases/download/v{version}/nghttp2-{version}.tar.gz"],
        use_category = ["controlplane", "dataplane_core"],
        release_date = "2024-01-21",
        cpe = "cpe:2.3:a:nghttp2:nghttp2:*",
        license = "MIT",
        license_url = "https://github.com/nghttp2/nghttp2/blob/v{version}/LICENSE",
    ),
    io_hyperscan = dict(
        project_name = "Hyperscan",
        project_desc = "High-performance regular expression matching library",
        project_url = "https://hyperscan.io",
        version = "5.4.2",
        sha256 = "32b0f24b3113bbc46b6bfaa05cf7cf45840b6b59333d078cc1f624e4c40b2b99",
        strip_prefix = "hyperscan-{version}",
        urls = ["https://github.com/intel/hyperscan/archive/v{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        extensions = [
            "envoy.matching.input_matchers.hyperscan",
            "envoy.regex_engines.hyperscan",
        ],
        release_date = "2023-04-19",
        cpe = "N/A",
        license = "BSD-3-Clause",
        license_url = "https://github.com/intel/hyperscan/blob/v{version}/LICENSE",
    ),
    io_vectorscan = dict(
        project_name = "Vectorscan",
        project_desc = "Hyperscan port for additional CPU architectures",
        project_url = "https://www.vectorcamp.gr/vectorscan/",
        version = "5.4.11",
        sha256 = "905f76ad1fa9e4ae0eb28232cac98afdb96c479666202c5a4c27871fb30a2711",
        strip_prefix = "vectorscan-vectorscan-{version}",
        urls = ["https://codeload.github.com/VectorCamp/vectorscan/tar.gz/refs/tags/vectorscan/{version}"],
        use_category = ["dataplane_ext"],
        extensions = [
            "envoy.matching.input_matchers.hyperscan",
            "envoy.regex_engines.hyperscan",
        ],
        release_date = "2023-11-20",
        cpe = "N/A",
        license = "BSD-3-Clause",
        license_url = "https://github.com/VectorCamp/vectorscan/blob/vectorscan/{version}/LICENSE",
    ),
    io_opentracing_cpp = dict(
        project_name = "OpenTracing",
        project_desc = "Vendor-neutral APIs and instrumentation for distributed tracing",
        project_url = "https://opentracing.io",
        version = "1.5.1",
        sha256 = "015c4187f7a6426a2b5196f0ccd982aa87f010cf61f507ae3ce5c90523f92301",
        strip_prefix = "opentracing-cpp-{version}",
        urls = ["https://github.com/opentracing/opentracing-cpp/archive/v{version}.tar.gz"],
        use_category = ["observability_ext"],
        extensions = [
            "envoy.tracers.datadog",
            "envoy.tracers.dynamic_ot",
        ],
        release_date = "2019-01-16",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/opentracing/opentracing-cpp/blob/v{version}/LICENSE",
    ),
    skywalking_data_collect_protocol = dict(
        project_name = "skywalking-data-collect-protocol",
        project_desc = "Data Collect Protocols of Apache SkyWalking",
        project_url = "https://github.com/apache/skywalking-data-collect-protocol",
        sha256 = "49bd689b9c1c0ea12064bd35581689cef7835e5ac15d335dc425fbfc2029aa90",
        urls = ["https://github.com/apache/skywalking-data-collect-protocol/archive/v{version}.tar.gz"],
        strip_prefix = "skywalking-data-collect-protocol-{version}",
        version = "8.9.1",
        use_category = ["observability_ext"],
        extensions = ["envoy.tracers.skywalking"],
        release_date = "2021-12-11",
        cpe = "cpe:2.3:a:apache:skywalking:*",
        license = "Apache-2.0",
    ),
    com_github_skyapm_cpp2sky = dict(
        project_name = "cpp2sky",
        project_desc = "C++ SDK for Apache SkyWalking",
        project_url = "https://github.com/SkyAPM/cpp2sky",
        sha256 = "eda4c32296aefde09cb7d059fc3d06698bf96d7827db51c582e1cd40e266c260",
        version = "0.4.0",
        strip_prefix = "cpp2sky-{version}",
        urls = ["https://github.com/SkyAPM/cpp2sky/archive/v{version}.tar.gz"],
        use_category = ["observability_ext"],
        extensions = ["envoy.tracers.skywalking"],
        release_date = "2022-03-28",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/SkyAPM/cpp2sky/blob/v{version}/LICENSE",
    ),
    com_github_datadog_dd_trace_cpp = dict(
        project_name = "Datadog C++ Tracing Library",
        project_desc = "Datadog distributed tracing for C++",
        project_url = "https://github.com/DataDog/dd-trace-cpp",
        version = "0.1.12",
        sha256 = "9609a9192fecf730473743662e9f5ed57b4c348c12a0e16dd11ed2e592462ebe",
        strip_prefix = "dd-trace-cpp-{version}",
        urls = ["https://github.com/DataDog/dd-trace-cpp/archive/v{version}.tar.gz"],
        use_category = ["observability_ext"],
        extensions = ["envoy.tracers.datadog"],
        release_date = "2023-11-17",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/DataDog/dd-trace-cpp/blob/v{version}/LICENSE.md",
    ),
    com_github_google_benchmark = dict(
        project_name = "Benchmark",
        project_desc = "Library to benchmark code snippets",
        project_url = "https://github.com/google/benchmark",
        version = "1.8.3",
        sha256 = "6bc180a57d23d4d9515519f92b0c83d61b05b5bab188961f36ac7b06b0d9e9ce",
        strip_prefix = "benchmark-{version}",
        urls = ["https://github.com/google/benchmark/archive/v{version}.tar.gz"],
        use_category = ["test_only"],
        release_date = "2023-08-31",
        license = "Apache-2.0",
        license_url = "https://github.com/google/benchmark/blob/v{version}/LICENSE",
    ),
    com_github_libevent_libevent = dict(
        project_name = "libevent",
        project_desc = "Event notification library",
        project_url = "https://libevent.org",
        # This SHA includes the new "prepare" and "check" watchers, used for event loop performance
        # stats (see https://github.com/libevent/libevent/pull/793) and the fix for a race condition
        # in the watchers (see https://github.com/libevent/libevent/pull/802).
        # This also includes the fixes for https://github.com/libevent/libevent/issues/806
        # and https://github.com/envoyproxy/envoy-mobile/issues/215.
        # This also includes the fixes for Phantom events with EV_ET (see
        # https://github.com/libevent/libevent/issues/984).
        # This also includes the wepoll backend for Windows (see
        # https://github.com/libevent/libevent/pull/1006)
        # TODO(adip): Update to v2.2 when it is released.
        version = "62c152d9a7cd264b993dad730c4163c6ede2e0a3",
        sha256 = "4c80e5fe044ce5f8055b20a2f141ee32ec2614000f3e95d2aa81611a4c8f5213",
        strip_prefix = "libevent-{version}",
        urls = ["https://github.com/libevent/libevent/archive/{version}.tar.gz"],
        use_category = ["dataplane_core", "controlplane"],
        release_date = "2020-07-28",
        cpe = "cpe:2.3:a:libevent_project:libevent:*",
        license = "BSD-3-Clause",
        license_url = "https://github.com/libevent/libevent/blob/{version}/LICENSE",
    ),
    net_colm_open_source_colm = dict(
        project_name = "Colm",
        project_desc = "The Colm Programming Language",
        project_url = "https://www.colm.net/open-source/colm/",
        # The latest release version v0.14.7 prevents building statically (see
        # https://github.com/adrian-thurston/colm/issues/146). The latest SHA includes the fix (see
        # https://github.com/adrian-thurston/colm/commit/fc61ecb3a22b89864916ec538eaf04840e7dd6b5).
        # TODO(zhxie): Update to the next release version when it is released.
        version = "2d8ba76ddaf6634f285d0a81ee42d5ee77d084cf",
        sha256 = "0399e9bef7603a8f3d94acd0b0af6b5944cc3103e586734719379d3ec09620c0",
        strip_prefix = "colm-{version}",
        urls = ["https://github.com/adrian-thurston/colm/archive/{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        extensions = [
            "envoy.matching.input_matchers.hyperscan",
            "envoy.regex_engines.hyperscan",
        ],
        release_date = "2021-12-28",
        cpe = "N/A",
        license = "MIT",
        license_url = "https://github.com/adrian-thurston/colm/blob/{version}/COPYING",
    ),
    net_colm_open_source_ragel = dict(
        project_name = "Ragel",
        project_desc = "Ragel State Machine Compiler",
        project_url = "https://www.colm.net/open-source/ragel/",
        # We used the stable release Ragel 6.10 previously and it is under GPLv2 license (see
        # http://www.colm.net/open-source/ragel). Envoy uses its binary only as a tool for
        # compiling contrib extension Hyperscan. For copyright consideration, we update Ragel to
        # its development release which is under MIT license.
        # The latest release version v7.0.4 is not compatible with its dependency Colm we use. The
        # latest SHA includes fix for compatibility.
        # TODO(zhxie): Update to the next release version when it is released.
        version = "d4577c924451b331c73c8ed0af04f6efd35ac0b4",
        sha256 = "fa3474d50da9c870b79b51ad43f8d11cdf05268f5ec05a602ecd5b1b5f5febb0",
        strip_prefix = "ragel-{version}",
        urls = ["https://github.com/adrian-thurston/ragel/archive/{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        extensions = [
            "envoy.matching.input_matchers.hyperscan",
            "envoy.regex_engines.hyperscan",
        ],
        release_date = "2021-12-28",
        cpe = "N/A",
        license = "MIT",
        license_url = "https://github.com/adrian-thurston/ragel/blob/{version}/COPYING",
    ),
    # This should be removed, see https://github.com/envoyproxy/envoy/issues/13261.
    net_zlib = dict(
        project_name = "zlib",
        project_desc = "zlib compression library",
        project_url = "https://zlib.net",
        version = "1.2.13",
        sha256 = "1525952a0a567581792613a9723333d7f8cc20b87a81f920fb8bc7e3f2251428",
        strip_prefix = "zlib-{version}",
        urls = ["https://github.com/madler/zlib/archive/v{version}.tar.gz"],
        use_category = ["controlplane", "dataplane_core"],
        release_date = "2022-10-14",
        cpe = "cpe:2.3:a:gnu:zlib:*",
        license = "zlib",
        license_url = "https://github.com/madler/zlib/blob/v{version}/zlib.h",
    ),
    org_boost = dict(
        project_name = "Boost",
        project_desc = "Boost C++ source libraries",
        project_url = "https://www.boost.org/",
        version = "1.84.0",
        sha256 = "a5800f405508f5df8114558ca9855d2640a2de8f0445f051fa1c7c3383045724",
        strip_prefix = "boost_{underscore_version}",
        urls = ["https://archives.boost.io/release/{version}/source/boost_{underscore_version}.tar.gz"],
        use_category = ["dataplane_ext"],
        extensions = [
            "envoy.matching.input_matchers.hyperscan",
            "envoy.regex_engines.hyperscan",
        ],
        release_date = "2023-12-13",
        cpe = "cpe:2.3:a:boost:boost:*",
        license = "Boost",
        license_url = "https://github.com/boostorg/boost/blob/boost-{version}/LICENSE_1_0.txt",
    ),
    org_brotli = dict(
        project_name = "brotli",
        project_desc = "brotli compression library",
        project_url = "https://brotli.org",
        version = "1.1.0",
        sha256 = "e720a6ca29428b803f4ad165371771f5398faba397edf6778837a18599ea13ff",
        strip_prefix = "brotli-{version}",
        urls = ["https://github.com/google/brotli/archive/v{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        extensions = [
            "envoy.compression.brotli.compressor",
            "envoy.compression.brotli.decompressor",
        ],
        release_date = "2023-08-31",
        cpe = "cpe:2.3:a:google:brotli:*",
        license = "MIT",
        license_url = "https://github.com/google/brotli/blob/v{version}/LICENSE",
    ),
    com_github_facebook_zstd = dict(
        project_name = "zstd",
        project_desc = "zstd compression library",
        project_url = "https://facebook.github.io/zstd",
        version = "1.5.5",
        sha256 = "98e9c3d949d1b924e28e01eccb7deed865eefebf25c2f21c702e5cd5b63b85e1",
        strip_prefix = "zstd-{version}",
        urls = ["https://github.com/facebook/zstd/archive/v{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        extensions = [
            "envoy.compression.zstd.compressor",
            "envoy.compression.zstd.decompressor",
        ],
        release_date = "2023-04-04",
        cpe = "cpe:2.3:a:facebook:zstandard:*",
    ),
    com_github_zlib_ng_zlib_ng = dict(
        project_name = "zlib-ng",
        project_desc = "zlib fork (higher performance)",
        project_url = "https://github.com/zlib-ng/zlib-ng",
        version = "2.0.7",
        sha256 = "6c0853bb27738b811f2b4d4af095323c3d5ce36ceed6b50e5f773204fb8f7200",
        strip_prefix = "zlib-ng-{version}",
        urls = ["https://github.com/zlib-ng/zlib-ng/archive/{version}.tar.gz"],
        use_category = ["controlplane", "dataplane_core"],
        release_date = "2023-03-17",
        cpe = "N/A",
        license = "zlib",
        license_url = "https://github.com/zlib-ng/zlib-ng/blob/{version}/LICENSE.md",
    ),
    com_github_jbeder_yaml_cpp = dict(
        project_name = "yaml-cpp",
        project_desc = "YAML parser and emitter in C++ matching the YAML 1.2 spec",
        project_url = "https://github.com/jbeder/yaml-cpp",
        version = "0.8.0",
        sha256 = "fbe74bbdcee21d656715688706da3c8becfd946d92cd44705cc6098bb23b3a16",
        strip_prefix = "yaml-cpp-{version}",
        urls = ["https://github.com/jbeder/yaml-cpp/archive/{version}.tar.gz"],
        # YAML is also used for runtime as well as controlplane. It shouldn't appear on the
        # dataplane but we can't verify this automatically due to code structure today.
        use_category = ["controlplane", "dataplane_core"],
        release_date = "2023-08-10",
        cpe = "cpe:2.3:a:yaml-cpp_project:yaml-cpp:*",
        license = "MIT",
        license_url = "https://github.com/jbeder/yaml-cpp/blob/{version}/LICENSE",
    ),
    com_github_google_jwt_verify = dict(
        project_name = "jwt_verify_lib",
        project_desc = "JWT verification library for C++",
        project_url = "https://github.com/google/jwt_verify_lib",
        version = "b59e8075d4a4f975ba6f109e1916d6e60aeb5613",
        sha256 = "637e4983506c4f26bbe2808ae4e1944e46cbb2277d34ff0b8a3b72bdac3c4b91",
        strip_prefix = "jwt_verify_lib-{version}",
        urls = ["https://github.com/google/jwt_verify_lib/archive/{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        extensions = ["envoy.filters.http.jwt_authn", "envoy.filters.http.gcp_authn"],
        release_date = "2023-05-17",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/google/jwt_verify_lib/blob/{version}/LICENSE",
    ),
    com_github_alibaba_hessian2_codec = dict(
        project_name = "hessian2-codec",
        project_desc = "hessian2-codec is a C++ library for hessian2 codec",
        project_url = "https://github.com/alibaba/hessian2-codec.git",
        version = "e9bb36e206f2c5054b50d11f88bb1b95c77766f8",
        sha256 = "82743dcbf2bd624a68eb2c0d54963ea87446eba4eb08c117744f0669ddc70786",
        strip_prefix = "hessian2-codec-{version}",
        urls = ["https://github.com/alibaba/hessian2-codec/archive/{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        extensions = ["envoy.filters.network.dubbo_proxy"],
        release_date = "2022-10-10",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/alibaba/hessian2-codec/blob/{version}/LICENSE",
    ),
    com_github_tencent_rapidjson = dict(
        project_name = "RapidJSON",
        project_desc = "Fast JSON parser/generator for C++",
        project_url = "https://rapidjson.org",
        version = "dfbe1db9da455552f7a9ad5d2aea17dd9d832ac1",
        sha256 = "a2faafbc402394df0fa94602df4b5e4befd734aad6bb55dfef46f62fcaf1090b",
        strip_prefix = "rapidjson-{version}",
        urls = ["https://github.com/Tencent/rapidjson/archive/{version}.tar.gz"],
        use_category = ["observability_ext"],
        # Rapidjson is used in the external dependency of zipkin tracer.
        extensions = ["envoy.tracers.zipkin", "envoy.tracers.opencensus"],
        release_date = "2019-12-03",
        cpe = "cpe:2.3:a:tencent:rapidjson:*",
        license = "RapidJSON",
        license_url = "https://github.com/Tencent/rapidjson/blob/{version}/license.txt",
    ),
    com_github_nlohmann_json = dict(
        project_name = "nlohmann JSON",
        project_desc = "Fast JSON parser/generator for C++",
        project_url = "https://nlohmann.github.io/json",
        version = "3.11.3",
        sha256 = "0d8ef5af7f9794e3263480193c491549b2ba6cc74bb018906202ada498a79406",
        strip_prefix = "json-{version}",
        urls = ["https://github.com/nlohmann/json/archive/v{version}.tar.gz"],
        # This will be a replacement for rapidJSON used in extensions and may also be a fast
        # replacement for protobuf JSON.
        use_category = ["controlplane", "dataplane_core"],
        release_date = "2023-11-28",
        cpe = "cpe:2.3:a:json-for-modern-cpp_project:json-for-modern-cpp:*",
        license = "MIT",
        license_url = "https://github.com/nlohmann/json/blob/v{version}/LICENSE.MIT",
    ),
    # This is an external dependency needed while running the
    # envoy docker image. A bazel target has been created since
    # there is no binary package available for the utility on Ubuntu
    # which is the base image used to build an envoy container.
    # This is not needed to build an envoy binary or run tests.
    com_github_ncopa_suexec = dict(
        project_name = "su-exec",
        project_desc = "Utility to switch user and group id, setgroups and exec",
        project_url = "https://github.com/ncopa/su-exec",
        version = "212b75144bbc06722fbd7661f651390dc47a43d1",
        sha256 = "939782774079ec156788ea3e04dd5e340e993544f4296be76a9c595334ca1779",
        strip_prefix = "su-exec-{version}",
        urls = ["https://github.com/ncopa/su-exec/archive/{version}.tar.gz"],
        use_category = ["other"],
        release_date = "2019-09-18",
        cpe = "N/A",
        license = "MIT",
        license_url = "https://github.com/ncopa/su-exec/blob/{version}/LICENSE",
    ),
    com_google_googletest = dict(
        project_name = "Google Test",
        project_desc = "Google's C++ test framework",
        project_url = "https://github.com/google/googletest",
        # Pick up fix for MOCK_METHOD compilation with clang-cl for Windows (resolved after 1.10.0)
        # see https://github.com/google/googletest/issues/2490
        version = "a4ab0abb93620ce26efad9de9296b73b16e88588",
        sha256 = "7897bfaa5ad39a479177cfb5c3ce010184dbaee22a7c3727b212282871918751",
        strip_prefix = "googletest-{version}",
        urls = ["https://github.com/google/googletest/archive/{version}.tar.gz"],
        release_date = "2020-09-10",
        use_category = ["test_only"],
        cpe = "cpe:2.3:a:google:google_test:*",
        license = "BSD-3-Clause",
        license_url = "https://github.com/google/googletest/blob/{version}/LICENSE",
    ),
    com_google_protobuf = dict(
        project_name = "Protocol Buffers",
        project_desc = "Language-neutral, platform-neutral extensible mechanism for serializing structured data",
        project_url = "https://developers.google.com/protocol-buffers",
        version = PROTOBUF_VERSION,
        # When upgrading the protobuf library, please re-run
        # test/common/json:gen_excluded_unicodes to recompute the ranges
        # excluded from differential fuzzing that are populated in
        # test/common/json/json_sanitizer_test_util.cc.
        sha256 = "a700a49470d301f1190a487a923b5095bf60f08f4ae4cac9f5f7c36883d17971",
        strip_prefix = "protobuf-{version}",
        urls = ["https://github.com/protocolbuffers/protobuf/releases/download/v{version}/protobuf-{version}.tar.gz"],
        use_category = ["dataplane_core", "controlplane"],
        release_date = "2023-07-06",
        cpe = "cpe:2.3:a:google:protobuf:*",
        license = "Protocol Buffers",
        license_url = "https://github.com/protocolbuffers/protobuf/blob/v{version}/LICENSE",
    ),
    grpc_httpjson_transcoding = dict(
        project_name = "grpc-httpjson-transcoding",
        project_desc = "Library that supports transcoding so that HTTP/JSON can be converted to gRPC",
        project_url = "https://github.com/grpc-ecosystem/grpc-httpjson-transcoding",
        version = "ff41eb3fc9209e6197595b54f7addfa244c0bdb6",
        sha256 = "dea66b3d2dfc150373697e25b1327877e0b7480dc2bacfff1e3fd7aa00b12790",
        strip_prefix = "grpc-httpjson-transcoding-{version}",
        urls = ["https://github.com/grpc-ecosystem/grpc-httpjson-transcoding/archive/{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        extensions = ["envoy.filters.http.grpc_json_transcoder", "envoy.filters.http.grpc_field_extraction"],
        release_date = "2023-06-07",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/grpc-ecosystem/grpc-httpjson-transcoding/blob/{version}/LICENSE",
    ),
    com_google_protoconverter = dict(
        project_name = "proto-converter",
        project_desc = "Library that supports the conversion between protobuf binary and json",
        project_url = "https://github.com/grpc-ecosystem/proto-converter",
        version = "d77ff301f48bf2e7a0f8935315e847c1a8e00017",
        sha256 = "6081836fa3838ebb1aa15089a5c3e20f877a0244c7a39b92a2000efb40408dcb",
        strip_prefix = "proto-converter-{version}",
        urls = ["https://github.com/grpc-ecosystem/proto-converter/archive/{version}.zip"],
        use_category = ["dataplane_ext"],
        extensions = ["envoy.filters.http.grpc_json_transcoder", "envoy.filters.http.grpc_field_extraction"],
        release_date = "2023-06-07",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/grpc-ecosystem/proto-converter/blob/{version}/LICENSE",
    ),
    com_google_protofieldextraction = dict(
        project_name = "proto-field-extraction",
        project_desc = "Library that supports the extraction from protobuf binary",
        project_url = "https://github.com/grpc-ecosystem/proto-field-extraction",
        version = "2dfe27548e1f21a665f9068b97b2fc5beb678566",
        sha256 = "ddbbd0dd07012339ac467f5fdac5c294e1efcdc93bb4b7152d468ddbfc9772f0",
        strip_prefix = "proto-field-extraction-{version}",
        urls = ["https://github.com/grpc-ecosystem/proto-field-extraction/archive/{version}.zip"],
        use_category = ["dataplane_ext"],
        extensions = ["envoy.filters.http.grpc_json_transcoder", "envoy.filters.http.grpc_field_extraction"],
        release_date = "2023-07-18",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/grpc-ecosystem/proto-field-extraction/blob/{version}/LICENSE",
    ),
    ocp = dict(
        project_name = "ocp",
        project_desc = "Libraries used in gRPC field extraction library",
        project_url = "https://github.com/opencomputeproject/ocp-diag-core",
        version = "e965ac0ac6db6686169678e2a6c77ede904fa82c",
        sha256 = "b83b8ea7a937ce7f5d6870421be8f9a5343e8c2de2bd2e269452981d67da1509",
        strip_prefix = "ocp-diag-core-{version}/apis/c++",
        urls = ["https://github.com/opencomputeproject/ocp-diag-core/archive/{version}.zip"],
        use_category = ["dataplane_ext"],
        extensions = ["envoy.filters.http.grpc_field_extraction"],
        release_date = "2023-05-05",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/opencomputeproject/ocp-diag-core/blob/{version}/LICENSE",
    ),
    io_bazel_rules_go = dict(
        project_name = "Go rules for Bazel",
        project_desc = "Bazel rules for the Go language",
        project_url = "https://github.com/bazelbuild/rules_go",
        version = "0.39.1",
        sha256 = "6dc2da7ab4cf5d7bfc7c949776b1b7c733f05e56edc4bcd9022bb249d2e2a996",
        urls = ["https://github.com/bazelbuild/rules_go/releases/download/v{version}/rules_go-v{version}.zip"],
        use_category = ["build", "api"],
        release_date = "2023-04-20",
        implied_untracked_deps = [
            "com_github_golang_protobuf",
            "io_bazel_rules_nogo",
            "org_golang_google_protobuf",
            "org_golang_x_tools",
        ],
        license = "Apache-2.0",
        license_url = "https://github.com/bazelbuild/rules_go/blob/v{version}/LICENSE.txt",
    ),
    rules_foreign_cc = dict(
        project_name = "Rules for using foreign build systems in Bazel",
        project_desc = "Rules for using foreign build systems in Bazel",
        project_url = "https://github.com/bazelbuild/rules_foreign_cc",
        version = "0.9.0",
        sha256 = "2a4d07cd64b0719b39a7c12218a3e507672b82a97b98c6a89d38565894cf7c51",
        strip_prefix = "rules_foreign_cc-{version}",
        urls = ["https://github.com/bazelbuild/rules_foreign_cc/archive/{version}.tar.gz"],
        release_date = "2022-08-02",
        use_category = ["build", "dataplane_core", "controlplane"],
        license = "Apache-2.0",
        license_url = "https://github.com/bazelbuild/rules_foreign_cc/blob/{version}/LICENSE",
    ),
    rules_python = dict(
        project_name = "Python rules for Bazel",
        project_desc = "Bazel rules for the Python language",
        project_url = "https://github.com/bazelbuild/rules_python",
        version = "0.29.0",
        sha256 = "d71d2c67e0bce986e1c5a7731b4693226867c45bfe0b7c5e0067228a536fc580",
        release_date = "2024-01-22",
        strip_prefix = "rules_python-{version}",
        urls = ["https://github.com/bazelbuild/rules_python/archive/{version}.tar.gz"],
        use_category = ["build"],
        license = "Apache-2.0",
        license_url = "https://github.com/bazelbuild/rules_python/blob/{version}/LICENSE",
    ),
    rules_ruby = dict(
        # This is needed only to compile protobuf, not used in Envoy code
        project_name = "Ruby rules for Bazel",
        project_desc = "Bazel rules for the Ruby language",
        project_url = "https://github.com/protocolbuffers/rules_ruby",
        version = "37cf5900d0b0e44fa379c0ea3f5fcee0035d77ca",
        sha256 = "24ed42b7e06907be993b21be603c130076c7d7e49d4f4d5bd228c5656a257f5e",
        release_date = "2023-01-12",
        strip_prefix = "rules_ruby-{version}",
        urls = ["https://github.com/protocolbuffers/rules_ruby/archive/{version}.tar.gz"],
        use_category = ["build"],
        license = "Apache-2.0",
        license_url = "https://github.com/protocolbuffers/rules_ruby/blob/{version}/LICENSE",
    ),
    rules_pkg = dict(
        project_name = "Packaging rules for Bazel",
        project_desc = "Bazel rules for the packaging distributions",
        project_url = "https://github.com/bazelbuild/rules_pkg",
        version = "0.7.0",
        sha256 = "e110311d898c1ff35f39829ae3ec56e39c0ef92eb44de74418982a114f51e132",
        strip_prefix = "rules_pkg-{version}",
        urls = ["https://github.com/bazelbuild/rules_pkg/archive/{version}.tar.gz"],
        use_category = ["build"],
        release_date = "2022-04-07",
        license = "Apache-2.0",
        license_url = "https://github.com/bazelbuild/rules_pkg/blob/{version}/LICENSE",
    ),
    org_llvm_llvm = dict(
        # When changing this, you must re-generate the list of llvm libs
        # see `bazel/foreign_cc/BUILD` for further information.
        project_name = "LLVM",
        project_desc = "LLVM Compiler Infrastructure",
        project_url = "https://llvm.org",
        version = "12.0.1",
        sha256 = "7d9a8405f557cefc5a21bf5672af73903b64749d9bc3a50322239f56f34ffddf",
        strip_prefix = "llvm-{version}.src",
        urls = ["https://github.com/llvm/llvm-project/releases/download/llvmorg-{version}/llvm-{version}.src.tar.xz"],
        release_date = "2021-07-09",
        use_category = ["dataplane_ext"],
        extensions = [
            "envoy.wasm.runtime.wamr",
            "envoy.wasm.runtime.wavm",
        ],
        cpe = "cpe:2.3:a:llvm:*:*",
        license = "Apache-2.0",
        license_url = "https://github.com/llvm/llvm-project/blob/llvmorg-{version}/llvm/LICENSE.TXT",
    ),
    com_github_wamr = dict(
        project_name = "Webassembly Micro Runtime",
        project_desc = "A standalone runtime with a small footprint for WebAssembly",
        project_url = "https://github.com/bytecodealliance/wasm-micro-runtime",
        version = "WAMR-1.2.2",
        sha256 = "d328fc1e19c54cfdb4248b861de54b62977b9b85c0a40eaaeb9cd9b628c0c788",
        strip_prefix = "wasm-micro-runtime-{version}",
        urls = ["https://github.com/bytecodealliance/wasm-micro-runtime/archive/{version}.tar.gz"],
        release_date = "2023-05-16",
        use_category = ["dataplane_ext"],
        extensions = ["envoy.wasm.runtime.wamr"],
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/bytecodealliance/wasm-micro-runtime/blob/{version}/LICENSE",
    ),
    com_github_wavm_wavm = dict(
        project_name = "WAVM",
        project_desc = "WebAssembly Virtual Machine",
        project_url = "https://wavm.github.io",
        version = "3f9a150cac7faf28eab357a2c5b83d2ec740c7d9",
        sha256 = "82e05ade03fdac60cf863972d3e7420a771ef4a18afad26ac442554ab0be1207",
        strip_prefix = "WAVM-{version}",
        urls = ["https://github.com/WAVM/WAVM/archive/{version}.tar.gz"],
        release_date = "2022-05-14",
        use_category = ["dataplane_ext"],
        extensions = ["envoy.wasm.runtime.wavm"],
        cpe = "cpe:2.3:a:webassembly_virtual_machine_project:webassembly_virtual_machine:*",
    ),
    com_github_wasmtime = dict(
        project_name = "wasmtime",
        project_desc = "A standalone runtime for WebAssembly",
        project_url = "https://github.com/bytecodealliance/wasmtime",
        version = "9.0.3",
        sha256 = "917da461249b11a3176a39573723f78c627259576d0ca10b00d6e7f7fa047081",
        strip_prefix = "wasmtime-{version}",
        urls = ["https://github.com/bytecodealliance/wasmtime/archive/v{version}.tar.gz"],
        release_date = "2023-05-31",
        use_category = ["dataplane_ext"],
        extensions = ["envoy.wasm.runtime.wasmtime"],
        cpe = "cpe:2.3:a:bytecodealliance:wasmtime:*",
        license = "Apache-2.0",
        license_url = "https://github.com/bytecodealliance/wasmtime/blob/v{version}/LICENSE",
    ),
    com_github_wasm_c_api = dict(
        project_name = "wasm-c-api",
        project_desc = "WebAssembly C and C++ API",
        project_url = "https://github.com/WebAssembly/wasm-c-api",
        # this is the submodule's specific commit used by wasmtime
        # https://github.com/bytecodealliance/wasmtime/tree/v0.25.0/crates/c-api
        version = "c9d31284651b975f05ac27cee0bab1377560b87e",
        sha256 = "c774044f51431429e878bd1b9e2a4e38932f861f9211df72f75e9427eb6b8d32",
        strip_prefix = "wasm-c-api-{version}",
        urls = ["https://github.com/WebAssembly/wasm-c-api/archive/{version}.tar.gz"],
        release_date = "2021-01-11",
        use_category = ["dataplane_ext"],
        extensions = ["envoy.wasm.runtime.wasmtime"],
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/WebAssembly/wasm-c-api/blob/{version}/LICENSE",
    ),
    io_opencensus_cpp = dict(
        project_name = "OpenCensus C++",
        project_desc = "OpenCensus tracing library",
        project_url = "https://github.com/census-instrumentation/opencensus-cpp",
        version = "f68a2d0ea43eb61a4b7889f09987294c4f94d436",
        sha256 = "b5fd69da558d08480e254c7e2a91e23a88ec8b72d9aec1a6c2329d7560a61744",
        strip_prefix = "opencensus-cpp-{version}",
        urls = ["https://github.com/census-instrumentation/opencensus-cpp/archive/{version}.tar.gz"],
        use_category = ["observability_ext"],
        extensions = ["envoy.tracers.opencensus"],
        release_date = "2022-09-20",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/census-instrumentation/opencensus-cpp/blob/{version}/LICENSE",
    ),
    # Curl usage is under deprecation and will be removed by Q3 2024 before v1.31 release in July-2024.
    # See https://github.com/envoyproxy/envoy/issues/11816 & https://github.com/envoyproxy/envoy/pull/30731.
    com_github_curl = dict(
        project_name = "curl",
        project_desc = "Library for transferring data with URLs",
        project_url = "https://curl.haxx.se",
        version = "8.4.0",
        sha256 = "816e41809c043ff285e8c0f06a75a1fa250211bbfb2dc0a037eeef39f1a9e427",
        strip_prefix = "curl-{version}",
        urls = ["https://github.com/curl/curl/releases/download/curl-{underscore_version}/curl-{version}.tar.gz"],
        use_category = ["dataplane_ext", "observability_ext"],
        extensions = [
            "envoy.filters.http.aws_lambda",
            "envoy.filters.http.aws_request_signing",
            "envoy.grpc_credentials.aws_iam",
            "envoy.tracers.opencensus",
        ],
        release_date = "2023-10-11",
        cpe = "cpe:2.3:a:haxx:libcurl:*",
        license = "curl",
        license_url = "https://github.com/curl/curl/blob/curl-{underscore_version}/COPYING",
    ),
    v8 = dict(
        project_name = "V8",
        project_desc = "Googles open source high-performance JavaScript and WebAssembly engine, written in C++",
        project_url = "https://v8.dev",
        # NOTE: Update together with com_googlesource_chromium_base_trace_event_common.
        # Patch contains workaround for https://github.com/bazelbuild/rules_python/issues/1221
        version = "10.7.193.13",
        # Static snapshot created using https://storage.googleapis.com/envoyproxy-wee8/wee8-fetch-deps.sh.
        sha256 = "2170df76ce5d7ecd7fb8d131370d210152f200273cba126f06d8b88fb53c9fbc",
        urls = ["https://storage.googleapis.com/envoyproxy-wee8/v8-{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        extensions = ["envoy.wasm.runtime.v8"],
        release_date = "2022-10-12",
        cpe = "cpe:2.3:a:google:v8:*",
    ),
    com_googlesource_chromium_base_trace_event_common = dict(
        project_name = "Chromium's trace event headers",
        project_desc = "Chromium's trace event headers",
        project_url = "https://chromium.googlesource.com/chromium/src/base/trace_event/common/",
        # NOTE: Update together with v8.
        # Use version and sha256 from https://storage.googleapis.com/envoyproxy-wee8/v8-<v8_version>-deps.sha256.
        version = "521ac34ebd795939c7e16b37d9d3ddb40e8ed556",
        # Static snapshot created using https://storage.googleapis.com/envoyproxy-wee8/wee8-fetch-deps.sh.
        sha256 = "d99726bd452d1dd6cd50ab33060774e8437d9f0fc6079589f657fe369c66ec09",
        urls = ["https://storage.googleapis.com/envoyproxy-wee8/chromium-base_trace_event_common-{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        extensions = ["envoy.wasm.runtime.v8"],
        release_date = "2022-10-12",
        cpe = "N/A",
    ),
    com_github_google_quiche = dict(
        project_name = "QUICHE",
        project_desc = "QUICHE (QUIC, HTTP/2, Etc) is Googles implementation of QUIC and related protocols",
        project_url = "https://github.com/google/quiche",
        version = "76531737853e2eb36ac2cc024f211431e7d28004",
        sha256 = "4fff746f039eed8b7642133ef9008cc60406c0b739beac511db1f01377e06933",
        urls = ["https://github.com/google/quiche/archive/{version}.tar.gz"],
        strip_prefix = "quiche-{version}",
        use_category = ["controlplane", "dataplane_core"],
        release_date = "2024-01-17",
        cpe = "N/A",
        license = "BSD-3-Clause",
        license_url = "https://github.com/google/quiche/blob/{version}/LICENSE",
    ),
    com_googlesource_googleurl = dict(
        project_name = "Chrome URL parsing library",
        project_desc = "Chrome URL parsing library",
        project_url = "https://quiche.googlesource.com/googleurl",
        # Static snapshot of https://quiche.googlesource.com/googleurl/+archive/dd4080fec0b443296c0ed0036e1e776df8813aa7.tar.gz
        version = "dd4080fec0b443296c0ed0036e1e776df8813aa7",
        sha256 = "59f14d4fb373083b9dc8d389f16bbb817b5f936d1d436aa67e16eb6936028a51",
        urls = ["https://storage.googleapis.com/quiche-envoy-integration/{version}.tar.gz"],
        use_category = ["controlplane", "dataplane_core"],
        extensions = [],
        release_date = "2022-11-03",
        cpe = "N/A",
        license = "googleurl",
        license_url = "https://quiche.googlesource.com/googleurl/+/{version}/LICENSE",
    ),
    com_google_cel_cpp = dict(
        project_name = "Common Expression Language (CEL) C++ library",
        project_desc = "Common Expression Language (CEL) C++ library",
        project_url = "https://opensource.google/projects/cel",
        version = "0abd738f9f54388452e6ebb0955eb039f9162b3d",
        sha256 = "d163805320a782c5194b7496cdd5e8c9d9604eeffc1e531770cf6b130bc182fd",
        strip_prefix = "cel-cpp-{version}",
        urls = ["https://github.com/google/cel-cpp/archive/{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        extensions = [
            "envoy.access_loggers.extension_filters.cel",
            "envoy.access_loggers.wasm",
            "envoy.bootstrap.wasm",
            "envoy.rate_limit_descriptors.expr",
            "envoy.filters.http.ext_proc",
            "envoy.filters.http.rate_limit_quota",
            "envoy.filters.http.rbac",
            "envoy.filters.http.wasm",
            "envoy.filters.network.rbac",
            "envoy.filters.network.wasm",
            "envoy.stat_sinks.wasm",
            "envoy.rbac.matchers.upstream_ip_port",
            "envoy.formatter.cel",
            "envoy.matching.inputs.cel_data_input",
            "envoy.matching.matchers.cel_matcher",
        ],
        release_date = "2023-12-20",
        cpe = "N/A",
    ),
    com_github_google_flatbuffers = dict(
        project_name = "FlatBuffers",
        project_desc = "FlatBuffers is a cross platform serialization library architected for maximum memory efficiency",
        project_url = "https://github.com/google/flatbuffers",
        version = "23.3.3",
        sha256 = "8aff985da30aaab37edf8e5b02fda33ed4cbdd962699a8e2af98fdef306f4e4d",
        strip_prefix = "flatbuffers-{version}",
        urls = ["https://github.com/google/flatbuffers/archive/v{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        extensions = [
            "envoy.access_loggers.extension_filters.cel",
            "envoy.access_loggers.wasm",
            "envoy.formatter.cel",
            "envoy.bootstrap.wasm",
            "envoy.rate_limit_descriptors.expr",
            "envoy.filters.http.ext_proc",
            "envoy.filters.http.rate_limit_quota",
            "envoy.filters.http.rbac",
            "envoy.filters.http.wasm",
            "envoy.filters.network.rbac",
            "envoy.filters.network.wasm",
            "envoy.stat_sinks.wasm",
            "envoy.rbac.matchers.upstream_ip_port",
            "envoy.matching.inputs.cel_data_input",
            "envoy.matching.matchers.cel_matcher",
        ],
        release_date = "2023-03-03",
        cpe = "cpe:2.3:a:google:flatbuffers:*",
        license = "Apache-2.0",
        license_url = "https://github.com/google/flatbuffers/blob/v{version}/LICENSE",
    ),
    com_googlesource_code_re2 = dict(
        project_name = "RE2",
        project_desc = "RE2, a regular expression library",
        project_url = "https://github.com/google/re2",
        version = "2023-11-01",
        sha256 = "4e6593ac3c71de1c0f322735bc8b0492a72f66ffccfad76e259fa21c41d27d8a",
        strip_prefix = "re2-{version}",
        urls = ["https://github.com/google/re2/archive/{version}.tar.gz"],
        use_category = ["controlplane", "dataplane_core"],
        release_date = "2023-10-31",
        cpe = "N/A",
        license = "BSD-3-Clause",
        license_url = "https://github.com/google/re2/blob/{version}/LICENSE",
    ),
    # Included to access FuzzedDataProvider.h. This is compiler agnostic but
    # provided as part of the compiler-rt source distribution. We can't use the
    # Clang variant as we are not a Clang-LLVM only shop today.
    org_llvm_releases_compiler_rt = dict(
        project_name = "compiler-rt",
        project_desc = "LLVM compiler runtime library",
        project_url = "https://compiler-rt.llvm.org",
        # Note: the llvm/clang version should match the version specified in:
        #  - .github/workflows/codeql-daily.yml
        #  - .github/workflows/codeql-push.yml
        #  - https://github.com/envoyproxy/envoy-build-tools/blob/main/build_container/build_container_ubuntu.sh#L84
        version = "14.0.0",
        sha256 = "27ab7fcfb21d108093c0be766a9ed5fe18c04e4f74f936069711a312c8ae0377",
        # Only allow peeking at fuzzer related files for now.
        strip_prefix = "compiler-rt-{version}.src",
        urls = ["https://github.com/llvm/llvm-project/releases/download/llvmorg-{version}/compiler-rt-{version}.src.tar.xz"],
        release_date = "2022-03-23",
        use_category = ["test_only"],
        cpe = "cpe:2.3:a:llvm:compiler-rt:*",
        license = "Apache-2.0",
        license_url = "https://github.com/llvm/llvm-project/blob/llvmorg-{version}/compiler-rt/LICENSE.TXT",
    ),
    upb = dict(
        project_name = "upb",
        project_desc = "A small protobuf implementation in C (gRPC dependency)",
        project_url = "https://github.com/protocolbuffers/upb",
        version = "e074c038c35e781a1876f8eb52b14f822ae2db66",
        sha256 = "8608c15b5612c6154d4ee0c23910afe6c283985e1d368ea71704dcd8684135d4",
        release_date = "2023-07-21",
        strip_prefix = "upb-{version}",
        urls = ["https://github.com/protocolbuffers/upb/archive/{version}.tar.gz"],
        use_category = ["controlplane"],
        cpe = "N/A",
        license = "upb",
        license_url = "https://github.com/protocolbuffers/upb/blob/{version}/LICENSE",
    ),
    kafka_source = dict(
        project_name = "Kafka (source)",
        project_desc = "Open-source distributed event streaming platform",
        project_url = "https://kafka.apache.org",
        version = "3.5.1",
        sha256 = "9715589a02148fb21bc80d79f29763dbd371457bedcbbeab3db4f5c7fdd2d29c",
        strip_prefix = "kafka-{version}/clients/src/main/resources/common/message",
        urls = ["https://github.com/apache/kafka/archive/{version}.zip"],
        use_category = ["dataplane_ext"],
        extensions = ["envoy.filters.network.kafka_broker", "envoy.filters.network.kafka_mesh"],
        release_date = "2023-07-14",
        cpe = "cpe:2.3:a:apache:kafka:*",
        license = "Apache-2.0",
        license_url = "https://github.com/apache/kafka/blob/{version}/LICENSE",
    ),
    confluentinc_librdkafka = dict(
        project_name = "Kafka (C/C++ client)",
        project_desc = "C/C++ client for Apache Kafka (open-source distributed event streaming platform)",
        project_url = "https://github.com/confluentinc/librdkafka",
        version = "2.3.0",
        sha256 = "2d49c35c77eeb3d42fa61c43757fcbb6a206daa560247154e60642bcdcc14d12",
        strip_prefix = "librdkafka-{version}",
        urls = ["https://github.com/confluentinc/librdkafka/archive/v{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        extensions = ["envoy.filters.network.kafka_mesh"],
        release_date = "2023-10-25",
        cpe = "N/A",
        license = "librdkafka",
        license_url = "https://github.com/confluentinc/librdkafka/blob/v{version}/LICENSE",
    ),
    kafka_server_binary = dict(
        project_name = "Kafka (server binary)",
        project_desc = "Open-source distributed event streaming platform",
        project_url = "https://kafka.apache.org",
        version = "3.5.1",
        sha256 = "f7b74d544023f2c0ec52a179de59975cb64e34ea03650d829328b407b560e4da",
        strip_prefix = "kafka_2.13-{version}",
        urls = ["https://archive.apache.org/dist/kafka/{version}/kafka_2.13-{version}.tgz"],
        release_date = "2023-07-21",
        use_category = ["test_only"],
    ),
    kafka_python_client = dict(
        project_name = "Kafka (Python client)",
        project_desc = "Open-source distributed event streaming platform",
        project_url = "https://kafka.apache.org",
        version = "2.0.2",
        sha256 = "5dcf87c559e7aee4f18d621a02e247db3e3552ee4589ca611d51eef87b37efed",
        strip_prefix = "kafka-python-{version}",
        urls = ["https://github.com/dpkp/kafka-python/archive/{version}.tar.gz"],
        release_date = "2020-09-30",
        use_category = ["test_only"],
        license = "Apache-2.0",
        license_url = "https://github.com/dpkp/kafka-python/blob/{version}/LICENSE",
    ),
    proxy_wasm_cpp_sdk = dict(
        project_name = "WebAssembly for Proxies (C++ SDK)",
        project_desc = "WebAssembly for Proxies (C++ SDK)",
        project_url = "https://github.com/proxy-wasm/proxy-wasm-cpp-sdk",
        version = "921039ae983ce053bf5cba78a85a3c08ff9791e5",
        sha256 = "a11adfe4e6346d3318ff72643aa5569dc8439d7e8927ed148f93226fa255cc7a",
        strip_prefix = "proxy-wasm-cpp-sdk-{version}",
        urls = ["https://github.com/proxy-wasm/proxy-wasm-cpp-sdk/archive/{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        extensions = [
            "envoy.access_loggers.wasm",
            "envoy.bootstrap.wasm",
            "envoy.filters.http.wasm",
            "envoy.filters.network.wasm",
            "envoy.stat_sinks.wasm",
            "envoy.wasm.runtime.null",
            "envoy.wasm.runtime.v8",
            "envoy.wasm.runtime.wamr",
            "envoy.wasm.runtime.wavm",
            "envoy.wasm.runtime.wasmtime",
        ],
        release_date = "2023-05-01",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/proxy-wasm/proxy-wasm-cpp-sdk/blob/{version}/LICENSE",
    ),
    proxy_wasm_cpp_host = dict(
        project_name = "WebAssembly for Proxies (C++ host implementation)",
        project_desc = "WebAssembly for Proxies (C++ host implementation)",
        project_url = "https://github.com/proxy-wasm/proxy-wasm-cpp-host",
        version = "e200fee8af40918c41f3275cff090993e3b26940",
        sha256 = "9711411b3b8d48a3ee9278f44824ce569c1fdd491183255f568f2b938360e964",
        strip_prefix = "proxy-wasm-cpp-host-{version}",
        urls = ["https://github.com/proxy-wasm/proxy-wasm-cpp-host/archive/{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        extensions = [
            "envoy.access_loggers.wasm",
            "envoy.bootstrap.wasm",
            "envoy.filters.http.wasm",
            "envoy.filters.network.wasm",
            "envoy.stat_sinks.wasm",
            "envoy.wasm.runtime.null",
            "envoy.wasm.runtime.v8",
            "envoy.wasm.runtime.wamr",
            "envoy.wasm.runtime.wavm",
            "envoy.wasm.runtime.wasmtime",
        ],
        release_date = "2023-12-19",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/proxy-wasm/proxy-wasm-cpp-host/blob/{version}/LICENSE",
    ),
    proxy_wasm_rust_sdk = dict(
        project_name = "WebAssembly for Proxies (Rust SDK)",
        project_desc = "WebAssembly for Proxies (Rust SDK)",
        project_url = "https://github.com/proxy-wasm/proxy-wasm-rust-sdk",
        version = "0.2.1",
        sha256 = "23f3f2d8c4c8069a2e72693b350d7442b7722d334f73169eea78804ff70cde20",
        strip_prefix = "proxy-wasm-rust-sdk-{version}",
        urls = ["https://github.com/proxy-wasm/proxy-wasm-rust-sdk/archive/v{version}.tar.gz"],
        use_category = ["test_only"],
        release_date = "2022-11-22",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/proxy-wasm/proxy-wasm-rust-sdk/blob/v{version}/LICENSE",
    ),
    emsdk = dict(
        project_name = "Emscripten SDK",
        project_desc = "Emscripten SDK (use by Wasm)",
        project_url = "https://github.com/emscripten-core/emsdk",
        # v3.1.7 with Bazel fixes
        version = "0ea8f8a8707070e9a7c83fbb4a3065683bcf1799",
        sha256 = "1ca0ff918d476c55707bb99bc0452be28ac5fb8f22a9260a8aae8a38d1bc0e27",
        strip_prefix = "emsdk-{version}/bazel",
        urls = ["https://github.com/emscripten-core/emsdk/archive/{version}.tar.gz"],
        use_category = ["test_only"],
        release_date = "2022-03-09",
        license = "Emscripten SDK",
        license_url = "https://github.com/emscripten-core/emsdk/blob/{version}/LICENSE",
    ),
    rules_rust = dict(
        project_name = "Bazel rust rules",
        project_desc = "Bazel rust rules (used by Wasm)",
        project_url = "https://github.com/bazelbuild/rules_rust",
        version = "0.35.0",
        strip_prefix = "rules_rust-{version}",
        sha256 = "3120c7aa3a146dfe6be8d5f23f4cf10af7d0f74a5aed8b94a818f88643bd24c3",
        urls = ["https://github.com/bazelbuild/rules_rust/archive/{version}.tar.gz"],
        use_category = [
            "controlplane",
            "dataplane_core",
            "dataplane_ext",
        ],
        implied_untracked_deps = ["rules_cc"],
        extensions = ["envoy.wasm.runtime.wasmtime"],
        release_date = "2023-12-27",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/bazelbuild/rules_rust/blob/{version}/LICENSE.txt",
    ),
    com_github_fdio_vpp_vcl = dict(
        project_name = "VPP Comms Library",
        project_desc = "FD.io Vector Packet Processor (VPP) Comms Library",
        project_url = "https://fd.io/",
        version = "493b8990d1185f818890560101e13e1b69f54b1d",
        sha256 = "94a515b9396822911271a8f72ba8ffd9965992241754a88625f4cf2a3883a4ac",
        strip_prefix = "vpp-{version}",
        urls = ["https://github.com/FDio/vpp/archive/{version}.tar.gz"],
        use_category = ["other"],
        extensions = ["envoy.bootstrap.vcl"],
        release_date = "2023-06-28",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/FDio/vpp/blob/{version}/LICENSE",
    ),
    intel_dlb = dict(
        project_name = "Intel Dlb",
        project_desc = "Dlb",
        project_url = "https://networkbuilders.intel.com/solutionslibrary/queue-management-and-load-balancing-on-intel-architecture",
        version = "8.0.0",
        sha256 = "075533229bb2bd2f945ec8089a707205f3f8e8d87a8030e9208603d997236171",
        urls = ["https://downloadmirror.intel.com/763709/dlb_linux_src_release8.0.0.txz"],
        use_category = ["dataplane_ext"],
        extensions = ["envoy.network.connection_balance.dlb"],
        release_date = "2022-12-15",
        cpe = "N/A",
    ),
    libpfm = dict(
        project_name = "libpfm",
        project_desc = "A helper library to develop monitoring tools",
        project_url = "https://sourceforge.net/projects/perfmon2",
        version = "4.11.0",
        sha256 = "5da5f8872bde14b3634c9688d980f68bda28b510268723cc12973eedbab9fecc",
        strip_prefix = "libpfm-{version}",
        use_category = ["test_only"],
        urls = ["https://downloads.sourceforge.net/project/perfmon2/libpfm4/libpfm-{version}.tar.gz"],
        release_date = "2020-09-03",
    ),
    rules_license = dict(
        project_name = "rules_license",
        project_desc = "Bazel rules for checking open source licenses",
        project_url = "https://github.com/bazelbuild/rules_license",
        version = "0.0.8",
        sha256 = "241b06f3097fd186ff468832150d6cc142247dc42a32aaefb56d0099895fd229",
        urls = ["https://github.com/bazelbuild/rules_license/releases/download/{version}/rules_license-{version}.tar.gz"],
        use_category = ["build", "dataplane_core", "controlplane"],
        release_date = "2024-01-24",
        cpe = "N/A",
        license = "Apache-2.0",
        license_url = "https://github.com/bazelbuild/rules_license/blob/{version}/LICENSE",
    ),
    utf8_range = dict(
        project_name = "utf8_range",
        project_desc = "Fast UTF-8 validation with Range algorithm (NEON+SSE4+AVX2)",
        project_url = "https://github.com/protocolbuffers/utf8_range",
        version = "d863bc33e15cba6d873c878dcca9e6fe52b2f8cb",
        sha256 = "c56f0a8c562050e6523a3095cf5610d19c190cd99bac622cc3e5754be51aaa7b",
        strip_prefix = "utf8_range-{version}",
        urls = ["https://github.com/protocolbuffers/utf8_range/archive/{version}.tar.gz"],
        use_category = ["build", "dataplane_core", "controlplane"],
        release_date = "2023-05-26",
        cpe = "N/A",
        license = "MIT",
        license_url = "https://github.com/protocolbuffers/utf8_range/blob/{version}/LICENSE",
    ),
    com_github_maxmind_libmaxminddb = dict(
        project_name = "maxmind_libmaxminddb",
        project_desc = "C library for reading MaxMind DB files",
        project_url = "https://github.com/maxmind/libmaxminddb",
        version = "1.9.1",
        sha256 = "a80682a89d915fdf60b35d316232fb04ebf36fff27fda9bd39fe8a38d3cd3f12",
        strip_prefix = "libmaxminddb-{version}",
        urls = ["https://github.com/maxmind/libmaxminddb/releases/download/{version}/libmaxminddb-{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        extensions = ["envoy.geoip_providers.maxmind"],
        release_date = "2024-01-10",
        cpe = "cpe:2.3:a:maxmind:libmaxminddb:*",
        license = "Apache-2.0",
        license_url = "https://github.com/maxmind/libmaxminddb/blob/{version}/LICENSE",
    ),
    com_github_lz4_lz4 = dict(
        project_name = "LZ4",
        project_desc = "Extremely Fast Compression algorithm",
        project_url = "http://www.lz4.org/",
        version = "1.9.4",
        sha256 = "0b0e3aa07c8c063ddf40b082bdf7e37a1562bda40a0ff5272957f3e987e0e54b",
        strip_prefix = "lz4-{version}",
        urls = ["https://github.com/lz4/lz4/archive/v{version}.tar.gz"],
        use_category = ["dataplane_ext"],
        release_date = "2022-08-15",
        extensions = ["envoy.compression.qatzip.compressor"],
        cpe = "N/A",
    ),
)

def _compiled_protoc_deps(locations, versions):
    for platform, sha in versions.items():
        locations["com_google_protobuf_protoc_%s" % platform] = dict(
            project_name = "Protocol Buffers (protoc) %s" % platform,
            project_desc = "Protoc compiler for protobuf (%s)" % platform,
            project_url = "https://developers.google.com/protocol-buffers",
            version = PROTOBUF_VERSION,
            sha256 = sha,
            urls = ["https://github.com/protocolbuffers/protobuf/releases/download/v{version}/protoc-{version}-%s.zip" % platform.replace("_", "-", 1)],
            use_category = ["dataplane_core", "controlplane"],
            release_date = "2023-07-06",
            cpe = "N/A",
            license = "Protocol Buffers",
            license_url = "https://github.com/protocolbuffers/protobuf/blob/v{version}/LICENSE",
        )

_compiled_protoc_deps(REPOSITORY_LOCATIONS_SPEC, PROTOC_VERSIONS)
load("@envoy_api//bazel:repositories.bzl", "api_dependencies")

def envoy_api_dependencies():
    api_dependencies()
diff --git a/lib/private/yq.bzl b/lib/private/yq.bzl
index 29ca3d7..c8cd5eb 100644
--- a/lib/private/yq.bzl
+++ b/lib/private/yq.bzl
@@ -71,10 +71,13 @@ def _yq_impl(ctx):
 
     # For split operations, yq outputs files in the same directory so we
     # must cd to the correct output dir before executing it
-    bin_dir = "/".join([ctx.bin_dir.path, ctx.label.package]) if ctx.label.package else ctx.bin_dir.path
+    bin_dir = ctx.bin_dir.path
+    if ctx.label.workspace_name:
+        bin_dir = "%s/external/%s" % (bin_dir, ctx.label.workspace_name)
+    bin_dir = "/".join([bin_dir, ctx.label.package]) if ctx.label.package else bin_dir
     escape_bin_dir = _escape_path(bin_dir)
     cmd = "cd {bin_dir} && {yq} {args} {eval_cmd} {expression} {sources} {maybe_out}".format(
-        bin_dir = ctx.bin_dir.path + "/" + ctx.label.package,
+        bin_dir = bin_dir,
         yq = escape_bin_dir + yq_bin.path,
         eval_cmd = "eval" if len(inputs) <= 1 else "eval-all",
         args = " ".join(args),
load("@rules_foreign_cc//foreign_cc:repositories.bzl", "rules_foreign_cc_dependencies")
load("@io_bazel_rules_go//go:deps.bzl", "go_download_sdk", "go_register_toolchains", "go_rules_dependencies")
load("@bazel_gazelle//:deps.bzl", "gazelle_dependencies", "go_repository")
load("@build_bazel_rules_apple//apple:repositories.bzl", "apple_rules_dependencies")
load("@rules_fuzzing//fuzzing:repositories.bzl", "rules_fuzzing_dependencies")
load("@upb//bazel:workspace_deps.bzl", "upb_deps")
load("@rules_pkg//:deps.bzl", "rules_pkg_dependencies")
load("@rules_rust//rust:repositories.bzl", "rules_rust_dependencies", "rust_register_toolchains", "rust_repository_set")
load("@rules_rust//rust:defs.bzl", "rust_common")
load("@proxy_wasm_rust_sdk//bazel:dependencies.bzl", "proxy_wasm_rust_sdk_dependencies")
load("@base_pip3//:requirements.bzl", pip_dependencies = "install_deps")
load("@dev_pip3//:requirements.bzl", pip_dev_dependencies = "install_deps")
load("@fuzzing_pip3//:requirements.bzl", pip_fuzzing_dependencies = "install_deps")
load("@emsdk//:emscripten_deps.bzl", "emscripten_deps")
load("@com_github_aignas_rules_shellcheck//:deps.bzl", "shellcheck_dependencies")
load("@aspect_bazel_lib//lib:repositories.bzl", "register_jq_toolchains", "register_yq_toolchains")
load("@com_google_cel_cpp//bazel:deps.bzl", "parser_deps")
load("@com_github_chrusty_protoc_gen_jsonschema//:deps.bzl", protoc_gen_jsonschema_go_dependencies = "go_dependencies")

# go version for rules_go
GO_VERSION = "1.20"

JQ_VERSION = "1.7"
YQ_VERSION = "4.24.4"

def envoy_dependency_imports(go_version = GO_VERSION, jq_version = JQ_VERSION, yq_version = YQ_VERSION):
    rules_foreign_cc_dependencies()
    go_rules_dependencies()
    go_register_toolchains(go_version)
    envoy_download_go_sdks(go_version)
    gazelle_dependencies(go_sdk = "go_sdk")
    apple_rules_dependencies()
    pip_dependencies()
    pip_dev_dependencies()
    pip_fuzzing_dependencies()
    rules_pkg_dependencies()
    rust_repository_set(
        name = "rust_linux_s390x",
        exec_triple = "s390x-unknown-linux-gnu",
        extra_target_triples = [
            "wasm32-unknown-unknown",
            "wasm32-wasi",
        ],
        versions = [rust_common.default_version],
    )
    rules_rust_dependencies()
    rust_register_toolchains(
        extra_target_triples = [
            "wasm32-unknown-unknown",
            "wasm32-wasi",
        ],
    )
    shellcheck_dependencies()
    upb_deps()
    proxy_wasm_rust_sdk_dependencies()
    rules_fuzzing_dependencies(
        oss_fuzz = True,
        honggfuzz = False,
    )
    emscripten_deps(emscripten_version = "3.1.7")
    register_jq_toolchains(version = jq_version)
    register_yq_toolchains(version = yq_version)
    parser_deps()

    # These dependencies, like most of the Go in this repository, exist only for the API.
    # These repos also have transient dependencies - `build_external` allows them to use them.
    # TODO(phlax): remove `build_external` and pin all transients
    go_repository(
        name = "org_golang_google_grpc",
        build_file_proto_mode = "disable",
        importpath = "google.golang.org/grpc",
        sum = "h1:raiipEjMOIC/TO2AvyTxP25XFdLxNIBwzDh3FM3XztI=",
        version = "v1.34.0",
        build_external = "external",
        # project_url = "https://pkg.go.dev/google.golang.org/grpc",
        # last_update = "2020-12-02"
        # use_category = ["api"],
        # cpe = "cpe:2.3:a:grpc:grpc:*",
    )
    go_repository(
        name = "org_golang_x_net",
        importpath = "golang.org/x/net",
        sum = "h1:0mm1VjtFUOIlE1SbDlwjYaDxZVDP2S5ou6y0gSgXHu8=",
        version = "v0.0.0-20200226121028-0de0cce0169b",
        build_external = "external",
        # project_url = "https://pkg.go.dev/golang.org/x/net",
        # last_update = "2020-02-26"
        # use_category = ["api"],
        # source = "https://github.com/bufbuild/protoc-gen-validate/blob/v0.6.1/dependencies.bzl#L129-L134"
    )
    go_repository(
        name = "org_golang_x_text",
        importpath = "golang.org/x/text",
        sum = "h1:cokOdA+Jmi5PJGXLlLllQSgYigAEfHXJAERHVMaCc2k=",
        version = "v0.3.3",
        build_external = "external",
        # project_url = "https://pkg.go.dev/golang.org/x/text",
        # last_update = "2021-06-16"
        # use_category = ["api"],
        # source = "https://github.com/bufbuild/protoc-gen-validate/blob/v0.6.1/dependencies.bzl#L148-L153"
    )
    go_repository(
        name = "org_golang_google_protobuf",
        importpath = "google.golang.org/protobuf",
        sum = "h1:d0NfwRgPtno5B1Wa6L2DAG+KivqkdutMf1UhdNx175w=",
        version = "v1.28.1",
        build_external = "external",
    )
    go_repository(
        name = "com_github_cncf_xds_go",
        importpath = "github.com/cncf/xds/go",
        sum = "h1:B/lvg4tQ5hfFZd4V2hcSfFVfUvAK6GSFKxIIzwnkv8g=",
        version = "v0.0.0-20220520190051-1e77728a1eaa",
        build_external = "external",
    )
    go_repository(
        name = "com_github_spf13_afero",
        importpath = "github.com/spf13/afero",
        sum = "h1:8q6vk3hthlpb2SouZcnBVKboxWQWMDNF38bwholZrJc=",
        version = "v1.3.4",
        build_external = "external",
        # project_url = "https://pkg.go.dev/github.com/spf13/afero",
        # last_update = "2021-03-20"
        # use_category = ["api"],
        # source = "https://github.com/bufbuild/protoc-gen-validate/blob/v0.6.1/dependencies.bzl#L60-L65"
    )
    go_repository(
        name = "com_github_lyft_protoc_gen_star_v2",
        importpath = "github.com/lyft/protoc-gen-star/v2",
        sum = "h1:keaAo8hRuAT0O3DfJ/wM3rufbAjGeJ1lAtWZHDjKGB0=",
        version = "v2.0.1",
        build_external = "external",
        # project_url = "https://pkg.go.dev/github.com/lyft/protoc-gen-star",
        # last_update = "2023-01-06"
        # use_category = ["api"],
        # source = "https://github.com/bufbuild/protoc-gen-validate/blob/v0.10.1/dependencies.bzl#L35-L40"
    )
    go_repository(
        name = "com_github_iancoleman_strcase",
        importpath = "github.com/iancoleman/strcase",
        sum = "h1:ux/56T2xqZO/3cP1I2F86qpeoYPCOzk+KF/UH/Ar+lk=",
        version = "v0.0.0-20180726023541-3605ed457bf7",
        build_external = "external",
        # project_url = "https://pkg.go.dev/github.com/iancoleman/strcase",
        # last_update = "2020-11-22"
        # use_category = ["api"],
        # source = "https://github.com/bufbuild/protoc-gen-validate/blob/v0.6.1/dependencies.bzl#L23-L28"
    )
    go_repository(
        name = "com_github_planetscale_vtprotobuf",
        importpath = "github.com/planetscale/vtprotobuf",
        sum = "h1:nve54OLsoKDQhb8ZnnHHUyvAK3vjBiwTEJeC3UsqzJ8=",
        version = "v0.5.1-0.20231205081218-d930d8ac92f8",
        build_external = "external",
    )

    protoc_gen_jsonschema_go_dependencies()

def envoy_download_go_sdks(go_version):
    go_download_sdk(
        name = "go_linux_amd64",
        goos = "linux",
        goarch = "amd64",
        version = go_version,
    )
    go_download_sdk(
        name = "go_linux_arm64",
        goos = "linux",
        goarch = "arm64",
        version = go_version,
    )
    go_download_sdk(
        name = "go_darwin_amd64",
        goos = "darwin",
        goarch = "amd64",
        version = go_version,
    )
    go_download_sdk(
        name = "go_darwin_arm64",
        goos = "darwin",
        goarch = "arm64",
        version = go_version,
    )
{
	lua*;
	envoyGo*;
};
load(
    "@bazel_tools//tools/build_defs/cc:action_names.bzl",
    "CPP_COMPILE_ACTION_NAME",
)

def _pch(ctx):
    deps_cc_info = cc_common.merge_cc_infos(
        cc_infos = [dep[CcInfo] for dep in ctx.attr.deps],
    )

    if not ctx.attr.enabled:
        return [deps_cc_info]

    cc_toolchain = ctx.attr._cc_toolchain[cc_common.CcToolchainInfo]
    feature_configuration = cc_common.configure_features(
        ctx = ctx,
        cc_toolchain = cc_toolchain,
        requested_features = ctx.features,
        unsupported_features = ctx.disabled_features,
    )

    cc_compiler_path = cc_common.get_tool_for_action(
        feature_configuration = feature_configuration,
        action_name = CPP_COMPILE_ACTION_NAME,
    )

    if "clang" not in cc_compiler_path:
        fail("error: attempting to use clang PCH without clang: {}".format(cc_compiler_path))

    generated_header_file = ctx.actions.declare_file(ctx.label.name + ".h")
    ctx.actions.write(
        generated_header_file,
        "\n".join(["#include \"{}\"".format(include) for include in ctx.attr.includes]) + "\n",
    )

    pch_flags = ["-x", "c++-header", "-Xclang", "-fno-pch-timestamp"]
    pch_file = ctx.actions.declare_file(ctx.label.name + ".pch")

    deps_ctx = deps_cc_info.compilation_context
    cc_compile_variables = cc_common.create_compile_variables(
        feature_configuration = feature_configuration,
        cc_toolchain = cc_toolchain,
        user_compile_flags = ctx.fragments.cpp.copts + ctx.fragments.cpp.cxxopts + pch_flags,
        source_file = generated_header_file.path,
        output_file = pch_file.path,
        preprocessor_defines = depset(deps_ctx.defines.to_list() + deps_ctx.local_defines.to_list()),
        include_directories = deps_ctx.includes,
        quote_include_directories = deps_ctx.quote_includes,
        system_include_directories = deps_ctx.system_includes,
        framework_include_directories = deps_ctx.framework_includes,
    )

    env = cc_common.get_environment_variables(
        feature_configuration = feature_configuration,
        action_name = CPP_COMPILE_ACTION_NAME,
        variables = cc_compile_variables,
    )

    command_line = cc_common.get_memory_inefficient_command_line(
        feature_configuration = feature_configuration,
        action_name = CPP_COMPILE_ACTION_NAME,
        variables = cc_compile_variables,
    )

    transitive_headers = []
    for dep in ctx.attr.deps:
        transitive_headers.append(dep[CcInfo].compilation_context.headers)
    ctx.actions.run(
        executable = cc_compiler_path,
        arguments = command_line,
        env = env,
        inputs = depset(
            items = [generated_header_file],
            transitive = [cc_toolchain.all_files] + transitive_headers,
        ),
        outputs = [pch_file],
    )

    return [
        DefaultInfo(files = depset(items = [pch_file])),
        cc_common.merge_cc_infos(
            direct_cc_infos = [
                CcInfo(
                    compilation_context = cc_common.create_compilation_context(
                        headers = depset([pch_file, generated_header_file]),
                    ),
                ),
            ],
            cc_infos = [deps_cc_info],
        ),
    ]

pch = rule(
    attrs = dict(
        includes = attr.string_list(
            mandatory = True,
            allow_empty = False,
        ),
        deps = attr.label_list(
            mandatory = True,
            allow_empty = False,
            providers = [CcInfo],
        ),
        enabled = attr.bool(
            mandatory = True,
        ),
        _cc_toolchain = attr.label(default = Label("@bazel_tools//tools/cpp:current_cc_toolchain")),
    ),
    fragments = ["cpp"],
    provides = [CcInfo],
    toolchains = ["@bazel_tools//tools/cpp:toolchain_type"],
    implementation = _pch,
)
#!/bin/bash

# Dummy shell implementation for nooping tests.
# TODO(lizan): remove when we have a solution for
# https://github.com/bazelbuild/bazel/issues/3510

cd "$(dirname "$0")" || exit 1

if [ $# -gt 0 ]; then
  "./${1}" "${@:2}"
fi
licenses(["notice"])  # Apache 2
load("@proxy_wasm_cpp_sdk//bazel:defs.bzl", "proxy_wasm_cc_binary")
load("@rules_rust//rust:defs.bzl", "rust_binary")

def _wasm_rust_transition_impl(settings, attr):
    return {
        "//command_line_option:platforms": "@rules_rust//rust/platform:wasm",
    }

def _wasi_rust_transition_impl(settings, attr):
    return {
        "//command_line_option:platforms": "@rules_rust//rust/platform:wasi",
    }

wasm_rust_transition = transition(
    implementation = _wasm_rust_transition_impl,
    inputs = [],
    outputs = [
        "//command_line_option:platforms",
    ],
)

wasi_rust_transition = transition(
    implementation = _wasi_rust_transition_impl,
    inputs = [],
    outputs = [
        "//command_line_option:platforms",
    ],
)

def _wasm_binary_impl(ctx):
    out = ctx.actions.declare_file(ctx.label.name)
    if ctx.attr.precompile:
        ctx.actions.run(
            executable = ctx.executable._compile_tool,
            arguments = [ctx.files.binary[0].path, out.path],
            outputs = [out],
            inputs = ctx.files.binary,
        )
    else:
        ctx.actions.run(
            executable = "cp",
            arguments = [ctx.files.binary[0].path, out.path],
            outputs = [out],
            inputs = ctx.files.binary,
        )

    return [DefaultInfo(files = depset([out]), runfiles = ctx.runfiles([out]))]

def _wasm_attrs(transition):
    return {
        "binary": attr.label(mandatory = True, cfg = transition),
        "precompile": attr.bool(default = False),
        # This is deliberately in target configuration to avoid compiling v8 twice.
        "_compile_tool": attr.label(default = "@envoy//test/tools/wee8_compile:wee8_compile_tool", executable = True, cfg = "target"),
        "_allowlist_function_transition": attr.label(default = "@bazel_tools//tools/allowlists/function_transition_allowlist"),
    }

wasm_rust_binary_rule = rule(
    implementation = _wasm_binary_impl,
    attrs = _wasm_attrs(wasm_rust_transition),
)

wasi_rust_binary_rule = rule(
    implementation = _wasm_binary_impl,
    attrs = _wasm_attrs(wasi_rust_transition),
)

def envoy_wasm_cc_binary(name, additional_linker_inputs = [], linkopts = [], tags = [], **kwargs):
    proxy_wasm_cc_binary(
        name = name,
        additional_linker_inputs = additional_linker_inputs + [
            "@envoy//source/extensions/common/wasm/ext:envoy_proxy_wasm_api_js",
        ],
        linkopts = linkopts + [
            "--js-library=$(location @envoy//source/extensions/common/wasm/ext:envoy_proxy_wasm_api_js)",
        ],
        tags = tags + ["manual"],
        **kwargs
    )

def wasm_rust_binary(name, tags = [], wasi = False, precompile = False, **kwargs):
    wasm_name = "_wasm_" + name.replace(".", "_")
    kwargs.setdefault("visibility", ["//visibility:public"])

    rust_binary(
        name = wasm_name,
        edition = "2018",
        crate_type = "cdylib",
        out_binary = True,
        tags = ["manual"],
        **kwargs
    )

    bin_rule = wasm_rust_binary_rule
    if wasi:
        bin_rule = wasi_rust_binary_rule

    bin_rule(
        name = name,
        precompile = precompile,
        binary = ":" + wasm_name,
        tags = tags + ["manual"],
    )
diff --git a/absl/flags/commandlineflag.h b/absl/flags/commandlineflag.h
index f2fa08977f..8e97fdb0ca 100644
--- a/absl/flags/commandlineflag.h
+++ b/absl/flags/commandlineflag.h
@@ -153,7 +153,7 @@ class CommandLineFlag {
   bool ParseFrom(absl::string_view value, std::string* error);
 
  protected:
-  ~CommandLineFlag() = default;
+  virtual ~CommandLineFlag() = default;
 
  private:
   friend class flags_internal::PrivateHandleAccessor;
diff --git a/absl/debugging/internal/stacktrace_config.h b/absl/debugging/internal/stacktrace_config.h
--- a/absl/debugging/internal/stacktrace_config.h	2023-06-30 13:00:30.464949167 +0000
+++ b/absl/debugging/internal/stacktrace_config.h	2023-06-30 13:01:11.844904587 +0000
@@ -40,7 +40,7 @@
 // Emscripten stacktraces rely on JS. Do not use them in standalone mode.
 #elif defined(__EMSCRIPTEN__) && !defined(STANDALONE_WASM)
 #define ABSL_STACKTRACE_INL_HEADER \
-  "absl/debugging/internal/stacktrace_emscripten-inl.inc"
+  "absl/debugging/internal/stacktrace_unimplemented-inl.inc"
 
 #elif defined(__linux__) && !defined(__ANDROID__)
 
diff --git a/absl/debugging/symbolize.cc b/absl/debugging/symbolize.cc
--- a/absl/debugging/symbolize.cc	2023-06-30 13:11:48.688535829 +0000
+++ b/absl/debugging/symbolize.cc	2023-06-30 13:12:03.960525578 +0000
@@ -37,7 +37,7 @@
 #elif defined(__APPLE__)
 #include "absl/debugging/symbolize_darwin.inc"
 #elif defined(ABSL_INTERNAL_HAVE_SYMBOLIZE_WASM)
-#include "absl/debugging/symbolize_emscripten.inc"
+#include "absl/debugging/symbolize_unimplemented.inc"
 #else
 #include "absl/debugging/symbolize_unimplemented.inc"
 #endif
# The main Envoy bazel file. Load this file for all Envoy-specific build macros
# and rules that you'd like to use in your BUILD files.
load("@rules_foreign_cc//foreign_cc:cmake.bzl", "cmake")
load(":envoy_binary.bzl", _envoy_cc_binary = "envoy_cc_binary")
load(":envoy_internal.bzl", "envoy_external_dep_path")
load(
    ":envoy_library.bzl",
    _envoy_basic_cc_library = "envoy_basic_cc_library",
    _envoy_cc_contrib_extension = "envoy_cc_contrib_extension",
    _envoy_cc_extension = "envoy_cc_extension",
    _envoy_cc_library = "envoy_cc_library",
    _envoy_cc_linux_library = "envoy_cc_linux_library",
    _envoy_cc_posix_library = "envoy_cc_posix_library",
    _envoy_cc_posix_without_linux_library = "envoy_cc_posix_without_linux_library",
    _envoy_cc_win32_library = "envoy_cc_win32_library",
    _envoy_proto_library = "envoy_proto_library",
)
load(":envoy_pch.bzl", _envoy_pch_library = "envoy_pch_library")
load(
    ":envoy_select.bzl",
    _envoy_select_admin_functionality = "envoy_select_admin_functionality",
    _envoy_select_admin_html = "envoy_select_admin_html",
    _envoy_select_admin_no_html = "envoy_select_admin_no_html",
    _envoy_select_boringssl = "envoy_select_boringssl",
    _envoy_select_disable_exceptions = "envoy_select_disable_exceptions",
    _envoy_select_disable_logging = "envoy_select_disable_logging",
    _envoy_select_enable_http3 = "envoy_select_enable_http3",
    _envoy_select_enable_http_datagrams = "envoy_select_enable_http_datagrams",
    _envoy_select_enable_yaml = "envoy_select_enable_yaml",
    _envoy_select_envoy_mobile_listener = "envoy_select_envoy_mobile_listener",
    _envoy_select_envoy_mobile_xds = "envoy_select_envoy_mobile_xds",
    _envoy_select_google_grpc = "envoy_select_google_grpc",
    _envoy_select_hot_restart = "envoy_select_hot_restart",
    _envoy_select_signal_trace = "envoy_select_signal_trace",
    _envoy_select_static_extension_registration = "envoy_select_static_extension_registration",
    _envoy_select_wasm_cpp_tests = "envoy_select_wasm_cpp_tests",
    _envoy_select_wasm_rust_tests = "envoy_select_wasm_rust_tests",
    _envoy_select_wasm_v8 = "envoy_select_wasm_v8",
    _envoy_select_wasm_wamr = "envoy_select_wasm_wamr",
    _envoy_select_wasm_wasmtime = "envoy_select_wasm_wasmtime",
    _envoy_select_wasm_wavm = "envoy_select_wasm_wavm",
)
load(
    ":envoy_test.bzl",
    _envoy_benchmark_test = "envoy_benchmark_test",
    _envoy_cc_benchmark_binary = "envoy_cc_benchmark_binary",
    _envoy_cc_fuzz_test = "envoy_cc_fuzz_test",
    _envoy_cc_mock = "envoy_cc_mock",
    _envoy_cc_test = "envoy_cc_test",
    _envoy_cc_test_binary = "envoy_cc_test_binary",
    _envoy_cc_test_library = "envoy_cc_test_library",
    _envoy_py_test = "envoy_py_test",
    _envoy_py_test_binary = "envoy_py_test_binary",
    _envoy_sh_test = "envoy_sh_test",
)
load(
    ":envoy_mobile_defines.bzl",
    _envoy_mobile_defines = "envoy_mobile_defines",
)
load(
    "@envoy_build_config//:extensions_build_config.bzl",
    "CONTRIB_EXTENSION_PACKAGE_VISIBILITY",
    "EXTENSION_PACKAGE_VISIBILITY",
)
load("@bazel_skylib//rules:common_settings.bzl", "bool_flag")

def envoy_package(default_visibility = ["//visibility:public"]):
    native.package(default_visibility = default_visibility)

def envoy_extension_package(enabled_default = True, default_visibility = EXTENSION_PACKAGE_VISIBILITY):
    native.package(default_visibility = default_visibility)

    bool_flag(
        name = "enabled",
        build_setting_default = enabled_default,
    )

    native.config_setting(
        name = "is_enabled",
        flag_values = {":enabled": "True"},
    )

def envoy_mobile_package(default_visibility = ["//visibility:public"]):
    envoy_extension_package(default_visibility = default_visibility)

def envoy_contrib_package():
    envoy_extension_package(default_visibility = CONTRIB_EXTENSION_PACKAGE_VISIBILITY)

# A genrule variant that can output a directory. This is useful when doing things like
# generating a fuzz corpus mechanically.
def _envoy_directory_genrule_impl(ctx):
    tree = ctx.actions.declare_directory(ctx.attr.name + ".outputs")
    ctx.actions.run_shell(
        inputs = ctx.files.srcs,
        tools = ctx.files.tools,
        outputs = [tree],
        command = "mkdir -p " + tree.path + " && " + ctx.expand_location(ctx.attr.cmd),
        env = {"GENRULE_OUTPUT_DIR": tree.path},
        toolchain = None,
    )
    return [DefaultInfo(files = depset([tree]))]

envoy_directory_genrule = rule(
    implementation = _envoy_directory_genrule_impl,
    attrs = {
        "srcs": attr.label_list(),
        "cmd": attr.string(),
        "tools": attr.label_list(),
    },
)

# External CMake C++ library targets should be specified with this function. This defaults
# to building the dependencies with ninja
def envoy_cmake(
        name,
        cache_entries = {},
        debug_cache_entries = {},
        default_cache_entries = {"CMAKE_BUILD_TYPE": "Bazel"},
        lib_source = "",
        postfix_script = "",
        copy_pdb = False,
        pdb_name = "",
        cmake_files_dir = "$BUILD_TMPDIR/CMakeFiles",
        generate_crosstool_file = False,
        generate_args = ["-GNinja"],
        targets = ["", "install"],
        **kwargs):
    cache_entries.update(default_cache_entries)
    cache_entries_debug = dict(cache_entries)
    cache_entries_debug.update(debug_cache_entries)

    pf = ""
    if copy_pdb:
        # TODO: Add iterator of the first list presented of these options;
        # static_libraries[.pdb], pdb_names, name[.pdb] files
        if pdb_name == "":
            pdb_name = name

        copy_command = "cp {cmake_files_dir}/{pdb_name}.dir/{pdb_name}.pdb $INSTALLDIR/lib/{pdb_name}.pdb".format(cmake_files_dir = cmake_files_dir, pdb_name = pdb_name)
        if postfix_script != "":
            copy_command = copy_command + " && " + postfix_script

        pf = select({
            "@envoy//bazel:windows_dbg_build": copy_command,
            "//conditions:default": postfix_script,
        })
    else:
        pf = postfix_script

    cmake(
        name = name,
        cache_entries = select({
            "@envoy//bazel:dbg_build": cache_entries_debug,
            "//conditions:default": cache_entries,
        }),
        generate_args = generate_args,
        targets = targets,
        # TODO: Remove install target and make this work
        install = False,
        # TODO(lizan): Make this always true
        generate_crosstool_file = select({
            "@envoy//bazel:windows_x86_64": True,
            "//conditions:default": generate_crosstool_file,
        }),
        lib_source = lib_source,
        postfix_script = pf,
        **kwargs
    )

# Used to select a dependency that has different implementations on POSIX vs Windows.
# The platform-specific implementations should be specified with envoy_cc_posix_library
# and envoy_cc_win32_library respectively
def envoy_cc_platform_dep(name):
    return select({
        "@envoy//bazel:windows_x86_64": [name + "_win32"],
        "//conditions:default": [name + "_posix"],
    })

# Used to select a dependency that has different implementations on Linux vs rest of POSIX vs Windows.
# The platform-specific implementations should be specified with envoy_cc_linux_library,
# envoy_cc_posix_without_library and envoy_cc_win32_library respectively
def envoy_cc_platform_specific_dep(name):
    return select({
        "@envoy//bazel:windows_x86_64": [name + "_win32"],
        "@envoy//bazel:linux": [name + "_linux"],
        "//conditions:default": [name + "_posix"],
    })

# Envoy proto descriptor targets should be specified with this function.
# This is used for testing only.
def envoy_proto_descriptor(name, out, srcs = [], external_deps = []):
    input_files = ["$(location " + src + ")" for src in srcs]
    include_paths = [".", native.package_name()]

    if "api_httpbody_protos" in external_deps:
        srcs.append("@com_google_googleapis//google/api:httpbody.proto")
        include_paths.append("external/com_google_googleapis")

    if "http_api_protos" in external_deps:
        srcs.append("@com_google_googleapis//google/api:annotations.proto")
        srcs.append("@com_google_googleapis//google/api:http.proto")
        include_paths.append("external/com_google_googleapis")

    if "well_known_protos" in external_deps:
        srcs.append("@com_google_protobuf//:well_known_type_protos")
        srcs.append("@com_google_protobuf//:descriptor_proto_srcs")
        include_paths.append("external/com_google_protobuf/src")

    options = ["--include_imports"]
    options.extend(["-I" + include_path for include_path in include_paths])
    options.append("--descriptor_set_out=$@")

    cmd = "$(location //external:protoc) " + " ".join(options + input_files)
    native.genrule(
        name = name,
        srcs = srcs,
        outs = [out],
        cmd = cmd,
        tools = ["//external:protoc"],
    )

# Dependencies on Google grpc should be wrapped with this function.
def envoy_google_grpc_external_deps():
    return envoy_select_google_grpc([envoy_external_dep_path("grpc")])

# Here we create wrappers for each of the public targets within the separate bazel
# files loaded above. This maintains envoy_build_system.bzl as the preferred import
# for BUILD files that need these build macros. Do not use the imports directly
# from the other bzl files (e.g. envoy_select.bzl, envoy_binary.bzl, etc.)

# Select wrappers (from envoy_select.bzl)
envoy_select_admin_html = _envoy_select_admin_html
envoy_select_admin_no_html = _envoy_select_admin_no_html
envoy_select_admin_functionality = _envoy_select_admin_functionality
envoy_select_static_extension_registration = _envoy_select_static_extension_registration
envoy_select_envoy_mobile_listener = _envoy_select_envoy_mobile_listener
envoy_select_envoy_mobile_xds = _envoy_select_envoy_mobile_xds
envoy_select_boringssl = _envoy_select_boringssl
envoy_select_disable_logging = _envoy_select_disable_logging
envoy_select_google_grpc = _envoy_select_google_grpc
envoy_select_enable_http3 = _envoy_select_enable_http3
envoy_select_enable_yaml = _envoy_select_enable_yaml
envoy_select_disable_exceptions = _envoy_select_disable_exceptions
envoy_select_hot_restart = _envoy_select_hot_restart
envoy_select_enable_http_datagrams = _envoy_select_enable_http_datagrams
envoy_select_signal_trace = _envoy_select_signal_trace
envoy_select_wasm_cpp_tests = _envoy_select_wasm_cpp_tests
envoy_select_wasm_rust_tests = _envoy_select_wasm_rust_tests
envoy_select_wasm_v8 = _envoy_select_wasm_v8
envoy_select_wasm_wamr = _envoy_select_wasm_wamr
envoy_select_wasm_wavm = _envoy_select_wasm_wavm
envoy_select_wasm_wasmtime = _envoy_select_wasm_wasmtime

# Binary wrappers (from envoy_binary.bzl)
envoy_cc_binary = _envoy_cc_binary

# Library wrappers (from envoy_library.bzl)
envoy_basic_cc_library = _envoy_basic_cc_library
envoy_cc_extension = _envoy_cc_extension
envoy_cc_contrib_extension = _envoy_cc_contrib_extension
envoy_cc_library = _envoy_cc_library
envoy_cc_linux_library = _envoy_cc_linux_library
envoy_cc_posix_library = _envoy_cc_posix_library
envoy_cc_posix_without_linux_library = _envoy_cc_posix_without_linux_library
envoy_cc_win32_library = _envoy_cc_win32_library
envoy_proto_library = _envoy_proto_library
envoy_pch_library = _envoy_pch_library

# Test wrappers (from envoy_test.bzl)
envoy_cc_fuzz_test = _envoy_cc_fuzz_test
envoy_cc_mock = _envoy_cc_mock
envoy_cc_test = _envoy_cc_test
envoy_cc_test_binary = _envoy_cc_test_binary
envoy_cc_test_library = _envoy_cc_test_library
envoy_cc_benchmark_binary = _envoy_cc_benchmark_binary
envoy_benchmark_test = _envoy_benchmark_test
envoy_py_test = _envoy_py_test
envoy_py_test_binary = _envoy_py_test_binary
envoy_sh_test = _envoy_sh_test

# Envoy Mobile defines (from envoy_mobile_defines.bz)
envoy_mobile_defines = _envoy_mobile_defines
# DO NOT LOAD THIS FILE. Load envoy_build_system.bzl instead.
# Envoy select targets. This is in a separate file to avoid a circular
# dependency with envoy_build_system.bzl.

# Used to select a dependency that has different implementations on POSIX vs Windows.
# The platform-specific implementations should be specified with envoy_cc_posix_library
# and envoy_cc_win32_library respectively
def envoy_cc_platform_dep(name):
    return select({
        "@envoy//bazel:windows_x86_64": [name + "_win32"],
        "//conditions:default": [name + "_posix"],
    })

def envoy_select_boringssl(if_fips, default = None, if_disabled = None):
    return select({
        "@envoy//bazel:boringssl_fips": if_fips,
        "@envoy//bazel:boringssl_disabled": if_disabled or [],
        "//conditions:default": default or [],
    })

# Selects the given values if Google gRPC is enabled in the current build.
def envoy_select_google_grpc(xs, repository = ""):
    return select({
        repository + "//bazel:disable_google_grpc": [],
        "//conditions:default": xs,
    })

# Selects the given values if logging is enabled in the current build.
def envoy_select_disable_logging(xs, repository = ""):
    return select({
        repository + "//bazel:disable_logging": xs,
        "//conditions:default": [],
    })

# Selects the given values if admin HTML is enabled in the current build.
def envoy_select_admin_html(xs, repository = ""):
    return select({
        repository + "//bazel:disable_admin_html": [],
        "//conditions:default": xs,
    })

# Selects the given values if admin functionality is enabled in the current build.
def envoy_select_admin_functionality(xs, repository = ""):
    return select({
        repository + "//bazel:disable_admin_functionality": [],
        "//conditions:default": xs,
    })

def envoy_select_admin_no_html(xs, repository = ""):
    return select({
        repository + "//bazel:disable_admin_html": xs,
        "//conditions:default": [],
    })

# Selects the given values if static extension registration is enabled in the current build.
def envoy_select_static_extension_registration(xs, repository = ""):
    return select({
        repository + "//bazel:disable_static_extension_registration": [],
        "//conditions:default": xs,
    })

# Selects the given values if the Envoy Mobile listener is enabled in the current build.
def envoy_select_envoy_mobile_listener(xs, repository = ""):
    return select({
        repository + "//bazel:disable_envoy_mobile_listener": [],
        "//conditions:default": xs,
    })

# Selects the given values if Envoy Mobile xDS is enabled in the current build.
def envoy_select_envoy_mobile_xds(xs, repository = ""):
    return select({
        repository + "//bazel:disable_envoy_mobile_xds": [],
        "//conditions:default": xs,
    })

# Selects the given values if http3 is enabled in the current build.
def envoy_select_enable_http3(xs, repository = ""):
    return select({
        repository + "//bazel:disable_http3": [],
        "//conditions:default": xs,
    })

# Selects the given values if yaml is enabled in the current build.
def envoy_select_enable_yaml(xs, repository = ""):
    return select({
        repository + "//bazel:disable_yaml": [],
        "//conditions:default": xs,
    })

# Selects the given values if exceptions are disabled in the current build.
def envoy_select_disable_exceptions(xs, repository = ""):
    return select({
        repository + "//bazel:disable_exceptions": xs,
        "//conditions:default": [],
    })

# Selects the given values if HTTP datagram support is enabled in the current build.
def envoy_select_enable_http_datagrams(xs, repository = ""):
    return select({
        repository + "//bazel:disable_http_datagrams": [],
        "//conditions:default": xs,
    })

# Selects the given values if hot restart is enabled in the current build.
def envoy_select_hot_restart(xs, repository = ""):
    return select({
        repository + "//bazel:disable_hot_restart": [],
        "//conditions:default": xs,
    })

# Selects the given values if full protos are enabled in the current build.
def envoy_select_enable_full_protos(xs, repository = ""):
    return select({
        repository + "//bazel:disable_full_protos": [],
        "//conditions:default": xs,
    })

# Selects the given values if lite protos are enabled in the current build.
def envoy_select_enable_lite_protos(xs, repository = ""):
    return select({
        repository + "//bazel:disable_full_protos": xs,
        "//conditions:default": [],
    })

# Selects the given values if signal trace is enabled in the current build.
def envoy_select_signal_trace(xs, repository = ""):
    return select({
        repository + "//bazel:disable_signal_trace": [],
        "//conditions:default": xs,
    })

# Selects the given values depending on the Wasm runtimes enabled in the current build,
# and the ability to build tests using Proxy-Wasm C++ SDK on the current platform.
def envoy_select_wasm_cpp_tests(xs):
    return select({
        "@envoy//bazel:not_x86_or_wasm_disabled": [],
        "//conditions:default": xs,
    })

# Selects the given values depending on the Wasm runtimes enabled in the current build,
# and the ability to build tests using Proxy-Wasm Rust SDK on the current platform.
def envoy_select_wasm_rust_tests(xs):
    return select({
        "@envoy//bazel:wasm_disabled": [],
        # TODO(phlax): re-enable once issues with llvm profiler are resolved
        #   (see https://github.com/envoyproxy/envoy/issues/24164)
        "@envoy//bazel:coverage_build": [],
        "//conditions:default": xs,
    })

# Selects the given values depending on the Wasm runtimes enabled in the current build.
def envoy_select_wasm_v8(xs):
    return select({
        "@envoy//bazel:wasm_v8": xs,
        "@envoy//bazel:wasm_wamr": [],
        "@envoy//bazel:wasm_wasmtime": [],
        "@envoy//bazel:wasm_wavm": [],
        "@envoy//bazel:wasm_disabled": [],
        # TODO(phlax): re-enable once issues with llvm profiler are resolved
        #   (see https://github.com/envoyproxy/envoy/issues/24164)
        "@envoy//bazel:coverage_build": [],
        "//conditions:default": xs,  # implicit default (v8)
    })

# Selects True or False depending on the Wasm runtimes enabled in the current build.
def envoy_select_wasm_v8_bool():
    return select({
        "@envoy//bazel:wasm_v8": True,
        "@envoy//bazel:wasm_wamr": False,
        "@envoy//bazel:wasm_wasmtime": False,
        "@envoy//bazel:wasm_wavm": False,
        "@envoy//bazel:wasm_disabled": False,
        # TODO(phlax): re-enable once issues with llvm profiler are resolved
        #   (see https://github.com/envoyproxy/envoy/issues/24164)
        "@envoy//bazel:coverage_build": False,
        "//conditions:default": True,  # implicit default (v8)
    })

# Selects the given values depending on the Wasm runtimes enabled in the current build.
def envoy_select_wasm_wamr(xs):
    return select({
        "@envoy//bazel:wasm_wamr": xs,
        "//conditions:default": [],
    })

# Selects the given values depending on the Wasm runtimes enabled in the current build.
def envoy_select_wasm_wavm(xs):
    return select({
        "@envoy//bazel:wasm_wavm": xs,
        "//conditions:default": [],
    })

# Selects the given values depending on the Wasm runtimes enabled in the current build.
def envoy_select_wasm_wasmtime(xs):
    return select({
        "@envoy//bazel:wasm_wasmtime": xs,
        "//conditions:default": [],
    })
diff --git a/java/repositories.bzl b/java/repositories.bzl
index 7e5b939..e8d10b3 100644
--- a/java/repositories.bzl
+++ b/java/repositories.bzl
@@ -88,7 +88,7 @@ def remote_jdk8_repos(name = ""):
     maybe(
         remote_java_repository,
         name = "remote_jdk8_linux_aarch64",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:linux",
             "@platforms//cpu:aarch64",
         ],
@@ -103,7 +103,7 @@ def remote_jdk8_repos(name = ""):
     maybe(
         remote_java_repository,
         name = "remote_jdk8_linux_s390x",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:linux",
             "@platforms//cpu:s390x",
         ],
@@ -117,7 +117,7 @@ def remote_jdk8_repos(name = ""):
     maybe(
         remote_java_repository,
         name = "remote_jdk8_linux",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:linux",
             "@platforms//cpu:x86_64",
         ],
@@ -132,7 +132,7 @@ def remote_jdk8_repos(name = ""):
     maybe(
         remote_java_repository,
         name = "remote_jdk8_macos_aarch64",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:macos",
             "@platforms//cpu:aarch64",
         ],
@@ -146,7 +146,7 @@ def remote_jdk8_repos(name = ""):
     maybe(
         remote_java_repository,
         name = "remote_jdk8_macos",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:macos",
             "@platforms//cpu:x86_64",
         ],
@@ -161,7 +161,7 @@ def remote_jdk8_repos(name = ""):
     maybe(
         remote_java_repository,
         name = "remote_jdk8_windows",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:windows",
             "@platforms//cpu:x86_64",
         ],
@@ -189,7 +189,7 @@ def remote_jdk11_repos():
     maybe(
         remote_java_repository,
         name = "remotejdk11_linux",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:linux",
             "@platforms//cpu:x86_64",
         ],
@@ -205,7 +205,7 @@ def remote_jdk11_repos():
     maybe(
         remote_java_repository,
         name = "remotejdk11_linux_aarch64",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:linux",
             "@platforms//cpu:aarch64",
         ],
@@ -221,7 +221,7 @@ def remote_jdk11_repos():
     maybe(
         remote_java_repository,
         name = "remotejdk11_linux_ppc64le",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:linux",
             "@platforms//cpu:ppc",
         ],
@@ -237,7 +237,7 @@ def remote_jdk11_repos():
     maybe(
         remote_java_repository,
         name = "remotejdk11_linux_s390x",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:linux",
             "@platforms//cpu:s390x",
         ],
@@ -253,7 +253,7 @@ def remote_jdk11_repos():
     maybe(
         remote_java_repository,
         name = "remotejdk11_macos",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:macos",
             "@platforms//cpu:x86_64",
         ],
@@ -269,7 +269,7 @@ def remote_jdk11_repos():
     maybe(
         remote_java_repository,
         name = "remotejdk11_macos_aarch64",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:macos",
             "@platforms//cpu:aarch64",
         ],
@@ -285,7 +285,7 @@ def remote_jdk11_repos():
     maybe(
         remote_java_repository,
         name = "remotejdk11_win",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:windows",
             "@platforms//cpu:x86_64",
         ],
@@ -301,7 +301,7 @@ def remote_jdk11_repos():
     maybe(
         remote_java_repository,
         name = "remotejdk11_win_arm64",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:windows",
             "@platforms//cpu:arm64",
         ],
@@ -318,7 +318,7 @@ def remote_jdk17_repos():
     maybe(
         remote_java_repository,
         name = "remotejdk17_linux",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:linux",
             "@platforms//cpu:x86_64",
         ],
@@ -334,7 +334,7 @@ def remote_jdk17_repos():
     maybe(
         remote_java_repository,
         name = "remotejdk17_linux_aarch64",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:linux",
             "@platforms//cpu:aarch64",
         ],
@@ -350,7 +350,7 @@ def remote_jdk17_repos():
     maybe(
         remote_java_repository,
         name = "remotejdk17_linux_s390x",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:linux",
             "@platforms//cpu:s390x",
         ],
@@ -366,7 +366,7 @@ def remote_jdk17_repos():
     maybe(
         remote_java_repository,
         name = "remotejdk17_linux_ppc64le",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:linux",
             "@platforms//cpu:ppc",
         ],
@@ -382,7 +382,7 @@ def remote_jdk17_repos():
     maybe(
         remote_java_repository,
         name = "remotejdk17_macos",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:macos",
             "@platforms//cpu:x86_64",
         ],
@@ -398,7 +398,7 @@ def remote_jdk17_repos():
     maybe(
         remote_java_repository,
         name = "remotejdk17_macos_aarch64",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:macos",
             "@platforms//cpu:aarch64",
         ],
@@ -413,7 +413,7 @@ def remote_jdk17_repos():
     maybe(
         remote_java_repository,
         name = "remotejdk17_win",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:windows",
             "@platforms//cpu:x86_64",
         ],
@@ -428,7 +428,7 @@ def remote_jdk17_repos():
     maybe(
         remote_java_repository,
         name = "remotejdk17_win_arm64",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:windows",
             "@platforms//cpu:arm64",
         ],
@@ -446,7 +446,7 @@ def remote_jdk20_repos():
     maybe(
         remote_java_repository,
         name = "remotejdk20_linux",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:linux",
             "@platforms//cpu:x86_64",
         ],
@@ -462,7 +462,7 @@ def remote_jdk20_repos():
     maybe(
         remote_java_repository,
         name = "remotejdk20_linux_aarch64",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:linux",
             "@platforms//cpu:aarch64",
         ],
@@ -478,7 +478,7 @@ def remote_jdk20_repos():
     maybe(
         remote_java_repository,
         name = "remotejdk20_macos",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:macos",
             "@platforms//cpu:x86_64",
         ],
@@ -494,7 +494,7 @@ def remote_jdk20_repos():
     maybe(
         remote_java_repository,
         name = "remotejdk20_macos_aarch64",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:macos",
             "@platforms//cpu:aarch64",
         ],
@@ -509,7 +509,7 @@ def remote_jdk20_repos():
     maybe(
         remote_java_repository,
         name = "remotejdk20_win",
-        target_compatible_with = [
+        exec_compatible_with = [
             "@platforms//os:windows",
             "@platforms//cpu:x86_64",
         ],
diff --git a/toolchains/remote_java_repository.bzl b/toolchains/remote_java_repository.bzl
index 86916ec..5521fcf 100644
--- a/toolchains/remote_java_repository.bzl
+++ b/toolchains/remote_java_repository.bzl
@@ -32,20 +32,20 @@ _toolchain_config = repository_rule(
     },
 )
 
-def remote_java_repository(name, version, target_compatible_with = None, prefix = "remotejdk", **kwargs):
+def remote_java_repository(name, version, exec_compatible_with = None, prefix = "remotejdk", **kwargs):
     """Imports a JDK from a http archive and creates runtime toolchain definitions for it.
 
     Register the toolchains defined by this macro via `register_toolchains("@<name>//:all")`, where
     `<name>` is the value of the `name` parameter.
 
-    Toolchain resolution is determined with target_compatible_with
+    Toolchain resolution is determined with exec_compatible_with
     parameter and constrained with --java_runtime_version flag either having value
     of "version" or "{prefix}_{version}" parameters.
 
     Args:
       name: A unique name for this rule.
       version: Version of the JDK imported.
-      target_compatible_with: Target platform constraints (CPU and OS) for this JDK.
+      exec_compatible_with: Target platform constraints (CPU and OS) for this JDK.
       prefix: Optional alternative prefix for configuration flag value used to determine this JDK.
       **kwargs: Refer to http_archive documentation
     """
@@ -77,7 +77,7 @@ alias(
 )
 toolchain(
     name = "toolchain",
-    target_compatible_with = {target_compatible_with},
+    exec_compatible_with = {exec_compatible_with},
     target_settings = [":version_or_prefix_version_setting"],
     toolchain_type = "@bazel_tools//tools/jdk:runtime_toolchain_type",
     toolchain = "{toolchain}",
@@ -85,7 +85,7 @@ toolchain(
 """.format(
             prefix = prefix,
             version = version,
-            target_compatible_with = target_compatible_with,
+            exec_compatible_with = exec_compatible_with,
             toolchain = "@{repo}//:jdk".format(repo = name),
         ),
     )
diff --git a/BUILD b/BUILD
index 06b69411a8..05cd878ae8 100644
--- a/BUILD
+++ b/BUILD
@@ -29,7 +29,7 @@ licenses(["reciprocal"])
 package(
     default_visibility = ["//visibility:public"],
     features = [
-        "layering_check",
+        "-layering_check",
         "-parse_headers",
     ],
 )
diff --git a/src/core/BUILD b/src/core/BUILD
index 1bb970e049..81265483e9 100644
--- a/src/core/BUILD
+++ b/src/core/BUILD
@@ -24,7 +24,7 @@ licenses(["reciprocal"])
 package(
     default_visibility = ["//:__subpackages__"],
     features = [
-        "layering_check",
+        "-layering_check",
     ],
 )
 
diff --git a/src/core/lib/channel/channel_args.h b/src/core/lib/channel/channel_args.h
index 38bb070213..b53086e680 100644
--- a/src/core/lib/channel/channel_args.h
+++ b/src/core/lib/channel/channel_args.h
@@ -284,7 +284,7 @@ class ChannelArgs {
 
   class Value {
    public:
-    explicit Value(int n) : rep_(reinterpret_cast<void*>(n), &int_vtable_) {}
+    explicit Value(int n) : rep_(reinterpret_cast<void*>(static_cast<intptr_t>(n)), &int_vtable_) {}
     explicit Value(std::string s)
         : rep_(RefCountedString::Make(s).release(), &string_vtable_) {}
     explicit Value(Pointer p) : rep_(std::move(p)) {}
#!/bin/bash -e

if [[ ! -f bazel-out/volatile-status.txt ]]; then
    # shellcheck disable=SC2016
    echo 'No `bazel-out/volatile-status.txt`, did you forget to stamp your build target?' >&2
    exit 1
fi

VOLATILE=$(cat bazel-out/volatile-status.txt)

while read -r line ; do
    export "$(echo "${line}" | cut -d' ' -f 1)=$(echo "${line}" | cut -d' ' -f 2)"
done <<< "$VOLATILE"
# Developer guide for writing Envoy Bazel rules

When adding or maintaining Envoy binary, library and test targets, it's
necessary to write or modify Bazel `BUILD` files. In general, each directory has
a `BUILD` file covering the source files contained immediately in the directory.

Some guidelines for defining new targets using the [custom Envoy build
rules](../bazel/envoy_build_system.bzl) are provided below. The [Bazel BUILD
Encyclopedia](https://bazel.build/versions/master/docs/be/overview.html)
provides further details regarding the underlying rules.

## Style guide

The [BUILD file style
guide](https://bazel.build/versions/master/docs/skylark/build-style.html) is the
canonical style reference. The
[buildifier](https://github.com/bazelbuild/buildifier) tool automatically
enforces these guidelines. In addition, within the `BUILD` file, targets should
be sorted alphabetically by their `name` attribute.

## Adding files to the Envoy build

All modules that make up the Envoy binary are statically linked at compile time.
Many of the modules within Envoy have a pure virtual interface living in
[`envoy`](../envoy), implementation sources in
[`source`](../source), mocks in [`test/mocks`](../test/mocks) and
unit/integration tests in [`test`](../test). The relevant `BUILD` files will
require updating or to be added in these locations as you extend Envoy.

As an example, consider adding the following interface in `envoy/foo/bar.h`:

```c++
#pragma once

#include "envoy/buffer/buffer.h"
#include "envoy/foo/baz.h"

class Bar {
public:
  virtual ~Bar() = default;

  virtual void someThing() PURE;
  ...
```

This would require the addition to `envoy/foo/BUILD` of the following target:

```python
envoy_cc_library(
    name = "bar_interface",
    hdrs = ["bar.h"],
    deps = [
        ":baz_interface",
        "//envoy/buffer:buffer_interface",
    ],
)
```

This declares a new target `bar_interface`, where the convention is that pure
virtual interfaces have their targets suffixed with `_interface`. The header
`bar.h` is exported to other targets that depend on
`//envoy/foo:bar_interface`. The interface target itself depends on
`baz_interface` (in the same directory, hence the relative Bazel label) and
`buffer_interface`.

In general, any header included via `#include` in a file belonging to the union
of the `hdrs` and `srcs` lists for a Bazel target X should appear directly in
the exported `hdrs` list for some target Y listed in the `deps` of X.

Continuing the above example, the implementation of `Bar` might take place in
`source/common/foo/bar_impl.h`, e.g.

```c++
#pragma once

#include "envoy/foo/bar.h"

class BarImpl : public Bar {
...
```

and `source/common/foo/bar_impl.cc`:

```c++
#include "source/common/foo/bar_impl.h"

#include "source/common/buffer/buffer_impl.h"
#include "source/common/foo/bar_internal.h"
#include "source/common/foo/baz_impl.h"
...
```

The corresponding target to be added to `source/common/foo/BUILD` would be:

```python
envoy_cc_library(
    name = "bar_lib",
    srcs = [
        "bar_impl.cc",
        "bar_internal.h",
    ],
    hdrs = ["bar_impl.h"],
    deps = [
        ":baz_lib",
        "//envoy/foo:bar_interface",
        "//source/common/buffer:buffer_lib",
    ],
)
```

By convention, Bazel targets for internal implementation libraries are suffixed
with `_lib`.

Similar to the above, a test mock target might be declared for `test/mocks/foo/mocks.h` in
`test/mocks/foo/BUILD` with:

```python
envoy_cc_mock(
    name = "foo_mocks",
    srcs = ["mocks.cc"],
    hdrs = ["mocks.h"],
    deps = [
        "//envoy/foo:bar_interface",
        ...
    ],
)
```

Typically, mocks are provided for all interfaces in a directory in a single
`mocks.{cc,h}` and corresponding `_mocks` Bazel target. There are some
exceptions, such as [test/mocks/upstream/BUILD](../test/mocks/upstream/BUILD),
where more granular mock targets are defined.

Unit tests for `BarImpl` would be written in `test/common/foo/bar_impl_test.cc`
and a target added to `test/common/foo/BUILD`:

```python
envoy_cc_test(
    name = "bar_impl_test",
    srcs = ["bar_impl_test.cc"],
    deps = [
        "//test/mocks/buffer:buffer_mocks",
        "//source/common/foo:bar_lib",
        ...
    ],
)
```

## Binary targets

New binary targets, for example tools that make use of some Envoy libraries, can be added
with the `envoy_cc_binary` rule, e.g. for a new `tools/hello/world.cc` that depends on
`bar_lib`, we might have in `tools/hello/BUILD`:

```python
envoy_cc_binary(
    name = "world",
    srcs = ["world.cc"],
    deps = [
        "//source/common/foo:bar_lib",
    ],
)
```

## Filter linking

Filters are registered via static initializers at early runtime by modules in
[`source/extensions/filters`](../source/extensions/filters). These require the `alwayslink
= 1` attribute to be set in the corresponding `envoy_cc_library` target to
ensure they are correctly linked. See
[`source/extensions/filters/http/BUILD`](../source/extensions/filters/http/BUILD) for
examples.

## Tests with environment dependencies

Some tests depends on read-only data files. In general, these can be specified by adding a
`data = ["some_file.csv", ...],` attribute to the `envoy_cc_test` target, e.g.

```python
envoy_cc_test(
    name = "bar_impl_test",
    srcs = ["bar_impl_test.cc"],
    data = ["some_file.csv"],
    deps = [
        "//test/mocks/buffer:buffer_mocks",
        "//source/common/foo:bar_lib",
        ...
    ],
)
```

A [glob
function](https://bazel.build/versions/master/docs/be/functions.html#glob) is
available for simple pattern matching. Within a test, the read-only data dependencies
can be accessed via the
[`TestEnvironment::runfilesPath()`](../test/test_common/environment.h) method.

A writable path is provided for test temporary files by
[`TestEnvironment::temporaryDirectory()`](../test/test_common/environment.h).

Integration tests might rely on JSON files that require paths for writable
temporary files and paths for file-based Unix Domain Sockets to be specified in
the JSON. Jinja-style `{{ test_tmpdir }}` and `{{ test_udsdir }}` macros can be used as
placeholders, with the substituted JSON files made available in
[`TestEnvironment::temporaryDirectory()`](../test/test_common/environment.h) by
the `envoy_cc_test_with_json` rule, e.g.

```python
envoy_cc_test_with_json(
    name = "bar_integration_test",
    srcs = ["bar_integration_test.cc"],
    jsons = ["//test/config/integration:server.json"],
    deps = [
        "//source/server:server_lib",
        ...
    ],
)
```

In general, the `setup_cmds` attribute can be used to declare a setup shell
script that executes in the [test
environment](https://bazel.build/versions/master/docs/test-encyclopedia.html#initial-conditions)
prior to the test, see [`bazel/envoy_build_system.bzl`](envoy_build_system.bzl)
for further details.
# Building Envoy with Bazel

## Installing Bazelisk as Bazel

It is recommended to use [Bazelisk](https://github.com/bazelbuild/bazelisk) installed as `bazel`, to avoid Bazel compatibility issues.

On Linux, run the following commands:

```console
sudo wget -O /usr/local/bin/bazel https://github.com/bazelbuild/bazelisk/releases/latest/download/bazelisk-linux-$([ $(uname -m) = "aarch64" ] && echo "arm64" || echo "amd64")
sudo chmod +x /usr/local/bin/bazel
```

On macOS, run the following command:
```console
brew install bazelisk
```

On Windows, run the following commands:
```cmd
mkdir %USERPROFILE%\bazel
powershell Invoke-WebRequest https://github.com/bazelbuild/bazelisk/releases/latest/download/bazelisk-windows-amd64.exe -OutFile %USERPROFILE%\bazel\bazel.exe
set PATH=%USERPROFILE%\bazel;%PATH%
```

## Production environments

To build Envoy with Bazel in a production environment, where the [Envoy
dependencies](https://www.envoyproxy.io/docs/envoy/latest/start/building#requirements) are typically
independently sourced, the following steps should be followed:

1. Configure, build and/or install the [Envoy dependencies](https://www.envoyproxy.io/docs/envoy/latest/start/building#requirements).
1. `bazel build -c opt envoy` from the repository root.

### Building from a release tarball

To build Envoy from a release tarball, you can download a release tarball from Assets section in each release in project [Releases page](https://github.com/envoyproxy/envoy/releases).
Given all required [Envoy dependencies](https://www.envoyproxy.io/docs/envoy/latest/start/building#requirements) are installed, the following steps should be followed:

1. Download and extract source code of a release tarball from the Releases page. For example: https://github.com/envoyproxy/envoy/releases/tag/v1.24.0.
1. `python3 tools/github/write_current_source_version.py` from the repository root.
1. `bazel build -c opt envoy` from the repository root.

> **Note**: If the the `write_current_source_version.py` script is missing from the extracted source code directory, you can download it from [here](https://raw.githubusercontent.com/envoyproxy/envoy/main/tools/github/write_current_source_version.py).
> This script is used to generate SOURCE_VERSION that is required by [`bazel/get_workspace_status`](./get_workspace_status) to "stamp" the binary in a non-git directory.

> **Note**: To avoid rate-limiting by GitHub API, you can provide [a valid GitHub token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/about-authentication-to-github#githubs-token-formats) to `GITHUB_TOKEN` environment variable.
> The environment variable name that holds the token can also be customized by setting `--github_api_token_env_name`.
> In a GitHub Actions workflow file, you can set this token from [`secrets.GITHUB_TOKEN`](https://docs.github.com/en/actions/security-guides/automatic-token-authentication#about-the-github_token-secret).

Examples:

```console
GITHUB_TOKEN=<GITHUB_TOKEN> python3 tools/github/write_current_source_version.py
MY_TOKEN=<GITHUB_TOKEN> python3 tools/github/write_current_source_version.py --github_api_token_env_name=MY_TOKEN
```

## Quick start Bazel build for developers

This section describes how to and what dependencies to install to get started building Envoy with Bazel.
If you would rather use a pre-build Docker image with required tools installed, skip to [this section](#building-envoy-with-the-ci-docker-image).

As a developer convenience, a [WORKSPACE](https://github.com/envoyproxy/envoy/blob/main/WORKSPACE) and
[rules for building a recent
version](https://github.com/envoyproxy/envoy/blob/main/bazel/repositories.bzl) of the various Envoy
dependencies are provided. These are provided as is, they are only suitable for development and
testing purposes. The specific versions of the Envoy dependencies used in this build may not be
up-to-date with the latest security patches. See
[this doc](https://github.com/envoyproxy/envoy/blob/main/bazel/EXTERNAL_DEPS.md#updating-an-external-dependency-version)
for how to update or override dependencies.

1. Install external dependencies.
    ### Ubuntu
    On Ubuntu, run the following:
    ```console
    sudo apt-get install \
       autoconf \
       curl \
       libtool \
       patch \
       python3-pip \
       unzip \
       virtualenv
    ```

    ### Fedora
    On Fedora (maybe also other red hat distros), run the following:
    ```console
    dnf install \
        aspell-en \
        libatomic \
        libstdc++ \
        libstdc++-static \
        libtool \
        lld \
        patch \
        python3-pip
    ```

    ### Linux
    On Linux, we recommend using the prebuilt Clang+LLVM package from [LLVM official site](http://releases.llvm.org/download.html).
    Extract the tar.xz and run the following:
    ```console
    bazel/setup_clang.sh <PATH_TO_EXTRACTED_CLANG_LLVM>
    ```

    This will setup a `clang.bazelrc` file in Envoy source root. If you want to make clang as default, run the following:
    ```console
    echo "build --config=clang" >> user.bazelrc
    ```

    Note: Either `libc++` or `libstdc++-7-dev` (or higher) must be installed.

    #### Config Flag Choices
    Different [config](https://docs.bazel.build/versions/master/guide.html#--config) flags specify the compiler libraries:

    - `--config=libc++` means using `clang` + `libc++`
    - `--config=clang` means using `clang` + `libstdc++`
    - no config flag means using `gcc` + `libstdc++`


    ### macOS
    On macOS, you'll need to install several dependencies. This can be accomplished via [Homebrew](https://brew.sh/):
    ```console
    brew install coreutils wget libtool go bazelisk clang-format autoconf aspell
    ```
    _notes_: `coreutils` is used for `realpath`, `gmd5sum` and `gsha256sum`

    _notes_: See Homebrew python setup notes: https://docs.brew.sh/Homebrew-and-Python.

    The full version of Xcode (not just Command Line Tools) is also required to build Envoy on macOS.
    Envoy compiles and passes tests with the version of clang installed by Xcode 11.1:
    Apple clang version 11.0.0 (clang-1100.0.33.8).

    #### Troubleshooting
    If you see some error messages like the following:
    ```console
    xcrun: error: SDK "macosx12.1" cannot be located
    xcrun: error: SDK "macosx12.1" cannot be located
    xcrun: error: unable to lookup item 'Path' in SDK 'macosx12.1'
    ```
    please check the installed sdk version.
    ```console
    xcrun --show-sdk-version
    ```

    If the sdk version is lower than the one in the error message, upgrade your Command Line Tools using the following commands:
    ```console
    sudo rm -rf /Library/Developer/CommandLineTools
    softwareupdate --all --install --force
    sudo xcode-select --install
    ```

    If the following error occurs during the compilation process:
    ```console
    xcode-select: error: tool 'xcodebuild' requires Xcode, but active developer directory '/Library/Developer/CommandLineTools' is a command line tools instance
    ```
    please execute the following command and retry:
    ```console
    sudo xcode-select -s /Applications/Xcode.app/Contents/Developer
    ```

    Having the binutils keg installed in Brew is known to cause issues due to putting an incompatible
    version of `ar` on the PATH, so if you run into issues building third party code like luajit
    consider uninstalling binutils.

    ### Windows

    > Note: These instructions apply to **Windows 10 SDK, version 1803 (10.0.17134.12)**. Earlier versions will not compile because the `afunix.h` header is not available. **The recommended Windows version is equal or later than Windows 10 SDK, version 1903 (10.0.18362.1)**

    Install bazelisk in the PATH using the `bazel.exe` executable name as described above in the first section.

    When building Envoy, Bazel creates very long path names. One way to work around these excessive path
    lengths is to change the output base directory for bazel to a very short root path. An example Bazel configuration
    to help with this is to use `C:\_eb` as the bazel base path. This and other preferences should be set up by placing
    the following bazelrc configuration line in a system `%ProgramData%\bazel.bazelrc` file or the individual
    user's `%USERPROFILE%\.bazelrc` file (rather than including it on every bazel command line):

    ```
    startup --output_base=C:/_eb
    ```

    Another option to shorten the output root for Bazel is to set the `USERNAME` environment variable in your shell
    session to a short value. Bazel uses this value when constructing its output root path if no explicit `--output_base`
    is set.

    Bazel also creates file symlinks when building Envoy. It's strongly recommended to enable file symlink support
    using [Bazel's instructions](https://docs.bazel.build/versions/master/windows.html#enable-symlink-support).
    For other common issues, see the
    [Using Bazel on Windows](https://docs.bazel.build/versions/master/windows.html) page.

    > The paths in this document are given as
    examples, make sure to verify you are using the correct paths for your environment. Also note
    that these examples assume using a `cmd.exe` shell to set environment variables etc., be sure
    to do the equivalent if using a different shell.

    [python3](https://www.python.org/downloads/): Specifically, the Windows-native flavor distributed
    by python.org. The POSIX flavor available via MSYS2, the Windows Store flavor and other distributions
    will not work. Add a symlink for `python3.exe` pointing to the installed `python.exe` for Envoy scripts
    and Bazel rules which follow POSIX python conventions. Add `pip.exe` to the PATH and install the `wheel`
    package.
    ```cmd
    mklink %USERPROFILE%\Python39\python3.exe %USERPROFILE%\Python39\python.exe
    set PATH=%USERPROFILE%\Python39;%PATH%
    set PATH=%USERPROFILE%\Python39\Scripts;%PATH%
    pip install wheel
    ```

    [Build Tools for Visual Studio 2019](https://visualstudio.microsoft.com/downloads/#build-tools-for-visual-studio-2019):
    For building with MSVC, you must install at least the VC++ workload.
    You may alternately install the entire Visual Studio 2019 and use the Build Tools installed in that
    package. Earlier versions of VC++ Build Tools/Visual Studio are not recommended or supported.
    If installed in a non-standard filesystem location, be sure to set the `BAZEL_VC` environment variable
    to the path of the VC++ package to allow Bazel to find your installation of VC++. NOTE: ensure that
    the `link.exe` that resolves on your PATH is from VC++ Build Tools and not `/usr/bin/link.exe` from MSYS2,
    which is determined by their relative ordering in your PATH.
    ```cmd
    set BAZEL_VC=%USERPROFILE%\VSBT2019\VC
    set PATH=%USERPROFILE%\VSBT2019\VC\Tools\MSVC\14.26.28801\bin\Hostx64\x64;%PATH%
    ```

    The Windows SDK contains header files and libraries you need when building Windows applications. Bazel always uses the latest, but you can specify a different version by setting the environment variable `BAZEL_WINSDK_FULL_VERSION`. See [bazel/windows](https://docs.bazel.build/versions/master/windows.html)

    [MSYS2 shell](https://msys2.github.io/): Install to a path with no spaces, e.g. C:\msys64.

    Set the `BAZEL_SH` environment variable to the path of the installed MSYS2 `bash.exe`
    executable. Additionally, setting the `MSYS2_ARG_CONV_EXCL` environment variable to a value
    of `*` is often advisable to ensure argument parsing in the MSYS2 shell behaves as expected.
    ```cmd
    set PATH=%USERPROFILE%\msys64\usr\bin;%PATH%
    set BAZEL_SH=%USERPROFILE%\msys64\usr\bin\bash.exe
    set MSYS2_ARG_CONV_EXCL=*
    set MSYS2_PATH_TYPE=inherit
    ```

    Set the `TMPDIR` environment variable to a path usable as a temporary directory (e.g.
    `C:\Windows\TEMP`), and create a directory symlink `C:\c` to `C:\`, so that the MSYS2
    path `/c/Windows/TEMP` is equivalent to the Windows path `C:/Windows/TEMP`:
    ```cmd
    set TMPDIR=C:/Windows/TEMP
    mklink /d C:\c C:\
    ```

    The TMPDIR path and MSYS2 `mktemp` command are used frequently by the `rules_foreign_cc`
    component of Bazel as well as Envoy's test scripts, causing problems if not set to a path
    accessible to both Windows and msys commands. [Note the `ci/windows_ci_steps.sh` script
    which builds envoy and run tests in CI creates this symlink automatically.]

    In the MSYS2 shell, install additional packages via pacman:
    ```
    pacman -S diffutils patch unzip zip
    ```

    [Git](https://git-scm.com/downloads): This version from the Git project, or the version
    distributed using pacman under MSYS2 will both work, ensure one is on the PATH:.
    ```cmd
    set PATH=%USERPROFILE%\Git\bin;%PATH%
    ```

    Lastly, persist environment variable changes.
    ``` cmd
    setx PATH "%PATH%"
    setx BAZEL_SH "%BAZEL_SH%"
    setx MSYS2_ARG_CONV_EXCL "%MSYS2_ARG_CONV_EXCL%"
    setx BAZEL_VC "%BAZEL_VC%"
    setx TMPDIR "%TMPDIR%"
    setx MSYS2_PATH_TYPE "%MSYS2_PATH_TYPE%"
    ```
    > On Windows the supported/recommended shell to interact with bazel is MSYS2. This means that all the bazel commands (i.e. build, test) should be executed from MSYS2.

1. Install Golang on your machine. This is required as part of building [BoringSSL](https://boringssl.googlesource.com/boringssl/+/HEAD/BUILDING.md)
   and also for [Buildifer](https://github.com/bazelbuild/buildtools) which is used for formatting bazel BUILD files.
   Make sure you have go version 1.17 or later.
1. `go install github.com/bazelbuild/buildtools/buildifier@latest` to install buildifier. You may need to set `BUILDIFIER_BIN` to `$GOPATH/bin/buildifier`
   in your shell for buildifier to work. If GOPATH is not set, it is $HOME/go by default.
1. `go install github.com/bazelbuild/buildtools/buildozer@latest` to install buildozer. You may need to set `BUILDOZER_BIN` to `$GOPATH/bin/buildozer`
   in your shell for buildozer to work. If GOPATH is not set, it is $HOME/go by default.
1. `bazel build envoy` from the Envoy source directory. Add `-c opt` for an optimized release build or
   `-c dbg` for an unoptimized, fully instrumented debugging build.

## Building Envoy with the CI Docker image

Envoy can also be built with the Docker image used for CI, by installing Docker and executing the following.

On Linux, run:

```
./ci/run_envoy_docker.sh './ci/do_ci.sh dev'
```

From a Windows host with Docker installed, the Windows containers feature enabled, and bash (installed via
MSYS2 or Git bash), run:

**Note: the command below executes the whole Windows CI and unlike Linux you are not able to set specific build targets. You can modify `./ci/windows_ci_steps.sh` to modify `bazel` arguments, tests to run, etc. as well as set environment variables to adjust your container build environment.**

```
./ci/run_envoy_docker.sh './ci/windows_ci_steps.sh'
```

See also the [documentation](https://github.com/envoyproxy/envoy/tree/main/ci) for developer use of the
CI Docker image.

## Building Envoy with Remote Execution

Envoy can also be built with Bazel [Remote Execution](https://docs.bazel.build/versions/master/remote-execution.html),
part of the CI is running with the hosted [GCP RBE](https://blog.bazel.build/2018/10/05/remote-build-execution.html) service.

To build Envoy with a remote build services, run Bazel with your remote build service flags and with `--config=remote-clang`.
For example the following command runs build with the GCP RBE service used in CI:

```
bazel build envoy --config=remote-clang \
    --remote_cache=grpcs://remotebuildexecution.googleapis.com \
    --remote_executor=grpcs://remotebuildexecution.googleapis.com \
    --remote_instance_name=projects/envoy-ci/instances/default_instance
```

Change the value of `--remote_cache`, `--remote_executor` and `--remote_instance_name` for your remote build services. Tests can
be run in remote execution too.

Note: Currently the test run configuration in `.bazelrc` doesn't download test binaries and test logs,
to override the behavior set [`--remote_download_outputs`](https://docs.bazel.build/versions/master/command-line-reference.html#flag--remote_download_outputs)
accordingly.

## Building Envoy with Docker sandbox

Building Envoy with Docker sandbox uses the same Docker image used in CI with fixed C++ toolchain configuration. It produces more consistent
output which is not depending on your local C++ toolchain. It can also help debugging issues with RBE. To build Envoy with Docker sandbox:

```
bazel build envoy --config=docker-clang
```

Tests can be run in docker sandbox too. Note that the network environment, such as IPv6, may be different in the docker sandbox so you may want
set different options. See below to configure test IP versions.

## Linking against libc++ on Linux

To link Envoy against libc++, follow the [quick start](#quick-start-bazel-build-for-developers) to setup Clang+LLVM and run:
```
bazel build --config=libc++ envoy
```

Or use our configuration with Remote Execution or Docker sandbox, pass `--config=remote-clang-libc++` or
`--config=docker-clang-libc++` respectively.

If you want to make libc++ as default, add a line `build --config=libc++` to the `user.bazelrc` file in Envoy source root.

## Using a compiler toolchain in a non-standard location

By setting the `CC` and `LD_LIBRARY_PATH` in the environment that Bazel executes from as
appropriate, an arbitrary compiler toolchain and standard library location can be specified. One
slight caveat is that (at the time of writing), Bazel expects the binutils in `$(dirname $CC)` to be
unprefixed, e.g. `as` instead of `x86_64-linux-gnu-as`.

Note: this configuration currently doesn't work with Remote Execution or Docker sandbox, you have to generate a
custom toolchains configuration for them. See [bazelbuild/bazel-toolchains](https://github.com/bazelbuild/bazel-toolchains)
for more details.

## Supported compiler versions

We now require Clang >= 9 due to C++17 support and tcmalloc requirement. GCC >= 9 is also known to work.
Currently the CI is running with Clang 14.

## Clang STL debug symbols

By default Clang drops some debug symbols that are required for pretty printing to work correctly.
More information can be found [here](https://bugs.llvm.org/show_bug.cgi?id=24202). The easy solution
is to set ```--copt=-fno-limit-debug-info``` on the CLI or in your .bazelrc file.

## Removing debug info

If you don't want your debug or release binaries to contain debug info
to reduce binary size, pass `--define=no_debug_info=1` when building.
This is primarily useful when building envoy as a static library. When
building a linked envoy binary you can build the implicit `.stripped`
target from [`cc_binary`](https://docs.bazel.build/versions/master/be/c-cpp.html#cc_binary)
or pass [`--strip=always`](https://docs.bazel.build/versions/master/command-line-reference.html#flag--strip)
instead.

# Running the built Envoy binary on the host system

After Envoy is built, it can be executed via CLI.

For example, if Envoy was built using the `bazel build -c opt //source/exe:envoy-static` command, then it can be executed from the project's root directory by running:

```console
$(bazel info bazel-genfiles)/source/exe/envoy-static --config-path /path/to/your/envoy/config.yaml
```

# Testing Envoy with Bazel

All the Envoy tests can be built and run with:

```
bazel test //test/...
```

An individual test target can be run with a more specific Bazel
[label](https://bazel.build/versions/master/docs/build-ref.html#Labels), e.g. to build and run only
the units tests in
[test/common/http/async_client_impl_test.cc](https://github.com/envoyproxy/envoy/blob/main/test/common/http/async_client_impl_test.cc):

```
bazel test //test/common/http:async_client_impl_test
```

To observe more verbose test output:

```
bazel test --test_output=streamed //test/common/http:async_client_impl_test
```

It's also possible to pass into an Envoy test additional command-line args via `--test_arg`. For
example, for extremely verbose test debugging:

```
bazel test --test_output=streamed //test/common/http:async_client_impl_test --test_arg="-l trace"
```

By default, testing exercises both IPv4 and IPv6 address connections. In IPv4 or IPv6 only
environments, set the environment variable ENVOY_IP_TEST_VERSIONS to "v4only" or
"v6only", respectively.

```
bazel test //test/... --test_env=ENVOY_IP_TEST_VERSIONS=v4only
bazel test //test/... --test_env=ENVOY_IP_TEST_VERSIONS=v6only
```

By default, tests are run with the [gperftools](https://github.com/gperftools/gperftools) heap
checker enabled in "normal" mode to detect leaks. For other mode options, see the gperftools
heap checker [documentation](https://gperftools.github.io/gperftools/heap_checker.html). To
disable the heap checker or change the mode, set the HEAPCHECK environment variable:

```
# Disables the heap checker
bazel test //test/... --test_env=HEAPCHECK=
# Changes the heap checker to "minimal" mode
bazel test //test/... --test_env=HEAPCHECK=minimal
```

If you see a leak detected, by default the reported offsets will require `addr2line` interpretation.
You can run under `--config=clang-asan` to have this automatically applied.

Bazel will by default cache successful test results. To force it to rerun tests:

```
bazel test //test/common/http:async_client_impl_test --cache_test_results=no
```

Bazel will by default run all tests inside a sandbox, which disallows access to the
local filesystem. If you need to break out of the sandbox (for example to run under a
local script or tool with [`--run_under`](https://docs.bazel.build/versions/master/user-manual.html#flag--run_under)),
you can run the test with `--strategy=TestRunner=local`, e.g.:

```
bazel test //test/common/http:async_client_impl_test --strategy=TestRunner=local --run_under=/some/path/foobar.sh
```
# Stack trace symbol resolution

Envoy can produce backtraces on demand and from assertions and other fatal
actions like segfaults. Where supported, stack traces will contain resolved
symbols, though not include line numbers. On systems where absl::Symbolization is
not supported, the stack traces written in the log or to stderr contain addresses rather
than resolved symbols. If the symbols were resolved, the address is also included at
the end of the line.

The `tools/stack_decode.py` script exists to process the output and do additional symbol
resolution including file names and line numbers. It requires the `addr2line` program be
installed and in your path. Any log lines not relevant to the backtrace capability are
passed through the script unchanged (it acts like a filter). File and line information
is appended to the stack trace lines.

The script runs in one of two modes. To process log input from stdin, pass `-s` as the first
argument, followed by the executable file path. You can postprocess a log or pipe the output
of an Envoy process. If you do not specify the `-s` argument it runs the arguments as a child
process. This enables you to run a test with backtrace post processing. Bazel sandboxing must
be disabled by specifying local execution. Example command line with
`run_under`:

```
bazel test -c dbg //test/server:backtrace_test
--run_under=//tools:stack_decode --strategy=TestRunner=local
--cache_test_results=no --test_output=all
```

Example using input on stdin:

```
bazel test -c dbg //test/server:backtrace_test --cache_test_results=no --test_output=streamed |& tools/stack_decode.py -s bazel-bin/test/server/backtrace_test
```

You will need to use either a `dbg` build type or the `opt` build type to get file and line
symbol information in the binaries.

By default main.cc will install signal handlers to print backtraces at the
location where a fatal signal occurred. The signal handler will re-raise the
fatal signal with the default handler so a core file will still be dumped after
the stack trace is logged. To inhibit this behavior use
`--define=signal_trace=disabled` on the Bazel command line. No signal handlers will
be installed.

# Running a single Bazel test under GDB

```
bazel build -c dbg //test/common/http:async_client_impl_test
bazel build -c dbg //test/common/http:async_client_impl_test.dwp
gdb bazel-bin/test/common/http/async_client_impl_test
```

We need to use `-c dbg` Bazel option to generate debugging symbols and without
that GDB will not be very useful. The debugging symbols are stored as separate
debugging information files (`.dwp` files) and we can build a DWARF package file
with `.dwp ` target. The `.dwp` file need to be presented in the same folder with the
binary for a full debugging experience.

# Running Bazel tests requiring privileges

Some tests may require privileges (e.g. CAP_NET_ADMIN) in order to execute. One option is to run
them with elevated privileges, e.g. `sudo test`. However, that may not always be possible,
particularly if the test needs to run in a CI pipeline. `tools/bazel-test-docker.sh` may be used in
such situations to run the tests in a privileged docker container.

The script works by wrapping the test execution in the current repository's circle ci build
container, then executing it either locally or on a remote docker container. In both cases, the
container runs with the `--privileged` flag, allowing it to execute operations which would otherwise
be restricted.

The command line format is:
`tools/bazel-test-docker.sh <bazel-test-target> [optional-flags-to-bazel]`

The script uses two optional environment variables to control its behaviour:

* `RUN_REMOTE=<yes|no>`: chooses whether to run on a remote docker server.
* `LOCAL_MOUNT=<yes|no>`: copy/mount local libraries onto the docker container.

Use `RUN_REMOTE=yes` when you don't want to run against your local docker instance. Note that you
will need to override a few environment variables to set up the remote docker. The list of variables
can be found in the [Documentation](https://docs.docker.com/engine/reference/commandline/cli/).

Use `LOCAL_MOUNT=yes` when you are not building with the Envoy build container. This will ensure
that the libraries against which the tests dynamically link will be available and of the correct
version.

## Examples

Running the http integration test in a privileged container:

```bash
tools/bazel-test-docker.sh  //test/integration:integration_test --jobs=4 -c dbg
```

Running the http integration test compiled locally against a privileged remote container:

```bash
setup_remote_docker_variables
RUN_REMOTE=yes MOUNT_LOCAL=yes tools/bazel-test-docker.sh  //test/integration:integration_test \
  --jobs=4 -c dbg
```

# Additional Envoy build and test options

In general, there are 3 [compilation
modes](https://docs.bazel.build/versions/master/user-manual.html#flag--compilation_mode)
that Bazel supports:

* `fastbuild`: `-O0`, aimed at developer speed (default).
* `opt`: `-O2 -DNDEBUG -ggdb3 -gsplit-dwarf`, for production builds and performance benchmarking.
* `dbg`: `-O0 -ggdb3 -gsplit-dwarf`, only debug symbols, no optimization.

You can use the `-c <compilation_mode>` flag to control this, e.g.

```
bazel build -c opt envoy
```

To override the compilation mode and optimize the build for binary size, you can
use the `sizeopt` configuration:

```
bazel build envoy --config=sizeopt
```

## Sanitizers

To build and run tests with the gcc compiler's [address sanitizer
(ASAN)](https://github.com/google/sanitizers/wiki/AddressSanitizer) and
[undefined behavior
(UBSAN)](https://developers.redhat.com/blog/2014/10/16/gcc-undefined-behavior-sanitizer-ubsan) sanitizer enabled:

```
bazel test -c dbg --config=asan //test/...
```

The ASAN failure stack traces include line numbers as a result of running ASAN with a `dbg` build above. If the
stack trace is not symbolized, try setting the ASAN_SYMBOLIZER_PATH environment variable to point to the
llvm-symbolizer binary (or make sure the llvm-symbolizer is in your $PATH).

If you have clang-5.0 or newer, additional checks are provided with:

```
bazel test -c dbg --config=clang-asan //test/...
```

[Thread sanitizer (TSAN)](https://github.com/google/sanitizers/wiki/ThreadSanitizerCppManual) tests rely on
a TSAN-instrumented version of libc++ and can be run under the docker sandbox:

```
bazel test -c dbg --config=docker-tsan //test/...
```

Alternatively, you can build a local copy of TSAN-instrumented libc++. Follow the [quick start](#quick-start-bazel-build-for-developers) instruction to setup Clang+LLVM environment. Download LLVM sources from the [LLVM official site](https://github.com/llvm/llvm-project)

```
curl -sSfL "https://github.com/llvm/llvm-project/archive/llvmorg-11.0.1.tar.gz" | tar zx

```

Configure and build a TSAN-instrumented libc++. Please note that `LLVM_USE_SANITIZER=Thread` preprocessor definition is used to enable TSAN instrumentation, and `CMAKE_INSTALL_PREFIX="/opt/libcxx_tsan"` defines the installation directory path.

```
mkdir tsan
pushd tsan

cmake -GNinja -DLLVM_ENABLE_PROJECTS="libcxxabi;libcxx" -DLLVM_USE_LINKER=lld -DLLVM_USE_SANITIZER=Thread -DCMAKE_BUILD_TYPE=Release \
  -DCMAKE_C_COMPILER=clang -DCMAKE_CXX_COMPILER=clang++ -DCMAKE_INSTALL_PREFIX="/opt/libcxx_tsan" "../llvm-project-llvmorg-11.0.1/llvm"
ninja install-cxx install-cxxabi

rm -rf /opt/libcxx_tsan/include
```

Generate local_tsan.bazelrc containing bazel configuration for tsan tests:

```
bazel/setup_local_tsan.sh </path/to/instrumented/libc++/home>

```

To execute TSAN tests using the local instrumented libc++ library pass `--config=local-tsan` to bazel:

```
bazel test --config=local-tsan //test/...
```

For [memory sanitizer (MSAN)](https://github.com/google/sanitizers/wiki/MemorySanitizer) testing,
it has to be run under the docker sandbox which comes with MSAN instrumented libc++:

```
bazel test -c dbg --config=docker-msan //test/...
```

To run the sanitizers on OS X, prefix `macos-` to the config option, e.g.:

```
bazel test -c dbg --config=macos-asan //test/...
```

## Log Verbosity

Log verbosity is controlled at runtime in all builds.

To obtain `nghttp2` traces, you can set `ENVOY_NGHTTP2_TRACE` in the environment for enhanced
logging at `-l trace`. For example, in tests:

```
bazel test //test/integration:protocol_integration_test --test_output=streamed \
  --test_arg="-l trace" --test_env="ENVOY_NGHTTP2_TRACE="
```

Similarly, `QUICHE` verbose logs can be enabled by setting `ENVOY_QUICHE_VERBOSITY=n` in the
environment where `n` is the desired verbosity level (e.g.
`--test_env="ENVOY_QUICHE_VERBOSITY=2"`.

## Disabling optional features

The following optional features can be disabled on the Bazel build command-line:

* Hot restart with `--define hot_restart=disabled`
* Google C++ gRPC client with `--define google_grpc=disabled`
* Backtracing on signals with `--define signal_trace=disabled`
* Active stream state dump on signals with `--define signal_trace=disabled` or `--define disable_object_dump_on_signal_trace=disabled`
* tcmalloc with `--define tcmalloc=disabled`. Also you can choose Gperftools' implementation of
  tcmalloc with `--define tcmalloc=gperftools` which is the default for builds other than x86_64 and aarch64.
* deprecated features with `--define deprecated_features=disabled`
* http3/quic with `--//bazel:http3=False`
* autolinking libraries with `--define=library_autolink=disabled`
* admin HTML home page with `--define=admin_html=disabled`
* admin functionality with `--define=admin_functionality=disabled`
* static extension registration with `--define=static_extension_registration=disabled`
* spdlogging functionality with `--define=enable_logging=disabled`

## Enabling optional features

The following optional features can be enabled on the Bazel build command-line:

* Exported symbols during linking with `--define exported_symbols=enabled`.
  This config will exports all symbols and results in larger binary size. If partial symbols export
  is required and target platform is Linux, then `bazel/exported_symbols.txt` can be used to land it.
* Perf annotation with `--define perf_annotation=enabled` (see
  source/common/common/perf_annotation.h for details).
* BoringSSL can be built in a FIPS-compliant mode with `--define boringssl=fips`
  (see [FIPS 140-2](https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/security/ssl#fips-140-2) for details).
* ASSERT() can be configured to log failures and increment a stat counter in a release build with
  `--define log_fast_debug_assert_in_release=enabled`. SLOW_ASSERT()s can be included with `--define log_debug_assert_in_release=enabled`. The default behavior is to compile all debug assertions out of
  release builds so that the condition is not evaluated. This option has no effect in debug builds.
* memory-debugging (scribbling over memory after allocation and before freeing) with
  `--define tcmalloc=debug`. Note this option cannot be used with FIPS-compliant mode BoringSSL and
  tcmalloc is built from the sources of Gperftools.
* Default [path normalization](https://github.com/envoyproxy/envoy/issues/6435) with
  `--define path_normalization_by_default=true`. Note this still could be disable by explicit xDS config.
* Manual stamping via VersionInfo with `--define manual_stamp=manual_stamp`.
  This is needed if the `version_info_lib` is compiled via a non-binary bazel rules, e.g `envoy_cc_library`.
  Otherwise, the linker will fail to resolve symbols that are included via the `linktamp` rule, which is only available to binary targets.
  This is being tracked as a feature in: https://github.com/envoyproxy/envoy/issues/6859.
* Process logging for Android applications can be enabled with `--define logger=android`.
* Excluding assertions for known issues with `--define disable_known_issue_asserts=true`.
  A KNOWN_ISSUE_ASSERT is an assertion that should pass (like all assertions), but sometimes fails for some as-yet unidentified or unresolved reason. Because it is known to potentially fail, it can be compiled out even when DEBUG is true, when this flag is set. This allows Envoy to be run in production with assertions generally enabled, without crashing for known issues. KNOWN_ISSUE_ASSERT should only be used for newly-discovered issues that represent benign violations of expectations.
* Envoy can be linked to [`zlib-ng`](https://github.com/zlib-ng/zlib-ng) instead of
  [`zlib`](https://zlib.net) with `--define zlib=ng`.

## Enabling and disabling extensions

Envoy uses a modular build which allows extensions to be removed if they are not needed or desired.
Extensions that can be removed are contained in
[extensions_build_config.bzl](../source/extensions/extensions_build_config.bzl). Contrib build
extensions are contained in [contrib_build_config.bzl](../contrib/contrib_build_config.bzl). Note
that contrib extensions are only included by default when building the contrib executable and in
the default contrib images pushed to Docker Hub.

The extensions disabled by default can be enabled by adding the following parameter to Bazel, for example to enable
`envoy.filters.http.kill_request` extension, add `--//source/extensions/filters/http/kill_request:enabled`.
The extensions enabled by default can be disabled by adding the following parameter to Bazel, for example to disable
`envoy.wasm.runtime.v8` extension, add `--//source/extensions/wasm_runtime/v8:enabled=false`.
Note not all extensions can be disabled.

To enable a specific WebAssembly (Wasm) engine, you'll need to pass `--define wasm=[wasm_engine]`, e.g. `--define wasm=wasmtime` to enable the [wasmtime](https://wasmtime.dev/) engine. Supported engines are:

* `v8` (the default included engine)
* `wamr`
* `wasmtime`
* `wavm`

If you're building from a custom build repository, the parameters need to prefixed with `@envoy`, for example
`--@envoy//source/extensions/filters/http/kill_request:enabled`.

You may persist those options in `user.bazelrc` in Envoy repo or your `.bazelrc`.

Contrib extensions can be enabled and disabled similarly to above when building the contrib
executable. For example:

`bazel build //contrib/exe:envoy-static --//contrib/squash/filters/http/source:enabled=false`

Will disable the squash extension when building the contrib executable.

## Customize extension build config

You can also use the following procedure to customize the extensions for your build:

* The Envoy build assumes that a Bazel repository named `@envoy_build_config` exists which
  contains the file `@envoy_build_config//:extensions_build_config.bzl`. In the default build,
  a synthetic repository is created containing [extensions_build_config.bzl](../source/extensions/extensions_build_config.bzl).
* Start by creating a new Bazel workspace somewhere in the filesystem that your build can access.
  This workspace should contain:
  * Empty WORKSPACE file.
  * Empty BUILD file.
  * A copy of [extensions_build_config.bzl](../source/extensions/extensions_build_config.bzl).
  * Comment out any extensions that you don't want to build in your file copy.

To have your local build use your overridden configuration repository there are two options:

1. Use the [`--override_repository`](https://docs.bazel.build/versions/master/command-line-reference.html)
   CLI option to override the `@envoy_build_config` repo.
2. Use the following snippet in your WORKSPACE before you load the Envoy repository. E.g.,

```
workspace(name = "envoy_filter_example")

local_repository(
    name = "envoy_build_config",
    # Relative paths are also supported.
    path = "/somewhere/on/filesystem/envoy_build_config",
)

local_repository(
    name = "envoy",
    # Relative paths are also supported.
    path = "/somewhere/on/filesystem/envoy",
)

...
```

When performing custom builds, it is acceptable to include contrib extensions as well. This can
be done by including the desired Bazel paths from [contrib_build_config.bzl](../contrib/contrib_build_config.bzl)
into the overridden `extensions_build_config.bzl`. (There is no need to specifically perform
a contrib build to include a contrib extension.)

## Extra extensions

If you are building your own Envoy extensions or custom Envoy builds and encounter visibility
problems with, you may need to adjust the default visibility rules to be public,
as documented in
[extensions_build_config.bzl](../source/extensions/extensions_build_config.bzl).
See the instructions above about how to create your own custom version of
[extensions_build_config.bzl](../source/extensions/extensions_build_config.bzl).

# Release builds

Release builds should be built in `opt` mode, processed with `strip` and have a
`.note.gnu.build-id` section with the Git SHA1 at which the build took place.
They should also ignore any local `.bazelrc` for reproducibility. This can be
achieved with:

```
bazel --bazelrc=/dev/null build -c opt envoy.stripped
```

One caveat to note is that the Git SHA1 is truncated to 16 bytes today as a
result of the workaround in place for
https://github.com/bazelbuild/bazel/issues/2805.

# Coverage builds

To generate coverage results, make sure you are using a Clang toolchain and have `llvm-cov` and
`llvm-profdata` in your `PATH`. Then run:

```
test/run_envoy_bazel_coverage.sh
```

**Note** that it is important to ensure that the versions of `clang`, `llvm-cov` and `llvm-profdata`
are consistent and that they match the most recent Clang/LLVM toolchain version in use by Envoy (see
the [build container
toolchain](https://github.com/envoyproxy/envoy-build-tools/blob/main/build_container/build_container_ubuntu.sh) for reference).

The summary results are printed to the standard output and the full coverage
report is available in `generated/coverage/coverage.html`.

To generate coverage results for fuzz targets, use the `FUZZ_COVERAGE` environment variable, e.g.:
```
FUZZ_COVERAGE=true VALIDATE_COVERAGE=false test/run_envoy_bazel_coverage.sh
```
This generates a coverage report for fuzz targets after running the target for one minute against fuzzing engine libfuzzer using its coprus as initial seed inputs. The full coverage report will be available in `generated/fuzz_coverage/coverage.html`.

Coverage for every PR is available in Circle in the "artifacts" tab of the coverage job. You will
need to navigate down and open "coverage.html" but then you can navigate per normal. NOTE: We
have seen some issues with seeing the artifacts tab. If you can't see it, log out of Circle, and
then log back in and it should start working.

The latest coverage report for main is available
[here](https://storage.googleapis.com/envoy-postsubmit/main/coverage/index.html). The latest fuzz coverage report for main is available [here](https://storage.googleapis.com/envoy-postsubmit/main/fuzz_coverage/index.html).

It's also possible to specialize the coverage build to a specified test or test dir. This is useful
when doing things like exploring the coverage of a fuzzer over its corpus. This can be done by
passing coverage targets as the command-line arguments and using the `VALIDATE_COVERAGE` environment
variable, e.g. for a fuzz test:

```
FUZZ_COVERAGE=true VALIDATE_COVERAGE=false test/run_envoy_bazel_coverage.sh //test/common/common:base64_fuzz_test
```

# Cleaning the build and test artifacts

`bazel clean` will nuke all the build/test artifacts from the Bazel cache for
Envoy proper. To remove the artifacts for the external dependencies run
`bazel clean --expunge`.

If something goes really wrong and none of the above work to resolve a stale build issue, you can
always remove your Bazel cache completely. It is likely located in `~/.cache/bazel`.

# Adding or maintaining Envoy build rules

See the [developer guide for writing Envoy Bazel rules](DEVELOPER.md).

# Bazel performance on (virtual) machines with low resources

If the (virtual) machine that is performing the build is low on memory or CPU
resources, you can override Bazel's default job parallelism determination with
`--jobs=N` to restrict the build to at most `N` simultaneous jobs, e.g.:

```
bazel build --jobs=2 envoy
```

# Debugging the Bazel build

When trying to understand what Bazel is doing, the `-s` and `--explain` options
are useful. To have Bazel provide verbose output on which commands it is executing:

```
bazel build -s envoy
```

To have Bazel emit to a text file the rationale for rebuilding a target:

```
bazel build --explain=file.txt envoy
```

To get more verbose explanations:

```
bazel build --explain=file.txt --verbose_explanations envoy
```

# Resolving paths in bazel build output

Sometimes it's useful to see real system paths in bazel error message output (vs. symbolic links).
`tools/path_fix.sh` is provided to help with this. See the comments in that file.

# Compilation database

Run `tools/gen_compilation_database.py` to generate
a [JSON Compilation Database](https://clang.llvm.org/docs/JSONCompilationDatabase.html). This could be used
with any tools (e.g. clang-tidy) compatible with the format. It is recommended to run this script
with `TEST_TMPDIR` set, so the Bazel artifacts doesn't get cleaned up in next `bazel build` or `bazel test`.

The compilation database could also be used to setup editors with cross reference, code completion.
For example, you can use [You Complete Me](https://valloric.github.io/YouCompleteMe/) or
[clangd](https://clangd.llvm.org/) with supported editors.

This requires Python 3.8.0+, download from [here](https://www.python.org/downloads/) if you do not have it installed already.

Use the following command to prepare a compilation database:

```
TEST_TMPDIR=/tmp tools/gen_compilation_database.py
```


# Running format linting without docker

Note that if you run the `check_spelling.py` script you will need to have `aspell` installed.

You can run clang-format directly, without docker:

```shell
bazel run //tools/code_format:check_format -- check
./tools/spelling/check_spelling_pedantic.py check
bazel run //tools/code_format:check_format -- fix
./tools/spelling/check_spelling_pedantic.py fix
```

# Advanced caching setup

Setting up an HTTP cache for Bazel output helps optimize Bazel performance and resource usage when
using multiple compilation modes or multiple trees.

## Setup local cache

You may use any [Remote Caching](https://docs.bazel.build/versions/master/remote-caching.html) backend
as an alternative to this.

This requires Go 1.11+, follow the [instructions](https://golang.org/doc/install#install) to install
if you don't have one. To start the cache, run the following from the root of the Envoy repository (or anywhere else
that the Go toolchain can find the necessary dependencies):

```
go run github.com/buchgr/bazel-remote --dir ${HOME}/bazel_cache --host 127.0.0.1 --port 28080 --max_size 64
```

See [Bazel remote cache](https://github.com/buchgr/bazel-remote) for more information on the parameters.
The command above will setup a maximum 64 GiB cache at `~/bazel_cache` on port 28080. You might
want to setup a larger cache if you run ASAN builds.

NOTE: Using docker to run remote cache server described in remote cache docs will likely have
slower cache performance on macOS due to slow disk performance on Docker for Mac.

Adding the following parameter to Bazel everytime or persist them in `.bazelrc`.

```
--remote_cache=http://127.0.0.1:28080/
```
# Table of Contents

   * [CPU or memory consumption testing with gperftools and pprof](#cpu-or-memory-consumption-testing-with-gperftools-and-pprof)
      * [Collecting CPU or heap profile for a full execution of envoy](#collecting-cpu-or-heap-profile-for-a-full-execution-of-envoy)
         * [Compiling a statically-linked Envoy](#compiling-a-statically-linked-envoy)
         * [Collecting the profile](#collecting-the-profile)
         * [Analyzing the profile](#analyzing-the-profile)
      * [Collecting CPU or heap profile for the full execution of a test target](#collecting-cpu-or-heap-profile-for-the-full-execution-of-a-test-target)
      * [Starting and stopping profile programmatically](#starting-and-stopping-profile-programmatically)
         * [Add tcmalloc_dep dependency to envoy_cc_library rules](#add-tcmalloc_dep-dependency-to-envoy_cc_library-rules)
      * [Memory Profiling in Tests](#memory-profiling-in-tests)
         * [Enabling Memory Profiling in Tests](#enabling-memory-profiling-in-tests)
         * [Bazel Configuration](#bazel-configuration)
   * [Methodology](#methodology)
   * [Analyzing with pprof](#analyzing-with-pprof)
   * [Alternatives to gperftools](#alternatives-to-gperftools)
      * [On-CPU analysis](#on-cpu-analysis)
      * [Memory analysis](#memory-analysis)
   * [Performance annotations](#performance-annotations)
   * [Performance analysis with Perfetto](#performance-analysis-with-perfetto)

# CPU or memory consumption testing with `gperftools` and `pprof`

To use `pprof` to analyze performance and memory consumption in Envoy, you can
use the built-in statically linked profiler provided by
[gperftools](https://github.com/gperftools/gperftools), or dynamically link it in to a
specific place yourself.

## Collecting CPU or heap profile for a full execution of envoy

Static linking is already available (because of a `HeapProfilerDump()` call
inside
[`Envoy::Profiler::Heap::stopProfiler())`](https://github.com/envoyproxy/envoy/blob/main/source/common/profiler/profiler.cc#L32-L39)).

### Compiling a statically-linked Envoy

Build the static binary using bazel:

    $ bazel build --define tcmalloc=gperftools //source/exe:envoy-static

### Collecting the profile

To collect a heap profile, run a statically-linked Envoy with `pprof`

and run the binary with a `CPUPROFILE` or `HEAPPROFILE` environment variable, like so:

    $ CPUPROFILE=/tmp/mybin.cpuprof bazel-bin/source/exe/envoy-static <args>
    $ HEAPPROFILE=/tmp/mybin.heapprof bazel-bin/source/exe/envoy-static <args>

`CPUPROFILE` or `HEAPPROFILE` sets a location for the profiler output. (See *Methodology*.)

There are several other environment variables that can be set to tweak the behavior of gperftools. See https://gperftools.github.io/gperftools/ for more details.

### Analyzing the profile

[pprof](https://github.com/google/pprof) can be used to symbolize CPU and heap profiles. For example:

    $ pprof -text bazel-bin/source/exe/envoy-static /tmp/mybin.cpuprof

## Collecting CPU or heap profile for the full execution of a test target

The profiler library is automatically linked into envoy_cc_test targets.

Run a test with heap profiling enabled, like so:

    $ bazel test --test_env=HEAPPROFILE=/tmp/heapprof --define tcmalloc=gperftools <test target>

Run a test with CPU profiling enabled, like so:

    $ bazel test --test_env=CPUPROFILE=/tmp/cpuprof --define tcmalloc=gperftools <test target>

Note that heap checks and heap profile collection in tests have noticiable performance implications. Use the following command to collect a CPU profile from a test target with heap check and heap profile collection disabled:

    $ bazel test --test_env=CPUPROFILE=/tmp/cpuprof --test_env=HEAPPROFILE= --test_env=HEAPCHECK= --define tcmalloc=gperftools <test target>

## Starting and stopping profile programmatically

### Add `tcmalloc_dep` dependency to envoy_cc_library rules

It is possible to start/stop the CPU or heap profiler programmatically.
The [Gperftools CPU Profiler](https://gperftools.github.io/gperftools/cpuprofile.html)
is controlled by `ProfilerStart()`/`ProfilerStop()`, and the
[Gperftools Heap Profiler](https://gperftools.github.io/gperftools/heapprofile.html)
is controlled by `HeapProfilerStart()`, `HeapProfilerStop()` and `HeapProfilerDump()`.

These functions are wrapped by Envoy objects defined in [`source/common/profiler/profiler.h`](https://github.com/envoyproxy/envoy/blob/main/source/common/profiler/profiler.h)).

To enable profiling programmatically:

1. Add a library dependency on "//source/common/profiler:profiler_lib" to your envoy_cc_library build rule.
2. Use the `startProfiler`/`stopProfiler` methods of `Envoy::Profiler::Cpu` or `Envoy::Profiler::Heap` to collect a profile.

Note that `startProfiler` should only be called if no other profile of that type is currently active (e.i. `profilerEnabled()` returns false).

Example:

```c++
    // includes
    #include "source/common/profiler/profiler.h"
    ...
    Function(...) {
        if (!Profiler::Cpu::startProfiler(profile_path)) {
           // Error handling
        }
        ...
        Do expensive stuff in one or more threads.
        ...

        // Stop the profiler and dump output to the `profile_path` specified when profile was started.
        Profiler::Cpu::stopProfiler();
    }
```

## Memory Profiling in Tests
To support memory leaks detection, tests are built with gperftools dependencies enabled by default.

### Enabling Memory Profiling in Tests
Use `HeapProfilerStart()`, `HeapProfilerStop()`, and `HeapProfilerDump()` to start, stop, and persist
memory dumps, respectively. Please see [above](#adding-tcmalloc_dep-to-envoy) for more details.

### Bazel Configuration
By default, bazel executes tests in a sandbox, which will be deleted together with memory dumps
after the test run. To preserve memory dumps, bazel can be forced to run tests without
sandboxing, by setting the ```TestRunner``` parameter to ```local```:
```
bazel test --strategy=TestRunner=local ...
```

An alternative is to set ```HEAPPROFILE``` environment variable for the test runner:
```
bazel test --test_env=HEAPPROFILE=/tmp/testprofile ...
```

# Methodology

For consistent testing, it makes sense to run Envoy for a constant amount of
time across trials:

    $ timeout <num_seconds> bazel-bin/source/exe/envoy <options>

Envoy will print to stdout something like:

    Starting tracking the heap

And then a series of stdouts like:

    Dumping heap profile to <heap file 0001> (100 MB currently in use)
    Dumping heap profile to <heap file 0002> (200 MB currently in use)
    ...

This will generate a series of files; if you statically-linked, these are
wherever `HEAPPROFILE` points to. Otherwise, they are in the current directory
by default. They'll be named something like `main_common_base.0001.heap`,
`main_common_base.0002.heap`, etc.

*NB:* There is no reason this needs to be titled `main_common_base`. Whatever
flag you supply `HeapProfilerStart` / `HeapProfilerDump` will become the
filename. Multiple sections of code could be profiled simultaneously by setting
multiple `HeapProfilerStart()` / `HeapProfilerStop()` breakpoints with unique
identifiers.

# Analyzing with `pprof`

[pprof](https://github.com/google/pprof) can read these heap files in a
number of ways. Most convenient for first-order inspection might be `pprof -top`
or `pprof -text`:

    $ pprof -text bazel-bin/source/exe/envoy main_common_base* | head -n5
    File: envoy
    Build ID: ...
    Type: inuse_space
    Showing nodes accounting for 6402800.62kB, 98.59% of 6494044.58kB total
    Dropped ... nodes (cum <= ...kB)

More complex flame/graph charts can be generated and viewed in a browser, which
is often more helpful than text-based output:

    $ pprof -http=localhost:9999 bazel-bin/source/exe/envoy main_common_base*

# Alternatives to `gperftools`

## On-CPU analysis

By default Envoy is built without gperftools. In this case the same results can be
achieved for On-CPU analysis with the `perf` tool. For this there is no need to tweak
Envoy's environment, you can even do measurements for an instance running in production
(beware of possible performance hit though). Simply run:
```
$ perf record -g -F 99 -p `pgrep envoy`
^C[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.694 MB perf.data (1532 samples) ]
```

The program will store the collected sampling data in the file `perf.data`. After installing
[perf_to_profile](https://github.com/google/perf_data_converter) this format
is also understood by recent enough versions of `pprof`:
```
$ pprof -http=localhost:9999 /path/to/envoy perf.data
```

Note that to see correct function names you need to pass an Envoy binary with debug symbols retained.
Its version must be the same as the version of the profiled Envoy binary.
You can get it from [envoyproxy/envoy:debug](https://hub.docker.com/r/envoyproxy/envoy/tags?name=debug).

Alternatively, you can use [allegro/envoy-perf-pprof](https://github.com/allegro/envoy-perf-pprof) which
wraps the pprof setup mentioned above (installing perf_to_profile, pprof and getting
the proper Envoy debug version) in a Dockerfile.

## Memory analysis

Unfortunately `perf` doesn't support heap profiling analogous to `gperftools`, but still
we can get some insight into memory allocations with
[Brendan Gregg's tools](http://www.brendangregg.com/FlameGraphs/memoryflamegraphs.html).
You'll need to have [bcc](https://github.com/iovisor/bcc) installed in your system and a
copy of [FlameGraph](https://github.com/brendangregg/FlameGraph):
```
$ git clone https://github.com/brendangregg/FlameGraph
$ sudo /usr/share/bcc/tools/stackcount -p `pgrep envoy` \
    -U "/full/path/to/envoy/bazel-bin/source/exe/envoy-static:_Znwm" > out.stack
$ ./FlameGraph/stackcollapse.pl < out.stacks | ./FlameGraph/flamegraph.pl --color=mem \
    --title="operator new(std::size_t) Flame Graph" --countname="calls" > out.svg
```

The `stackcount` utility counts function calls and their stack traces using eBPF probes.
Since Envoy by default links statically to tcmalloc which provides its own implementation
of memory management functions the used uprobe looks like
```/full/path/to/envoy/bazel-bin/source/exe/envoy-static:_Znwm```. The part before
the colon is a library name (a path to Envoy's binary in our case). The part after the
colon is a function name as it looks like in the output of `objdump -tT /path/to/lib`,
that is mangled in our case. To get an idea how your compiler mangles the name you
can use this one-liner:
```
$ echo -e "#include <new>\n void* operator new(std::size_t) {} " | g++ -x c++ -S - -o- 2> /dev/null
        .file   ""
        .text
        .globl  _Znwm
        .type   _Znwm, @function
_Znwm:
.LFB73:
        .cfi_startproc
        pushq   %rbp
        .cfi_def_cfa_offset 16
        .cfi_offset 6, -16
        movq    %rsp, %rbp
        .cfi_def_cfa_register 6
        movq    %rdi, -8(%rbp)
        nop
        popq    %rbp
        .cfi_def_cfa 7, 8
        ret
        .cfi_endproc
.LFE73:
        .size   _Znwm, .-_Znwm
        .ident  "GCC: (GNU) 10.2.1 20201016 (Red Hat 10.2.1-6)"
        .section        .note.GNU-stack,"",@progbits
```

WARNING: The name is going to be different on 32-bit and 64-bit platforms due to different sizes
of `size_t`. Also ```void* operator new[](std::size_t)``` is a separate function as well as `malloc()`.
The latter is a C function and hence not mangled by the way.

`stackcount` doesn't count how much memory is allocated, but how often. To answer the "how much"
question you could use Brendan's
[mallocstacks](https://github.com/brendangregg/BPF-tools/blob/master/old/2017-12-23/mallocstacks.py)
tool, but it works only for `malloc()` calls. You need to modify it to take into
account other memory allocating functions.

# Performance annotations

In case there is a need to measure how long a code path takes time to execute in Envoy you may
resort to instrumenting the code with the
[performance annotations](https://github.com/envoyproxy/envoy/blob/main/source/common/common/perf_annotation.h).

There are two types of the annotations. The first one is used to measure operations limited by
a common lexical scope. For example:

```c++
void doHeavyLifting() {
  PERF_OPERATION(op);
  bool success = doSomething();
  if (success) {
    finalizeSuccessfulOperation();
    PERF_RECORD(op, "successful", "heavy lifting");
  } else {
    recoverFromFailure();
    PERF_RECORD(op, "failed", "heavy lifting")
  }
}
```

The recorded performance data can be dumped to stdout with a call to `PERF_DUMP()`:
```
Duration(us)  # Calls  Mean(ns)  StdDev(ns)  Min(ns)  Max(ns)  Category    Description
        2837       22    128965     37035.5   109731   241957  successful  heavy lifting
         204       13     15745      2449.4    13323    20446  failed      heavy lifting
```

The second type is performance annotations owned by a class instance. They can measure
operations spanned across the instance's methods:
```c++
class CustomFilter : public Http::StreamEncoderFilter {
public:

  ...
  // Http::StreamEncoderFilter
  Http::FilterHeadersStatus encodeHeaders(Http::ResponseHeaderMap& headers,
                                          bool end_stream) override {
    PERF_OWNED_OPERATION(perf_operation_);
    return Http::FilterHeadersStatus::Continue;
  }

  Http::FilterDataStatus encodeData(Buffer::Instance& buffer, bool end_stream) override {
    if (end_stream) {
      PERF_OWNED_RECORD(perf_operation_, "without trailers", "stream encoding")
    }
    return Http::FilterDataStatus::Continue;
  }

  Http::FilterTrailersStatus encodeTrailers(Http::ResponseTrailerMap&) override {
    PERF_OWNED_RECORD(perf_operation_, "with trailers", "stream encoding");
    return Http::FilterTrailersStatus::Continue;
  }

  ...

private:
  ...
  PERF_OWNER(perf_operation_);
};
```

# Performance analysis with Perfetto

Similar results can be achieved with [Perfetto tracing macros](https://github.com/envoyproxy/envoy/blob/main/source/common/common/perf_tracing.h) enabled with

```
bazel --define=perf_tracing=enabled ...
```

[Perfetto](https://perfetto.dev/) is a production-grade open-source stack for
performance instrumentation and trace analysis. It offers services and libraries
for recording system-level and app-level traces, a library for analyzing traces
using SQL and a web-based UI to visualize and explore multi-GB traces.

Currently when the Perfetto support is enabled the tracing data in binary Protobuf
format is dumped into `envoy.pftrace` upon process termination. The file
can be analyzed online at https://ui.perfetto.dev/ or with a custom tool.

To generate a scoped trace event which uses C++ RAII under the hood add the
`TRACE_EVENT` macro to the block of your interest:

```c++
#include "source/common/common/perf_tracing.h"

RequestDecoder& ConnectionManagerImpl::newStream(ResponseEncoder& response_encoder,
                                                 bool is_internally_created) {
  TRACE_EVENT("core", "ConnectionManagerImpl::newStream"); // Begin "ConnectionManagerImpl::newStream" slice.
  ...

  // End "ConnectionManagerImpl::newStream" slice.
}
```

For events that don't follow function scoping, use `TRACE_EVENT_BEGIN` and
`TRACE_EVENT_END`. Please be careful with these events as all events on a given
thread share the same stack. This means that it's not recommended to have a matching
pair of `TRACE_EVENT_BEGIN` and `TRACE_EVENT_END` markers in separate functions,
since an unrelated event might terminate the original event unexpectedly; for events
that cross function boundaries it's usually best to emit them on a separate track.
Below is an example for a trace event covering an object's life span:

```c++
#include "source/common/common/perf_tracing.h"

Http::Request::Request(int request_id)
 : request_id_(request_id) {
  TRACE_EVENT_BEGIN("core", "Http::Request",
                    perfetto::Track(request_id_, perfetto::ThreadTrack::Current()));
  ...
}

Http::Request::~Request() {
  ...

  TRACE_EVENT_END("core", perfetto::Track(request_id_, perfetto::ThreadTrack::Current()));
}

```

Unfortunately this may lead to excessive number of tracks if they are unique for every
pair of emitted events. The existing visualization tools may not work well if the number
of tracks is too big. In this case the resulting trace data needs to be processed
differently. Alternatively, if you are interested in benchmarking only and don't need
any tracing capabilities, then you can resort to the Performance Annotation system mentioned
above which supports cross-scoped events too, but doesn't require any post-processing to get
a benchmark's final report.

Time-varying numeric data can be recorded with the `TRACE_COUNTER` macro:

```c++
TRACE_COUNTER("extensions", "MemoryAllocated",
              tcmalloc::MallocExtension::GetNumericProperty("generic.current_allocated_bytes"));
```

For more details please refer https://perfetto.dev/docs/instrumentation/track-events.
#!/bin/bash

BAZELRC_FILE="${BAZELRC_FILE:-$(bazel info workspace)/local_tsan.bazelrc}"

LIBCXX_PREFIX=$1

if [[ ! -e "${LIBCXX_PREFIX}/lib" ]]; then
  echo "Error: cannot find /lib in ${LIBCXX_PREFIX}."
  exit 1
fi


echo "# Generated file, do not edit. Delete this file if you no longer use local tsan-instrumented libc++
build:local-tsan --config=libc++
build:local-tsan --config=clang-tsan
build:local-tsan --linkopt=-L${LIBCXX_PREFIX}/lib
build:local-tsan --linkopt=-Wl,-rpath,${LIBCXX_PREFIX}/lib
" > "${BAZELRC_FILE}"
# DO NOT LOAD THIS FILE. Load envoy_build_system.bzl instead.
load(
    ":envoy_select.bzl",
    "envoy_select_admin_functionality",
    "envoy_select_disable_exceptions",
    "envoy_select_enable_full_protos",
    "envoy_select_enable_http3",
    "envoy_select_enable_http_datagrams",
    "envoy_select_enable_yaml",
    "envoy_select_envoy_mobile_listener",
    "envoy_select_envoy_mobile_xds",
    "envoy_select_google_grpc",
)

# Compute the defines needed for Envoy Mobile libraries that don't use Envoy's main library wrappers.
def envoy_mobile_defines(repository):
    return envoy_select_admin_functionality(["ENVOY_ADMIN_FUNCTIONALITY"], repository) + \
           envoy_select_enable_http3(["ENVOY_ENABLE_QUIC"], repository) + \
           envoy_select_enable_full_protos(["ENVOY_ENABLE_FULL_PROTOS"], repository) + \
           envoy_select_enable_yaml(["ENVOY_ENABLE_YAML"], repository) + \
           envoy_select_disable_exceptions(["ENVOY_DISABLE_EXCEPTIONS"], repository) + \
           envoy_select_enable_http_datagrams(["ENVOY_ENABLE_HTTP_DATAGRAMS"], repository) + \
           envoy_select_envoy_mobile_listener(["ENVOY_MOBILE_ENABLE_LISTENER"], repository) + \
           envoy_select_envoy_mobile_xds(["ENVOY_MOBILE_XDS"], repository) + \
           envoy_select_google_grpc(["ENVOY_GOOGLE_GRPC"], repository)
# DO NOT LOAD THIS FILE. Targets from this file should be considered private
# and not used outside of the @envoy//bazel package.
load(":envoy_select.bzl", "envoy_select_admin_html", "envoy_select_disable_exceptions", "envoy_select_disable_logging", "envoy_select_google_grpc", "envoy_select_hot_restart", "envoy_select_signal_trace", "envoy_select_static_extension_registration")

# Compute the final copts based on various options.
def envoy_copts(repository, test = False):
    posix_options = [
        "-Wall",
        "-Wextra",
        "-Werror",
        "-Wnon-virtual-dtor",
        "-Woverloaded-virtual",
        "-Wold-style-cast",
        "-Wformat",
        "-Wformat-security",
        "-Wvla",
        "-Wno-deprecated-declarations",
        "-Wreturn-type",
    ]

    # Windows options for cleanest service compilation;
    #   General MSVC C++ options for Envoy current expectations.
    #   Target windows.h for all Windows 10 (0x0A) API prototypes (ntohll etc)
    #   (See https://msdn.microsoft.com/en-us/library/windows/desktop/aa383745(v=vs.85).aspx )
    #   Optimize Windows headers by dropping GUI-oriented features from compilation
    msvc_options = [
        "-WX",
        "-Zc:__cplusplus",
        "-DWIN32",
        "-D_WIN32_WINNT=0x0A00",  # _WIN32_WINNT_WIN10
        "-DNTDDI_VERSION=0x0A000005",  # NTDDI_WIN10_RS4
        "-DWIN32_LEAN_AND_MEAN",
        "-DNOUSER",
        "-DNOMCX",
        "-DNOIME",
        "-DNOCRYPT",
        # Ignore unguarded gcc pragmas in quiche (unrecognized by MSVC)
        "-wd4068",
        # Silence incorrect MSVC compiler warnings when converting between std::optional
        # data types (while conversions between primitive types are producing no error)
        "-wd4244",
        # Allow inline functions to be undefined
        "-wd4506",
    ]

    return select({
               repository + "//bazel:windows_x86_64": msvc_options,
               "//conditions:default": posix_options,
           }) + select({
               # Simplify the amount of symbolic debug info for test binaries, since
               # debugging info detailing some 1600 test binaries would be wasteful.
               # targets listed in order from generic to increasing specificity.
               # Bazel adds an implicit -DNDEBUG for opt targets.
               repository + "//bazel:opt_build": [] if test else ["-ggdb3"],
               repository + "//bazel:fastbuild_build": [],
               repository + "//bazel:dbg_build": ["-ggdb3"],
               repository + "//bazel:windows_opt_build": [] if test else ["-Z7"],
               repository + "//bazel:windows_fastbuild_build": [],
               repository + "//bazel:windows_dbg_build": [],
               repository + "//bazel:clang_cl_opt_build": [] if test else ["-Z7", "-fstandalone-debug"],
               repository + "//bazel:clang_cl_fastbuild_build": ["-fno-standalone-debug"],
               repository + "//bazel:clang_cl_dbg_build": ["-fstandalone-debug"],
           }) + select({
               # Toggle expected features and warnings by compiler
               repository + "//bazel:clang_build": [
                   "-fno-limit-debug-info",
                   "-Wgnu-conditional-omitted-operand",
                   "-Wc++2a-extensions",
                   "-Wrange-loop-analysis",
               ],
               repository + "//bazel:gcc_build": ["-Wno-maybe-uninitialized"],
               # Allow 'nodiscard' function results values to be discarded for test code only
               # TODO(envoyproxy/windows-dev): Replace /Zc:preprocessor with /experimental:preprocessor
               # for msvc versions between 15.8 through 16.4.x. see
               # https://docs.microsoft.com/en-us/cpp/build/reference/zc-preprocessor
               repository + "//bazel:windows_x86_64": ["-wd4834", "-Zc:preprocessor", "-Wv:19.4"] if test else ["-Zc:preprocessor", "-Wv:19.4"],
               repository + "//bazel:clang_cl_build": ["-Wno-unused-result"] if test else [],
               "//conditions:default": [],
           }) + select({
               # TODO: Remove once https://reviews.llvm.org/D73007 is in the lowest supported Xcode version
               repository + "//bazel:apple": ["-Wno-range-loop-analysis"],
               "//conditions:default": [],
           }) + select({
               repository + "//bazel:no_debug_info": ["-g0"],
               "//conditions:default": [],
           }) + select({
               repository + "//bazel:disable_tcmalloc": ["-DABSL_MALLOC_HOOK_MMAP_DISABLE"],
               repository + "//bazel:disable_tcmalloc_on_linux_x86_64": ["-DABSL_MALLOC_HOOK_MMAP_DISABLE"],
               repository + "//bazel:disable_tcmalloc_on_linux_aarch64": ["-DABSL_MALLOC_HOOK_MMAP_DISABLE"],
               repository + "//bazel:gperftools_tcmalloc": ["-DGPERFTOOLS_TCMALLOC"],
               repository + "//bazel:gperftools_tcmalloc_on_linux_x86_64": ["-DGPERFTOOLS_TCMALLOC"],
               repository + "//bazel:gperftools_tcmalloc_on_linux_aarch64": ["-DGPERFTOOLS_TCMALLOC"],
               repository + "//bazel:debug_tcmalloc": ["-DENVOY_MEMORY_DEBUG_ENABLED=1", "-DGPERFTOOLS_TCMALLOC"],
               repository + "//bazel:debug_tcmalloc_on_linux_x86_64": ["-DENVOY_MEMORY_DEBUG_ENABLED=1", "-DGPERFTOOLS_TCMALLOC"],
               repository + "//bazel:debug_tcmalloc_on_linux_aarch64": ["-DENVOY_MEMORY_DEBUG_ENABLED=1", "-DGPERFTOOLS_TCMALLOC"],
               repository + "//bazel:linux_x86_64": ["-DTCMALLOC"],
               repository + "//bazel:linux_aarch64": ["-DTCMALLOC"],
               "//conditions:default": ["-DGPERFTOOLS_TCMALLOC"],
           }) + select({
               repository + "//bazel:disable_object_dump_on_signal_trace": [],
               "//conditions:default": ["-DENVOY_OBJECT_TRACE_ON_DUMP"],
           }) + select({
               repository + "//bazel:disable_deprecated_features": ["-DENVOY_DISABLE_DEPRECATED_FEATURES"],
               "//conditions:default": [],
           }) + select({
               repository + "//bazel:enable_log_debug_assert_in_release": ["-DENVOY_LOG_DEBUG_ASSERT_IN_RELEASE"],
               "//conditions:default": [],
           }) + select({
               repository + "//bazel:enable_log_fast_debug_assert_in_release": ["-DENVOY_LOG_FAST_DEBUG_ASSERT_IN_RELEASE"],
               "//conditions:default": [],
           }) + select({
               repository + "//bazel:disable_known_issue_asserts": ["-DENVOY_DISABLE_KNOWN_ISSUE_ASSERTS"],
               "//conditions:default": [],
           }) + select({
               # APPLE_USE_RFC_3542 is needed to support IPV6_PKTINFO in MAC OS.
               repository + "//bazel:apple": ["-D__APPLE_USE_RFC_3542"],
               "//conditions:default": [],
           }) + select({
               repository + "//bazel:uhv_enabled": ["-DENVOY_ENABLE_UHV"],
               "//conditions:default": [],
           }) + envoy_select_hot_restart(["-DENVOY_HOT_RESTART"], repository) + \
           envoy_select_disable_exceptions(["-fno-unwind-tables", "-fno-exceptions"], repository) + \
           envoy_select_admin_html(["-DENVOY_ADMIN_HTML"], repository) + \
           envoy_select_static_extension_registration(["-DENVOY_STATIC_EXTENSION_REGISTRATION"], repository) + \
           envoy_select_disable_logging(["-DENVOY_DISABLE_LOGGING"], repository) + \
           _envoy_select_perf_annotation(["-DENVOY_PERF_ANNOTATION"]) + \
           _envoy_select_perfetto(["-DENVOY_PERFETTO"]) + \
           envoy_select_google_grpc(["-DENVOY_GOOGLE_GRPC"], repository) + \
           envoy_select_signal_trace(["-DENVOY_HANDLE_SIGNALS"], repository) + \
           _envoy_select_path_normalization_by_default(["-DENVOY_NORMALIZE_PATH_BY_DEFAULT"], repository)

# References to Envoy external dependencies should be wrapped with this function.
def envoy_external_dep_path(dep):
    return "//external:%s" % dep

def envoy_linkstatic():
    return select({
        "@envoy//bazel:dynamic_link_tests": 0,
        "//conditions:default": 1,
    })

def envoy_select_force_libcpp(if_libcpp, default = None):
    return select({
        "@envoy//bazel:force_libcpp": if_libcpp,
        "@envoy//bazel:apple": [],
        "@envoy//bazel:windows_x86_64": [],
        "//conditions:default": default or [],
    })

def envoy_stdlib_deps():
    return select({
        "@envoy//bazel:asan_build": ["@envoy//bazel:dynamic_stdlib"],
        "@envoy//bazel:msan_build": ["@envoy//bazel:dynamic_stdlib"],
        "@envoy//bazel:tsan_build": ["@envoy//bazel:dynamic_stdlib"],
        "//conditions:default": ["@envoy//bazel:static_stdlib"],
    })

def envoy_dbg_linkopts():
    return select({
        # TODO: Remove once we have https://github.com/bazelbuild/bazel/pull/15635
        "@envoy//bazel:apple_non_opt": ["-Wl,-no_deduplicate"],
        "//conditions:default": [],
    })

# Dependencies on tcmalloc_and_profiler should be wrapped with this function.
def tcmalloc_external_dep(repository):
    return select({
        repository + "//bazel:disable_tcmalloc": None,
        repository + "//bazel:disable_tcmalloc_on_linux_x86_64": None,
        repository + "//bazel:disable_tcmalloc_on_linux_aarch64": None,
        repository + "//bazel:debug_tcmalloc": envoy_external_dep_path("gperftools"),
        repository + "//bazel:debug_tcmalloc_on_linux_x86_64": envoy_external_dep_path("gperftools"),
        repository + "//bazel:debug_tcmalloc_on_linux_aarch64": envoy_external_dep_path("gperftools"),
        repository + "//bazel:gperftools_tcmalloc": envoy_external_dep_path("gperftools"),
        repository + "//bazel:gperftools_tcmalloc_on_linux_x86_64": envoy_external_dep_path("gperftools"),
        repository + "//bazel:gperftools_tcmalloc_on_linux_aarch64": envoy_external_dep_path("gperftools"),
        repository + "//bazel:linux_x86_64": envoy_external_dep_path("tcmalloc"),
        repository + "//bazel:linux_aarch64": envoy_external_dep_path("tcmalloc"),
        "//conditions:default": envoy_external_dep_path("gperftools"),
    })

# Select the given values if default path normalization is on in the current build.
def _envoy_select_path_normalization_by_default(xs, repository = ""):
    return select({
        repository + "//bazel:enable_path_normalization_by_default": xs,
        "//conditions:default": [],
    })

def _envoy_select_perf_annotation(xs):
    return select({
        "@envoy//bazel:enable_perf_annotation": xs,
        "//conditions:default": [],
    })

def _envoy_select_perfetto(xs):
    return select({
        "@envoy//bazel:enable_perf_tracing": xs,
        "//conditions:default": [],
    })

def envoy_exported_symbols_input():
    return ["@envoy//bazel:exported_symbols.txt"]

# Default symbols to be exported.
# TODO(wbpcode): make this work correctly for apple/darwin.
def _envoy_default_exported_symbols():
    return select({
        "@envoy//bazel:linux": [
            "-Wl,--dynamic-list=$(location @envoy//bazel:exported_symbols.txt)",
        ],
        "//conditions:default": [],
    })

# Select the given values if exporting is enabled in the current build.
def envoy_select_exported_symbols(xs):
    return select({
        "@envoy//bazel:enable_exported_symbols": xs,
        "//conditions:default": [],
    }) + _envoy_default_exported_symbols()
diff --git a/CMakeLists.txt b/CMakeLists.txt
index 1db128b..ee3b4a9 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -27,7 +27,7 @@ include (${CMAKE_MODULE_PATH}/platform.cmake)
 include (${CMAKE_MODULE_PATH}/boost.cmake)
 include (${CMAKE_MODULE_PATH}/ragel.cmake)
 
-find_package(PkgConfig REQUIRED)
+find_package(PkgConfig QUIET)
 
 find_program(RAGEL ragel)
 
diff --git a/cmake/sqlite3.cmake b/cmake/sqlite3.cmake
index 92b18ce..5291726 100644
--- a/cmake/sqlite3.cmake
+++ b/cmake/sqlite3.cmake
@@ -2,6 +2,8 @@
 # a lot of noise to find sqlite
 #
 
+if(NOT SQLITE_SKIP_CHECK)
+
 option(SQLITE_PREFER_STATIC "Build sqlite3 statically instead of using an installed lib" OFF)
 
 if(NOT SQLITE_PREFER_STATIC)
@@ -33,4 +35,6 @@ else()
     endif()
 endif()
 
+endif()
+
 # that's enough about sqlite
diff --git src/CMakeLists.txt src/CMakeLists.txt
index fb4463e33..de1ef8990 100644
--- src/CMakeLists.txt
+++ src/CMakeLists.txt
@@ -31,12 +31,8 @@ include(cmake/ccache.cmake)
 ##############################################################################
 # VPP Version
 ##############################################################################
-execute_process(
-  WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}
-  COMMAND scripts/version
-  OUTPUT_VARIABLE VPP_VERSION
-  OUTPUT_STRIP_TRAILING_WHITESPACE
-)
+
+set(VPP_VERSION 23.06-release)
 string(REPLACE "-" ";" VPP_LIB_VERSION ${VPP_VERSION})
 list(GET VPP_LIB_VERSION 0 VPP_LIB_VERSION)
 
@@ -215,8 +211,7 @@ elseif("${CMAKE_SYSTEM_NAME}" STREQUAL "Linux")
   find_package(OpenSSL)
   set(SUBDIRS
     vppinfra svm vlib vlibmemory vlibapi vnet vpp vat vat2 vcl vpp-api
-    plugins tools/vppapigen tools/g2 tools/perftool cmake pkg
-    tools/appimage
+    tools/vppapigen cmake pkg
   )
 elseif("${CMAKE_SYSTEM_NAME}" STREQUAL "Darwin")
   set(SUBDIRS vppinfra)
diff --git src/cmake/ccache.cmake src/cmake/ccache.cmake
index a7b395bc6..d6a4c5b30 100644
--- src/cmake/ccache.cmake
+++ src/cmake/ccache.cmake
@@ -14,7 +14,7 @@
 ##############################################################################
 # ccache
 ##############################################################################
-option(VPP_USE_CCACHE "Use ccache compiler cache." ON)
+option(VPP_USE_CCACHE "Use ccache compiler cache." OFF)
 if(VPP_USE_CCACHE)
   find_program(CCACHE_FOUND ccache)
   message(STATUS "Looking for ccache")
diff --git src/cmake/library.cmake src/cmake/library.cmake
index 45b3944eb..b1dcc56e1 100644
--- src/cmake/library.cmake
+++ src/cmake/library.cmake
@@ -24,7 +24,7 @@ macro(add_vpp_library lib)
   set_target_properties(${lo} PROPERTIES POSITION_INDEPENDENT_CODE ON)
   target_compile_options(${lo} PUBLIC ${VPP_DEFAULT_MARCH_FLAGS})
 
-  add_library(${lib} SHARED)
+  add_library(${lib} STATIC)
   target_sources(${lib} PRIVATE $<TARGET_OBJECTS:${lo}>)
 
   if(VPP_LIB_VERSION)
diff --git src/tools/vppapigen/CMakeLists.txt src/tools/vppapigen/CMakeLists.txt
index 04ebed548..bfabc3a67 100644
--- src/tools/vppapigen/CMakeLists.txt
+++ src/tools/vppapigen/CMakeLists.txt
@@ -11,22 +11,6 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-find_package(
-  Python3
-  REQUIRED
-  COMPONENTS Interpreter
-)
-
-execute_process(
-  COMMAND ${Python3_EXECUTABLE} -c "import ply"
-  RESULT_VARIABLE _rv
-  OUTPUT_QUIET
-)
-
-if (NOT ${_rv} EQUAL 0)
-  message( FATAL_ERROR "The \"ply\" Python3 package is not installed.")
-endif()
-
 install(
   FILES vppapigen.py
   RENAME vppapigen
diff --git src/tools/vppapigen/vppapigen.py src/tools/vppapigen/vppapigen.py
index 2b0ce9999..f28a17302 100755
--- src/tools/vppapigen/vppapigen.py
+++ src/tools/vppapigen/vppapigen.py
@@ -7,6 +7,13 @@ import logging
 import binascii
 import os
 from subprocess import Popen, PIPE
+
+# Put ply on the path ...
+plypath = os.path.join(
+    os.environ["EXT_BUILD_ROOT"],
+    os.path.dirname(os.environ["PLYPATHS"].split()[0]))
+sys.path += [plypath]
+
 import ply.lex as lex
 import ply.yacc as yacc
 
diff --git src/vcl/CMakeLists.txt src/vcl/CMakeLists.txt
index 610b422d1..c5e6f8ca8 100644
--- src/vcl/CMakeLists.txt
+++ src/vcl/CMakeLists.txt
@@ -35,6 +35,8 @@ if (LDP_HAS_GNU_SOURCE)
   add_compile_definitions(HAVE_GNU_SOURCE)
 endif(LDP_HAS_GNU_SOURCE)
 
+file(COPY vppcom.h DESTINATION ${CMAKE_LIBRARY_OUTPUT_DIRECTORY})
+
 add_vpp_library(vcl_ldpreload
   SOURCES
   ldp_socket_wrapper.c

# Add support for compiling to WebAssembly using Emscripten.
# https://github.com/zlib-ng/zlib-ng/pull/794
diff --git a/cmake/detect-arch.c b/cmake/detect-arch.c

--- a/cmake/detect-arch.c
+++ b/cmake/detect-arch.c
@@ -101,6 +101,10 @@
         #error archfound riscv32
     #endif

+// Emscripten (WebAssembly)
+#elif defined(__EMSCRIPTEN__)
+    #error archfound wasm32
+
 // return 'unrecognized' if we do not know what architecture this is
 #else
     #error archfound unrecognized
diff --git a/cmake/detect-arch.cmake b/cmake/detect-arch.cmake

--- a/cmake/detect-arch.cmake
+++ b/cmake/detect-arch.cmake
@@ -85,6 +85,9 @@
 elseif("${ARCH}" MATCHES "rs6000")
     set(BASEARCH "rs6000")
     set(BASEARCH_RS6000_FOUND TRUE)
+elseif("${ARCH}" MATCHES "wasm32")
+    set(BASEARCH "wasm32")
+    set(BASEARCH_WASM32_FOUND TRUE)
 elseif("${ARCH}" MATCHES "riscv(32|64)")
     set(BASEARCH "riscv")
     set(BASEARCH_RISCV_FOUND TRUE)
diff --git a/sources/ippcp/crypto_mb/src/CMakeLists.txt b/sources/ippcp/crypto_mb/src/CMakeLists.txt
index f75f448..043a0a2 100644
--- a/sources/ippcp/crypto_mb/src/CMakeLists.txt
+++ b/sources/ippcp/crypto_mb/src/CMakeLists.txt
@@ -90,41 +90,6 @@ if(CMAKE_C_COMPILER_VERSION VERSION_LESS 20.2.3)
                                                                 COMPILE_FLAGS        "${AVX512_CFLAGS} ${CMAKE_C_FLAGS_SECURITY}")
 endif()
 
-# Create shared library
-if(DYNAMIC_LIB OR MB_STANDALONE)
-    if(WIN32)
-        add_library(${MB_DYN_LIB_TARGET} SHARED ${CRYPTO_MB_HEADERS} ${CRYPTO_MB_SOURCES} ${CPU_FEATURES_FILE} ${WIN_RESOURCE_FILE})
-    else()
-        add_library(${MB_DYN_LIB_TARGET} SHARED ${CRYPTO_MB_HEADERS} ${CRYPTO_MB_SOURCES} ${CPU_FEATURES_FILE})
-    endif()
-
-    set_target_properties(${MB_DYN_LIB_TARGET} PROPERTIES C_VISIBILITY_PRESET hidden
-                                                          VISIBILITY_INLINES_HIDDEN ON
-                                                          LINK_FLAGS "${LINK_FLAGS_DYNAMIC} ${LINK_FLAG_SECURITY}"
-                                                          PUBLIC_HEADER "${PUBLIC_HEADERS}"
-                                                          )
-
-    if(UNIX)
-        set_target_properties(${MB_DYN_LIB_TARGET} PROPERTIES  VERSION   ${MBX_INTERFACE_VERSION}
-                                                               SOVERSION ${MBX_INTERFACE_VERSION_MAJOR})
-    endif()
-
-    target_link_libraries(${MB_DYN_LIB_TARGET} OpenSSL::Crypto)
-endif(DYNAMIC_LIB OR MB_STANDALONE)
-
-# Installation of the shared library
-if (MB_STANDALONE) # standalone crypto_mb's cmake run
-    install(TARGETS ${MB_DYN_LIB_TARGET}
-            LIBRARY DESTINATION "lib"
-            RUNTIME DESTINATION "lib"
-            PUBLIC_HEADER DESTINATION "include/crypto_mb")
-elseif (DYNAMIC_LIB) # build from ippcp's cmake
-    install(TARGETS ${MB_DYN_LIB_TARGET}
-            LIBRARY DESTINATION "lib/intel64"
-            RUNTIME DESTINATION "lib/intel64"
-            PUBLIC_HEADER DESTINATION "include/crypto_mb")
-endif()
-
 # Static library
 if(WIN32)
     add_library(${MB_STATIC_LIB_TARGET} STATIC ${CRYPTO_MB_HEADERS} ${CRYPTO_MB_SOURCES} ${CPU_FEATURES_FILE} ${WIN_RESOURCE_FILE})
diff --git a/CMakeLists.txt b/CMakeLists.txt
index b412dc7..658a109 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -147,10 +147,15 @@ if(MINGW)
     set(ZLIB_DLL_SRCS ${CMAKE_CURRENT_BINARY_DIR}/zlib1rc.obj)
 endif(MINGW)
 
-add_library(zlib SHARED ${ZLIB_SRCS} ${ZLIB_DLL_SRCS} ${ZLIB_PUBLIC_HDRS} ${ZLIB_PRIVATE_HDRS})
-add_library(zlibstatic STATIC ${ZLIB_SRCS} ${ZLIB_PUBLIC_HDRS} ${ZLIB_PRIVATE_HDRS})
-set_target_properties(zlib PROPERTIES DEFINE_SYMBOL ZLIB_DLL)
-set_target_properties(zlib PROPERTIES SOVERSION 1)
+if(NOT DEFINED BUILD_SHARED_LIBS)
+    add_library(zlib SHARED ${ZLIB_SRCS} ${ZLIB_DLL_SRCS} ${ZLIB_PUBLIC_HDRS} ${ZLIB_PRIVATE_HDRS})
+    add_library(zlibstatic STATIC ${ZLIB_SRCS} ${ZLIB_PUBLIC_HDRS} ${ZLIB_PRIVATE_HDRS})
+    set_target_properties(zlib PROPERTIES DEFINE_SYMBOL ZLIB_DLL)
+    set_target_properties(zlib PROPERTIES SOVERSION 1)
+else()
+    add_library(zlib ${ZLIB_SRCS} ${ZLIB_ASMS} ${ZLIB_PUBLIC_HDRS} ${ZLIB_PRIVATE_HDRS})
+    set(ZLIB_INSTALL_LIBRARIES zlib)
+endif()
 
 if(NOT CYGWIN)
     # This property causes shared libraries on Linux to have the full version
@@ -160,22 +165,22 @@ if(NOT CYGWIN)
     #
     # This has no effect with MSVC, on that platform the version info for
     # the DLL comes from the resource file win32/zlib1.rc
-    set_target_properties(zlib PROPERTIES VERSION ${ZLIB_FULL_VERSION})
+    set_target_properties(${ZLIB_INSTALL_LIBRARIES} PROPERTIES VERSION ${ZLIB_FULL_VERSION})
 endif()
 
 if(UNIX)
     # On unix-like platforms the library is almost always called libz
-   set_target_properties(zlib zlibstatic PROPERTIES OUTPUT_NAME z)
+   set_target_properties(${ZLIB_INSTALL_LIBRARIES} PROPERTIES OUTPUT_NAME z)
    if(NOT APPLE)
-     set_target_properties(zlib PROPERTIES LINK_FLAGS "-Wl,--version-script,\"${CMAKE_CURRENT_SOURCE_DIR}/zlib.map\"")
+       set_target_properties(${ZLIB_INSTALL_LIBRARIES} PROPERTIES LINK_FLAGS "-Wl,--version-script,\"${CMAKE_CURRENT_SOURCE_DIR}/zlib.map\"")
    endif()
 elseif(BUILD_SHARED_LIBS AND WIN32)
     # Creates zlib1.dll when building shared library version
-    set_target_properties(zlib PROPERTIES SUFFIX "1.dll")
+    set_target_properties(${ZLIB_INSTALL_LIBRARIES} PROPERTIES SUFFIX "1.dll")
 endif()
 
 if(NOT SKIP_INSTALL_LIBRARIES AND NOT SKIP_INSTALL_ALL )
-    install(TARGETS zlib zlibstatic
+    install(TARGETS ${ZLIB_INSTALL_LIBRARIES}
         RUNTIME DESTINATION "${INSTALL_BIN_DIR}"
         ARCHIVE DESTINATION "${INSTALL_LIB_DIR}"
         LIBRARY DESTINATION "${INSTALL_LIB_DIR}" )
@@ -194,20 +199,22 @@ endif()
 # Example binaries
 #============================================================================
 
-add_executable(example test/example.c)
-target_link_libraries(example zlib)
-add_test(example example)
+if(NOT SKIP_BUILD_EXAMPLES)
+    add_executable(example test/example.c)
+    target_link_libraries(example zlib)
+    add_test(example example)
 
-add_executable(minigzip test/minigzip.c)
-target_link_libraries(minigzip zlib)
+    add_executable(minigzip test/minigzip.c)
+    target_link_libraries(minigzip zlib)
 
-if(HAVE_OFF64_T)
-    add_executable(example64 test/example.c)
-    target_link_libraries(example64 zlib)
-    set_target_properties(example64 PROPERTIES COMPILE_FLAGS "-D_FILE_OFFSET_BITS=64")
-    add_test(example64 example64)
-
-    add_executable(minigzip64 test/minigzip.c)
-    target_link_libraries(minigzip64 zlib)
-    set_target_properties(minigzip64 PROPERTIES COMPILE_FLAGS "-D_FILE_OFFSET_BITS=64")
+    if(HAVE_OFF64_T)
+        add_executable(example64 test/example.c)
+        target_link_libraries(example64 zlib)
+        set_target_properties(example64 PROPERTIES COMPILE_FLAGS "-D_FILE_OFFSET_BITS=64")
+        add_test(example64 example64)
+
+        add_executable(minigzip64 test/minigzip.c)
+        target_link_libraries(minigzip64 zlib)
+        set_target_properties(minigzip64 PROPERTIES COMPILE_FLAGS "-D_FILE_OFFSET_BITS=64")
+    endif()
 endif()
{
  "strategy": "additive",
  "featureFilters": {
    "misc": "include"
  }
}

diff --git a/WORKSPACE b/WORKSPACE
deleted file mode 100644
index e69de29..0000000
diff --git a/icu4c/source/common/BUILD.bazel b/icu4c/source/common/BUILD.bazel
deleted file mode 100644
index e385d3b..0000000
--- a/icu4c/source/common/BUILD.bazel
+++ /dev/null
@@ -1,1213 +0,0 @@
-#  2021 and later: Unicode, Inc. and others.
-# License & terms of use: http://www.unicode.org/copyright.html
-
-# This file defines Bazel targets for a subset of ICU4C "common" library header and source files.
-# The configuration of dependencies among targets is strongly assisted by the
-# file in depstest that maintains such information, at
-# icu4c/source/test/depstest/dependencies.txt .
-
-load("@rules_cc//cc:defs.bzl", "cc_binary", "cc_library")
-
-package(
-    default_visibility = ["//visibility:public"],
-)
-
-# When compiling code in the `common` dir, the constant
-# `U_COMMON_IMPLEMENTATION` needs to be defined. See 
-# https://unicode-org.github.io/icu/userguide/howtouseicu#c-with-your-own-build-system .
-
-# If linker errors occur, then this may be a sign that the dependencies were 
-# not specified correctly. Use dependencies.txt in depstest for assistance. See
-# https://stackoverflow.com/q/66111709/2077918 .
-
-cc_library(
-    name = "headers",
-    hdrs = glob([
-        "unicode/*.h", # public
-        "*.h",         # internal
-        ],
-        # Instead of using these checked-in files, our Bazel build process
-        # regenerates them and then uses the new versions.
-        # Same list of .h files as in icu4c/source/data/unidata/clean.sh.
-        exclude = ["norm2_nfc_data.h", "propname_data.h", "*_props_data.h"],
-    ),
-    # We need to add includes in order to preserve existing source files'
-    # include directives that use traditional paths, not paths relative to
-    # Bazel workspace:
-    # https://stackoverflow.com/a/65635893/2077918
-    includes = ["."],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "platform",
-    srcs = [
-        "cmemory.cpp", 
-        "uobject.cpp",
-        "cstring.cpp",
-        "cwchar.cpp",
-        "uinvchar.cpp",
-        "charstr.cpp",
-        "unistr.cpp",
-        "appendable.cpp",
-        "stringpiece.cpp",
-        "ustrtrns.cpp",
-        "ustring.cpp",  
-        "ustrfmt.cpp",  
-        "utf_impl.cpp",
-        "putil.cpp",
-        "ucln_cmn.cpp",  
-        "udataswp.cpp",  
-        "umath.cpp",
-        "umutex.cpp",
-        "sharedobject.cpp",
-        "utrace.cpp",
-    ],
-    deps = [
-        ":headers",
-        # omit other deps b/c they are sys symbols
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-    linkopts = ["-ldl"],
-)
-
-cc_library(
-    name = "utrie",
-    srcs = ["utrie.cpp"],
-    deps = [":platform"],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "utrie2",
-    srcs = ["utrie2.cpp"],
-    deps = [":platform"],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "utrie2_builder",
-    srcs = ["utrie2_builder.cpp"],
-    deps = [
-        ":utrie",
-        ":utrie2",
-        ":platform",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "ucptrie",
-    srcs = ["ucptrie.cpp"],
-    deps = [":platform"],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "umutablecptrie",
-    srcs = ["umutablecptrie.cpp"],
-    deps = [":ucptrie"],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "bytestrie",
-    srcs = ["bytestrie.cpp"],
-    deps = [":platform"],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "bytestriebuilder",
-    srcs = ["bytestriebuilder.cpp"],
-    deps = [
-        ":bytestrie",
-        ":stringtriebuilder",
-        ":sort",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "stringtriebuilder",
-    srcs = ["stringtriebuilder.cpp"],
-    deps = [
-        ":uhash",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "uhash",
-    hdrs = [
-        "uhash.h",
-    ],
-    srcs = [
-        "uhash.cpp",
-    ],
-    deps = [
-        ":headers",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "errorcode",
-    hdrs = [
-    ],
-    srcs = [
-        "errorcode.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":platform",
-        ":utypes",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "utypes",
-    srcs = [
-        "utypes.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "uniset",
-    srcs = [
-        "uniset.cpp",
-        "unifilt.cpp",
-        "unisetspan.cpp",
-        "bmpset.cpp",
-        "util.cpp",
-        "unifunct.cpp",
-        "usetiter.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":patternprops",
-        ":uvector",
-        ":headers",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "patternprops",
-    srcs = [
-        "patternprops.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "propsvec",
-    srcs = [
-        "propsvec.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":sort",
-        ":utrie2_builder",
-        ":headers",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "propname",
-    srcs = [
-        "propname.cpp",
-        "propname_data.h",
-    ],
-    includes = ["."],
-    deps = [
-        ":bytestrie",
-        ":headers",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-# Note: The cc_library target names "uvector32" and "uvector64" match the
-# dependencies.txt group names, but the filenames are "uvectr32.*"/"uvectr64.*".
-cc_library(
-    name = "uvector32",
-    srcs = [
-        "uvectr32.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":platform",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "uvector64",
-    srcs = [
-        "uvectr64.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":platform",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "sort",
-    srcs = [
-        "uarrsort.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "uvector",
-    srcs = [
-        "uvector.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":platform",
-        ":sort",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "breakiterator",
-    srcs = [
-        "brkiter.cpp",
-        "brkeng.cpp",
-        "dictbe.cpp",
-        "dictionarydata.cpp",
-        "filteredbrk.cpp",
-        "lstmbe.cpp",
-        "rbbi.cpp",
-        "rbbi_cache.cpp",
-        "rbbidata.cpp",
-        "rbbinode.cpp",
-        "rbbirb.cpp",
-        "rbbiscan.cpp",
-        "rbbisetb.cpp",
-        "rbbistbl.cpp",
-        "rbbitblb.cpp",
-        "ubrk.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":bytestrie",
-        ":headers",
-        ":normlzr",
-        ":resourcebundle",
-        ":schriter",
-        ":service_registration",
-        ":ucharstrie",
-        ":ucharstriebuilder",
-        ":uhash",
-        ":uniset_core",
-        ":uniset_props",
-        ":ustack",
-        ":utext",
-        ":utrie2_builder",
-        ":uvector32",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "bytesinkutil",
-    srcs = [
-        "bytesinkutil.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":bytestream",
-        ":edits",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "bytestream",
-    srcs = [
-        "bytestream.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":platform",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "canonical_iterator",
-    srcs = [
-        "caniter.cpp",
-    ],
-    deps = [
-        ":normalizer2",
-        ":usetiter",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "characterproperties",
-    srcs = [
-        "characterproperties.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":emojiprops",
-        ":ucptrie",
-        ":umutablecptrie",
-        ":uniset_core",
-        ":uprops",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "chariter",
-    srcs = [
-        "chariter.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":platform",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "edits",
-    srcs = [
-        "edits.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":icu_utility",
-        ":platform",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "filterednormalizer2",
-    srcs = [
-        "filterednormalizer2.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":normalizer2",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "hashtable",
-    srcs = [
-        "uhash_us.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":uhash",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "icu_utility",
-    srcs = [
-        "util.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":patternprops",
-        ":platform",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "loadednormalizer2",
-    srcs = [
-        "loadednormalizer2impl.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":normalizer2",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "locale_display_names",
-    srcs = [
-        "locdispnames.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":locresdata",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "locresdata",
-    srcs = [
-        "locresdata.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":resourcebundle",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "normlzr",
-    srcs = [
-        "normlzr.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":filterednormalizer2",
-        ":headers",
-        ":schriter",
-        ":uniset_props",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "parsepos",
-    srcs = [
-        "parsepos.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":platform",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "resourcebundle",
-    srcs = [
-        "localebuilder.cpp",
-        "locavailable.cpp",
-        "locbased.cpp",
-        "locid.cpp",
-        "loclikely.cpp",
-        "locmap.cpp",
-        "resbund.cpp",
-        "resource.cpp",
-        "uloc.cpp",
-        "uloc_tag.cpp",
-        "uloc_keytype.cpp",
-        "uresbund.cpp",
-        "uresdata.cpp",
-        "wintz.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":bytesinkutil",
-        ":errorcode",
-        ":headers",
-        ":propname",
-        ":sort",
-        ":stringenumeration",
-        ":ucol_swp",
-        ":udata",
-        ":uhash",
-        ":uscript_props",
-        ":uvector",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "schriter",
-    srcs = [
-        "schriter.cpp",
-        "uchriter.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":chariter",
-        ":headers",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "service_registration",
-    srcs = [
-        "locutil.cpp",
-        "serv.cpp",
-        "servlk.cpp",
-        "servlkf.cpp",
-        "servls.cpp",
-        "servnotf.cpp",
-        "servrbf.cpp",
-        "servslkf.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":hashtable",
-        ":headers",
-        ":locale_display_names",
-        ":resourcebundle",
-        ":uvector",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "stringenumeration",
-    srcs = [
-        "uenum.cpp",
-        "ustrenum.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":platform",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "ubidi_props",
-    srcs = [
-        "ubidi_props.cpp",
-        "ubidi_props_data.h",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":utrie2",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "ucase",
-    srcs = [
-        "ucase.cpp",
-        "ucase_props_data.h",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":utrie2",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "uchar",
-    srcs = [
-        "uchar.cpp",
-        "uchar_props_data.h",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":utrie2",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "emojiprops",
-    srcs = [
-        "emojiprops.cpp",
-        "emojiprops.h",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":ucharstrie",
-        ":ucharstrieiterator",
-        ":ucptrie",
-        ":udata",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "ucharstrie",
-    srcs = [
-        "ucharstrie.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":platform",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "ucharstriebuilder",
-    srcs = [
-        "ucharstriebuilder.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":sort",
-        ":stringtriebuilder",
-        ":ucharstrie",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "ucharstrieiterator",
-    srcs = [
-        "ucharstrieiterator.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":ucharstrie",
-        ":uvector32",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "ucol_swp",
-    srcs = [
-        "ucol_swp.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":utrie_swap",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "udata",
-    srcs = [
-        "restrace.cpp",
-        "ucmndata.cpp",
-        "udata.cpp",
-        "udatamem.cpp",
-        "umapfile.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":icu_utility",
-        ":platform",
-        ":uhash",
-        "//icu4c/source/stubdata",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "uiter",
-    srcs = [
-        "uiter.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":platform",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "ulist",
-    srcs = [
-        "ulist.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":platform",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "unames",
-    srcs = [
-        "unames.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":uchar",
-        ":udata",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "unifiedcache",
-    srcs = [
-        "unifiedcache.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":platform",
-        ":uhash",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "uniset_core",
-    srcs = [
-        "bmpset.cpp",
-        "unifilt.cpp",
-        "unifunct.cpp",
-        "uniset.cpp",
-        "unisetspan.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":icu_utility",
-        ":patternprops",
-        ":uvector",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "uniset_closure",
-    srcs = [
-        "uniset_closure.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":uniset_core",
-        ":unistr_case_locale",
-        ":unistr_titlecase_brkiter",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "uniset_props",
-    srcs = [
-        "uniset_props.cpp",
-        "ruleiter.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":characterproperties",
-        ":headers",
-        ":parsepos",
-        ":propname",
-        ":resourcebundle",
-        ":unames",
-        ":uniset_core",
-        ":unistr_case",
-        ":uprops",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "unistr_case",
-    srcs = [
-        "unistr_case.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":ustring_case",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "unistr_case_locale",
-    srcs = [
-        "unistr_case_locale.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":unistr_case",
-        ":ustring_case_locale",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "unistr_titlecase_brkiter",
-    srcs = [
-        "unistr_titlecase_brkiter.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":ustr_titlecase_brkiter",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "uprops",
-    srcs = [
-        "uprops.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":emojiprops",
-        ":loadednormalizer2",
-        ":normalizer2",
-        ":ubidi_props",
-        ":ucase",
-        ":uchar",
-        ":unistr_case",
-        ":ustring_case",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "uscript_props",
-    srcs = [
-        "uscript_props.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":platform",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "uset",
-    srcs = [
-        "uset.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":platform",
-        ":uniset_core",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "uset_props",
-    srcs = [
-        "uset_props.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":uniset_closure",
-        ":uniset_core",
-        ":uniset_props",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "usetiter",
-    srcs = [
-        "usetiter.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":platform",
-        ":uniset_core",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "ustack",
-    srcs = [
-        "ustack.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":uvector",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "ustr_titlecase_brkiter",
-    srcs = [
-        "ustr_titlecase_brkiter.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":breakiterator",
-        ":headers",
-        ":ucase",
-        ":ustring_case_locale",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "ustring_case",
-    srcs = [
-        "ustrcase.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":ucase",
-        ":uchar",
-        ":edits",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "ustring_case_locale",
-    srcs = [
-        "ustrcase_locale.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":resourcebundle",
-        ":ustring_case",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "utext",
-    srcs = [
-        "utext.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":ucase",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "utrie_swap",
-    srcs = [
-        "utrie_swap.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":udata",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
-
-# This target depends on a header file that contains NFC/NFD normalization data.
-# This header file is generated by a script (generate.sh) that invokes the gennorm2 binary.
-# See the Unicode update change log (changes.txt).
-cc_library(
-    name = "normalizer2",
-    srcs = [
-        "norm2_nfc_data.h",  # generated by gennorm2
-        "normalizer2.cpp",
-        "normalizer2impl.cpp",
-    ],
-    includes = ["."],
-    hdrs = [
-        "normalizer2impl.h",
-    ],
-    deps = [
-        ":headers",
-    ],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",  
-    ],
-)
diff --git a/icu4c/source/data/unidata/norm2/BUILD.bazel b/icu4c/source/data/unidata/norm2/BUILD.bazel
deleted file mode 100644
index 049e19b..0000000
--- a/icu4c/source/data/unidata/norm2/BUILD.bazel
+++ /dev/null
@@ -1,13 +0,0 @@
-#  2021 and later: Unicode, Inc. and others.
-# License & terms of use: http://www.unicode.org/copyright.html
-
-# This Bazel build file is needed to declare targets for the files used as
-# inputs to binary executables that are a part of other Bazel genrule targets.
-
-package(
-    default_visibility = ["//visibility:public"],
-)
-
-exports_files([
-    "nfc.txt", "nfkc.txt", "nfkc_cf.txt", "uts46.txt",
-])
diff --git a/icu4c/source/i18n/BUILD.bazel b/icu4c/source/i18n/BUILD.bazel
deleted file mode 100644
index 2d85cdb..0000000
--- a/icu4c/source/i18n/BUILD.bazel
+++ /dev/null
@@ -1,130 +0,0 @@
-#  2021 and later: Unicode, Inc. and others.
-# License & terms of use: http://www.unicode.org/copyright.html
-
-# This file defines Bazel targets for a subset of the ICU4C "i18n" library header and source files.
-# The configuration of dependencies among targets is strongly assisted by the
-# file in depstest that maintains such information, at
-# icu4c/source/test/depstest/dependencies.txt .
-
-load("@rules_cc//cc:defs.bzl", "cc_binary", "cc_library")
-
-package(
-    default_visibility = ["//visibility:public"],
-)
-
-# When compiling code in the `common` dir, the constant
-# `U_I18n_IMPLEMENTATION` needs to be defined. See 
-# https://unicode-org.github.io/icu/userguide/howtouseicu#c-with-your-own-build-system .
-
-# If linker errors occur, then this may be a sign that the dependencies were 
-# not specified correctly. Use dependencies.txt in depstest for assistance. See
-# https://stackoverflow.com/q/66111709/2077918 .
-
-cc_library(
-    name = "headers",
-    hdrs = glob([
-        "unicode/*.h", # public
-        "*.h",         # internal
-    ]),
-    # We need to add includes in order to preserve existing source files'
-    # include directives that use traditional paths, not paths relative to
-    # Bazel workspace:
-    # https://stackoverflow.com/a/65635893/2077918
-    includes = ["."],
-    local_defines = [
-        "U_I18N_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "collation",
-    srcs = [
-        "bocsu.cpp",
-        "coleitr.cpp",
-        "coll.cpp",
-        "collation.cpp",
-        "collationcompare.cpp",
-        "collationdata.cpp",
-        "collationdatareader.cpp",
-        "collationdatawriter.cpp",
-        "collationfastlatin.cpp",
-        # collationfcd.cpp is generated by genuca;
-        # probably hard to build genuca without depending on the old version.
-        "collationfcd.cpp",
-        "collationiterator.cpp",
-        "collationkeys.cpp",
-        "collationroot.cpp",
-        "collationrootelements.cpp",
-        "collationsets.cpp",
-        "collationsettings.cpp",
-        "collationtailoring.cpp",
-        "rulebasedcollator.cpp",
-        "sortkey.cpp",
-        "ucol.cpp",
-        "ucol_res.cpp",
-        "ucol_sit.cpp",
-        "ucoleitr.cpp",
-        "uitercollationiterator.cpp",
-        "utf16collationiterator.cpp",
-        "utf8collationiterator.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":headers",
-        ":uclean_i18n",
-        "//icu4c/source/common:bytestream",
-        "//icu4c/source/common:normalizer2",
-        "//icu4c/source/common:platform",
-        "//icu4c/source/common:propname",
-        "//icu4c/source/common:resourcebundle",
-        "//icu4c/source/common:service_registration",
-        "//icu4c/source/common:ucharstrieiterator",
-        "//icu4c/source/common:uiter",
-        "//icu4c/source/common:ulist",
-        "//icu4c/source/common:unifiedcache",
-        "//icu4c/source/common:uset",
-        "//icu4c/source/common:usetiter",
-        "//icu4c/source/common:utrie2",
-        "//icu4c/source/common:uvector32",
-        "//icu4c/source/common:uvector64",
-    ],
-    local_defines = [
-        "U_I18N_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "collation_builder",
-    srcs = [
-        "collationbuilder.cpp",
-        "collationdatabuilder.cpp",
-        "collationfastlatinbuilder.cpp",
-        "collationruleparser.cpp",
-        "collationweights.cpp",
-    ],
-    includes = ["."],
-    deps = [
-        ":collation",
-        "//icu4c/source/common:canonical_iterator",
-        "//icu4c/source/common:ucharstriebuilder",
-        "//icu4c/source/common:uset_props"
-    ],
-    local_defines = [
-        "U_I18N_IMPLEMENTATION",
-    ],
-)
-
-cc_library(
-    name = "uclean_i18n",
-    srcs = [
-        "ucln_in.cpp",
-    ],
-    hdrs = ["ucln_in.h"],
-    includes = ["."],
-    deps = [
-        "//icu4c/source/common:platform",
-    ],
-    local_defines = [
-        "U_I18N_IMPLEMENTATION",
-    ],
-)
diff --git a/icu4c/source/icudefs.mk.in b/icu4c/source/icudefs.mk.in
index 2c35816..4ad6f52 100644
--- a/icu4c/source/icudefs.mk.in
+++ b/icu4c/source/icudefs.mk.in
@@ -117,7 +117,7 @@ EXEEXT = @EXEEXT@
 CC = @CC@
 CXX = @CXX@
 AR = @AR@
-ARFLAGS = @ARFLAGS@ r
+ARFLAGS = @ARFLAGS@
 RANLIB = @RANLIB@
 COMPILE_LINK_ENVVAR = @COMPILE_LINK_ENVVAR@
 UCLN_NO_AUTO_CLEANUP = @UCLN_NO_AUTO_CLEANUP@
diff --git a/icu4c/source/stubdata/BUILD.bazel b/icu4c/source/stubdata/BUILD.bazel
deleted file mode 100644
index 20344ef..0000000
--- a/icu4c/source/stubdata/BUILD.bazel
+++ /dev/null
@@ -1,24 +0,0 @@
-#  2021 and later: Unicode, Inc. and others.
-# License & terms of use: http://www.unicode.org/copyright.html
-
-# This file defines Bazel targets for the ICU4C "stubdata" library header and source files.
-
-load("@rules_cc//cc:defs.bzl", "cc_library")
-
-package(
-    default_visibility = ["//visibility:public"],
-)
-
-# When compiling code in the `common` dir, the constant
-# `U_COMMON_IMPLEMENTATION` needs to be defined. See 
-# https://unicode-org.github.io/icu/userguide/howtouseicu#c-with-your-own-build-system .
-
-cc_library(
-    name = "stubdata",
-    srcs = ["stubdata.cpp"],
-    hdrs = ["stubdata.h"],
-    deps = ["//icu4c/source/common:headers"],
-    local_defines = [
-        "U_COMMON_IMPLEMENTATION",
-    ],
-)
diff --git a/icu4c/source/tools/gennorm2/BUILD.bazel b/icu4c/source/tools/gennorm2/BUILD.bazel
deleted file mode 100644
index c602897..0000000
--- a/icu4c/source/tools/gennorm2/BUILD.bazel
+++ /dev/null
@@ -1,39 +0,0 @@
-#  2021 and later: Unicode, Inc. and others.
-# License & terms of use: http://www.unicode.org/copyright.html
-
-# This Bazel build file defines a target for the gennorm2 binary that generates
-# headers needed for bootstrapping the ICU4C build process in a way that
-# integrates the normalization data.
-
-load("@rules_cc//cc:defs.bzl", "cc_binary", "cc_library")
-
-package(
-    default_visibility = ["//visibility:public"],
-)
-
-cc_binary(
-    name = "gennorm2",
-    srcs = glob([
-        "*.c",
-        "*.cpp",
-        "*.h",   # cannot have hdrs section in cc_binary
-    ]),
-    deps = [
-        "//icu4c/source/common:uhash",
-        "//icu4c/source/common:umutablecptrie",
-        "//icu4c/source/common:ucptrie",
-        "//icu4c/source/common:errorcode",
-        "//icu4c/source/common:uniset",
-        "//icu4c/source/common:uvector32",
-
-        "//icu4c/source/common:platform",
-        "//icu4c/source/common:headers",
-        
-        "//icu4c/source/tools/toolutil:toolutil",
-        "//icu4c/source/tools/toolutil:unewdata",
-        "//icu4c/source/tools/toolutil:writesrc",
-        "//icu4c/source/tools/toolutil:uoptions",
-        "//icu4c/source/tools/toolutil:uparse",
-    ],
-    linkopts = ["-pthread"],
-)
diff --git a/icu4c/source/tools/toolutil/BUILD.bazel b/icu4c/source/tools/toolutil/BUILD.bazel
deleted file mode 100644
index 276c857..0000000
--- a/icu4c/source/tools/toolutil/BUILD.bazel
+++ /dev/null
@@ -1,126 +0,0 @@
-#  2021 and later: Unicode, Inc. and others.
-# License & terms of use: http://www.unicode.org/copyright.html
-
-# This Bazel build file defines targets that are dependencies for building
-# the gennorm2 and genprops binaries.
-
-load("@rules_cc//cc:defs.bzl", "cc_binary", "cc_library")
-
-package(
-    default_visibility = ["//visibility:public"],
-)
-
-cc_library(
-    name = "toolutil",
-    includes = ["."],
-    hdrs = ["toolutil.h"],
-    srcs = ["toolutil.cpp"],
-    local_defines = [
-        "U_TOOLUTIL_IMPLEMENTATION",
-    ],
-    deps = ["//icu4c/source/common:platform"],
-)
-
-cc_library(
-    name = "unewdata",
-    includes = ["."],
-    hdrs = ["unewdata.h"],
-    srcs = ["unewdata.cpp"],
-    local_defines = [
-        "U_TOOLUTIL_IMPLEMENTATION",
-    ],
-    deps = [
-        ":filestrm",
-        "//icu4c/source/common:platform",
-    ],
-)
-
-cc_library(
-    name = "uoptions",
-    includes = ["."],
-    hdrs = ["uoptions.h"],
-    srcs = ["uoptions.cpp"],
-    local_defines = [
-        "U_TOOLUTIL_IMPLEMENTATION",
-    ],
-    deps = ["//icu4c/source/common:platform"],
-)
-
-cc_library(
-    name = "writesrc",
-    includes = ["."],
-    hdrs = ["writesrc.h"],
-    srcs = ["writesrc.cpp"],
-    local_defines = [
-        "U_TOOLUTIL_IMPLEMENTATION",
-    ],
-    deps = [
-        "//icu4c/source/common:bytestream",
-        "//icu4c/source/common:platform",
-        "//icu4c/source/common:uniset_core",
-    ],
-)
-
-cc_library(
-    name = "uparse",
-    includes = ["."],
-    hdrs = ["uparse.h"],
-    srcs = ["uparse.cpp"],
-    local_defines = [
-        "U_TOOLUTIL_IMPLEMENTATION",
-    ],
-    deps = [
-        ":filestrm",
-        "//icu4c/source/common:platform",
-        ],
-)
-
-cc_library(
-    name = "filestrm",
-    includes = ["."],
-    hdrs = ["filestrm.h"],
-    srcs = ["filestrm.cpp"],
-    local_defines = [
-        "U_TOOLUTIL_IMPLEMENTATION",
-    ],
-    deps = ["//icu4c/source/common:platform"],
-)
-
-cc_library(
-    name = "ppucd",
-    includes = ["."],
-    hdrs = ["ppucd.h"],
-    srcs = ["ppucd.cpp"],
-    local_defines = [
-        "U_TOOLUTIL_IMPLEMENTATION",
-    ],
-    deps = [
-        ":uparse",
-        "//icu4c/source/common:platform",
-    ],
-)
-
-cc_library(
-    name = "denseranges",
-    includes = ["."],
-    hdrs = ["denseranges.h"],
-    srcs = ["denseranges.cpp"],
-    local_defines = [
-        "U_TOOLUTIL_IMPLEMENTATION",
-    ],
-    deps = ["//icu4c/source/common:platform"],
-)
-
-cc_library(
-    name = "collationinfo",
-    includes = ["."],
-    hdrs = ["collationinfo.h"],
-    srcs = ["collationinfo.cpp"],
-    local_defines = [
-        "U_TOOLUTIL_IMPLEMENTATION",
-    ],
-    deps = [
-        "//icu4c/source/common:platform",
-        "//icu4c/source/i18n:headers",
-    ],
-)
diff --git a/tools/unicode/c/genprops/BUILD.bazel b/tools/unicode/c/genprops/BUILD.bazel
deleted file mode 100644
index a7c3b27..0000000
--- a/tools/unicode/c/genprops/BUILD.bazel
+++ /dev/null
@@ -1,50 +0,0 @@
-#  2021 and later: Unicode, Inc. and others.
-# License & terms of use: http://www.unicode.org/copyright.html
-
-# This Bazel build file defines a target representing the binary executable
-# `genprops`, which is used for generating headers needed for bootstrapping
-# the ICU4C build process in a way that integrates core Unicode properties data.
-
-# Defining a binary executable (done in Bazel using `cc_binary`)
-# enables the use of the output file from executing the binary as a part of
-# other Bazel targets defined using `genrule`.
-
-load("@rules_cc//cc:defs.bzl", "cc_binary", "cc_library")
-
-package(
-    default_visibility = ["//visibility:public"],
-)
-
-cc_binary(
-    name = "genprops",
-    srcs = glob([
-        "*.cpp",
-        "*.h",   # cannot have hdrs section in cc_binary
-    ]),
-    deps = [
-        "//icu4c/source/common:uhash",
-        "//icu4c/source/common:umutablecptrie",
-        "//icu4c/source/common:ucptrie",
-        "//icu4c/source/common:utrie2",
-        "//icu4c/source/common:utrie2_builder",
-        "//icu4c/source/common:bytestrie",
-        "//icu4c/source/common:bytestriebuilder",
-        "//icu4c/source/common:propsvec",
-        "//icu4c/source/common:errorcode",
-        "//icu4c/source/common:ucharstriebuilder",
-        "//icu4c/source/common:uniset",
-        "//icu4c/source/common:uvector32",
-
-        "//icu4c/source/common:platform",
-        "//icu4c/source/common:headers",
-
-        "//icu4c/source/tools/toolutil:ppucd",
-        "//icu4c/source/tools/toolutil:unewdata",
-        "//icu4c/source/tools/toolutil:writesrc",
-        "//icu4c/source/tools/toolutil:uoptions",
-        "//icu4c/source/tools/toolutil:uparse",
-        "//icu4c/source/tools/toolutil:toolutil",
-        "//icu4c/source/tools/toolutil:denseranges",
-    ],
-    linkopts = ["-pthread"],
-)
diff --git a/tools/unicode/c/genuca/BUILD.bazel b/tools/unicode/c/genuca/BUILD.bazel
deleted file mode 100644
index 7da631d..0000000
--- a/tools/unicode/c/genuca/BUILD.bazel
+++ /dev/null
@@ -1,52 +0,0 @@
-#  2021 and later: Unicode, Inc. and others.
-# License & terms of use: http://www.unicode.org/copyright.html
-
-# This Bazel build file defines a target representing the binary executable
-# `genuca`, which is used for generating ICU root collation data files.
-
-load("@rules_cc//cc:defs.bzl", "cc_binary", "cc_library")
-
-package(
-    default_visibility = ["//visibility:public"],
-)
-
-cc_binary(
-    name = "genuca",
-    srcs = glob([
-        "*.cpp",
-        "*.h",   # cannot have hdrs section in cc_binary
-    ]),
-    deps = [
-        "//icu4c/source/common:headers",
-        "//icu4c/source/common:platform",
-        "//icu4c/source/i18n:collation_builder",
-        "//icu4c/source/i18n:headers",
-        "//icu4c/source/tools/toolutil:collationinfo",
-        "//icu4c/source/tools/toolutil:toolutil",
-        "//icu4c/source/tools/toolutil:unewdata",
-        "//icu4c/source/tools/toolutil:uoptions",
-        "//icu4c/source/tools/toolutil:uparse",
-        "//icu4c/source/tools/toolutil:writesrc",
-    ],
-    # Markus 2021-06-16:
-    # The pthread library is not linked in automatically.
-    # See https://docs.bazel.build/versions/main/cpp-use-cases.html
-    # When pthread is absent, then we get runtime errors instead of compile/link errors.
-    # See https://stackoverflow.com/questions/51584960/stdcall-once-throws-stdsystem-error-unknown-error-1
-    #
-    # My first genuca build crashed with
-    #   terminate called after throwing an instance of 'std::system_error'
-    #   what():  Unknown error -1
-    #
-    #   Program received signal SIGABRT, Aborted.
-    #   ...
-    #   #4  0x00007ffff7e809d1 in std::terminate() () from /lib/x86_64-linux-gnu/libstdc++.so.6
-    #   #5  0x00007ffff7e80c65 in __cxa_throw () from /lib/x86_64-linux-gnu/libstdc++.so.6
-    #   #6  0x00007ffff7e78458 in std::__throw_system_error(int) () from /lib/x86_64-linux-gnu/libstdc++.so.6
-    #   #7  0x0000555555601c75 in std::call_once<void (&)()> (__once=..., __f=@0x55555560156c: {void (void)} 0x55555560156c <icu_70::umtx_init()>)
-    #       at /usr/include/c++/10/mutex:743
-    #   #8  0x00005555556017ca in icu_70::umtx_initImplPreInit (uio=...) at icu4c/source/common/umutex.cpp:146
-    #   #9  0x0000555555592236 in icu_70::umtx_initOnce (uio=..., fp=0x5555555e0716 <icu_70::initNFCSingleton(UErrorCode&)>,
-    #   errCode=@0x7fffffffd738: U_ZERO_ERROR) at icu4c/source/common/umutex.h:143
-    linkopts = ["-pthread"],
-)
diff --git a/vendor/double-conversion/upstream/WORKSPACE b/vendor/double-conversion/upstream/WORKSPACE
deleted file mode 100644
index 52106e7..0000000
--- a/vendor/double-conversion/upstream/WORKSPACE
+++ /dev/null
@@ -1 +0,0 @@
-# Bazel (http://bazel.io/) WORKSPACE file for double-conversion.
diff --git a/src/Makefile b/src/Makefile
index 30d64be2..ae7ec875 100644
--- a/src/Makefile
+++ b/src/Makefile
@@ -27,7 +27,7 @@ NODOTABIVER= 51
 DEFAULT_CC = gcc
 #
 # LuaJIT builds as a native 32 or 64 bit binary by default.
-CC= $(DEFAULT_CC)
+CC ?= $(DEFAULT_CC)
 #
 # Use this if you want to force a 32 bit build on a 64 bit multilib OS.
 #CC= $(DEFAULT_CC) -m32
@@ -71,10 +71,10 @@ CCWARN= -Wall
 # as dynamic mode.
 #
 # Mixed mode creates a static + dynamic library and a statically linked luajit.
-BUILDMODE= mixed
+#BUILDMODE= mixed
 #
 # Static mode creates a static library and a statically linked luajit.
-#BUILDMODE= static
+BUILDMODE= static
 #
 # Dynamic mode creates a dynamic library and a dynamically linked luajit.
 # Note: this executable will only run when the library is installed!
@@ -99,7 +99,7 @@ XCFLAGS=
 # enabled by default. Some other features that *might* break some existing
 # code (e.g. __pairs or os.execute() return values) can be enabled here.
 # Note: this does not provide full compatibility with Lua 5.2 at this time.
-#XCFLAGS+= -DLUAJIT_ENABLE_LUA52COMPAT
+XCFLAGS+= -DLUAJIT_ENABLE_LUA52COMPAT
 #
 # Disable the JIT compiler, i.e. turn LuaJIT into a pure interpreter.
 #XCFLAGS+= -DLUAJIT_DISABLE_JIT
@@ -212,7 +212,7 @@ TARGET_STCC= $(STATIC_CC)
 TARGET_DYNCC= $(DYNAMIC_CC)
 TARGET_LD= $(CROSS)$(CC)
 TARGET_AR= $(CROSS)ar rcus
-TARGET_STRIP= $(CROSS)strip
+TARGET_STRIP?= $(CROSS)strip
 
 TARGET_LIBPATH= $(or $(PREFIX),/usr/local)/$(or $(MULTILIB),lib)
 TARGET_SONAME= libluajit-$(ABIVER).so.$(MAJVER)
@@ -598,7 +598,7 @@ endif
 
 Q= @
 E= @echo
-#Q=
+Q=
 #E= @:
 
 ##############################################################################
diff --git a/src/msvcbuild.bat b/src/msvcbuild.bat
index d323d8d4..2e08a3a1 100644
--- a/src/msvcbuild.bat
+++ b/src/msvcbuild.bat
@@ -13,9 +13,7 @@
 @if not defined INCLUDE goto :FAIL
 
 @setlocal
-@rem Add more debug flags here, e.g. DEBUGCFLAGS=/DLUA_USE_APICHECK
-@set DEBUGCFLAGS=
-@set LJCOMPILE=cl /nologo /c /O2 /W3 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_STDIO_INLINE=__declspec(dllexport)__inline
+@set LJCOMPILE=cl /nologo /c /W3 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_STDIO_INLINE=__declspec(dllexport)__inline /DLUAJIT_ENABLE_LUA52COMPAT
 @set LJLINK=link /nologo
 @set LJMT=mt /nologo
 @set LJLIB=lib /nologo /nodefaultlib
@@ -24,10 +22,9 @@
 @set DASC=vm_x64.dasc
 @set LJDLLNAME=lua51.dll
 @set LJLIBNAME=lua51.lib
-@set BUILDTYPE=release
 @set ALL_LIB=lib_base.c lib_math.c lib_bit.c lib_string.c lib_table.c lib_io.c lib_os.c lib_package.c lib_debug.c lib_jit.c lib_ffi.c lib_buffer.c
 
-%LJCOMPILE% host\minilua.c
+%LJCOMPILE% /O2 host\minilua.c
 @if errorlevel 1 goto :BAD
 %LJLINK% /out:minilua.exe minilua.obj
 @if errorlevel 1 goto :BAD
@@ -51,7 +48,7 @@ if exist minilua.exe.manifest^
 minilua %DASM% -LN %DASMFLAGS% -o host\buildvm_arch.h %DASC%
 @if errorlevel 1 goto :BAD
 
-%LJCOMPILE% /I "." /I %DASMDIR% host\buildvm*.c
+%LJCOMPILE% /O2 /I "." /I %DASMDIR% host\buildvm*.c
 @if errorlevel 1 goto :BAD
 %LJLINK% /out:buildvm.exe buildvm*.obj
 @if errorlevel 1 goto :BAD
@@ -75,26 +72,35 @@ buildvm -m folddef -o lj_folddef.h lj_opt_fold.c
 
 @if "%1" neq "debug" goto :NODEBUG
 @shift
-@set BUILDTYPE=debug
-@set LJCOMPILE=%LJCOMPILE% /Zi %DEBUGCFLAGS%
-@set LJLINK=%LJLINK% /opt:ref /opt:icf /incremental:no
+@set LJCOMPILE=%LJCOMPILE% /O0 /Z7
+@set LJLINK=%LJLINK% /debug /opt:ref /opt:icf /incremental:no
+@set LJCRTDBG=d
+@goto :ENDDEBUG
 :NODEBUG
-@set LJLINK=%LJLINK% /%BUILDTYPE%
+@set LJCOMPILE=%LJCOMPILE% /O2 /Z7
+@set LJLINK=%LJLINK% /release /incremental:no
+@set LJCRTDBG=
+:ENDDEBUG
 @if "%1"=="amalg" goto :AMALGDLL
 @if "%1"=="static" goto :STATIC
-%LJCOMPILE% /MD /DLUA_BUILD_AS_DLL lj_*.c lib_*.c
+@set LJCOMPILE=%LJCOMPILE% /MD%LJCRTDBG% 
+%LJCOMPILE% /DLUA_BUILD_AS_DLL lj_*.c lib_*.c
 @if errorlevel 1 goto :BAD
 %LJLINK% /DLL /out:%LJDLLNAME% lj_*.obj lib_*.obj
 @if errorlevel 1 goto :BAD
 @goto :MTDLL
 :STATIC
+@shift
+@set LJCOMPILE=%LJCOMPILE% /MT%LJCRTDBG%
 %LJCOMPILE% lj_*.c lib_*.c
 @if errorlevel 1 goto :BAD
 %LJLIB% /OUT:%LJLIBNAME% lj_*.obj lib_*.obj
 @if errorlevel 1 goto :BAD
 @goto :MTDLL
 :AMALGDLL
-%LJCOMPILE% /MD /DLUA_BUILD_AS_DLL ljamalg.c
+@shift
+@set LJCOMPILE=%LJCOMPILE% /MD%LJCRTDBG% 
+%LJCOMPILE% /DLUA_BUILD_AS_DLL ljamalg.c
 @if errorlevel 1 goto :BAD
 %LJLINK% /DLL /out:%LJDLLNAME% ljamalg.obj lj_vm.obj
 @if errorlevel 1 goto :BAD
diff --git a/build.py b/build.py
new file mode 100755
index 00000000..1201542c
--- /dev/null
+++ b/build.py
@@ -0,0 +1,52 @@
+#!/usr/bin/env python3
+
+import argparse
+import os
+import shutil
+
+def main():
+    parser = argparse.ArgumentParser()
+    parser.add_argument("--prefix")
+    args = parser.parse_args()
+    src_dir = os.path.dirname(os.path.realpath(__file__))
+    shutil.copytree(src_dir, os.path.basename(src_dir))
+    os.chdir(os.path.basename(src_dir))
+
+    os.environ["MACOSX_DEPLOYMENT_TARGET"] = "10.8"
+    os.environ["DEFAULT_CC"] = os.environ.get("CC", "")
+    os.environ["TARGET_CFLAGS"] = os.environ.get("CFLAGS", "") + " -fno-function-sections -fno-data-sections"
+    os.environ["TARGET_LDFLAGS"] = os.environ.get("CFLAGS", "") + " -fno-function-sections -fno-data-sections"
+    os.environ["CFLAGS"] = ""
+    os.environ["LDFLAGS"] = ""
+
+    # Don't strip the binary - it doesn't work when cross-compiling, and we don't use it anyway.
+    os.environ["TARGET_STRIP"] = "@echo"
+
+    # Remove LuaJIT from ASAN for now.
+    # TODO(htuch): Remove this when https://github.com/envoyproxy/envoy/issues/6084 is resolved.
+    if "ENVOY_CONFIG_ASAN" in os.environ or "ENVOY_CONFIG_MSAN" in os.environ:
+      os.environ["TARGET_CFLAGS"] += " -fsanitize-blacklist=%s/com_github_luajit_luajit/clang-asan-blocklist.txt" % os.environ["PWD"]
+      with open("clang-asan-blocklist.txt", "w") as f:
+        f.write("fun:*\n")
+
+    os.system('"{}" -j{} V=1 PREFIX="{}" install'.format(os.environ["MAKE"], os.cpu_count(), args.prefix))
+
+def win_main():
+    src_dir = os.path.dirname(os.path.realpath(__file__))
+    dst_dir = os.getcwd() + "/luajit"
+    shutil.copytree(src_dir, os.path.basename(src_dir))
+    os.chdir(os.path.basename(src_dir) + "/src")
+    os.system('msvcbuild.bat ' + os.getenv('WINDOWS_DBG_BUILD', '') + ' static')
+    os.makedirs(dst_dir + "/lib", exist_ok=True)
+    shutil.copy("lua51.lib", dst_dir + "/lib")
+    os.makedirs(dst_dir + "/include/luajit-2.1", exist_ok=True)
+    for header in ["lauxlib.h", "luaconf.h", "lua.h", "lua.hpp", "luajit.h", "lualib.h"]:
+      shutil.copy(header, dst_dir + "/include/luajit-2.1")
+    os.makedirs(dst_dir + "/bin", exist_ok=True)
+    shutil.copy("luajit.exe", dst_dir + "/bin")
+
+if os.name == 'nt':
+  win_main()
+else:
+  main()
+
diff -u -r a/CMakeLists.txt b/CMakeLists.txt
--- a/CMakeLists.txt	2020-11-23 08:59:08.000000000 -0600
+++ b/CMakeLists.txt	2021-01-15 17:15:43.665745800 -0600
@@ -271,7 +271,11 @@
 if(SIZEOF_SSIZE_T STREQUAL "")
   # ssize_t is a signed type in POSIX storing at least -1.
   # Set it to "int" to match the behavior of AC_TYPE_SSIZE_T (autotools).
-  set(ssize_t int)
+  if(WIN32 AND CMAKE_SIZEOF_VOID_P EQUAL 8)
+    set(ssize_t ptrdiff_t)
+  else()
+    set(ssize_t int)
+  endif()
 endif()
 # AC_TYPE_UINT8_T
 # AC_TYPE_UINT16_T
# No compilation for unused binaries and libs.
diff --git a/CMakeLists.txt b/CMakeLists.txt
index 7757916..6241f45 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -477,8 +477,8 @@ else()
     set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS}")
 endif()
 
-add_subdirectory(util)
-add_subdirectory(doc/dev-reference)
+# add_subdirectory(util)
+# add_subdirectory(doc/dev-reference)
 
 if (NOT WIN32)
 # PCRE check, we have a fixed requirement for PCRE to use Chimera
@@ -496,9 +496,9 @@ if (CORRECT_PCRE_VERSION AND PCRE_BUILD_SOURCE AND BUILD_STATIC_LIBS)
     set(BUILD_CHIMERA TRUE)
 endif()
 
-add_subdirectory(unit)
+# add_subdirectory(unit)
 if (EXISTS ${CMAKE_SOURCE_DIR}/tools/CMakeLists.txt)
-    add_subdirectory(tools)
+    # add_subdirectory(tools)
 endif()
 if (EXISTS ${CMAKE_SOURCE_DIR}/chimera/CMakeLists.txt AND BUILD_CHIMERA)
     add_subdirectory(chimera)
@@ -548,9 +548,9 @@ if (CORRECT_PCRE_VERSION AND PCRE_BUILD_SOURCE AND BUILD_STATIC_LIBS)
     set(BUILD_CHIMERA TRUE)
 endif()
 
-add_subdirectory(unit)
+# add_subdirectory(unit)
 if (EXISTS ${CMAKE_SOURCE_DIR}/tools/CMakeLists.txt)
-    add_subdirectory(tools)
+    # add_subdirectory(tools)
 endif()
 if (EXISTS ${CMAKE_SOURCE_DIR}/chimera/CMakeLists.txt AND BUILD_CHIMERA)
     add_subdirectory(chimera)
@@ -1194,8 +1194,8 @@ if (NOT FAT_RUNTIME)
     if (BUILD_STATIC_LIBS)
         add_library(hs_exec OBJECT ${hs_exec_SRCS})
 
-        add_library(hs_runtime STATIC src/hs_version.c src/hs_valid_platform.c $<TARGET_OBJECTS:hs_exec>)
-        set_target_properties(hs_runtime PROPERTIES LINKER_LANGUAGE C)
+        # add_library(hs_runtime STATIC src/hs_version.c src/hs_valid_platform.c $<TARGET_OBJECTS:hs_exec>)
+        # set_target_properties(hs_runtime PROPERTIES LINKER_LANGUAGE C)
 
         add_library(hs_compile OBJECT ${hs_compile_SRCS})
 
@@ -1271,10 +1271,10 @@ else (FAT_RUNTIME)
        # hs_version.c is added explicitly to avoid some build systems that refuse to
        # create a lib without any src (I'm looking at you Xcode)
 
-       add_library(hs_runtime STATIC src/hs_version.c
-           $<TARGET_OBJECTS:hs_exec_common>
-           ${RUNTIME_LIBS})
-       set_target_properties(hs_runtime PROPERTIES LINKER_LANGUAGE C)
+       # add_library(hs_runtime STATIC src/hs_version.c
+       #     $<TARGET_OBJECTS:hs_exec_common>
+       #     ${RUNTIME_LIBS})
+       # set_target_properties(hs_runtime PROPERTIES LINKER_LANGUAGE C)
         add_library(hs_compile OBJECT ${hs_compile_SRCS})
 
        # we want the static lib for testing
@@ -1342,7 +1342,7 @@ else (FAT_RUNTIME)
 endif (NOT FAT_RUNTIME)
 
 if (NOT BUILD_SHARED_LIBS)
-    install(TARGETS hs_runtime DESTINATION ${CMAKE_INSTALL_LIBDIR})
+    # install(TARGETS hs_runtime DESTINATION ${CMAKE_INSTALL_LIBDIR})
 endif()
 
 if (BUILD_STATIC_AND_SHARED OR BUILD_SHARED_LIBS)
# Workaround for uninitialized use.
diff --git a/src/fdr/teddy_runtime_common.h b/src/fdr/teddy_runtime_common.h
index b76800e..6e587c2 100644
--- a/src/fdr/teddy_runtime_common.h
+++ b/src/fdr/teddy_runtime_common.h
@@ -362,6 +362,7 @@ m512 vectoredLoad512(m512 *p_mask, const u8 *ptr, const size_t start_offset,
             *p_mask = set_mask_m512(~k);
             return loadu512(ptr);
         }
+        val = zeroes512();
         assert(start_offset - start <= avail);
         u64a k = ones_u64a << (64 - avail + start_offset - start)
                            >> (64 - avail);
#commit 743021d6c7abba91c47e5be8035ff0497f2b78bd
#Author: Jay Satiro <raysatiro@yahoo.com>
#Date:   Tue Dec 22 15:31:03 2020 -0500
#
#    cmake: Add an option to disable libidn2
#    
#    New option USE_LIBIDN2 defaults to ON for libidn2 detection. Prior to
#    this change libidn2 detection could not be turned off in cmake builds.
#    
#    Reported-by: William A Rowe Jr
#    
#    Fixes https://github.com/curl/curl/issues/6361
#    Closes #xxxx
#
#commit e952764adbb89f37dbf227a48a55cc57c60b537d
#Author: William A Rowe Jr <wrowe@vmware.com>
#Date:   Wed Oct 7 14:32:49 2020 -0500
#
#    Correct fragile windows assumptions
#    
#    - Locking CMake to 3.16 breaks all features and corrections applied to
#      CMake 3.17 and later, including the correction of the poorly designed
#      and now abandoned Windows CRT election policy CMP0091 (see final para
#      of the policy description here:
#      https://cmake.org/cmake/help/v3.18/policy/CMP0091.html). Locking to
#      rev 3.16 from ensures a more difficult transition to CMake-current
#    
#    - Windows curl builds previously only adjusted the Release and Debug
#      builds, and combined with CMP0091 to break other flavors. Update any
#      /MD* flags with /MT* present in the base and four alternate build
#      flavors, without introducing conflicting flag values or introducing
#      a CRT election where one is not present
#    
#    - Windows clang-cl builds of curl static libs are broken when using
#      link-lld.exe because curl appended the dynamic run time flags to the
#      static library lib.exe options. While these were ignored/no-op on
#      Windows link.exe, they cause link-lld from LLVM/clang-cl compile
#      toolchain to fail to parse the library command.
#    
#    Summary exists in this bazel-specific bug report;
#    https://github.com/bazelbuild/rules_foreign_cc/issues/426
diff --git a/CMakeLists.txt b/CMakeLists.txt
index ed60f07bc..0d2088cb9 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -62,6 +62,11 @@
 
 cmake_minimum_required(VERSION 3.7...3.16 FATAL_ERROR)
 
+# Revert CMake bug triggered by curl's defined max CMake policy version, see https://gitlab.kitware.com/cmake/cmake/-/issues/21288
+if(POLICY CMP0091)
+  cmake_policy(SET CMP0091 OLD)
+endif()
+
 set(CMAKE_MODULE_PATH "${CMAKE_CURRENT_SOURCE_DIR}/CMake;${CMAKE_MODULE_PATH}")
 include(Utilities)
 include(Macros)
@@ -306,9 +311,12 @@ if(ENABLE_MANUAL)
 endif()
 
 if(CURL_STATIC_CRT)
-  set(CMAKE_MSVC_RUNTIME_LIBRARY "MultiThreaded$<$<CONFIG:Debug>:Debug>")
-  set(CMAKE_C_FLAGS_RELEASE "${CMAKE_C_FLAGS_RELEASE} /MT")
-  set(CMAKE_C_FLAGS_DEBUG "${CMAKE_C_FLAGS_DEBUG} /MTd")
+  foreach(build_suffix "" _DEBUG _RELEASE _MINSIZEREL _RELWITHDEBINFO)
+    set(flags_var CMAKE_C_FLAGS${build_suffix})
+    if("${${flags_var}}" MATCHES "/MD")
+      string(REGEX REPLACE "/MD" "/MT" ${flags_var} "${${flags_var}}")
+    endif()
+  endforeach()
 endif()
 
 # Disable warnings on Borland to avoid changing 3rd party code.
# Workaround for Envoy's CMAKE_BUILD_TYPE=Bazel.
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -247,7 +247,7 @@
 string(TOUPPER "${CMAKE_BUILD_TYPE}" uppercase_CMAKE_BUILD_TYPE)
 
 if (CMAKE_BUILD_TYPE AND
-    NOT uppercase_CMAKE_BUILD_TYPE MATCHES "^(DEBUG|RELEASE|RELWITHDEBINFO|MINSIZEREL)$")
+    NOT uppercase_CMAKE_BUILD_TYPE MATCHES "^(DEBUG|RELEASE|RELWITHDEBINFO|MINSIZEREL|BAZEL)$")
   message(FATAL_ERROR "Invalid value for CMAKE_BUILD_TYPE: ${CMAKE_BUILD_TYPE}")
 endif()
 
# Workaround for a missing -fuse-ld flag in CXXFLAGS, which results in
# different linkers being used during configure and compilation phases.
--- a/cmake/modules/HandleLLVMOptions.cmake
+++ b/cmake/modules/HandleLLVMOptions.cmake
@@ -718,8 +718,6 @@ endif()
 if (UNIX AND CMAKE_GENERATOR STREQUAL "Ninja")
   include(CheckLinkerFlag)
   check_linker_flag("-Wl,--color-diagnostics" LINKER_SUPPORTS_COLOR_DIAGNOSTICS)
-  append_if(LINKER_SUPPORTS_COLOR_DIAGNOSTICS "-Wl,--color-diagnostics"
-    CMAKE_EXE_LINKER_FLAGS CMAKE_MODULE_LINKER_FLAGS CMAKE_SHARED_LINKER_FLAGS)
 endif()
 
 # Add flags for add_dead_strip().
diff --git a/src/CMakeLists.txt b/src/CMakeLists.txt
index 33481ba1..681d0c5c 100644
--- a/src/CMakeLists.txt
+++ b/src/CMakeLists.txt
@@ -66,7 +66,6 @@ set(
     tinycthread.c
     tinycthread_extra.c
     rdxxhash.c
-    cJSON.c
 )
 
 if(WITH_SSL)
diff --git a/src/Makefile b/src/Makefile
index 26df5723..69bdb427 100644
--- a/src/Makefile
+++ b/src/Makefile
@@ -43,7 +43,7 @@ SRCS=		rdkafka.c rdkafka_broker.c rdkafka_msg.c rdkafka_topic.c \
 		rdkafka_assignor.c rdkafka_range_assignor.c \
 		rdkafka_roundrobin_assignor.c rdkafka_sticky_assignor.c \
 		rdkafka_feature.c \
-		rdcrc32.c crc32c.c rdmurmur2.c rdfnv1a.c cJSON.c \
+		rdcrc32.c crc32c.c rdmurmur2.c rdfnv1a.c \
 		rdaddr.c rdrand.c rdlist.c \
 		tinycthread.c tinycthread_extra.c \
 		rdlog.c rdstring.c rdkafka_event.c rdkafka_metadata.c \
diff --git a/src/rdkafka.c b/src/rdkafka.c
index 33147ccd..5ed33b29 100644
--- a/src/rdkafka.c
+++ b/src/rdkafka.c
@@ -71,9 +71,6 @@
 #include <sys/timeb.h>
 #endif
 
-#define CJSON_HIDE_SYMBOLS
-#include "cJSON.h"
-
 #if WITH_CURL
 #include "rdhttp.h"
 #endif
@@ -139,8 +136,6 @@ void rd_kafka_set_thread_sysname(const char *fmt, ...) {
 }
 
 static void rd_kafka_global_init0(void) {
-        cJSON_Hooks json_hooks = {.malloc_fn = rd_malloc, .free_fn = rd_free};
-
         mtx_init(&rd_kafka_global_lock, mtx_plain);
 #if ENABLE_DEVEL
         rd_atomic32_init(&rd_kafka_op_cnt, 0);
@@ -153,8 +148,6 @@ static void rd_kafka_global_init0(void) {
         rd_kafka_ssl_init();
 #endif
 
-        cJSON_InitHooks(&json_hooks);
-
 #if WITH_CURL
         rd_http_global_init();
 #endif
load("@rules_foreign_cc//foreign_cc:configure.bzl", "configure_make")
load("@rules_foreign_cc//foreign_cc:make.bzl", "make")
load("//bazel:envoy_build_system.bzl", "envoy_cc_library", "envoy_cmake", "envoy_package")

licenses(["notice"])  # Apache 2

exports_files(["icu_data_filter.json"])

envoy_package()

configure_make(
    name = "liburing",
    configure_in_place = True,
    lib_source = "@com_github_axboe_liburing//:all",
    tags = [
        "nocompdb",
        "skip_on_windows",
    ],
)

envoy_cc_library(
    name = "liburing_linux",
    srcs = [],
    deps = select({
        "//bazel:linux": [":liburing"],
        "//conditions:default": [],
    }),
)

# autotools packages are unusable on Windows as-is
# TODO: Consider our own gperftools.BUILD file as we do with many other packages
configure_make(
    name = "gperftools_build",
    configure_options = [
        "--enable-shared=no",
        "--enable-frame-pointers",
        "--disable-libunwind",
    ] + select({
        "//bazel:apple": ["AR=/usr/bin/ar"],
        "//conditions:default": [],
    }),
    lib_source = "@com_github_gperftools_gperftools//:all",
    linkopts = ["-lpthread"],
    out_static_libs = select({
        "//bazel:debug_tcmalloc": ["libtcmalloc_debug.a"],
        "//conditions:default": ["libtcmalloc_and_profiler.a"],
    }),
    tags = ["skip_on_windows"],
    targets = [
        "install-libLTLIBRARIES install-perftoolsincludeHEADERS",
    ],
)

# Workaround for https://github.com/bazelbuild/rules_foreign_cc/issues/227
cc_library(
    name = "gperftools",
    tags = ["skip_on_windows"],
    deps = [
        "gperftools_build",
    ],
)

make(
    name = "lz4",
    args = [
        "MOREFLAGS='-fPIC'",
        "BUILD_SHARED=no",
    ],
    lib_source = "@com_github_lz4_lz4//:all",
    out_static_libs = [
        "liblz4.a",
    ],
    tags = ["skip_on_windows"],
    targets = [
        "lib",
        "install",
    ],
    visibility = ["//visibility:public"],
    alwayslink = False,
)

# Kafka client dependency used by Kafka-mesh filter.
# librdkafka build generates extra headers that need to be copied into source to get it to compile.
configure_make(
    name = "librdkafka_build",
    configure_in_place = True,
    configure_options = ["--disable-ssl --disable-gssapi --disable-zstd --disable-curl && cp Makefile.config src/.. && cp config.h src/.."],
    lib_source = "@confluentinc_librdkafka//:all",
    out_static_libs = [
        "librdkafka.a",
        "librdkafka++.a",
    ],
    tags = ["skip_on_windows"],
    targets = [
        "ARFLAGS='' libs install-subdirs",
    ],
    deps = [":lz4"],
    alwayslink = True,
)

cc_library(
    name = "librdkafka",
    tags = ["skip_on_windows"],
    deps = [
        "librdkafka_build",
    ],
)

configure_make(
    name = "luajit",
    configure_command = "build.py",
    env = select({
        # This shouldn't be needed! See
        # https://github.com/envoyproxy/envoy/issues/6084
        # TODO(htuch): Remove when #6084 is fixed
        "//bazel:asan_build": {"ENVOY_CONFIG_ASAN": "1"},
        "//bazel:msan_build": {"ENVOY_CONFIG_MSAN": "1"},
        "//bazel:windows_dbg_build": {"WINDOWS_DBG_BUILD": "debug"},
        "//conditions:default": {},
    }),
    lib_source = "@com_github_luajit_luajit//:all",
    out_include_dir = "include/luajit-2.1",
    out_static_libs = select({
        "//bazel:windows_x86_64": ["lua51.lib"],
        "//conditions:default": ["libluajit-5.1.a"],
    }),
    targets = [],
)

configure_make(
    name = "colm",
    autogen = True,
    configure_in_place = True,
    configure_options = [
        "AUTOMAKE=automake",
        "ACLOCAL=aclocal",
        "--disable-shared",
        "--enable-static",
    ],
    # Workaround for the issue with statically linked libstdc++
    # using -l:libstdc++.a.
    env = {
        "CXXFLAGS": "--static -lstdc++ -Wno-unused-command-line-argument",
    },
    lib_source = "@net_colm_open_source_colm//:all",
    out_binaries = ["colm"],
    tags = ["skip_on_windows"],
)

configure_make(
    name = "ragel",
    autogen = True,
    configure_in_place = True,
    configure_options = [
        "AUTOMAKE=automake",
        "ACLOCAL=aclocal",
        "--disable-manual",
        "--disable-shared",
        "--enable-static",
        "--with-colm=$EXT_BUILD_DEPS/colm",
    ],
    # Workaround for the issue with statically linked libstdc++
    # using -l:libstdc++.a.
    env = {
        "CXXFLAGS": "--static -lstdc++ -Wno-unused-command-line-argument",
    },
    lib_source = "@net_colm_open_source_ragel//:all",
    out_binaries = ["ragel"],
    tags = ["skip_on_windows"],
    deps = [":colm"],
)

# ICU used by the language detection filter (i18n).
# Generates a minimal configuration and reduces the size of the ICU locale data filter file.
# https://unicode-org.github.io/icu/userguide/icu_data/buildtool.html
configure_make(
    name = "unicode_icu_build",
    build_data = ["//bazel/foreign_cc:icu_data_filter.json"],
    configure_command = "icu4c/source/configure",
    configure_options = [
        "--enable-option-checking",
        "--enable-static",
        "--enable-tools",
        "--disable-draft",
        "--disable-dyload",
        "--disable-extras",
        "--disable-icuio",
        "--disable-plugins",
        "--disable-samples",
        "--disable-shared",
        "--disable-tests",
        "--with-data-packaging=static",
    ],
    data = ["@com_github_unicode_org_icu//:all"],
    env = {
        "CXXFLAGS": "-fPIC -DU_CHARSET_IS_UTF8=1 -DU_USING_ICU_NAMESPACE=0 -DUCONFIG_ONLY_HTML_CONVERSION=1 -DUCONFIG_NO_LEGACY_CONVERSION=1 -DUCONFIG_NO_BREAK_ITERATION=1 -DUCONFIG_NO_COLLATION=1 -DUCONFIG_NO_FORMATTING=1 -DUCONFIG_NO_TRANSLITERATION=1 -DUCONFIG_NO_REGULAR_EXPRESSIONS=1",
        "CFLAGS": "-fPIC",
        "ICU_DATA_FILTER_FILE": "$(execpath //bazel/foreign_cc:icu_data_filter.json)",
    },
    lib_source = "@com_github_unicode_org_icu//:all",
    out_static_libs = [
        "libicuuc.a",
        "libicudata.a",
    ],
    tags = ["skip_on_windows"],
    alwayslink = True,
)

cc_library(
    name = "unicode_icu",
    tags = ["skip_on_windows"],
    # Can not be used for the core dataplane due to security concerns
    visibility = ["//contrib/language/filters/http/source:__pkg__"],
    deps = ["unicode_icu_build"],
)

envoy_cmake(
    name = "libsxg",
    cache_entries = {
        "CMAKE_BUILD_TYPE": "Release",
        "SXG_BUILD_EXECUTABLES": "off",
        "SXG_BUILD_SHARED": "off",
        "SXG_BUILD_STATIC": "on",
        "SXG_WITH_CERT_CHAIN": "off",
        "RUN_TEST": "off",
        "CMAKE_INSTALL_LIBDIR": "lib",
    },
    lib_source = "@com_github_google_libsxg//:all",
    out_static_libs = ["libsxg.a"],
    tags = ["skip_on_windows"],
    # Use boringssl alias to select fips vs non-fips version.
    deps = ["//bazel:boringssl"],
)

envoy_cmake(
    name = "ares",
    cache_entries = {
        "CARES_BUILD_TOOLS": "no",
        "CARES_SHARED": "no",
        "CARES_STATIC": "on",
        "CMAKE_CXX_COMPILER_FORCED": "on",
        "CMAKE_INSTALL_LIBDIR": "lib",
    },
    defines = ["CARES_STATICLIB"],
    lib_source = "@com_github_c_ares_c_ares//:all",
    linkopts = select({
        "//bazel:apple": ["-lresolv"],
        "//conditions:default": [],
    }),
    out_static_libs = select({
        "//bazel:windows_x86_64": ["cares.lib"],
        "//conditions:default": ["libcares.a"],
    }),
    postfix_script = select({
        "//bazel:windows_x86_64": "cp -L $EXT_BUILD_ROOT/external/com_github_c_ares_c_ares/src/lib/ares_nameser.h $INSTALLDIR/include/ares_nameser.h && cp -L $EXT_BUILD_ROOT/external/com_github_c_ares_c_ares/include/ares_dns.h $INSTALLDIR/include/ares_dns.h",
        "//conditions:default": "rm -f $INSTALLDIR/include/ares_dns.h && cp -L $EXT_BUILD_ROOT/external/com_github_c_ares_c_ares/include/ares_dns.h $INSTALLDIR/include/ares_dns.h",
    }),
)

envoy_cmake(
    name = "curl",
    cache_entries = {
        "BUILD_CURL_EXE": "off",
        "BUILD_TESTING": "off",
        "BUILD_SHARED_LIBS": "off",
        "CURL_HIDDEN_SYMBOLS": "off",
        "CURL_USE_LIBSSH2": "off",
        "CURL_USE_LIBPSL": "off",
        "CURL_BROTLI": "off",
        "CURL_USE_GSSAPI": "off",
        "HTTP_ONLY": "on",
        "CMAKE_INSTALL_LIBDIR": "lib",
        # Explicitly enable Unix sockets, once afunix.h is correctly detected
        # "USE_UNIX_SOCKETS": "on",
        # Explicitly disable "Windows" crypto for Windows
        "CURL_DISABLE_CRYPTO_AUTH": "on",
        # C-Ares.
        "ENABLE_ARES": "on",
        "CARES_LIBRARY": "$EXT_BUILD_DEPS/ares",
        "CARES_INCLUDE_DIR": "$EXT_BUILD_DEPS/ares/include",
        # SSL (via Envoy's SSL dependency) is disabled, curl's CMake uses
        # FindOpenSSL.cmake which fails at what looks like version parsing
        # (the libraries are found ok).
        "CURL_CA_PATH": "none",
        "CURL_USE_OPENSSL": "off",
        "OPENSSL_ROOT_DIR": "$EXT_BUILD_DEPS",
        # Avoid libidn2
        "USE_LIBIDN2": "off",
        # NGHTTP2.
        "USE_NGHTTP2": "on",
        "NGHTTP2_LIBRARY": "$EXT_BUILD_DEPS/nghttp2",
        "NGHTTP2_INCLUDE_DIR": "$EXT_BUILD_DEPS/nghttp2/include",
        # ZLIB.
        "CURL_ZLIB": "on",
        "ZLIB_LIBRARY": "$EXT_BUILD_DEPS/zlib",
        "ZLIB_INCLUDE_DIR": "$EXT_BUILD_DEPS/zlib/include",
        "CMAKE_CXX_COMPILER_FORCED": "on",
    },
    defines = ["CURL_STATICLIB"],
    generate_crosstool_file = True,
    lib_source = "@com_github_curl//:all",
    out_static_libs = select({
        "//bazel:windows_x86_64": ["libcurl.lib"],
        "//conditions:default": ["libcurl.a"],
    }),
    deps = [
        ":ares",
        ":nghttp2",
        "//external:ssl",
        "//external:zlib",
    ],
)

envoy_cmake(
    name = "event",
    cache_entries = {
        "EVENT__DISABLE_OPENSSL": "on",
        "EVENT__DISABLE_MBEDTLS": "on",
        "EVENT__DISABLE_REGRESS": "on",
        "EVENT__DISABLE_TESTS": "on",
        "EVENT__LIBRARY_TYPE": "STATIC",
        # Force _GNU_SOURCE on for Android builds. This would be contained in
        # a 'select' but the downstream macro uses a select on all of these
        # options, and they cannot be nested.
        # If https://github.com/bazelbuild/rules_foreign_cc/issues/289 is fixed
        # this can be removed.
        # More details https://github.com/envoyproxy/envoy-mobile/issues/116
        "_GNU_SOURCE": "on",
    },
    lib_source = "@com_github_libevent_libevent//:all",
    out_static_libs = select({
        # macOS organization of libevent is different from Windows/Linux.
        # Including libevent_core is a requirement on those platforms, but
        # results in duplicate symbols when built on macOS.
        # See https://github.com/envoyproxy/envoy-mobile/issues/677 for details.
        "//bazel:apple": [
            "libevent.a",
            "libevent_pthreads.a",
        ],
        "//bazel:windows_x86_64": [
            "event.lib",
            "event_core.lib",
        ],
        "//conditions:default": [
            "libevent.a",
            "libevent_pthreads.a",
            "libevent_core.a",
        ],
    }),
)

envoy_cmake(
    name = "llvm",
    cache_entries = {
        # Disable both: BUILD and INCLUDE, since some of the INCLUDE
        # targets build code instead of only generating build files.
        "LLVM_BUILD_BENCHMARKS": "off",
        "LLVM_INCLUDE_BENCHMARKS": "off",
        "LLVM_BUILD_DOCS": "off",
        "LLVM_INCLUDE_DOCS": "off",
        "LLVM_BUILD_EXAMPLES": "off",
        "LLVM_INCLUDE_EXAMPLES": "off",
        "LLVM_BUILD_RUNTIME": "off",
        "LLVM_BUILD_RUNTIMES": "off",
        "LLVM_INCLUDE_RUNTIMES": "off",
        "LLVM_BUILD_TESTS": "off",
        "LLVM_INCLUDE_TESTS": "off",
        "LLVM_BUILD_TOOLS": "off",
        "LLVM_INCLUDE_TOOLS": "off",
        "LLVM_BUILD_UTILS": "off",
        "LLVM_INCLUDE_UTILS": "off",
        "LLVM_ENABLE_IDE": "off",
        "LLVM_ENABLE_LIBEDIT": "off",
        "LLVM_ENABLE_LIBXML2": "off",
        "LLVM_ENABLE_TERMINFO": "off",
        "LLVM_ENABLE_ZLIB": "off",
        "LLVM_TARGETS_TO_BUILD": "X86",
        "CMAKE_CXX_COMPILER_FORCED": "on",
        # Workaround for the issue with statically linked libstdc++
        # using -l:libstdc++.a.
        "CMAKE_CXX_FLAGS": "-lstdc++",
    },
    env = {
        # Workaround for the -DDEBUG flag added in fastbuild on macOS,
        # which conflicts with DEBUG macro used in LLVM.
        "CFLAGS": "-UDEBUG",
        "CXXFLAGS": "-UDEBUG",
        "ASMFLAGS": "-UDEBUG",
    },
    lib_source = "@org_llvm_llvm//:all",
    out_static_libs = select({
        "//conditions:default": [
            # This list must be updated when the bazel llvm version is updated
            # (in `bazel/repository_locations.bzl`)
            #
            # The list can be regenerated by compiling the correct/updated llvm version
            # from sources and running:
            #
            #  `llvm-config --libnames`
            #
            "libLLVMWindowsManifest.a",
            "libLLVMXRay.a",
            "libLLVMLibDriver.a",
            "libLLVMDlltoolDriver.a",
            "libLLVMCoverage.a",
            "libLLVMLineEditor.a",
            "libLLVMX86Disassembler.a",
            "libLLVMX86AsmParser.a",
            "libLLVMX86CodeGen.a",
            "libLLVMX86Desc.a",
            "libLLVMX86Info.a",
            "libLLVMOrcJIT.a",
            "libLLVMMCJIT.a",
            "libLLVMJITLink.a",
            "libLLVMOrcTargetProcess.a",
            "libLLVMOrcShared.a",
            "libLLVMInterpreter.a",
            "libLLVMExecutionEngine.a",
            "libLLVMRuntimeDyld.a",
            "libLLVMSymbolize.a",
            "libLLVMDebugInfoPDB.a",
            "libLLVMDebugInfoGSYM.a",
            "libLLVMOption.a",
            "libLLVMObjectYAML.a",
            "libLLVMMCA.a",
            "libLLVMMCDisassembler.a",
            "libLLVMLTO.a",
            "libLLVMPasses.a",
            "libLLVMCFGuard.a",
            "libLLVMCoroutines.a",
            "libLLVMObjCARCOpts.a",
            "libLLVMHelloNew.a",
            "libLLVMipo.a",
            "libLLVMVectorize.a",
            "libLLVMLinker.a",
            "libLLVMInstrumentation.a",
            "libLLVMFrontendOpenMP.a",
            "libLLVMFrontendOpenACC.a",
            "libLLVMExtensions.a",
            "libLLVMDWARFLinker.a",
            "libLLVMGlobalISel.a",
            "libLLVMMIRParser.a",
            "libLLVMAsmPrinter.a",
            "libLLVMDebugInfoDWARF.a",
            "libLLVMSelectionDAG.a",
            "libLLVMCodeGen.a",
            "libLLVMIRReader.a",
            "libLLVMAsmParser.a",
            "libLLVMInterfaceStub.a",
            "libLLVMFileCheck.a",
            "libLLVMFuzzMutate.a",
            "libLLVMTarget.a",
            "libLLVMScalarOpts.a",
            "libLLVMInstCombine.a",
            "libLLVMAggressiveInstCombine.a",
            "libLLVMTransformUtils.a",
            "libLLVMBitWriter.a",
            "libLLVMAnalysis.a",
            "libLLVMProfileData.a",
            "libLLVMObject.a",
            "libLLVMTextAPI.a",
            "libLLVMMCParser.a",
            "libLLVMMC.a",
            "libLLVMDebugInfoCodeView.a",
            "libLLVMDebugInfoMSF.a",
            "libLLVMBitReader.a",
            "libLLVMCore.a",
            "libLLVMRemarks.a",
            "libLLVMBitstreamReader.a",
            "libLLVMBinaryFormat.a",
            "libLLVMSupport.a",
            "libLLVMDemangle.a",
        ],
    }),
    tags = ["skip_on_windows"],
    alwayslink = True,
)

envoy_cmake(
    name = "nghttp2",
    cache_entries = {
        "ENABLE_LIB_ONLY": "on",
        "ENABLE_SHARED_LIB": "off",
        "ENABLE_STATIC_LIB": "on",
        "CMAKE_INSTALL_LIBDIR": "lib",
        "CMAKE_CXX_COMPILER_FORCED": "on",
    },
    cmake_files_dir = "$BUILD_TMPDIR/lib/CMakeFiles",
    debug_cache_entries = {"ENABLE_DEBUG": "on"},
    defines = ["NGHTTP2_STATICLIB"],
    lib_source = "@com_github_nghttp2_nghttp2//:all",
    out_static_libs = select({
        "//bazel:windows_x86_64": ["nghttp2.lib"],
        "//conditions:default": ["libnghttp2.a"],
    }),
)

envoy_cmake(
    name = "wamr",
    cache_entries = {
        "WAMR_BUILD_AOT": "0",
        "WAMR_BUILD_FAST_INTERP": "1",
        "WAMR_BUILD_INTERP": "1",
        "WAMR_BUILD_JIT": "0",
        "WAMR_BUILD_LIBC_WASI": "0",
        "WAMR_BUILD_MULTI_MODULE": "0",
        "WAMR_BUILD_SIMD": "0",
        "WAMR_BUILD_TAIL_CALL": "1",
        "WAMR_BUILD_WASM_CACHE": "0",
        "WAMR_DISABLE_HW_BOUND_CHECK": "0",
        "WAMR_DISABLE_STACK_HW_BOUND_CHECK": "1",
    },
    lib_source = "@com_github_wamr//:all",
    out_static_libs = ["libvmlib.a"],
    tags = ["skip_on_windows"],
)

envoy_cmake(
    name = "wavm",
    cache_entries = {
        "LLVM_DIR": "$EXT_BUILD_DEPS/copy_llvm/llvm/lib/cmake/llvm",
        "WAVM_ENABLE_STATIC_LINKING": "on",
        "WAVM_ENABLE_RELEASE_ASSERTS": "on",
        "WAVM_ENABLE_UNWIND": "on",
        # Workaround for the issue with statically linked libstdc++
        # using -l:libstdc++.a.
        "CMAKE_CXX_FLAGS": "-lstdc++ -Wno-unused-command-line-argument",
    },
    env = {
        # Workaround for the -DDEBUG flag added in fastbuild on macOS,
        # which conflicts with DEBUG macro used in LLVM.
        "CFLAGS": "-UDEBUG",
        "CXXFLAGS": "-UDEBUG -Wno-error=unused-but-set-variable",
        "ASMFLAGS": "-UDEBUG",
    },
    lib_source = "@com_github_wavm_wavm//:all",
    out_binaries = ["wavm"],
    out_static_libs = select({
        "//conditions:default": [
            "libWAVM.a",
            "libWAVMUnwind.a",
        ],
    }),
    tags = ["skip_on_windows"],
    deps = [":llvm"],
)

envoy_cmake(
    name = "zlib",
    cache_entries = {
        "CMAKE_CXX_COMPILER_FORCED": "on",
        "CMAKE_C_COMPILER_FORCED": "on",
        "SKIP_BUILD_EXAMPLES": "on",
        "BUILD_SHARED_LIBS": "off",

        # The following entries are for zlib-ng. Since zlib and zlib-ng are compatible source
        # codes and CMake ignores unknown cache entries, it is fine to combine it into one
        # dictionary.
        #
        # Reference: https://github.com/zlib-ng/zlib-ng#build-options.
        "ZLIB_COMPAT": "on",
        "ZLIB_ENABLE_TESTS": "off",

        # Warning: Turning WITH_OPTIM to "on" doesn't pass ZlibCompressorImplTest.CallingChecksum.
        "WITH_OPTIM": "on",
        # However turning off SSE4 fixes it.
        "WITH_SSE4": "off",

        # Warning: Turning WITH_NEW_STRATEGIES to "on" doesn't pass gzip compressor fuzz test.
        # Turning this off means falling into NO_QUICK_STRATEGY route.
        "WITH_NEW_STRATEGIES": "off",

        # Only allow aligned address.
        # Reference: https://github.com/zlib-ng/zlib-ng#advanced-build-options.
        "UNALIGNED_OK": "off",
    },
    lib_source = select({
        "//bazel:zlib_ng": "@com_github_zlib_ng_zlib_ng//:all",
        "//conditions:default": "@net_zlib//:all",
    }),
    out_static_libs = select({
        "//bazel:windows_x86_64": ["zlib.lib"],
        "//conditions:default": ["libz.a"],
    }),
)

envoy_cmake(
    name = "zstd",
    build_data = ["@com_github_facebook_zstd//:all"],
    cache_entries = {
        "CMAKE_BUILD_TYPE": "Release",
        "CMAKE_INSTALL_LIBDIR": "lib",
        "ZSTD_BUILD_SHARED": "off",
        "ZSTD_BUILD_STATIC": "on",
    },
    lib_source = "@com_github_facebook_zstd//:all",
    out_static_libs = select({
        "//bazel:windows_x86_64": ["zstd_static.lib"],
        "//conditions:default": ["libzstd.a"],
    }),
    working_directory = "build/cmake",
)

envoy_cmake(
    name = "maxmind",
    cache_entries = {
        "CMAKE_BUILD_TYPE": "Release",
        "CMAKE_INSTALL_LIBDIR": "lib",
        "CMAKE_CXX_COMPILER_FORCED": "on",
        "BUILD_SHARED_LIBS": "off",
        "BUILD_TESTING": "off",
    },
    defines = ["MAXMIND_STATICLIB"],
    lib_source = "@com_github_maxmind_libmaxminddb//:all",
    out_static_libs = ["libmaxminddb.a"],
    tags = ["skip_on_windows"],
)

envoy_cc_library(
    name = "maxmind_linux_darwin",
    srcs = [],
    deps = select({
        "//bazel:linux": [":maxmind"],
        "//bazel:darwin_any": [":maxmind"],
        "//conditions:default": [],
    }),
)
diff --git a/sources/ippcp/crypto_mb/src/common/ifma_cvt52.c b/sources/ippcp/crypto_mb/src/common/ifma_cvt52.c
index 1099518..7526fdc 100644
--- a/sources/ippcp/crypto_mb/src/common/ifma_cvt52.c
+++ b/sources/ippcp/crypto_mb/src/common/ifma_cvt52.c
@@ -168,12 +168,6 @@ __INLINE void transform_8sb_to_mb8(U64 out_mb8[], int bitLen, int8u *inp[8], int
    }
 }

-#ifdef OPENSSL_IS_BORINGSSL
-static int BN_bn2lebinpad(const BIGNUM *a, unsigned char *to, int tolen) {
-    return BN_bn2le_padded(to, tolen, a);
-}
-#endif
-
 #ifndef BN_OPENSSL_DISABLE
 // Convert BIGNUM into MB8(Radix=2^52) format
 // Returns bitmask of succesfully converted values
def _default_envoy_dev_impl(ctxt):
    if "LLVM_CONFIG" in ctxt.os.environ:
        ctxt.file("WORKSPACE", "")
        ctxt.file("BUILD.bazel", "")
        ctxt.symlink(ctxt.path(ctxt.attr.envoy_root).dirname.get_child("tools").get_child("clang_tools"), "clang_tools")

_default_envoy_dev = repository_rule(
    implementation = _default_envoy_dev_impl,
    attrs = {
        "envoy_root": attr.label(default = "@envoy//:BUILD"),
    },
)

def _clang_tools_impl(ctxt):
    if "LLVM_CONFIG" in ctxt.os.environ:
        llvm_config_path = ctxt.os.environ["LLVM_CONFIG"]
        exec_result = ctxt.execute([llvm_config_path, "--includedir"])
        if exec_result.return_code != 0:
            fail(llvm_config_path + " --includedir returned %d" % exec_result.return_code)
        clang_tools_include_path = exec_result.stdout.rstrip()
        exec_result = ctxt.execute([llvm_config_path, "--libdir"])
        if exec_result.return_code != 0:
            fail(llvm_config_path + " --libdir returned %d" % exec_result.return_code)
        clang_tools_lib_path = exec_result.stdout.rstrip()
        for include_dir in ["clang", "clang-c", "llvm", "llvm-c"]:
            ctxt.symlink(clang_tools_include_path + "/" + include_dir, include_dir)
        ctxt.symlink(clang_tools_lib_path, "lib")
        ctxt.symlink(Label("@envoy_dev//clang_tools/support:BUILD.prebuilt"), "BUILD")

_clang_tools = repository_rule(
    implementation = _clang_tools_impl,
    environ = ["LLVM_CONFIG"],
)

def envoy_dev_binding():
    # Treat the Envoy developer tools that require llvm as an external repo, this avoids
    # breaking bazel build //... when llvm is not installed.
    if "envoy_dev" not in native.existing_rules().keys():
        _default_envoy_dev(name = "envoy_dev")
        _clang_tools(name = "clang_tools")
--- a/templates/cc/register.go	2023-06-22 14:25:05.776175085 +0000
+++ b/templates/cc/register.go	2023-06-22 14:26:33.008090583 +0000
@@ -116,6 +116,10 @@
 func (fns CCFuncs) methodName(name interface{}) string {
 	nameStr := fmt.Sprintf("%s", name)
 	switch nameStr {
+	case "concept":
+		return "concept_"
+	case "requires":
+		return "requires_"
 	case "const":
 		return "const_"
 	case "inline":
# 1. Use already imported python dependencies
# 2. Disable pointer compression (limits the maximum number of WasmVMs).
# 3. Add support for --define=no_debug_info=1. 
# 4. Allow compiling v8 on macOS 10.15 to 13.0. TODO(dio): Will remove this patch when https://bugs.chromium.org/p/v8/issues/detail?id=13428 is fixed.
# 5. Don't expose Wasm C API (only Wasm C++ API).

diff --git a/BUILD.bazel b/BUILD.bazel
index 4e89f90e7e..ced403d5aa 100644
--- a/BUILD.bazel
+++ b/BUILD.bazel
@@ -4,7 +4,7 @@
 
 load("@bazel_skylib//lib:selects.bzl", "selects")
 load("@rules_python//python:defs.bzl", "py_binary")
-load("@v8_python_deps//:requirements.bzl", "requirement")
+load("@base_pip3//:requirements.bzl", "requirement")
 load(
     "@v8//:bazel/defs.bzl",
     "v8_binary",
diff --git a/BUILD.bazel b/BUILD.bazel
index 4e89f90e7e..3fcb38b3f3 100644
--- a/BUILD.bazel
+++ b/BUILD.bazel
@@ -157,7 +157,7 @@ v8_int(
 # If no explicit value for v8_enable_pointer_compression, we set it to 'none'.
 v8_string(
     name = "v8_enable_pointer_compression",
-    default = "none",
+    default = "False",
 )
 
 # Default setting for v8_enable_pointer_compression.
diff --git a/bazel/defs.bzl b/bazel/defs.bzl
index e957c0fad3..a6de50e6ab 100644
--- a/bazel/defs.bzl
+++ b/bazel/defs.bzl
@@ -116,6 +116,7 @@ def _default_args():
         }) + select({
             "@v8//bazel/config:is_clang": [
                 "-Wno-invalid-offsetof",
+                "-Wno-unneeded-internal-declaration",
                 "-std=c++17",
             ],
             "@v8//bazel/config:is_gcc": [
@@ -131,6 +132,7 @@ def _default_args():
                 "-Wno-redundant-move",
                 "-Wno-return-type",
                 "-Wno-stringop-overflow",
+                "-Wno-nonnull",
                 # Use GNU dialect, because GCC doesn't allow using
                 # ##__VA_ARGS__ when in standards-conforming mode.
                 "-std=gnu++17",
@@ -151,6 +153,23 @@ def _default_args():
                 "-fno-integrated-as",
             ],
             "//conditions:default": [],
+        }) + select({
+            "@envoy//bazel:no_debug_info": [
+                "-g0",
+            ],
+            "//conditions:default": [],
+        }) + select({
+            "@v8//bazel/config:is_macos": [
+                # The clang available on macOS catalina has a warning that isn't clean on v8 code.
+                "-Wno-range-loop-analysis",
+
+                # To supress warning on deprecated declaration on v8 code. For example:
+                # external/v8/src/base/platform/platform-darwin.cc:56:22: 'getsectdatafromheader_64'
+                # is deprecated: first deprecated in macOS 13.0.
+                # https://bugs.chromium.org/p/v8/issues/detail?id=13428.
+                "-Wno-deprecated-declarations",
+            ],
+            "//conditions:default": [],
         }),
         includes = ["include"],
         linkopts = select({
diff --git a/src/wasm/c-api.cc b/src/wasm/c-api.cc
index ce3f569fd5..dc8a4c4f6a 100644
--- a/src/wasm/c-api.cc
+++ b/src/wasm/c-api.cc
@@ -2238,6 +2238,8 @@ auto Instance::exports() const -> ownvec<Extern> {
 
 }  // namespace wasm
 
+#if 0
+
 // BEGIN FILE wasm-c.cc
 
 extern "C" {
@@ -3257,3 +3259,5 @@ wasm_instance_t* wasm_frame_instance(const wasm_frame_t* frame) {
 #undef WASM_DEFINE_SHARABLE_REF
 
 }  // extern "C"
+
+#endif
diff --git a/third_party/inspector_protocol/code_generator.py b/third_party/inspector_protocol/code_generator.py
index c3768b8..d4a1dda 100644
--- a/third_party/inspector_protocol/code_generator.py
+++ b/third_party/inspector_protocol/code_generator.py
@@ -16,6 +16,8 @@ try:
 except ImportError:
   import simplejson as json

+sys.path += [os.path.dirname(__file__)]
+
 import pdl

 try:
#!/usr/bin/env bash

# Bazel expects the helper to read stdin.
# See https://github.com/bazelbuild/bazel/pull/17666
cat /dev/stdin > /dev/null

# `GITHUB_TOKEN` is provided as a secret.
echo "{\"headers\":{\"Authorization\":[\"Bearer ${GITHUB_TOKEN}\"]}}"
diff --git a/mocktracer/BUILD b/mocktracer/BUILD
index 3b22bab..d425e2e 100644
--- a/mocktracer/BUILD
+++ b/mocktracer/BUILD
@@ -7,11 +7,13 @@ cc_library(
     deps = [
         "//:opentracing",
     ],
+    alwayslink = 1,
 )

 cc_binary(
     name = "libmocktracer_plugin.so",
     linkshared = 1,
+    linkstatic = 1,
     visibility = ["//visibility:public"],
     deps = [
         "//mocktracer:mocktracer"
diff --git a/src/dynamic_load_unix.cpp b/src/dynamic_load_unix.cpp
index 17e08fd..7e8ac02 100644
--- a/src/dynamic_load_unix.cpp
+++ b/src/dynamic_load_unix.cpp
@@ -35,7 +35,13 @@ DynamicallyLoadTracingLibrary(const char* shared_library,
                               std::string& error_message) noexcept try {
   dlerror();  // Clear any existing error.

-  const auto handle = dlopen(shared_library, RTLD_NOW | RTLD_LOCAL);
+  const auto handle = dlopen(shared_library, RTLD_NOW | RTLD_LOCAL
+#if defined(__has_feature)
+#if __has_feature(address_sanitizer)
+      | RTLD_NODELETE
+#endif
+#endif
+  );
   if (handle == nullptr) {
     error_message = dlerror();
     return make_unexpected(dynamic_load_failure_error);
# commit 3a6f049c123a1906c7381e824292c18fd8698293
# Author: Christian Neumller <cn00@gmx.at>
# Date:   Wed Feb 27 01:48:17 2019 +0100
#
# Fix MSVC compiler flags. (#104)
# 
#    * All debug specific flags would be replaced by release specific on MSVC.
#    * The OPENTRACING_STATIC flag would be missing from OpenTracingConfig.cmake when linking against OpenTracing::opentracing-static
#
diff --git a/CMakeLists.txt b/CMakeLists.txt
index 1721fb3..3873b3a 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -52,7 +52,7 @@ if ("${CMAKE_CXX_COMPILER_ID}" MATCHES "Clang")
 elseif ("${CMAKE_CXX_COMPILER_ID}" STREQUAL "GNU")
   set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -Wall -Wextra")
 elseif ("${CMAKE_CXX_COMPILER_ID}" STREQUAL "MSVC")
-  set(CMAKE_CXX_FLAGS_DEBUG "${CMAKE_CXX_FLAGS_RELEASE} -D_SCL_SECURE_NO_WARNINGS")
+  set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -D_SCL_SECURE_NO_WARNINGS")
 endif()
 
 # ==============================================================================
diff --git a/include/opentracing/config.h b/include/opentracing/config.h
new file mode 100755
index 0000000..cae3e61
--- /dev/null
+++ b/include/opentracing/config.h
@@ -0,0 +1,3 @@
+#pragma once
+
+#define OPENTRACING_BUILD_DYNAMIC_LOADING
diff --git a/include/opentracing/version.h b/include/opentracing/version.h
new file mode 100755
index 0000000..25b9945
--- /dev/null
+++ b/include/opentracing/version.h
@@ -0,0 +1,14 @@
+#ifndef OPENTRACING_VERSION_H
+#define OPENTRACING_VERSION_H
+
+#define OPENTRACING_VERSION "1.5.1"
+#define OPENTRACING_ABI_VERSION "2"
+
+// clang-format off
+#define BEGIN_OPENTRACING_ABI_NAMESPACE \
+  inline namespace v2 {
+#define END_OPENTRACING_ABI_NAMESPACE \
+  }  // namespace v2
+// clang-format on
+
+#endif // OPENTRACING_VERSION_H
diff --git a/BUILD.bazel b/BUILD.bazel
index c57dc9f..587bf0e 100644
--- a/BUILD.bazel
+++ b/BUILD.bazel
@@ -1,10 +1,7 @@
 cc_library(
     name = "opentracing",
     srcs = glob(["src/**/*.cpp"], exclude=["src/dynamic_load_unsupported.cpp", "src/dynamic_load_windows.cpp"]),
-    hdrs = glob(["include/opentracing/**/*.h"]) + [
-        ":include/opentracing/config.h",
-        ":include/opentracing/version.h",
-    ],
+    hdrs = glob(["include/opentracing/**/*.h"]),
     strip_include_prefix = "include",
     visibility = ["//visibility:public"],
     deps = [
@@ -15,27 +12,3 @@ cc_library(
       "-ldl",
     ],
 )
-
-genrule(
-    name = "generate_version_h",
-    srcs = glob([
-        "*",
-        "cmake/*",
-        "src/**/*.cpp",
-    ]),
-    outs = [
-      "include/opentracing/config.h",
-      "include/opentracing/version.h"
-    ],
-    cmd = """
-    TEMP_DIR=$$(mktemp -d)
-    CONFIG_H_OUT=$${PWD}/$(location :include/opentracing/config.h)
-    VERSION_H_OUT=$${PWD}/$(location :include/opentracing/version.h)
-    OPENTRACING_ROOT=$$(dirname $${PWD}/$(location :CMakeLists.txt))
-    cd $$TEMP_DIR
-    cmake -DBUILD_TESTING=OFF -DBUILD_MOCKTRACER=OFF -L $$OPENTRACING_ROOT
-    mv include/opentracing/config.h $$CONFIG_H_OUT
-    mv include/opentracing/version.h $$VERSION_H_OUT
-    rm -rf $$TEMP_DIR
-    """,
-)
diff --git a/3rd_party/include/opentracing/variant/variant.hpp b/3rd_party/include/opentracing/variant/variant.hpp
--- a/3rd_party/include/opentracing/variant/variant.hpp	2023-07-11 17:17:48.563874883 +0000
+++ b/3rd_party/include/opentracing/variant/variant.hpp	2023-07-11 17:45:38.558235212 +0000
@@ -167,7 +167,11 @@
 template <typename F, typename V, typename Enable = void>
 struct result_of_unary_visit
 {
+#if __cplusplus >= 202002L
+    using type = typename std::invoke_result<F, V&>::type;
+#else
     using type = typename std::result_of<F(V&)>::type;
+#endif
 };
 
 template <typename F, typename V>
@@ -179,7 +183,11 @@
 template <typename F, typename V, typename Enable = void>
 struct result_of_binary_visit
 {
+#if __cplusplus >= 202002L
+    using type = typename std::invoke_result<F, V&, V&>::type;
+#else
     using type = typename std::result_of<F(V&, V&)>::type;
+#endif
 };
 
 template <typename F, typename V># DO NOT LOAD THIS FILE. Load envoy_build_system.bzl instead.
# Envoy library targets
load(
    ":envoy_internal.bzl",
    "envoy_copts",
    "envoy_external_dep_path",
    "envoy_linkstatic",
)
load(":envoy_pch.bzl", "envoy_pch_copts", "envoy_pch_deps")
load("@envoy_api//bazel:api_build_system.bzl", "api_cc_py_proto_library")
load(
    "@envoy_build_config//:extensions_build_config.bzl",
    "CONTRIB_EXTENSION_PACKAGE_VISIBILITY",
    "EXTENSION_CONFIG_VISIBILITY",
)
load(":envoy_mobile_defines.bzl", "envoy_mobile_defines")

# As above, but wrapped in list form for adding to dep lists. This smell seems needed as
# SelectorValue values have to match the attribute type. See
# https://github.com/bazelbuild/bazel/issues/2273.
def tcmalloc_external_deps(repository):
    return select({
        repository + "//bazel:disable_tcmalloc": [],
        repository + "//bazel:disable_tcmalloc_on_linux_x86_64": [],
        repository + "//bazel:disable_tcmalloc_on_linux_aarch64": [],
        repository + "//bazel:debug_tcmalloc": [envoy_external_dep_path("gperftools")],
        repository + "//bazel:debug_tcmalloc_on_linux_x86_64": [envoy_external_dep_path("gperftools")],
        repository + "//bazel:debug_tcmalloc_on_linux_aarch64": [envoy_external_dep_path("gperftools")],
        repository + "//bazel:gperftools_tcmalloc": [envoy_external_dep_path("gperftools")],
        repository + "//bazel:gperftools_tcmalloc_on_linux_x86_64": [envoy_external_dep_path("gperftools")],
        repository + "//bazel:gperftools_tcmalloc_on_linux_aarch64": [envoy_external_dep_path("gperftools")],
        repository + "//bazel:linux_x86_64": [
            envoy_external_dep_path("tcmalloc"),
            envoy_external_dep_path("tcmalloc_profile_marshaler"),
            envoy_external_dep_path("tcmalloc_malloc_extension"),
        ],
        repository + "//bazel:linux_aarch64": [
            envoy_external_dep_path("tcmalloc"),
            envoy_external_dep_path("tcmalloc_profile_marshaler"),
            envoy_external_dep_path("tcmalloc_malloc_extension"),
        ],
        "//conditions:default": [envoy_external_dep_path("gperftools")],
    })

# Envoy C++ library targets that need no transformations or additional dependencies before being
# passed to cc_library should be specified with this function. Note: this exists to ensure that
# all envoy targets pass through an envoy-declared Starlark function where they can be modified
# before being passed to a native bazel function.
def envoy_basic_cc_library(name, deps = [], external_deps = [], **kargs):
    native.cc_library(
        name = name,
        deps = deps + [envoy_external_dep_path(dep) for dep in external_deps],
        **kargs
    )

def envoy_cc_extension(
        name,
        tags = [],
        extra_visibility = [],
        visibility = EXTENSION_CONFIG_VISIBILITY,
        alwayslink = 1,
        **kwargs):
    if "//visibility:public" not in visibility:
        visibility = visibility + extra_visibility

    ext_name = name + "_envoy_extension"
    envoy_cc_library(
        name = name,
        tags = tags,
        visibility = visibility,
        alwayslink = alwayslink,
        **kwargs
    )
    native.cc_library(
        name = ext_name,
        tags = tags,
        deps = select({
            ":is_enabled": [":" + name],
            "//conditions:default": [],
        }),
        visibility = visibility,
    )

def envoy_cc_contrib_extension(
        name,
        tags = [],
        extra_visibility = [],
        visibility = CONTRIB_EXTENSION_PACKAGE_VISIBILITY,
        alwayslink = 1,
        **kwargs):
    envoy_cc_extension(name, tags, extra_visibility, visibility, **kwargs)

# Envoy C++ library targets should be specified with this function.
def envoy_cc_library(
        name,
        srcs = [],
        hdrs = [],
        copts = [],
        visibility = None,
        external_deps = [],
        tcmalloc_dep = None,
        repository = "",
        tags = [],
        deps = [],
        strip_include_prefix = None,
        include_prefix = None,
        textual_hdrs = None,
        alwayslink = None,
        defines = [],
        linkopts = []):
    if tcmalloc_dep:
        deps += tcmalloc_external_deps(repository)

    # If alwayslink is not specified, allow turning it off via --define=library_autolink=disabled
    # alwayslink is defaulted on for envoy_cc_extensions to ensure the REGISTRY macros work.
    if alwayslink == None:
        alwayslink = select({
            repository + "//bazel:disable_library_autolink": 0,
            "//conditions:default": 1,
        })

    native.cc_library(
        name = name,
        srcs = srcs,
        hdrs = hdrs,
        copts = envoy_copts(repository) + envoy_pch_copts(repository, "//source/common/common:common_pch") + copts,
        linkopts = linkopts,
        visibility = visibility,
        tags = tags,
        textual_hdrs = textual_hdrs,
        deps = deps + [envoy_external_dep_path(dep) for dep in external_deps] +
               envoy_pch_deps(repository, "//source/common/common:common_pch"),
        alwayslink = alwayslink,
        linkstatic = envoy_linkstatic(),
        strip_include_prefix = strip_include_prefix,
        include_prefix = include_prefix,
        defines = envoy_mobile_defines(repository) + defines,
    )

    # Intended for usage by external consumers. This allows them to disambiguate
    # include paths via `external/envoy...`
    native.cc_library(
        name = name + "_with_external_headers",
        hdrs = hdrs,
        copts = envoy_copts(repository) + copts,
        visibility = visibility,
        tags = ["nocompdb"] + tags,
        deps = [":" + name],
        strip_include_prefix = strip_include_prefix,
        include_prefix = include_prefix,
    )

# Used to specify a library that only builds on POSIX
def envoy_cc_posix_library(name, srcs = [], hdrs = [], **kargs):
    envoy_cc_library(
        name = name + "_posix",
        srcs = select({
            "@envoy//bazel:windows_x86_64": [],
            "//conditions:default": srcs,
        }),
        hdrs = select({
            "@envoy//bazel:windows_x86_64": [],
            "//conditions:default": hdrs,
        }),
        **kargs
    )

# Used to specify a library that only builds on POSIX excluding Linux
def envoy_cc_posix_without_linux_library(name, srcs = [], hdrs = [], **kargs):
    envoy_cc_library(
        name = name + "_posix",
        srcs = select({
            "@envoy//bazel:windows_x86_64": [],
            "@envoy//bazel:linux": [],
            "//conditions:default": srcs,
        }),
        hdrs = select({
            "@envoy//bazel:windows_x86_64": [],
            "@envoy//bazel:linux": [],
            "//conditions:default": hdrs,
        }),
        **kargs
    )

# Used to specify a library that only builds on Linux
def envoy_cc_linux_library(name, srcs = [], hdrs = [], **kargs):
    envoy_cc_library(
        name = name + "_linux",
        srcs = select({
            "@envoy//bazel:linux": srcs,
            "//conditions:default": [],
        }),
        hdrs = select({
            "@envoy//bazel:linux": hdrs,
            "//conditions:default": [],
        }),
        **kargs
    )

# Used to specify a library that only builds on Windows
def envoy_cc_win32_library(name, srcs = [], hdrs = [], **kargs):
    envoy_cc_library(
        name = name + "_win32",
        srcs = select({
            "@envoy//bazel:windows_x86_64": srcs,
            "//conditions:default": [],
        }),
        hdrs = select({
            "@envoy//bazel:windows_x86_64": hdrs,
            "//conditions:default": [],
        }),
        **kargs
    )

# Envoy proto targets should be specified with this function.
def envoy_proto_library(name, **kwargs):
    api_cc_py_proto_library(
        name,
        # Avoid generating .so, we don't need it, can interfere with builds
        # such as OSS-Fuzz.
        linkstatic = 1,
        visibility = ["//visibility:public"],
        **kwargs
    )
diff --git a/eval/public/cel_value.cc b/eval/public/cel_value.cc
index 6aeff6d..c43864c 100644
--- a/eval/public/cel_value.cc
+++ b/eval/public/cel_value.cc
@@ -107,7 +107,7 @@ struct DebugStringVisitor {
 
 }  // namespace
 
-const absl::string_view kPayloadUrlMissingAttributePath =
+ABSL_CONST_INIT const absl::string_view kPayloadUrlMissingAttributePath =
     cel::runtime_internal::kPayloadUrlMissingAttributePath;
 
 CelValue CelValue::CreateDuration(absl::Duration value) {
diff --git a/eval/public/containers/container_backed_map_impl.h b/eval/public/containers/container_backed_map_impl.h
index 6092eef..7548bbf 100644
--- a/eval/public/containers/container_backed_map_impl.h
+++ b/eval/public/containers/container_backed_map_impl.h
@@ -30,6 +30,7 @@ class CelMapBuilder : public CelMap {
     return values_map_.contains(cel_key);
   }
 
+  using CelMap::ListKeys;
   absl::StatusOr<const CelList*> ListKeys() const override {
     return &key_list_;
   }
diff --git a/eval/public/containers/internal_field_backed_map_impl.h b/eval/public/containers/internal_field_backed_map_impl.h
index ec773d9..caa2f3a 100644
--- a/eval/public/containers/internal_field_backed_map_impl.h
+++ b/eval/public/containers/internal_field_backed_map_impl.h
@@ -43,6 +43,7 @@ class FieldBackedMapImpl : public CelMap {
   // Presence test function.
   absl::StatusOr<bool> Has(const CelValue& key) const override;
 
+  using CelMap::ListKeys;
   absl::StatusOr<const CelList*> ListKeys() const override;
 
  protected:
diff --git a/eval/public/structs/cel_proto_lite_wrap_util.cc b/eval/public/structs/cel_proto_lite_wrap_util.cc
index 4cb21e5..35fdf7f 100644
--- a/eval/public/structs/cel_proto_lite_wrap_util.cc
+++ b/eval/public/structs/cel_proto_lite_wrap_util.cc
@@ -172,6 +172,7 @@ class DynamicMap : public CelMap {
 
   int size() const override { return values_->fields_size(); }
 
+  using CelMap::ListKeys;
   absl::StatusOr<const CelList*> ListKeys() const override {
     return &key_list_;
   }
diff --git a/eval/public/structs/cel_proto_wrap_util.cc b/eval/public/structs/cel_proto_wrap_util.cc
index fabb594..86a314c 100644
--- a/eval/public/structs/cel_proto_wrap_util.cc
+++ b/eval/public/structs/cel_proto_wrap_util.cc
@@ -137,6 +137,7 @@ class DynamicMap : public CelMap {
 
   int size() const override { return values_->fields_size(); }
 
+  using CelMap::ListKeys;
   absl::StatusOr<const CelList*> ListKeys() const override {
     return &key_list_;
   }
diff --git a/internal/strings.cc b/internal/strings.cc
index dc5a118..24457ab 100644
--- a/internal/strings.cc
+++ b/internal/strings.cc
@@ -53,12 +53,12 @@ bool CheckForClosingString(absl::string_view source,
   if (closing_str.empty()) return true;
 
   const char* p = source.data();
-  const char* end = source.end();
+  const char* end = p + source.size();
 
   bool is_closed = false;
   while (p + closing_str.length() <= end) {
     if (*p != '\\') {
-      size_t cur_pos = p - source.begin();
+      size_t cur_pos = p - source.data();
       bool is_closing =
           absl::StartsWith(absl::ClippedSubstr(source, cur_pos), closing_str);
       if (is_closing && p + closing_str.length() < end) {
@@ -132,7 +132,7 @@ bool UnescapeInternal(absl::string_view source, absl::string_view closing_str,
   dest->reserve(source.size());
 
   const char* p = source.data();
-  const char* end = source.end();
+  const char* end = p + source.size();
   const char* last_byte = end - 1;
 
   while (p < end) {
@@ -446,7 +446,9 @@ std::string EscapeInternal(absl::string_view src, bool escape_all_bytes,
   // byte.
   dest.reserve(src.size() * 4);
   bool last_hex_escape = false;  // true if last output char was \xNN.
-  for (const char* p = src.begin(); p < src.end(); ++p) {
+  const char* p = src.data();
+  const char* end = p + src.size();
+  for (; p < end; ++p) {
     unsigned char c = static_cast<unsigned char>(*p);
     bool is_hex_escape = false;
     switch (c) {
@@ -552,7 +554,9 @@ std::string EscapeString(absl::string_view str) {
 std::string EscapeBytes(absl::string_view str, bool escape_all_bytes,
                         char escape_quote_char) {
   std::string escaped_bytes;
-  for (const char* p = str.begin(); p < str.end(); ++p) {
+  const char* p = str.data();
+  const char* end = p + str.size();
+  for (; p < end; ++p) {
     unsigned char c = *p;
     if (escape_all_bytes || !absl::ascii_isprint(c)) {
       escaped_bytes += "\\x";
diff --git a/tools/flatbuffers_backed_impl.cc b/tools/flatbuffers_backed_impl.cc
index 10c0b1c..45ba72f 100644
--- a/tools/flatbuffers_backed_impl.cc
+++ b/tools/flatbuffers_backed_impl.cc
@@ -130,6 +130,7 @@ class ObjectStringIndexedMapImpl : public CelMap {
     return absl::nullopt;
   }
 
+  using CelMap::ListKeys;
   absl::StatusOr<const CelList*> ListKeys() const override { return &keys_; }
 
  private:
# DO NOT LOAD THIS FILE. Load envoy_build_system.bzl instead.
# Envoy test targets. This includes both test library and test binary targets.
load("@rules_python//python:defs.bzl", "py_binary", "py_test")
load("@rules_fuzzing//fuzzing:cc_defs.bzl", "fuzzing_decoration")
load(":envoy_binary.bzl", "envoy_cc_binary")
load(":envoy_library.bzl", "tcmalloc_external_deps")
load(":envoy_pch.bzl", "envoy_pch_copts", "envoy_pch_deps")
load(
    ":envoy_internal.bzl",
    "envoy_copts",
    "envoy_dbg_linkopts",
    "envoy_exported_symbols_input",
    "envoy_external_dep_path",
    "envoy_linkstatic",
    "envoy_select_exported_symbols",
    "envoy_select_force_libcpp",
    "envoy_stdlib_deps",
    "tcmalloc_external_dep",
)

# Envoy C++ related test infrastructure (that want gtest, gmock, but may be
# relied on by envoy_cc_test_library) should use this function.
def _envoy_cc_test_infrastructure_library(
        name,
        srcs = [],
        hdrs = [],
        data = [],
        external_deps = [],
        deps = [],
        repository = "",
        tags = [],
        include_prefix = None,
        copts = [],
        alwayslink = 1,
        disable_pch = False,
        **kargs):
    # Add implicit tcmalloc external dependency(if available) in order to enable CPU and heap profiling in tests.
    deps += tcmalloc_external_deps(repository)
    extra_deps = []
    pch_copts = []
    if disable_pch:
        extra_deps = [envoy_external_dep_path("googletest")]
    else:
        extra_deps = envoy_pch_deps(repository, "//test:test_pch")
        pch_copts = envoy_pch_copts(repository, "//test:test_pch")

    native.cc_library(
        name = name,
        srcs = srcs,
        hdrs = hdrs,
        data = data,
        copts = envoy_copts(repository, test = True) + copts + pch_copts,
        testonly = 1,
        deps = deps + [envoy_external_dep_path(dep) for dep in external_deps] + extra_deps,
        tags = tags,
        include_prefix = include_prefix,
        alwayslink = alwayslink,
        linkstatic = envoy_linkstatic(),
        **kargs
    )

# Compute the test linkopts based on various options.
def _envoy_test_linkopts():
    return select({
        "@envoy//bazel:apple": [],
        "@envoy//bazel:windows_x86_64": [
            "-DEFAULTLIB:ws2_32.lib",
            "-DEFAULTLIB:iphlpapi.lib",
            "-WX",
        ],

        # TODO(mattklein123): It's not great that we universally link against the following libs.
        # In particular, -latomic and -lrt are not needed on all platforms. Make this more granular.
        "//conditions:default": ["-pthread", "-lrt", "-ldl"],
    }) + envoy_select_force_libcpp([], ["-lstdc++fs", "-latomic"]) + envoy_dbg_linkopts() + envoy_select_exported_symbols(["-Wl,-E"])

# Envoy C++ fuzz test targets. These are not included in coverage runs.
def envoy_cc_fuzz_test(
        name,
        corpus,
        dictionaries = [],
        repository = "",
        size = "medium",
        deps = [],
        tags = [],
        **kwargs):
    if not (corpus.startswith("//") or corpus.startswith(":") or corpus.startswith("@")):
        corpus_name = name + "_corpus_files"
        native.filegroup(
            name = corpus_name,
            srcs = native.glob([corpus + "/**"]),
        )
    else:
        corpus_name = corpus

    test_lib_name = name + "_lib"
    envoy_cc_test_library(
        name = test_lib_name,
        deps = deps + envoy_stdlib_deps() + [
            repository + "//test/fuzz:fuzz_runner_lib",
            repository + "//test/test_common:test_version_linkstamp",
        ],
        repository = repository,
        tags = tags,
        **kwargs
    )

    native.cc_test(
        name = name,
        copts = envoy_copts("@envoy", test = True),
        additional_linker_inputs = envoy_exported_symbols_input(),
        linkopts = _envoy_test_linkopts() + select({
            "@envoy//bazel:libfuzzer": ["-fsanitize=fuzzer"],
            "//conditions:default": [],
        }),
        linkstatic = envoy_linkstatic(),
        args = select({
            "@envoy//bazel:libfuzzer_coverage": ["$(locations %s)" % corpus_name],
            "@envoy//bazel:libfuzzer": [],
            "//conditions:default": ["$(locations %s)" % corpus_name],
        }),
        data = [corpus_name],
        # No fuzzing on macOS or Windows
        deps = select({
            "@envoy//bazel:apple": [repository + "//test:dummy_main"],
            "@envoy//bazel:windows_x86_64": [repository + "//test:dummy_main"],
            "//conditions:default": [
                ":" + test_lib_name,
                "@envoy//bazel:fuzzing_engine",
            ],
        }),
        size = size,
        tags = ["fuzz_target"] + tags,
    )

    fuzzing_decoration(
        name = name,
        raw_binary = name,
        engine = "@envoy//bazel:fuzzing_engine",
        corpus = [corpus_name],
        dicts = dictionaries,
        define_regression_test = False,
    )

# Envoy C++ test targets should be specified with this function.
def envoy_cc_test(
        name,
        srcs = [],
        data = [],
        # List of pairs (Bazel shell script target, shell script args)
        repository = "",
        external_deps = [],
        deps = [],
        tags = [],
        args = [],
        copts = [],
        condition = None,
        shard_count = None,
        coverage = True,
        local = False,
        size = "medium",
        flaky = False,
        env = {},
        exec_properties = {}):
    coverage_tags = tags + ([] if coverage else ["nocoverage"])

    native.cc_test(
        name = name,
        srcs = srcs,
        data = data,
        copts = envoy_copts(repository, test = True) + copts + envoy_pch_copts(repository, "//test:test_pch"),
        additional_linker_inputs = envoy_exported_symbols_input(),
        linkopts = _envoy_test_linkopts(),
        linkstatic = envoy_linkstatic(),
        malloc = tcmalloc_external_dep(repository),
        deps = envoy_stdlib_deps() + deps + [envoy_external_dep_path(dep) for dep in external_deps + ["googletest"]] + [
            repository + "//test:main",
            repository + "//test/test_common:test_version_linkstamp",
        ] + envoy_pch_deps(repository, "//test:test_pch"),
        # from https://github.com/google/googletest/blob/6e1970e2376c14bf658eb88f655a054030353f9f/googlemock/src/gmock.cc#L51
        # 2 - by default, mocks act as StrictMocks.
        args = args + ["--gmock_default_mock_behavior=2"],
        tags = coverage_tags,
        local = local,
        shard_count = shard_count,
        size = size,
        flaky = flaky,
        env = env,
        exec_properties = exec_properties,
    )

# Envoy C++ test related libraries (that want gtest, gmock) should be specified
# with this function.
def envoy_cc_test_library(
        name,
        srcs = [],
        hdrs = [],
        data = [],
        external_deps = [],
        deps = [],
        repository = "",
        tags = [],
        include_prefix = None,
        copts = [],
        alwayslink = 1,
        **kargs):
    disable_pch = kargs.pop("disable_pch", True)
    _envoy_cc_test_infrastructure_library(
        name,
        srcs,
        hdrs,
        data,
        external_deps,
        deps,
        repository,
        tags,
        include_prefix,
        copts,
        visibility = ["//visibility:public"],
        alwayslink = alwayslink,
        disable_pch = disable_pch,
        **kargs
    )

# Envoy test binaries should be specified with this function.
def envoy_cc_test_binary(
        name,
        tags = [],
        deps = [],
        stamp = 0,
        **kargs):
    envoy_cc_binary(
        name,
        testonly = 1,
        linkopts = _envoy_test_linkopts(),
        tags = tags + ["compilation_db_dep"],
        deps = deps + [
            "@envoy//test/test_common:test_version_linkstamp",
        ],
        stamp = stamp,
        **kargs
    )

# Envoy benchmark binaries should be specified with this function. bazel run
# these targets to measure performance.
def envoy_cc_benchmark_binary(
        name,
        deps = [],
        repository = "",
        **kargs):
    envoy_cc_test_binary(
        name,
        deps = deps + [repository + "//test/benchmark:main"],
        repository = repository,
        **kargs
    )

# Tests to validate that Envoy benchmarks run successfully should be specified
# with this function. Not for actual performance measurements: iteratons and
# expensive benchmarks will be skipped in the interest of execution time.
def envoy_benchmark_test(
        name,
        benchmark_binary,
        data = [],
        tags = [],
        repository = "",
        **kargs):
    native.sh_test(
        name = name,
        srcs = [repository + "//bazel:test_for_benchmark_wrapper.sh"],
        data = [":" + benchmark_binary] + data,
        args = ["%s/%s" % (native.package_name(), benchmark_binary)],
        tags = tags + ["nocoverage"],
        **kargs
    )

# Envoy Python test binaries should be specified with this function.
def envoy_py_test_binary(
        name,
        external_deps = [],
        deps = [],
        **kargs):
    py_binary(
        name = name,
        deps = deps + [envoy_external_dep_path(dep) for dep in external_deps],
        **kargs
    )

# Envoy py_tests should be specified with this function.
def envoy_py_test(
        name,
        external_deps = [],
        deps = [],
        **kargs):
    py_test(
        name = name,
        deps = deps + [envoy_external_dep_path(dep) for dep in external_deps],
        **kargs
    )

# Envoy C++ mock targets should be specified with this function.
def envoy_cc_mock(name, **kargs):
    envoy_cc_test_library(name = name, disable_pch = True, **kargs)

# Envoy shell tests that need to be included in coverage run should be specified with this function.
def envoy_sh_test(
        name,
        srcs = [],
        data = [],
        coverage = True,
        cc_binary = [],
        tags = [],
        **kargs):
    if coverage:
        if cc_binary == []:
            fail("cc_binary is required for coverage-enabled test.")
        test_runner_cc = name + "_test_runner.cc"
        native.genrule(
            name = name + "_gen_test_runner",
            srcs = srcs,
            outs = [test_runner_cc],
            cmd = "$(location //bazel:gen_sh_test_runner.sh) $(SRCS) >> $@",
            tools = ["//bazel:gen_sh_test_runner.sh"],
        )
        envoy_cc_test(
            name = name,
            srcs = [test_runner_cc],
            data = srcs + data + cc_binary,
            tags = tags,
            deps = ["//test/test_common:environment_lib"] + cc_binary,
            **kargs
        )

    else:
        native.sh_test(
            name = name,
            srcs = ["//bazel:sh_test_wrapper.sh"],
            data = srcs + data + cc_binary,
            args = srcs,
            tags = tags + ["nocoverage"],
            **kargs
        )
#!/bin/bash -e

set -o pipefail


EXISTING_DATE="$("${JQ}" -r ".${DEP}.release_date" "${DEP_DATA}")"
DATE_SEARCH="release_date = \"${EXISTING_DATE}\","
DEP_CHECK="${DEP_CHECK:-tools/dependency/check}"

find_date_line () {
    local match match_ln date_match_ln
    # This needs to find the correct date to replace
    match="$(\
        grep -n "${DEP_SEARCH}" "${VERSION_FILE}" \
        | cut -d: -f-2)"
    match_ln="$(\
        echo "${match}" \
        | cut -d: -f1)"
    match_ln="$((match_ln + 1))"
    date_match_ln="$(\
        tail -n "+${match_ln}" "${VERSION_FILE}" \
        | grep -n "${DATE_SEARCH}" \
        | head -n1 \
        | cut -d: -f1)"
    date_match_ln="$((match_ln + date_match_ln - 1))"
    printf '%s' "$date_match_ln"
}

update_date () {
    local match_ln search replace
    match_ln="$1"
    search="$2"
    replace="$3"
    echo "Updating date(${match_ln}): ${search} -> ${replace}"
    sed -i "${match_ln}s/${search}/${replace}/" "$VERSION_FILE"
}

get_new_date () {
    # create a repository_locations with just the dep and with updated version
    tmpfile="$(mktemp)"
    # shellcheck disable=SC2016
    "$JQ" --arg new_version "$VERSION" \
       --arg existing_version "$EXISTING_VERSION" \
       --arg dep "$DEP" \
       'if has($dep) then .[$dep].version = $new_version | .[$dep].urls |= map(gsub($existing_version; $new_version)) else . end' \
       "$DEP_DATA" > "$tmpfile"
    output="$(\
      "$DEP_CHECK" \
        --repository_locations="$tmpfile" \
        --path "${BUILD_WORKSPACE_DIRECTORY}" \
        -c release_dates 2>&1)"
    echo "$output" \
        | grep -E "^Mismatch" \
        | grep "$DEP" \
        | cut -d= -f2 \
        | xargs || {
        cat "$tmpfile" >&2
        echo "$output" >&2
        rm "$tmpfile"
        exit 1
    }
    rm "$tmpfile"
}

post_version_update () {
    local date_ln new_date
    if [[ "$EXISTING_VERSION" == "$VERSION" ]]; then
        echo "Nothing to update" >&2
        exit 0
    fi
    date_ln="$(find_date_line)"
    new_date="$(get_new_date)"
    if [[ -z "$new_date" ]]; then
        echo "Unable to retrieve date" >&2
        exit 1
    fi
    update_date "$date_ln" "$EXISTING_DATE" "$new_date"
}
flags:
  --cpu=arm64-v8a
  --crosstool_top=//external:android/crosstool
    @envoy//bazel:android_aarch64

  --cpu=armeabi-v7a
  --crosstool_top=//external:android/crosstool
    @envoy//bazel:android_armeabi

  --cpu=x86
  --crosstool_top=//external:android/crosstool
    @envoy//bazel:android_x86

  --cpu=x86_64
  --crosstool_top=//external:android/crosstool
    @envoy//bazel:android_x86_64

  --cpu=darwin_x86_64
  --apple_platform_type=macos
    @envoy//bazel:macos_x86_64

  --cpu=darwin_arm64
  --apple_platform_type=macos
    @envoy//bazel:macos_arm64

  --cpu=ios_x86_64
  --apple_platform_type=ios
    @envoy//bazel:ios_x86_64_platform

  --cpu=ios_sim_arm64
  --apple_platform_type=ios
    @envoy//bazel:ios_sim_arm64_platform

  --cpu=ios_arm64
  --apple_platform_type=ios
    @envoy//bazel:ios_arm64_platform
licenses(["notice"])  # Apache 2

cc_library(
    name = "nlohmann_json_lib",
    hdrs = glob([
        "include/nlohmann/*.hpp",
        "include/nlohmann/**/*.hpp",
        "include/nlohmann/*/*/*.hpp",
    ]),
    includes = ["external/nlohmann_json_lib"],
    visibility = ["//visibility:public"],
)

cc_library(
    name = "json",
    includes = ["include"],
    visibility = ["//visibility:public"],
    deps = [":nlohmann_json_lib"],
)
#!/bin/bash

set -e

export CXXFLAGS=''
export LDFLAGS=''

# BoringSSL build as described in the Security Policy for BoringCrypto module (2022-05-06):
# https://csrc.nist.gov/CSRC/media/projects/cryptographic-module-validation-program/documents/security-policies/140sp4407.pdf

OS=`uname`
ARCH=`uname -m`
# This works only on Linux-x86_64 and Linux-aarch64.
if [[ "$OS" != "Linux" || ("$ARCH" != "x86_64" && "$ARCH" != "aarch64") ]]; then
  echo "ERROR: BoringSSL FIPS is currently supported only on Linux-x86_64 and Linux-aarch64."
  exit 1
fi


# Bazel magic.
# ROOT=$(dirname $(rootpath boringssl/BUILDING.md))/..
ROOT=./external/boringssl_fips
pushd "$ROOT"

# Build tools requirements (from section 12.1 of https://csrc.nist.gov/CSRC/media/projects/cryptographic-module-validation-program/documents/security-policies/140sp4407.pdf):
# - Clang compiler version 12.0.0 (https://releases.llvm.org/download.html)
# - Go programming language version 1.16.5 (https://golang.org/dl/)
# - Ninja build system version 1.10.2 (https://github.com/ninja-build/ninja/releases)
# - Cmake version 3.20.1 (https://cmake.org/download/)

# Override $PATH for build tools, to avoid picking up anything else.
export PATH="$(dirname `which cmake`):/usr/bin:/bin"

# Clang
VERSION=12.0.0
if [[ "$ARCH" == "x86_64" ]]; then
  PLATFORM="x86_64-linux-gnu-ubuntu-20.04"
  SHA256=a9ff205eb0b73ca7c86afc6432eed1c2d49133bd0d49e47b15be59bbf0dd292e
else
  PLATFORM="aarch64-linux-gnu"
  SHA256=d05f0b04fb248ce1e7a61fcd2087e6be8bc4b06b2cc348792f383abf414dec48
fi

curl -sLO https://github.com/llvm/llvm-project/releases/download/llvmorg-"$VERSION"/clang+llvm-"$VERSION"-"$PLATFORM".tar.xz
tar xf clang+llvm-"$VERSION"-"$PLATFORM".tar.xz

export HOME="$PWD"
printf "set(CMAKE_C_COMPILER \"clang\")\nset(CMAKE_CXX_COMPILER \"clang++\")\n" > ${HOME}/toolchain
export PATH="$PWD/clang+llvm-$VERSION-$PLATFORM/bin:$PATH"

if [[ `clang --version | head -1 | awk '{print $3}'` != "$VERSION" ]]; then
  echo "ERROR: Clang version doesn't match."
  exit 1
fi

# Go
VERSION=1.16.5
if [[ "$ARCH" == "x86_64" ]]; then
  PLATFORM="linux-amd64"
  SHA256=b12c23023b68de22f74c0524f10b753e7b08b1504cb7e417eccebdd3fae49061
else
  PLATFORM="linux-arm64"
  SHA256=d5446b46ef6f36fdffa852f73dfbbe78c1ddf010b99fa4964944b9ae8b4d6799
fi

curl -sLO https://dl.google.com/go/go"$VERSION"."$PLATFORM".tar.gz \
  && echo "$SHA256" go"$VERSION"."$PLATFORM".tar.gz | sha256sum --check
tar xf go"$VERSION"."$PLATFORM".tar.gz

export GOPATH="$PWD/gopath"
export GOROOT="$PWD/go"
export PATH="$GOPATH/bin:$GOROOT/bin:$PATH"

if [[ `go version | awk '{print $3}'` != "go$VERSION" ]]; then
  echo "ERROR: Go version doesn't match."
  exit 1
fi

# Ninja
VERSION=1.10.2
SHA256=ce35865411f0490368a8fc383f29071de6690cbadc27704734978221f25e2bed
curl -sLO https://github.com/ninja-build/ninja/archive/refs/tags/v"$VERSION".tar.gz \
  && echo "$SHA256" v"$VERSION".tar.gz | sha256sum --check
tar -xvf v"$VERSION".tar.gz
cd ninja-"$VERSION"
python3 ./configure.py --bootstrap

export PATH="$PWD:$PATH"

if [[ `ninja --version` != "$VERSION" ]]; then
  echo "ERROR: Ninja version doesn't match."
  exit 1
fi
cd ..

# CMake
VERSION=3.20.1
if [[ "$ARCH" == "x86_64" ]]; then
  PLATFORM="linux-x86_64"
  SHA256=b8c141bd7a6d335600ab0a8a35e75af79f95b837f736456b5532f4d717f20a09
else
  PLATFORM="linux-aarch64"
  SHA256=5ad1f8139498a1956df369c401658ec787f63c8cb4e9759f2edaa51626a86512
fi

curl -sLO https://github.com/Kitware/CMake/releases/download/v"$VERSION"/cmake-"$VERSION"-"$PLATFORM".tar.gz \
  && echo "$SHA256" cmake-"$VERSION"-"$PLATFORM".tar.gz | sha256sum --check
tar xf cmake-"$VERSION"-"$PLATFORM".tar.gz

export PATH="$PWD/cmake-$VERSION-$PLATFORM/bin:$PATH"

if [[ `cmake --version | head -n1` != "cmake version $VERSION" ]]; then
  echo "ERROR: CMake version doesn't match."
  exit 1
fi

# Clean after previous build.
rm -rf boringssl/build

# Build BoringSSL.
cd boringssl
mkdir build && cd build && cmake -GNinja -DCMAKE_TOOLCHAIN_FILE=${HOME}/toolchain -DFIPS=1 -DCMAKE_BUILD_TYPE=Release ..
ninja
ninja run_tests
./crypto/crypto_test

# Verify correctness of the FIPS build.
if [[ `tool/bssl isfips` != "1" ]]; then
  echo "ERROR: BoringSSL tool didn't report FIPS build."
  exit 1
fi

# Move compiled libraries to the expected destinations.
popd
mv $ROOT/boringssl/build/crypto/libcrypto.a $1
mv $ROOT/boringssl/build/ssl/libssl.a $2
load(
    "@envoy//bazel:envoy_build_system.bzl",
    "envoy_cc_library",
    "envoy_cc_test_library",
)
load("@envoy//bazel:envoy_select.bzl", "envoy_select_enable_http3")

# These options are only used to suppress errors in brought-in QUICHE tests.
# Use #pragma GCC diagnostic ignored in integration code to suppress these errors.
quiche_common_copts = [
    # hpack_huffman_decoder.cc overloads operator<<.
    "-Wno-unused-function",
    "-Wno-old-style-cast",
]

quiche_copts = select({
    # Ignore unguarded #pragma GCC statements in QUICHE sources
    "@envoy//bazel:windows_x86_64": ["-wd4068"],
    # Remove these after upstream fix.
    "//conditions:default": quiche_common_copts,
})

def envoy_quiche_platform_impl_cc_library(
        name,
        srcs = [],
        hdrs = [],
        deps = []):
    envoy_cc_library(
        name = name,
        srcs = srcs,
        hdrs = hdrs,
        deps = deps,
        repository = "@envoy",
        strip_include_prefix = "quiche/common/platform/default/",
        tags = ["nofips"],
        visibility = ["//visibility:public"],
    )

def envoy_quiche_platform_impl_cc_test_library(
        name,
        srcs = [],
        hdrs = [],
        deps = []):
    envoy_cc_test_library(
        name = name,
        srcs = srcs,
        hdrs = hdrs,
        deps = deps,
        repository = "@envoy",
        strip_include_prefix = "quiche/common/platform/default/",
        tags = ["nofips"],
    )

# Used for QUIC libraries
def envoy_quic_cc_library(
        name,
        srcs = [],
        hdrs = [],
        deps = [],
        defines = [],
        external_deps = [],
        tags = []):
    envoy_cc_library(
        name = name,
        srcs = envoy_select_enable_http3(srcs, "@envoy"),
        hdrs = envoy_select_enable_http3(hdrs, "@envoy"),
        repository = "@envoy",
        copts = quiche_copts,
        tags = ["nofips"] + tags,
        visibility = ["//visibility:public"],
        defines = defines,
        external_deps = external_deps,
        deps = envoy_select_enable_http3(deps, "@envoy"),
    )

def envoy_quic_cc_test_library(
        name,
        srcs = [],
        hdrs = [],
        tags = [],
        external_deps = [],
        deps = []):
    envoy_cc_test_library(
        name = name,
        srcs = envoy_select_enable_http3(srcs, "@envoy"),
        hdrs = envoy_select_enable_http3(hdrs, "@envoy"),
        copts = quiche_copts,
        repository = "@envoy",
        tags = ["nofips"] + tags,
        external_deps = external_deps,
        deps = envoy_select_enable_http3(deps, "@envoy"),
    )
licenses(["notice"])  # Apache 2

cc_library(
    name = "fuzzed_data_provider",
    hdrs = ["include/fuzzer/FuzzedDataProvider.h"],
    strip_include_prefix = "include",
    visibility = ["//visibility:public"],
)

libfuzzer_copts = [
    "-fno-sanitize=address,thread,undefined",
    "-fsanitize-coverage=0",
    "-O3",
]

cc_library(
    name = "libfuzzer_main",
    srcs = ["lib/fuzzer/FuzzerMain.cpp"],
    copts = libfuzzer_copts,
    visibility = ["//visibility:public"],
    deps = [":libfuzzer_no_main"],
    alwayslink = True,
)

cc_library(
    name = "libfuzzer_no_main",
    srcs = glob(
        ["lib/fuzzer/Fuzzer*.cpp"],
        exclude = ["lib/fuzzer/FuzzerMain.cpp"],
    ),
    hdrs = glob([
        "lib/fuzzer/Fuzzer*.h",
        "lib/fuzzer/Fuzzer*.def",
    ]),
    copts = libfuzzer_copts,
    visibility = ["//visibility:public"],
    alwayslink = True,
)
licenses(["notice"])  # Apache 2

cc_library(
    name = "libprotobuf_mutator",
    srcs = glob(
        [
            "src/**/*.cc",
            "src/**/*.h",
            "port/protobuf.h",
        ],
        exclude = ["**/*_test.cc"],
    ),
    hdrs = ["src/libfuzzer/libfuzzer_macro.h"],
    include_prefix = "libprotobuf_mutator",
    includes = ["."],
    visibility = ["//visibility:public"],
    deps = ["//external:protobuf"],
)
load(
    "@envoy//bazel:envoy_build_system.bzl",
    "envoy_cc_library",
    "envoy_cc_test",
    "envoy_cc_test_library",
)
load(
    "@envoy//bazel/external:quiche.bzl",
    "envoy_quic_cc_library",
    "envoy_quic_cc_test_library",
    "envoy_quiche_platform_impl_cc_library",
    "envoy_quiche_platform_impl_cc_test_library",
    "quiche_copts",
)
load("@rules_proto//proto:defs.bzl", "proto_library")

licenses(["notice"])  # Apache 2

# QUICHE is Google's implementation of QUIC and related protocols. It is the
# same code used in Chromium and Google's servers, but packaged in a form that
# is intended to be easier to incorporate into third-party projects.
#
# QUICHE code falls into three groups:
# 1. Platform-independent code. Most QUICHE code is in this category.
# 2. APIs and type aliases to platform-dependent code/types, referenced by code
#    in group 1. This group is called the "Platform API".
# 3. Definitions of types declared in group 2. This group is called the
#    "Platform impl", and must be provided by the codebase that embeds QUICHE.
#
# Concretely, header files in group 2 (the Platform API) #include header and
# source files in group 3 (the Platform impl). The #include path for these
# files is always "quiche_platform_impl/". The files in type 3 are placed in
# //source/common/quic/platform/ or //test/common/quic/platform/ and are
# defined with include_prefix set to "quiche_platform_impl".

src_files = glob([
    "**/*.h",
    "**/*.c",
    "**/*.cc",
    "**/*.inc",
    "**/*.proto",
])

test_suite(
    name = "ci_tests",
    tests = [
        "http2_adapter_callback_visitor_test",
        "http2_adapter_event_forwarder_test",
        "http2_adapter_header_validator_test",
        "http2_adapter_impl_comparison_test",
        "http2_adapter_nghttp2_adapter_test",
        "http2_adapter_nghttp2_data_provider_test",
        "http2_adapter_nghttp2_session_test",
        "http2_adapter_nghttp2_util_test",
        "http2_adapter_oghttp2_adapter_test",
        "http2_adapter_oghttp2_session_test",
        "http2_adapter_oghttp2_util_test",
        "http2_adapter_recording_http2_visitor_test",
        "http2_adapter_window_manager_test",
        "http2_platform_api_test",
        "quiche_balsa_balsa_frame_test",
        "quiche_balsa_balsa_headers_test",
        "quiche_balsa_header_properties_test",
        "quiche_balsa_simple_buffer_test",
        "quiche_common_test",
        "quiche_http_header_block_test",
    ],
)

envoy_cc_test_library(
    name = "http2_test_tools_random",
    srcs = ["quiche/http2/test_tools/http2_random.cc"],
    hdrs = ["quiche/http2/test_tools/http2_random.h"],
    external_deps = ["ssl"],
    repository = "@envoy",
    deps = [":quiche_common_platform"],
)

envoy_cc_library(
    name = "http2_adapter_callback_visitor",
    srcs = ["quiche/http2/adapter/callback_visitor.cc"],
    hdrs = ["quiche/http2/adapter/callback_visitor.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_http2_util",
        ":http2_adapter_http2_visitor_interface",
        ":http2_adapter_nghttp2_include",
        ":http2_adapter_nghttp2_util",
        ":quiche_common_callbacks",
        ":quiche_common_platform_export",
    ],
)

envoy_cc_test(
    name = "http2_adapter_callback_visitor_test",
    srcs = ["quiche/http2/adapter/callback_visitor_test.cc"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_callback_visitor",
        ":http2_adapter_mock_nghttp2_callbacks",
        ":http2_adapter_nghttp2_adapter",
        ":http2_adapter_nghttp2_test_utils",
        ":http2_adapter_test_frame_sequence",
        ":http2_adapter_test_utils",
        ":quiche_common_platform_test",
    ],
)

envoy_cc_library(
    name = "http2_adapter_data_source",
    hdrs = ["quiche/http2/adapter/data_source.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":quiche_common_platform_export",
    ],
)

envoy_cc_library(
    name = "http2_adapter_event_forwarder",
    srcs = ["quiche/http2/adapter/event_forwarder.cc"],
    hdrs = ["quiche/http2/adapter/event_forwarder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":quiche_common_callbacks",
        ":quiche_common_platform_export",
        ":spdy_core_http2_deframer_lib",
    ],
)

envoy_cc_test(
    name = "http2_adapter_event_forwarder_test",
    srcs = ["quiche/http2/adapter/event_forwarder_test.cc"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_event_forwarder",
        ":quiche_common_platform_test",
        ":spdy_core_protocol_lib",
        ":spdy_test_tools_mock_spdy_framer_visitor_lib",
    ],
)

envoy_cc_library(
    name = "http2_adapter_header_validator",
    srcs = [
        "quiche/http2/adapter/header_validator.cc",
        "quiche/http2/adapter/noop_header_validator.cc",
    ],
    hdrs = [
        "quiche/http2/adapter/header_validator.h",
        "quiche/http2/adapter/header_validator_base.h",
        "quiche/http2/adapter/noop_header_validator.h",
    ],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":quiche_common_platform_export",
    ],
)

envoy_cc_test(
    name = "http2_adapter_header_validator_test",
    srcs = [
        "quiche/http2/adapter/header_validator_test.cc",
        "quiche/http2/adapter/noop_header_validator_test.cc",
    ],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_header_validator",
        ":quiche_common_platform_test",
    ],
)

envoy_cc_library(
    name = "http2_adapter_http2_protocol",
    srcs = ["quiche/http2/adapter/http2_protocol.cc"],
    hdrs = ["quiche/http2/adapter/http2_protocol.h"],
    copts = quiche_copts,
    repository = "@envoy",
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_export",
        "@com_google_absl//absl/strings",
        "@com_google_absl//absl/types:variant",
    ],
)

envoy_cc_library(
    name = "http2_adapter_http2_util",
    srcs = ["quiche/http2/adapter/http2_util.cc"],
    hdrs = ["quiche/http2/adapter/http2_util.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_http2_protocol",
        ":http2_adapter_http2_visitor_interface",
        ":quiche_common_platform_export",
        ":spdy_core_protocol_lib",
    ],
)

envoy_cc_library(
    name = "http2_adapter_http2_visitor_interface",
    hdrs = ["quiche/http2/adapter/http2_visitor_interface.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_http2_protocol",
        ":quiche_common_platform_export",
    ],
)

envoy_cc_test(
    name = "http2_adapter_impl_comparison_test",
    srcs = ["quiche/http2/adapter/adapter_impl_comparison_test.cc"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter",
        ":http2_adapter_http2_protocol",
        ":http2_adapter_recording_http2_visitor",
        ":http2_adapter_test_frame_sequence",
        ":quiche_common_platform_test",
    ],
)

envoy_cc_library(
    name = "http2_adapter_interface_lib",
    hdrs = [
        "quiche/http2/adapter/http2_adapter.h",
        "quiche/http2/adapter/http2_session.h",
    ],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_data_source",
        ":http2_adapter_http2_protocol",
        ":http2_adapter_http2_visitor_interface",
        ":quiche_common_platform_export",
    ],
)

envoy_cc_test_library(
    name = "http2_adapter_mock_http2_visitor",
    hdrs = ["quiche/http2/adapter/mock_http2_visitor.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_http2_visitor_interface",
        ":quiche_common_platform_export",
        ":quiche_common_platform_test",
    ],
)

envoy_cc_test_library(
    name = "http2_adapter_mock_nghttp2_callbacks",
    srcs = ["quiche/http2/adapter/mock_nghttp2_callbacks.cc"],
    hdrs = ["quiche/http2/adapter/mock_nghttp2_callbacks.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_nghttp2_include",
        ":http2_adapter_nghttp2_util",
        ":quiche_common_platform_test",
    ],
)

envoy_cc_library(
    name = "http2_adapter_nghttp2_adapter",
    srcs = [
        "quiche/http2/adapter/nghttp2_adapter.cc",
        "quiche/http2/adapter/nghttp2_session.cc",
    ],
    hdrs = [
        "quiche/http2/adapter/nghttp2_adapter.h",
        "quiche/http2/adapter/nghttp2_session.h",
    ],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_callback_visitor",
        ":http2_adapter_data_source",
        ":http2_adapter_http2_protocol",
        ":http2_adapter_http2_util",
        ":http2_adapter_http2_visitor_interface",
        ":http2_adapter_interface_lib",
        ":http2_adapter_nghttp2_callbacks",
        ":http2_adapter_nghttp2_data_provider",
        ":http2_adapter_nghttp2_include",
        ":http2_adapter_nghttp2_util",
        ":http2_adapter_window_manager",
        ":http2_core_http2_trace_logging_lib",
        ":http2_core_priority_write_scheduler_lib",
        ":quiche_common_platform_export",
    ],
)

envoy_cc_test(
    name = "http2_adapter_nghttp2_adapter_test",
    srcs = ["quiche/http2/adapter/nghttp2_adapter_test.cc"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_http2_protocol",
        ":http2_adapter_http2_visitor_interface",
        ":http2_adapter_mock_http2_visitor",
        ":http2_adapter_nghttp2_adapter",
        ":http2_adapter_nghttp2_include",
        ":http2_adapter_nghttp2_test_utils",
        ":http2_adapter_oghttp2_util",
        ":http2_adapter_test_frame_sequence",
        ":http2_adapter_test_utils",
        ":quiche_common_platform_test",
    ],
)

envoy_cc_library(
    name = "http2_adapter_nghttp2_callbacks",
    srcs = ["quiche/http2/adapter/nghttp2_callbacks.cc"],
    hdrs = ["quiche/http2/adapter/nghttp2_callbacks.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_data_source",
        ":http2_adapter_http2_protocol",
        ":http2_adapter_http2_visitor_interface",
        ":http2_adapter_nghttp2_data_provider",
        ":http2_adapter_nghttp2_include",
        ":http2_adapter_nghttp2_util",
        ":quiche_common_platform",
        ":quiche_common_platform_export",
    ],
)

envoy_cc_library(
    name = "http2_adapter_nghttp2_data_provider",
    srcs = ["quiche/http2/adapter/nghttp2_data_provider.cc"],
    hdrs = ["quiche/http2/adapter/nghttp2_data_provider.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_data_source",
        ":http2_adapter_http2_visitor_interface",
        ":http2_adapter_nghttp2_include",
        ":http2_adapter_nghttp2_util",
    ],
)

envoy_cc_test(
    name = "http2_adapter_nghttp2_data_provider_test",
    srcs = ["quiche/http2/adapter/nghttp2_data_provider_test.cc"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_nghttp2_data_provider",
        ":http2_adapter_test_utils",
        ":quiche_common_platform_test",
    ],
)

envoy_cc_library(
    name = "http2_adapter_nghttp2_include",
    hdrs = ["quiche/http2/adapter/nghttp2.h"],
    copts = quiche_copts,
    external_deps = ["nghttp2"],
    repository = "@envoy",
)

envoy_cc_test(
    name = "http2_adapter_nghttp2_session_test",
    srcs = ["quiche/http2/adapter/nghttp2_session_test.cc"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter",
        ":http2_adapter_mock_http2_visitor",
        ":http2_adapter_nghttp2_callbacks",
        ":http2_adapter_nghttp2_util",
        ":http2_adapter_test_frame_sequence",
        ":http2_adapter_test_utils",
        ":quiche_common_platform_expect_bug",
        ":quiche_common_platform_test",
    ],
)

envoy_cc_test_library(
    name = "http2_adapter_nghttp2_test_utils",
    srcs = ["quiche/http2/adapter/nghttp2_test_utils.cc"],
    hdrs = ["quiche/http2/adapter/nghttp2_test_utils.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_http2_protocol",
        ":http2_adapter_nghttp2_include",
        ":http2_adapter_nghttp2_util",
        ":quiche_common_platform_export",
        ":quiche_common_platform_test",
    ],
)

envoy_cc_library(
    name = "http2_adapter_nghttp2_util",
    srcs = ["quiche/http2/adapter/nghttp2_util.cc"],
    hdrs = ["quiche/http2/adapter/nghttp2_util.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_data_source",
        ":http2_adapter_http2_protocol",
        ":http2_adapter_http2_visitor_interface",
        ":http2_adapter_nghttp2_include",
        ":quiche_common_platform_export",
        ":spdy_core_http2_header_block_lib",
    ],
)

envoy_cc_test(
    name = "http2_adapter_nghttp2_util_test",
    srcs = ["quiche/http2/adapter/nghttp2_util_test.cc"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_nghttp2_test_utils",
        ":http2_adapter_nghttp2_util",
        ":http2_adapter_test_utils",
        ":quiche_common_platform_test",
    ],
)

envoy_cc_library(
    name = "http2_adapter_oghttp2_adapter",
    srcs = [
        "quiche/http2/adapter/oghttp2_adapter.cc",
        "quiche/http2/adapter/oghttp2_session.cc",
    ],
    hdrs = [
        "quiche/http2/adapter/oghttp2_adapter.h",
        "quiche/http2/adapter/oghttp2_session.h",
    ],
    copts = quiche_copts,
    external_deps = [
        "abseil_algorithm",
    ],
    repository = "@envoy",
    deps = [
        ":http2_adapter_callback_visitor",
        ":http2_adapter_data_source",
        ":http2_adapter_event_forwarder",
        ":http2_adapter_header_validator",
        ":http2_adapter_http2_protocol",
        ":http2_adapter_http2_util",
        ":http2_adapter_http2_visitor_interface",
        ":http2_adapter_interface_lib",
        ":http2_adapter_oghttp2_util",
        ":http2_adapter_window_manager",
        ":http2_core_http2_trace_logging_lib",
        ":http2_core_priority_write_scheduler_lib",
        ":quiche_common_callbacks",
        ":spdy_core_framer_lib",
        ":spdy_core_http2_deframer_lib",
        ":spdy_core_http2_header_block_lib",
        ":spdy_core_protocol_lib",
        ":spdy_header_byte_listener_interface_lib",
        ":spdy_no_op_headers_handler_lib",
        "@com_google_absl//absl/cleanup",
    ],
)

envoy_cc_test(
    name = "http2_adapter_oghttp2_adapter_test",
    srcs = ["quiche/http2/adapter/oghttp2_adapter_test.cc"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_http2_protocol",
        ":http2_adapter_http2_visitor_interface",
        ":http2_adapter_mock_http2_visitor",
        ":http2_adapter_oghttp2_adapter",
        ":http2_adapter_oghttp2_util",
        ":http2_adapter_test_frame_sequence",
        ":http2_adapter_test_utils",
        ":quiche_common_platform_expect_bug",
        ":quiche_common_platform_test",
    ],
)

envoy_cc_test(
    name = "http2_adapter_oghttp2_session_test",
    srcs = ["quiche/http2/adapter/oghttp2_session_test.cc"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_mock_http2_visitor",
        ":http2_adapter_oghttp2_adapter",
        ":http2_adapter_test_frame_sequence",
        ":http2_adapter_test_utils",
        ":quiche_common_platform_test",
    ],
)

envoy_cc_library(
    name = "http2_adapter_oghttp2_util",
    srcs = ["quiche/http2/adapter/oghttp2_util.cc"],
    hdrs = ["quiche/http2/adapter/oghttp2_util.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_http2_protocol",
        ":quiche_common_platform_export",
        ":spdy_core_http2_header_block_lib",
    ],
)

envoy_cc_test(
    name = "http2_adapter_oghttp2_util_test",
    srcs = ["quiche/http2/adapter/oghttp2_util_test.cc"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_http2_protocol",
        ":http2_adapter_oghttp2_util",
        ":http2_adapter_test_frame_sequence",
        ":quiche_common_platform_test",
    ],
)

envoy_cc_test_library(
    name = "http2_adapter_recording_http2_visitor",
    srcs = ["quiche/http2/adapter/recording_http2_visitor.cc"],
    hdrs = ["quiche/http2/adapter/recording_http2_visitor.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_http2_protocol",
        ":http2_adapter_http2_util",
        ":http2_adapter_http2_visitor_interface",
        ":quiche_common_platform_export",
        ":quiche_common_platform_test",
    ],
)

envoy_cc_test(
    name = "http2_adapter_recording_http2_visitor_test",
    srcs = ["quiche/http2/adapter/recording_http2_visitor_test.cc"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_http2_protocol",
        ":http2_adapter_http2_visitor_interface",
        ":http2_adapter_recording_http2_visitor",
        ":http2_test_tools_random",
        ":quiche_common_platform_test",
    ],
)

envoy_cc_test_library(
    name = "http2_adapter_test_frame_sequence",
    srcs = ["quiche/http2/adapter/test_frame_sequence.cc"],
    hdrs = ["quiche/http2/adapter/test_frame_sequence.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_http2_protocol",
        ":http2_adapter_http2_util",
        ":http2_adapter_oghttp2_util",
        ":quiche_common_platform_export",
        ":spdy_core_framer_lib",
        ":spdy_core_hpack_hpack_lib",
        ":spdy_core_protocol_lib",
    ],
)

envoy_cc_test_library(
    name = "http2_adapter_test_utils",
    srcs = ["quiche/http2/adapter/test_utils.cc"],
    hdrs = ["quiche/http2/adapter/test_utils.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_data_source",
        ":http2_adapter_http2_protocol",
        ":http2_adapter_http2_visitor_interface",
        ":http2_adapter_mock_http2_visitor",
        ":quiche_common_platform_test",
        ":spdy_core_hpack_hpack_lib",
        ":spdy_core_http2_header_block_lib",
        ":spdy_core_protocol_lib",
    ],
)

envoy_cc_test_library(
    name = "http2_adapter_test_utils_test",
    srcs = ["quiche/http2/adapter/test_utils_test.cc"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_test_utils",
        ":quiche_common_platform_test",
        ":spdy_core_framer_lib",
    ],
)

envoy_cc_library(
    name = "http2_adapter_window_manager",
    srcs = ["quiche/http2/adapter/window_manager.cc"],
    hdrs = ["quiche/http2/adapter/window_manager.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":quiche_common_callbacks",
        ":quiche_common_platform",
        ":quiche_common_platform_export",
    ],
)

envoy_cc_test(
    name = "http2_adapter_window_manager_test",
    srcs = ["quiche/http2/adapter/window_manager_test.cc"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_adapter_window_manager",
        ":http2_test_tools_random",
        ":quiche_common_platform_expect_bug",
        ":quiche_common_platform_export",
        ":quiche_common_platform_test",
        "@com_google_absl//absl/functional:bind_front",
    ],
)

envoy_cc_library(
    name = "http2_adapter",
    copts = quiche_copts,
    repository = "@envoy",
    visibility = ["//visibility:public"],
    deps = [
        ":http2_adapter_nghttp2_adapter",
        ":http2_adapter_oghttp2_adapter",
    ],
)

envoy_cc_library(
    name = "http2_core_http2_priority_write_scheduler_lib",
    hdrs = ["quiche/http2/core/http2_priority_write_scheduler.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":quiche_common_platform",
        ":spdy_core_intrusive_list_lib",
        ":spdy_core_protocol_lib",
    ],
)

envoy_cc_library(
    name = "http2_core_priority_write_scheduler_lib",
    hdrs = ["quiche/http2/core/priority_write_scheduler.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":quiche_common_circular_deque_lib",
        ":quiche_common_platform",
        ":spdy_core_protocol_lib",
    ],
)

envoy_cc_library(
    name = "http2_core_http2_trace_logging_lib",
    srcs = ["quiche/http2/core/http2_trace_logging.cc"],
    hdrs = ["quiche/http2/core/http2_trace_logging.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":quiche_common_platform",
        ":spdy_core_headers_handler_interface_lib",
        ":spdy_core_http2_deframer_lib",
        ":spdy_core_protocol_lib",
        ":spdy_core_recording_headers_handler_lib",
    ],
)

envoy_cc_library(
    name = "http2_constants_lib",
    srcs = ["quiche/http2/http2_constants.cc"],
    hdrs = ["quiche/http2/http2_constants.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":quiche_common_platform",
        ":quiche_common_text_utils_lib",
    ],
)

envoy_cc_library(
    name = "http2_structures_lib",
    srcs = ["quiche/http2/http2_structures.cc"],
    hdrs = ["quiche/http2/http2_structures.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_decoder_decode_buffer_lib",
    srcs = ["quiche/http2/decoder/decode_buffer.cc"],
    hdrs = ["quiche/http2/decoder/decode_buffer.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [":quiche_common_platform"],
)

envoy_cc_library(
    name = "http2_decoder_decode_http2_structures_lib",
    srcs = ["quiche/http2/decoder/decode_http2_structures.cc"],
    hdrs = ["quiche/http2/decoder/decode_http2_structures.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":http2_decoder_decode_buffer_lib",
        ":http2_structures_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_decoder_decode_status_lib",
    srcs = ["quiche/http2/decoder/decode_status.cc"],
    hdrs = ["quiche/http2/decoder/decode_status.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [":quiche_common_platform"],
)

envoy_cc_library(
    name = "http2_decoder_frame_decoder_state_lib",
    srcs = ["quiche/http2/decoder/frame_decoder_state.cc"],
    hdrs = ["quiche/http2/decoder/frame_decoder_state.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_decoder_frame_decoder_listener_lib",
        ":http2_decoder_structure_decoder_lib",
        ":http2_structures_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_decoder_frame_decoder_lib",
    srcs = ["quiche/http2/decoder/http2_frame_decoder.cc"],
    hdrs = [
        "quiche/http2/decoder/frame_decoder_state.h",
        "quiche/http2/decoder/http2_frame_decoder.h",
    ],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_decoder_frame_decoder_listener_lib",
        ":http2_decoder_frame_decoder_state_lib",
        ":http2_decoder_payload_decoders_altsvc_payload_decoder_lib",
        ":http2_decoder_payload_decoders_continuation_payload_decoder_lib",
        ":http2_decoder_payload_decoders_data_payload_decoder_lib",
        ":http2_decoder_payload_decoders_goaway_payload_decoder_lib",
        ":http2_decoder_payload_decoders_headers_payload_decoder_lib",
        ":http2_decoder_payload_decoders_ping_payload_decoder_lib",
        ":http2_decoder_payload_decoders_priority_payload_decoder_lib",
        ":http2_decoder_payload_decoders_priority_update_payload_decoder_lib",
        ":http2_decoder_payload_decoders_push_promise_payload_decoder_lib",
        ":http2_decoder_payload_decoders_rst_stream_payload_decoder_lib",
        ":http2_decoder_payload_decoders_settings_payload_decoder_lib",
        ":http2_decoder_payload_decoders_unknown_payload_decoder_lib",
        ":http2_decoder_payload_decoders_window_update_payload_decoder_lib",
        ":http2_decoder_structure_decoder_lib",
        ":http2_hpack_varint_hpack_varint_decoder_lib",
        ":http2_structures_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_decoder_frame_decoder_listener_lib",
    srcs = ["quiche/http2/decoder/http2_frame_decoder_listener.cc"],
    hdrs = ["quiche/http2/decoder/http2_frame_decoder_listener.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":http2_structures_lib",
    ],
)

envoy_cc_library(
    name = "http2_decoder_payload_decoders_altsvc_payload_decoder_lib",
    srcs = ["quiche/http2/decoder/payload_decoders/altsvc_payload_decoder.cc"],
    hdrs = ["quiche/http2/decoder/payload_decoders/altsvc_payload_decoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_decoder_frame_decoder_listener_lib",
        ":http2_decoder_frame_decoder_state_lib",
        ":http2_structures_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_decoder_payload_decoders_continuation_payload_decoder_lib",
    srcs = ["quiche/http2/decoder/payload_decoders/continuation_payload_decoder.cc"],
    hdrs = ["quiche/http2/decoder/payload_decoders/continuation_payload_decoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_decoder_frame_decoder_listener_lib",
        ":http2_decoder_frame_decoder_state_lib",
        ":http2_structures_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_decoder_payload_decoders_data_payload_decoder_lib",
    srcs = ["quiche/http2/decoder/payload_decoders/data_payload_decoder.cc"],
    hdrs = ["quiche/http2/decoder/payload_decoders/data_payload_decoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_decoder_frame_decoder_listener_lib",
        ":http2_decoder_frame_decoder_state_lib",
        ":http2_structures_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_decoder_payload_decoders_goaway_payload_decoder_lib",
    srcs = ["quiche/http2/decoder/payload_decoders/goaway_payload_decoder.cc"],
    hdrs = ["quiche/http2/decoder/payload_decoders/goaway_payload_decoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_decoder_frame_decoder_listener_lib",
        ":http2_decoder_frame_decoder_state_lib",
        ":http2_structures_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_decoder_payload_decoders_headers_payload_decoder_lib",
    srcs = ["quiche/http2/decoder/payload_decoders/headers_payload_decoder.cc"],
    hdrs = ["quiche/http2/decoder/payload_decoders/headers_payload_decoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_decoder_frame_decoder_listener_lib",
        ":http2_decoder_frame_decoder_state_lib",
        ":http2_structures_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_decoder_payload_decoders_ping_payload_decoder_lib",
    srcs = ["quiche/http2/decoder/payload_decoders/ping_payload_decoder.cc"],
    hdrs = ["quiche/http2/decoder/payload_decoders/ping_payload_decoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_decoder_frame_decoder_listener_lib",
        ":http2_decoder_frame_decoder_state_lib",
        ":http2_structures_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_decoder_payload_decoders_priority_payload_decoder_lib",
    srcs = ["quiche/http2/decoder/payload_decoders/priority_payload_decoder.cc"],
    hdrs = ["quiche/http2/decoder/payload_decoders/priority_payload_decoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_decoder_frame_decoder_listener_lib",
        ":http2_decoder_frame_decoder_state_lib",
        ":http2_structures_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_decoder_payload_decoders_push_promise_payload_decoder_lib",
    srcs = ["quiche/http2/decoder/payload_decoders/push_promise_payload_decoder.cc"],
    hdrs = ["quiche/http2/decoder/payload_decoders/push_promise_payload_decoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_decoder_frame_decoder_listener_lib",
        ":http2_decoder_frame_decoder_state_lib",
        ":http2_structures_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_decoder_payload_decoders_rst_stream_payload_decoder_lib",
    srcs = ["quiche/http2/decoder/payload_decoders/rst_stream_payload_decoder.cc"],
    hdrs = ["quiche/http2/decoder/payload_decoders/rst_stream_payload_decoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_decoder_frame_decoder_listener_lib",
        ":http2_decoder_frame_decoder_state_lib",
        ":http2_structures_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_decoder_payload_decoders_settings_payload_decoder_lib",
    srcs = ["quiche/http2/decoder/payload_decoders/settings_payload_decoder.cc"],
    hdrs = ["quiche/http2/decoder/payload_decoders/settings_payload_decoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_decoder_frame_decoder_listener_lib",
        ":http2_decoder_frame_decoder_state_lib",
        ":http2_structures_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_decoder_payload_decoders_unknown_payload_decoder_lib",
    srcs = ["quiche/http2/decoder/payload_decoders/unknown_payload_decoder.cc"],
    hdrs = ["quiche/http2/decoder/payload_decoders/unknown_payload_decoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_decoder_frame_decoder_listener_lib",
        ":http2_decoder_frame_decoder_state_lib",
        ":http2_structures_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_decoder_payload_decoders_priority_update_payload_decoder_lib",
    srcs = [
        "quiche/http2/decoder/payload_decoders/priority_update_payload_decoder.cc",
    ],
    hdrs = [
        "quiche/http2/decoder/payload_decoders/priority_update_payload_decoder.h",
    ],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_decoder_frame_decoder_listener_lib",
        ":http2_decoder_frame_decoder_state_lib",
        ":http2_structures_lib",
        ":quiche_common_platform",
        ":quiche_common_platform_export",
    ],
)

envoy_cc_library(
    name = "http2_decoder_payload_decoders_window_update_payload_decoder_lib",
    srcs = ["quiche/http2/decoder/payload_decoders/window_update_payload_decoder.cc"],
    hdrs = ["quiche/http2/decoder/payload_decoders/window_update_payload_decoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_http2_structures_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_decoder_frame_decoder_listener_lib",
        ":http2_decoder_frame_decoder_state_lib",
        ":http2_structures_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_decoder_structure_decoder_lib",
    srcs = ["quiche/http2/decoder/http2_structure_decoder.cc"],
    hdrs = ["quiche/http2/decoder/http2_structure_decoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_http2_structures_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_structures_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_hpack_decoder_hpack_block_decoder_lib",
    srcs = ["quiche/http2/hpack/decoder/hpack_block_decoder.cc"],
    hdrs = ["quiche/http2/hpack/decoder/hpack_block_decoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_hpack_decoder_hpack_decoding_error_lib",
        ":http2_hpack_decoder_hpack_entry_decoder_lib",
        ":http2_hpack_decoder_hpack_entry_decoder_listener_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_hpack_decoder_hpack_decoder_lib",
    srcs = ["quiche/http2/hpack/decoder/hpack_decoder.cc"],
    hdrs = ["quiche/http2/hpack/decoder/hpack_decoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    visibility = ["//visibility:public"],
    deps = [
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_hpack_decoder_hpack_block_decoder_lib",
        ":http2_hpack_decoder_hpack_decoder_listener_lib",
        ":http2_hpack_decoder_hpack_decoder_state_lib",
        ":http2_hpack_decoder_hpack_decoder_tables_lib",
        ":http2_hpack_decoder_hpack_decoding_error_lib",
        ":http2_hpack_decoder_hpack_whole_entry_buffer_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_hpack_decoder_hpack_decoder_listener_lib",
    srcs = ["quiche/http2/hpack/decoder/hpack_decoder_listener.cc"],
    hdrs = ["quiche/http2/hpack/decoder/hpack_decoder_listener.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_hpack_hpack_constants_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_hpack_decoder_hpack_decoder_state_lib",
    srcs = ["quiche/http2/hpack/decoder/hpack_decoder_state.cc"],
    hdrs = ["quiche/http2/hpack/decoder/hpack_decoder_state.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":http2_hpack_decoder_hpack_decoder_listener_lib",
        ":http2_hpack_decoder_hpack_decoder_string_buffer_lib",
        ":http2_hpack_decoder_hpack_decoder_tables_lib",
        ":http2_hpack_decoder_hpack_decoding_error_lib",
        ":http2_hpack_decoder_hpack_whole_entry_listener_lib",
        ":http2_hpack_hpack_constants_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_hpack_decoder_hpack_decoder_string_buffer_lib",
    srcs = ["quiche/http2/hpack/decoder/hpack_decoder_string_buffer.cc"],
    hdrs = ["quiche/http2/hpack/decoder/hpack_decoder_string_buffer.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_hpack_huffman_hpack_huffman_decoder_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_hpack_decoder_hpack_decoder_tables_lib",
    srcs = ["quiche/http2/hpack/decoder/hpack_decoder_tables.cc"],
    hdrs = ["quiche/http2/hpack/decoder/hpack_decoder_tables.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":http2_hpack_hpack_constants_lib",
        ":http2_hpack_hpack_static_table_entries_lib",
        ":quiche_common_circular_deque_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_hpack_decoder_hpack_decoding_error_lib",
    srcs = ["quiche/http2/hpack/decoder/hpack_decoding_error.cc"],
    hdrs = ["quiche/http2/hpack/decoder/hpack_decoding_error.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_hpack_decoder_hpack_entry_decoder_lib",
    srcs = ["quiche/http2/hpack/decoder/hpack_entry_decoder.cc"],
    hdrs = ["quiche/http2/hpack/decoder/hpack_entry_decoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_hpack_decoder_hpack_decoding_error_lib",
        ":http2_hpack_decoder_hpack_entry_decoder_listener_lib",
        ":http2_hpack_decoder_hpack_entry_type_decoder_lib",
        ":http2_hpack_decoder_hpack_string_decoder_lib",
        ":http2_hpack_hpack_constants_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_hpack_decoder_hpack_entry_decoder_listener_lib",
    srcs = ["quiche/http2/hpack/decoder/hpack_entry_decoder_listener.cc"],
    hdrs = ["quiche/http2/hpack/decoder/hpack_entry_decoder_listener.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_hpack_hpack_constants_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_hpack_decoder_hpack_entry_type_decoder_lib",
    srcs = ["quiche/http2/hpack/decoder/hpack_entry_type_decoder.cc"],
    hdrs = ["quiche/http2/hpack/decoder/hpack_entry_type_decoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_hpack_hpack_constants_lib",
        ":http2_hpack_varint_hpack_varint_decoder_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_hpack_decoder_hpack_string_decoder_lib",
    srcs = ["quiche/http2/hpack/decoder/hpack_string_decoder.cc"],
    hdrs = ["quiche/http2/hpack/decoder/hpack_string_decoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_hpack_varint_hpack_varint_decoder_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_hpack_decoder_hpack_string_decoder_listener_lib",
    srcs = ["quiche/http2/hpack/decoder/hpack_string_decoder_listener.cc"],
    hdrs = ["quiche/http2/hpack/decoder/hpack_string_decoder_listener.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [":quiche_common_platform"],
)

envoy_cc_library(
    name = "http2_hpack_decoder_hpack_whole_entry_buffer_lib",
    srcs = ["quiche/http2/hpack/decoder/hpack_whole_entry_buffer.cc"],
    hdrs = ["quiche/http2/hpack/decoder/hpack_whole_entry_buffer.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_hpack_decoder_hpack_decoder_string_buffer_lib",
        ":http2_hpack_decoder_hpack_decoding_error_lib",
        ":http2_hpack_decoder_hpack_entry_decoder_listener_lib",
        ":http2_hpack_decoder_hpack_whole_entry_listener_lib",
        ":http2_hpack_hpack_constants_lib",
        ":quiche_common_platform",
        ":quiche_common_text_utils_lib",
    ],
)

envoy_cc_library(
    name = "http2_hpack_decoder_hpack_whole_entry_listener_lib",
    srcs = ["quiche/http2/hpack/decoder/hpack_whole_entry_listener.cc"],
    hdrs = ["quiche/http2/hpack/decoder/hpack_whole_entry_listener.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_hpack_decoder_hpack_decoder_string_buffer_lib",
        ":http2_hpack_decoder_hpack_decoding_error_lib",
        ":http2_hpack_hpack_constants_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_hpack_huffman_hpack_huffman_decoder_lib",
    srcs = ["quiche/http2/hpack/huffman/hpack_huffman_decoder.cc"],
    hdrs = ["quiche/http2/hpack/huffman/hpack_huffman_decoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [":quiche_common_platform"],
)

envoy_cc_library(
    name = "http2_hpack_huffman_hpack_huffman_encoder_lib",
    srcs = ["quiche/http2/hpack/huffman/hpack_huffman_encoder.cc"],
    hdrs = ["quiche/http2/hpack/huffman/hpack_huffman_encoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_hpack_huffman_huffman_spec_tables_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_hpack_huffman_huffman_spec_tables_lib",
    srcs = ["quiche/http2/hpack/huffman/huffman_spec_tables.cc"],
    hdrs = ["quiche/http2/hpack/huffman/huffman_spec_tables.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_hpack_hpack_constants_lib",
    srcs = ["quiche/http2/hpack/http2_hpack_constants.cc"],
    hdrs = ["quiche/http2/hpack/http2_hpack_constants.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [":quiche_common_platform"],
)

envoy_cc_library(
    name = "http2_hpack_hpack_static_table_entries_lib",
    hdrs = ["quiche/http2/hpack/hpack_static_table_entries.inc"],
    repository = "@envoy",
)

envoy_cc_library(
    name = "http2_hpack_varint_hpack_varint_decoder_lib",
    srcs = ["quiche/http2/hpack/varint/hpack_varint_decoder.cc"],
    hdrs = ["quiche/http2/hpack/varint/hpack_varint_decoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "http2_hpack_varint_hpack_varint_encoder_lib",
    srcs = ["quiche/http2/hpack/varint/hpack_varint_encoder.cc"],
    hdrs = ["quiche/http2/hpack/varint/hpack_varint_encoder.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [":quiche_common_platform"],
)

envoy_cc_library(
    name = "spdy_no_op_headers_handler_lib",
    hdrs = ["quiche/spdy/core/no_op_headers_handler.h"],
    repository = "@envoy",
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform",
        ":spdy_header_byte_listener_interface_lib",
    ],
)

envoy_cc_library(
    name = "spdy_header_byte_listener_interface_lib",
    hdrs = ["quiche/spdy/core/header_byte_listener_interface.h"],
    repository = "@envoy",
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "spdy_core_alt_svc_wire_format_lib",
    srcs = ["quiche/spdy/core/spdy_alt_svc_wire_format.cc"],
    hdrs = ["quiche/spdy/core/spdy_alt_svc_wire_format.h"],
    copts = quiche_copts,
    repository = "@envoy",
    visibility = ["//visibility:public"],
    deps = [":quiche_common_platform"],
)

envoy_cc_library(
    name = "spdy_core_framer_lib",
    srcs = [
        "quiche/spdy/core/spdy_frame_builder.cc",
        "quiche/spdy/core/spdy_framer.cc",
    ],
    hdrs = [
        "quiche/spdy/core/spdy_frame_builder.h",
        "quiche/spdy/core/spdy_framer.h",
    ],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":quiche_common_platform",
        ":spdy_core_alt_svc_wire_format_lib",
        ":spdy_core_headers_handler_interface_lib",
        ":spdy_core_hpack_hpack_lib",
        ":spdy_core_http2_header_block_lib",
        ":spdy_core_protocol_lib",
        ":spdy_core_zero_copy_output_buffer_lib",
    ],
)

envoy_cc_library(
    name = "spdy_core_http2_header_block_lib",
    hdrs = ["quiche/spdy/core/http2_header_block.h"],
    copts = quiche_copts,
    repository = "@envoy",
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_lib",
        ":quiche_common_platform",
        ":quiche_common_text_utils_lib",
        ":quiche_http_header_block_lib",
    ],
)

envoy_cc_library(
    name = "spdy_core_headers_handler_interface_lib",
    hdrs = ["quiche/spdy/core/spdy_headers_handler_interface.h"],
    copts = quiche_copts,
    repository = "@envoy",
    visibility = ["//visibility:public"],
    deps = [":quiche_common_platform"],
)

envoy_cc_library(
    name = "spdy_core_http2_deframer_lib",
    srcs = ["quiche/spdy/core/http2_frame_decoder_adapter.cc"],
    hdrs = ["quiche/spdy/core/http2_frame_decoder_adapter.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_constants_lib",
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_decoder_frame_decoder_lib",
        ":http2_decoder_frame_decoder_listener_lib",
        ":http2_structures_lib",
        ":quiche_common_platform",
        ":spdy_core_alt_svc_wire_format_lib",
        ":spdy_core_headers_handler_interface_lib",
        ":spdy_core_hpack_hpack_decoder_adapter_lib",
        ":spdy_core_hpack_hpack_lib",
        ":spdy_core_http2_header_block_lib",
        ":spdy_core_protocol_lib",
    ],
)

envoy_cc_library(
    name = "spdy_core_intrusive_list_lib",
    hdrs = ["quiche/spdy/core/spdy_intrusive_list.h"],
    repository = "@envoy",
)

envoy_cc_library(
    name = "spdy_core_hpack_hpack_lib",
    srcs = [
        "quiche/spdy/core/hpack/hpack_constants.cc",
        "quiche/spdy/core/hpack/hpack_encoder.cc",
        "quiche/spdy/core/hpack/hpack_entry.cc",
        "quiche/spdy/core/hpack/hpack_header_table.cc",
        "quiche/spdy/core/hpack/hpack_output_stream.cc",
        "quiche/spdy/core/hpack/hpack_static_table.cc",
    ],
    hdrs = [
        "quiche/spdy/core/hpack/hpack_constants.h",
        "quiche/spdy/core/hpack/hpack_encoder.h",
        "quiche/spdy/core/hpack/hpack_entry.h",
        "quiche/spdy/core/hpack/hpack_header_table.h",
        "quiche/spdy/core/hpack/hpack_output_stream.h",
        "quiche/spdy/core/hpack/hpack_static_table.h",
    ],
    copts = quiche_copts,
    repository = "@envoy",
    visibility = ["//visibility:public"],
    deps = [
        ":http2_hpack_huffman_hpack_huffman_encoder_lib",
        ":quiche_common_callbacks",
        ":quiche_common_circular_deque_lib",
        ":quiche_common_platform",
        ":spdy_core_protocol_lib",
    ],
)

envoy_cc_library(
    name = "spdy_core_hpack_hpack_decoder_adapter_lib",
    srcs = ["quiche/spdy/core/hpack/hpack_decoder_adapter.cc"],
    hdrs = ["quiche/spdy/core/hpack/hpack_decoder_adapter.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":http2_hpack_decoder_hpack_decoder_lib",
        ":http2_hpack_decoder_hpack_decoder_listener_lib",
        ":http2_hpack_decoder_hpack_decoder_tables_lib",
        ":http2_hpack_hpack_constants_lib",
        ":quiche_common_platform",
        ":spdy_core_headers_handler_interface_lib",
        ":spdy_core_hpack_hpack_lib",
        ":spdy_core_http2_header_block_lib",
        ":spdy_no_op_headers_handler_lib",
    ],
)

envoy_cc_test_library(
    name = "spdy_test_tools_mock_spdy_framer_visitor_lib",
    srcs = ["quiche/spdy/test_tools/mock_spdy_framer_visitor.cc"],
    hdrs = ["quiche/spdy/test_tools/mock_spdy_framer_visitor.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":quiche_common_platform_test",
        ":spdy_core_http2_deframer_lib",
        ":spdy_core_recording_headers_handler_lib",
        ":spdy_test_tools_test_utils_lib",
    ],
)

envoy_cc_library(
    name = "spdy_core_protocol_lib",
    srcs = ["quiche/spdy/core/spdy_protocol.cc"],
    hdrs = [
        "quiche/spdy/core/spdy_bitmasks.h",
        "quiche/spdy/core/spdy_protocol.h",
    ],
    copts = quiche_copts,
    repository = "@envoy",
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform",
        ":spdy_core_alt_svc_wire_format_lib",
        ":spdy_core_http2_header_block_lib",
    ],
)

envoy_cc_library(
    name = "spdy_core_recording_headers_handler_lib",
    srcs = ["quiche/spdy/core/recording_headers_handler.cc"],
    hdrs = ["quiche/spdy/core/recording_headers_handler.h"],
    repository = "@envoy",
    deps = [
        ":spdy_core_headers_handler_interface_lib",
        ":spdy_core_http2_header_block_lib",
    ],
)

envoy_cc_library(
    name = "spdy_core_write_scheduler_lib",
    hdrs = ["quiche/spdy/core/write_scheduler.h"],
    repository = "@envoy",
    deps = [
        ":quiche_common_platform",
        ":spdy_core_protocol_lib",
    ],
)

envoy_cc_test_library(
    name = "spdy_test_tools_test_utils_lib",
    srcs = ["quiche/spdy/test_tools/spdy_test_utils.cc"],
    hdrs = ["quiche/spdy/test_tools/spdy_test_utils.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":quiche_common_platform",
        ":quiche_common_test_tools_test_utils_lib",
        ":spdy_core_headers_handler_interface_lib",
        ":spdy_core_http2_header_block_lib",
        ":spdy_core_protocol_lib",
    ],
)

envoy_cc_library(
    name = "spdy_core_zero_copy_output_buffer_lib",
    hdrs = ["quiche/spdy/core/zero_copy_output_buffer.h"],
    copts = quiche_copts,
    repository = "@envoy",
)

envoy_cc_library(
    name = "quic_platform",
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_core_time_lib",
        ":quic_platform_base",
        ":quic_platform_hostname_utils",
        ":quic_platform_mutex",
    ],
)

envoy_cc_library(
    name = "quic_platform_hostname_utils",
    hdrs = [
        "quiche/quic/platform/api/quic_hostname_utils.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_hostname_utils",
    ],
)

envoy_cc_library(
    name = "quic_platform_stack_trace",
    hdrs = [
        "quiche/quic/platform/api/quic_stack_trace.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_stack_trace",
    ],
)

envoy_cc_library(
    name = "quic_platform_server_stats",
    hdrs = [
        "quiche/quic/platform/api/quic_server_stats.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_server_stats",
    ],
)

envoy_cc_library(
    name = "quic_platform_mutex",
    hdrs = [
        "quiche/quic/platform/api/quic_mutex.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_mutex",
    ],
)

envoy_cc_library(
    name = "quic_platform_base",
    hdrs = [
        "quiche/quic/platform/api/quic_client_stats.h",
        "quiche/quic/platform/api/quic_exported_stats.h",
        "quiche/quic/platform/api/quic_flag_utils.h",
        "quiche/quic/platform/api/quic_flags.h",
        "quiche/quic/platform/api/quic_logging.h",
        "quiche/quic/platform/api/quic_testvalue.h",
        # TODO: uncomment the following files as implementations are added.
        # "quiche/quic/platform/api/quic_fuzzed_data_provider.h",
        # "quiche/quic/platform/api/quic_test_loopback.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_platform_bug_tracker",
        ":quic_platform_server_stats",
        ":quic_platform_stack_trace",
        ":quiche_common_buffer_allocator_lib",
        ":quiche_common_lib",
        ":quiche_common_platform_client_stats",
        ":quiche_common_platform_export",
        ":quiche_common_platform_server_stats",
        ":quiche_common_platform_testvalue",
        "@envoy//source/common/quic/platform:quic_base_impl_lib",
    ],
)

envoy_cc_library(
    name = "quic_platform_bug_tracker",
    hdrs = [
        "quiche/quic/platform/api/quic_bug_tracker.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_bug_tracker",
    ],
)

envoy_cc_library(
    name = "quic_platform_export",
    hdrs = ["quiche/quic/platform/api/quic_export.h"],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_export",
    ],
)

envoy_cc_test_library(
    name = "quic_platform_expect_bug",
    hdrs = ["quiche/quic/platform/api/quic_expect_bug.h"],
    repository = "@envoy",
    tags = ["nofips"],
    deps = [":quiche_common_platform_expect_bug"],
)

envoy_cc_library(
    name = "quic_platform_ip_address_family",
    hdrs = ["quiche/quic/platform/api/quic_ip_address_family.h"],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_platform_bug_tracker",
        ":quiche_common_ip_address_family",
    ],
)

envoy_cc_library(
    name = "quiche_common_ip_address_family",
    srcs = ["quiche/common/quiche_ip_address_family.cc"],
    hdrs = ["quiche/common/quiche_ip_address_family.h"],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_platform_bug_tracker",
    ],
)

envoy_cc_library(
    name = "quic_platform_ip_address",
    hdrs = ["quiche/quic/platform/api/quic_ip_address.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_platform_base",
        ":quic_platform_export",
        ":quiche_common_ip_address",
    ],
)

envoy_cc_library(
    name = "quiche_common_ip_address",
    srcs = ["quiche/common/quiche_ip_address.cc"],
    hdrs = ["quiche/common/quiche_ip_address.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_platform_base",
        ":quic_platform_export",
        ":quic_platform_ip_address_family",
    ],
)

envoy_cc_test_library(
    name = "quic_platform_port_utils",
    hdrs = ["quiche/quic/platform/api/quic_port_utils.h"],
    repository = "@envoy",
    tags = ["nofips"],
)

envoy_cc_library(
    name = "quic_platform_udp_socket_platform",
    hdrs = select({
        "@envoy//bazel:linux": ["quiche/quic/platform/api/quic_udp_socket_platform_api.h"],
        "//conditions:default": [],
    }),
    repository = "@envoy",
    tags = ["nofips"],
    deps = [":quiche_common_platform_udp_socket_platform"],
)

envoy_cc_library(
    name = "quic_platform_socket_address",
    srcs = ["quiche/quic/platform/api/quic_socket_address.cc"],
    hdrs = ["quiche/quic/platform/api/quic_socket_address.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_platform_export",
        ":quic_platform_ip_address",
    ],
)

envoy_cc_test_library(
    name = "quic_platform_test",
    hdrs = ["quiche/quic/platform/api/quic_test.h"],
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quic_platform_base",
        ":quiche_common_platform_test",
        "@envoy//test/common/quic/platform:quiche_test_impl_lib",
    ],
)

envoy_cc_test_library(
    name = "quic_platform_test_output",
    hdrs = ["quiche/quic/platform/api/quic_test_output.h"],
    repository = "@envoy",
    tags = ["nofips"],
    deps = [":quiche_common_platform_test_output"],
)

envoy_cc_test_library(
    name = "quic_platform_thread",
    hdrs = ["quiche/quic/platform/api/quic_thread.h"],
    repository = "@envoy",
    tags = ["nofips"],
    deps = [":quiche_common_platform_thread"],
)

#TODO(danzh) Figure out why using envoy_proto_library() fails.
proto_library(
    name = "quic_core_proto_cached_network_parameters_proto",
    srcs = ["quiche/quic/core/proto/cached_network_parameters.proto"],
)

cc_proto_library(
    name = "quic_core_proto_cached_network_parameters_proto_cc",
    deps = [":quic_core_proto_cached_network_parameters_proto"],
)

envoy_cc_library(
    name = "quic_core_proto_cached_network_parameters_proto_header",
    hdrs = ["quiche/quic/core/proto/cached_network_parameters_proto.h"],
    repository = "@envoy",
    tags = ["nofips"],
    deps = [":quic_core_proto_cached_network_parameters_proto_cc"],
)

proto_library(
    name = "quic_core_proto_source_address_token_proto",
    srcs = ["quiche/quic/core/proto/source_address_token.proto"],
    deps = [":quic_core_proto_cached_network_parameters_proto"],
)

cc_proto_library(
    name = "quic_core_proto_source_address_token_proto_cc",
    deps = [":quic_core_proto_source_address_token_proto"],
)

envoy_cc_library(
    name = "quic_core_proto_source_address_token_proto_header",
    hdrs = ["quiche/quic/core/proto/source_address_token_proto.h"],
    repository = "@envoy",
    tags = ["nofips"],
    deps = [":quic_core_proto_source_address_token_proto_cc"],
)

proto_library(
    name = "quic_core_proto_crypto_server_config_proto",
    srcs = ["quiche/quic/core/proto/crypto_server_config.proto"],
)

cc_proto_library(
    name = "quic_core_proto_crypto_server_config_proto_cc",
    deps = [":quic_core_proto_crypto_server_config_proto"],
)

envoy_cc_library(
    name = "quic_core_proto_crypto_server_config_proto_header",
    hdrs = ["quiche/quic/core/proto/crypto_server_config_proto.h"],
    repository = "@envoy",
    tags = ["nofips"],
    deps = [":quic_core_proto_crypto_server_config_proto_cc"],
)

envoy_cc_library(
    name = "quic_core_ack_listener_interface_lib",
    srcs = ["quiche/quic/core/quic_ack_listener_interface.cc"],
    hdrs = ["quiche/quic/core/quic_ack_listener_interface.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_core_time_lib",
        ":quic_core_types_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_alarm_lib",
    srcs = ["quiche/quic/core/quic_alarm.cc"],
    hdrs = ["quiche/quic/core/quic_alarm.h"],
    deps = [
        ":quic_core_arena_scoped_ptr_lib",
        ":quic_core_connection_context_lib",
        ":quic_core_time_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_alarm_factory_lib",
    hdrs = ["quiche/quic/core/quic_alarm_factory.h"],
    deps = [
        ":quic_core_alarm_lib",
        ":quic_core_one_block_arena_lib",
    ],
)

envoy_cc_library(
    name = "quic_core_bandwidth_lib",
    srcs = ["quiche/quic/core/quic_bandwidth.cc"],
    hdrs = ["quiche/quic/core/quic_bandwidth.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_core_constants_lib",
        ":quic_core_time_lib",
        ":quic_core_types_lib",
        ":quic_platform_base",
    ],
)

envoy_cc_library(
    name = "quic_core_batch_writer_batch_writer_buffer_lib",
    srcs = select({
        "@envoy//bazel:linux": [
            "quiche/quic/core/batch_writer/quic_batch_writer_buffer.cc",
        ],
        "//conditions:default": [],
    }),
    hdrs = select({
        "@envoy//bazel:linux": [
            "quiche/quic/core/batch_writer/quic_batch_writer_buffer.h",
        ],
        "//conditions:default": [],
    }),
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_core_linux_socket_utils_lib",
        ":quic_core_packet_writer_lib",
        ":quic_platform",
        ":quiche_common_circular_deque_lib",
    ],
)

envoy_cc_library(
    name = "quic_core_batch_writer_batch_writer_base_lib",
    srcs = select({
        "@envoy//bazel:linux": [
            "quiche/quic/core/batch_writer/quic_batch_writer_base.cc",
        ],
        "//conditions:default": [],
    }),
    hdrs = select({
        "@envoy//bazel:linux": [
            "quiche/quic/core/batch_writer/quic_batch_writer_base.h",
        ],
        "//conditions:default": [],
    }),
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_core_batch_writer_batch_writer_buffer_lib",
        ":quic_core_packet_writer_lib",
        ":quic_core_types_lib",
        ":quic_platform",
    ],
)

envoy_cc_test_library(
    name = "quic_core_batch_writer_batch_writer_test_lib",
    hdrs = select({
        "@envoy//bazel:linux": [
            "quiche/quic/core/batch_writer/quic_batch_writer_test.h",
        ],
        "//conditions:default": [],
    }),
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quic_core_batch_writer_batch_writer_base_lib",
        ":quic_core_udp_socket_lib",
        ":quic_platform_test",
    ],
)

envoy_cc_library(
    name = "quic_core_batch_writer_gso_batch_writer_lib",
    srcs = select({
        "@envoy//bazel:linux": [
            "quiche/quic/core/batch_writer/quic_gso_batch_writer.cc",
        ],
        "//conditions:default": [],
    }),
    hdrs = select({
        "@envoy//bazel:linux": [
            "quiche/quic/core/batch_writer/quic_gso_batch_writer.h",
        ],
        "//conditions:default": [],
    }),
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_core_batch_writer_batch_writer_base_lib",
        ":quic_core_linux_socket_utils_lib",
        ":quic_platform",
    ],
)

envoy_cc_library(
    name = "quic_core_batch_writer_sendmmsg_batch_writer_lib",
    srcs = select({
        "@envoy//bazel:linux": [
            "quiche/quic/core/batch_writer/quic_sendmmsg_batch_writer.cc",
        ],
        "//conditions:default": [],
    }),
    hdrs = select({
        "@envoy//bazel:linux": [
            "quiche/quic/core/batch_writer/quic_sendmmsg_batch_writer.h",
        ],
        "//conditions:default": [],
    }),
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_core_batch_writer_batch_writer_base_lib",
        ":quic_core_linux_socket_utils_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_blocked_writer_interface_lib",
    hdrs = ["quiche/quic/core/quic_blocked_writer_interface.h"],
    tags = ["nofips"],
    deps = [":quic_platform_export"],
)

envoy_quic_cc_library(
    name = "quic_core_arena_scoped_ptr_lib",
    hdrs = ["quiche/quic/core/quic_arena_scoped_ptr.h"],
    deps = [":quic_platform_base"],
)

envoy_quic_cc_library(
    name = "quic_core_chaos_protector_lib",
    srcs = [
        "quiche/quic/core/quic_chaos_protector.cc",
    ],
    hdrs = [
        "quiche/quic/core/quic_chaos_protector.h",
    ],
    deps = [
        ":quic_core_crypto_random_lib",
        ":quic_core_data_lib",
        ":quic_core_framer_lib",
        ":quic_core_frames_frames_lib",
        ":quic_core_packets_lib",
        ":quic_core_stream_frame_data_producer_lib",
        ":quic_core_types_lib",
        ":quic_platform",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_clock_lib",
    hdrs = ["quiche/quic/core/quic_clock.h"],
    deps = [
        ":quic_core_time_lib",
        ":quic_platform_base",
    ],
)

envoy_cc_library(
    name = "quic_core_coalesced_packet_lib",
    srcs = ["quiche/quic/core/quic_coalesced_packet.cc"],
    hdrs = ["quiche/quic/core/quic_coalesced_packet.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":quic_core_packets_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_config_lib",
    srcs = ["quiche/quic/core/quic_config.cc"],
    hdrs = ["quiche/quic/core/quic_config.h"],
    deps = [
        ":quic_core_constants_lib",
        ":quic_core_crypto_crypto_handshake_lib",
        ":quic_core_crypto_encryption_lib",
        ":quic_core_packets_lib",
        ":quic_core_socket_address_coder_lib",
        ":quic_core_time_lib",
        ":quic_core_utils_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_congestion_control_bandwidth_sampler_lib",
    srcs = ["quiche/quic/core/congestion_control/bandwidth_sampler.cc"],
    hdrs = ["quiche/quic/core/congestion_control/bandwidth_sampler.h"],
    deps = [
        ":quic_core_bandwidth_lib",
        ":quic_core_congestion_control_congestion_control_interface_lib",
        ":quic_core_congestion_control_windowed_filter_lib",
        ":quic_core_packet_number_indexed_queue_lib",
        ":quic_core_packets_lib",
        ":quic_core_time_lib",
        ":quic_core_types_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_congestion_control_bbr_lib",
    srcs = ["quiche/quic/core/congestion_control/bbr_sender.cc"],
    hdrs = ["quiche/quic/core/congestion_control/bbr_sender.h"],
    deps = [
        ":quic_core_bandwidth_lib",
        ":quic_core_congestion_control_bandwidth_sampler_lib",
        ":quic_core_congestion_control_congestion_control_interface_lib",
        ":quic_core_congestion_control_rtt_stats_lib",
        ":quic_core_congestion_control_windowed_filter_lib",
        ":quic_core_crypto_encryption_lib",
        ":quic_core_crypto_random_lib",
        ":quic_core_packets_lib",
        ":quic_core_time_lib",
        ":quic_core_unacked_packet_map_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_congestion_control_bbr2_lib",
    srcs = [
        "quiche/quic/core/congestion_control/bbr2_drain.cc",
        "quiche/quic/core/congestion_control/bbr2_misc.cc",
        "quiche/quic/core/congestion_control/bbr2_probe_bw.cc",
        "quiche/quic/core/congestion_control/bbr2_probe_rtt.cc",
        "quiche/quic/core/congestion_control/bbr2_sender.cc",
        "quiche/quic/core/congestion_control/bbr2_startup.cc",
    ],
    hdrs = [
        "quiche/quic/core/congestion_control/bbr2_drain.h",
        "quiche/quic/core/congestion_control/bbr2_misc.h",
        "quiche/quic/core/congestion_control/bbr2_probe_bw.h",
        "quiche/quic/core/congestion_control/bbr2_probe_rtt.h",
        "quiche/quic/core/congestion_control/bbr2_sender.h",
        "quiche/quic/core/congestion_control/bbr2_startup.h",
    ],
    deps = [
        ":quic_core_bandwidth_lib",
        ":quic_core_congestion_control_bandwidth_sampler_lib",
        ":quic_core_congestion_control_bbr_lib",
        ":quic_core_congestion_control_congestion_control_interface_lib",
        ":quic_core_congestion_control_rtt_stats_lib",
        ":quic_core_congestion_control_windowed_filter_lib",
        ":quic_core_crypto_encryption_lib",
        ":quic_core_time_lib",
        ":quic_core_types_lib",
        ":quic_platform",
        ":quiche_common_print_elements_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_congestion_control_general_loss_algorithm_lib",
    srcs = ["quiche/quic/core/congestion_control/general_loss_algorithm.cc"],
    hdrs = ["quiche/quic/core/congestion_control/general_loss_algorithm.h"],
    deps = [
        ":quic_core_congestion_control_congestion_control_interface_lib",
        ":quic_core_congestion_control_rtt_stats_lib",
        ":quic_core_packets_lib",
        ":quic_core_time_lib",
        ":quic_core_unacked_packet_map_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_congestion_control_congestion_control_interface_lib",
    hdrs = [
        "quiche/quic/core/congestion_control/loss_detection_interface.h",
        "quiche/quic/core/congestion_control/send_algorithm_interface.h",
    ],
    deps = [
        ":quic_core_bandwidth_lib",
        ":quic_core_clock_lib",
        ":quic_core_config_lib",
        ":quic_core_connection_stats_lib",
        ":quic_core_crypto_random_lib",
        ":quic_core_packets_lib",
        ":quic_core_time_lib",
        ":quic_core_types_lib",
        ":quic_core_unacked_packet_map_lib",
        ":quic_platform",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_congestion_control_congestion_control_lib",
    srcs = [
        "quiche/quic/core/congestion_control/send_algorithm_interface.cc",
    ],
    hdrs = [
        "quiche/quic/core/congestion_control/loss_detection_interface.h",
        "quiche/quic/core/congestion_control/send_algorithm_interface.h",
    ],
    deps = [
        ":quic_core_bandwidth_lib",
        ":quic_core_config_lib",
        ":quic_core_congestion_control_bbr2_lib",
        ":quic_core_congestion_control_bbr_lib",
        ":quic_core_congestion_control_tcp_cubic_bytes_lib",
        ":quic_core_connection_stats_lib",
        ":quic_core_crypto_random_lib",
        ":quic_core_packets_lib",
        ":quic_core_time_lib",
        ":quic_core_types_lib",
        ":quic_core_unacked_packet_map_lib",
        ":quic_platform",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_congestion_control_pacing_sender_lib",
    srcs = ["quiche/quic/core/congestion_control/pacing_sender.cc"],
    hdrs = ["quiche/quic/core/congestion_control/pacing_sender.h"],
    deps = [
        ":quic_core_bandwidth_lib",
        ":quic_core_config_lib",
        ":quic_core_congestion_control_congestion_control_interface_lib",
        ":quic_core_packets_lib",
        ":quic_core_time_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_congestion_control_rtt_stats_lib",
    srcs = ["quiche/quic/core/congestion_control/rtt_stats.cc"],
    hdrs = ["quiche/quic/core/congestion_control/rtt_stats.h"],
    deps = [
        ":quic_core_packets_lib",
        ":quic_core_time_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_congestion_control_tcp_cubic_helper",
    srcs = [
        "quiche/quic/core/congestion_control/hybrid_slow_start.cc",
        "quiche/quic/core/congestion_control/prr_sender.cc",
    ],
    hdrs = [
        "quiche/quic/core/congestion_control/hybrid_slow_start.h",
        "quiche/quic/core/congestion_control/prr_sender.h",
    ],
    deps = [
        ":quic_core_bandwidth_lib",
        ":quic_core_packets_lib",
        ":quic_core_time_lib",
        ":quic_platform_base",
        ":quic_platform_export",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_congestion_control_tcp_cubic_bytes_lib",
    srcs = [
        "quiche/quic/core/congestion_control/cubic_bytes.cc",
        "quiche/quic/core/congestion_control/tcp_cubic_sender_bytes.cc",
    ],
    hdrs = [
        "quiche/quic/core/congestion_control/cubic_bytes.h",
        "quiche/quic/core/congestion_control/tcp_cubic_sender_bytes.h",
    ],
    deps = [
        ":quic_core_bandwidth_lib",
        ":quic_core_congestion_control_congestion_control_interface_lib",
        ":quic_core_congestion_control_rtt_stats_lib",
        ":quic_core_congestion_control_tcp_cubic_helper",
        ":quic_core_connection_stats_lib",
        ":quic_core_constants_lib",
        ":quic_core_crypto_encryption_lib",
        ":quic_core_packets_lib",
        ":quic_core_time_lib",
        ":quic_platform",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_congestion_control_uber_loss_algorithm_lib",
    srcs = ["quiche/quic/core/congestion_control/uber_loss_algorithm.cc"],
    hdrs = ["quiche/quic/core/congestion_control/uber_loss_algorithm.h"],
    deps = [":quic_core_congestion_control_general_loss_algorithm_lib"],
)

envoy_quic_cc_library(
    name = "quic_core_congestion_control_windowed_filter_lib",
    hdrs = ["quiche/quic/core/congestion_control/windowed_filter.h"],
    deps = [":quic_core_time_lib"],
)

envoy_quic_cc_library(
    name = "quic_core_connection_context_lib",
    srcs = [
        "quiche/quic/core/quic_connection_context.cc",
    ],
    hdrs = [
        "quiche/quic/core/quic_connection_context.h",
    ],
    external_deps = [
        "abseil_str_format",
    ],
    deps = [
        ":quic_platform_export",
        ":quiche_common_platform",
        ":quiche_common_text_utils_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_connection_id_manager",
    srcs = ["quiche/quic/core/quic_connection_id_manager.cc"],
    hdrs = ["quiche/quic/core/quic_connection_id_manager.h"],
    deps = [
        ":quic_core_alarm_factory_lib",
        ":quic_core_alarm_lib",
        ":quic_core_clock_lib",
        ":quic_core_connection_id_generator_interface_lib",
        ":quic_core_frames_frames_lib",
        ":quic_core_interval_set_lib",
        ":quic_core_types_lib",
        ":quic_core_utils_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_connection_id_generator_interface_lib",
    hdrs = ["quiche/quic/core/connection_id_generator.h"],
    deps = [
        ":quic_core_types_lib",
        ":quic_core_versions_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_deterministic_connection_id_generator_lib",
    srcs = ["quiche/quic/core/deterministic_connection_id_generator.cc"],
    hdrs = ["quiche/quic/core/deterministic_connection_id_generator.h"],
    deps = [
        ":quic_core_connection_id_generator_interface_lib",
        ":quic_core_utils_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_connection_lib",
    srcs = ["quiche/quic/core/quic_connection.cc"],
    hdrs = ["quiche/quic/core/quic_connection.h"],
    deps = [
        ":quic_core_alarm_factory_lib",
        ":quic_core_alarm_lib",
        ":quic_core_bandwidth_lib",
        ":quic_core_blocked_writer_interface_lib",
        ":quic_core_config_lib",
        ":quic_core_connection_context_lib",
        ":quic_core_connection_id_manager",
        ":quic_core_connection_stats_lib",
        ":quic_core_crypto_crypto_handshake_lib",
        ":quic_core_crypto_encryption_lib",
        ":quic_core_framer_lib",
        ":quic_core_idle_network_detector_lib",
        ":quic_core_mtu_discovery_lib",
        ":quic_core_network_blackhole_detector_lib",
        ":quic_core_one_block_arena_lib",
        ":quic_core_packet_creator_lib",
        ":quic_core_packet_writer_lib",
        ":quic_core_packets_lib",
        ":quic_core_path_validator_lib",
        ":quic_core_ping_manager_lib",
        ":quic_core_proto_cached_network_parameters_proto_header",
        ":quic_core_sent_packet_manager_lib",
        ":quic_core_time_lib",
        ":quic_core_types_lib",
        ":quic_core_uber_received_packet_manager_lib",
        ":quic_core_utils_lib",
        ":quic_platform_base",
        ":quiche_common_text_utils_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_connection_stats_lib",
    srcs = ["quiche/quic/core/quic_connection_stats.cc"],
    hdrs = ["quiche/quic/core/quic_connection_stats.h"],
    deps = [
        ":quic_core_bandwidth_lib",
        ":quic_core_packets_lib",
        ":quic_core_time_accumulator_lib",
        ":quic_core_time_lib",
        ":quic_platform_export",
    ],
)

envoy_cc_library(
    name = "quic_core_constants_lib",
    srcs = ["quiche/quic/core/quic_constants.cc"],
    hdrs = ["quiche/quic/core/quic_constants.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_core_types_lib",
        ":quic_platform_export",
    ],
)

envoy_cc_library(
    name = "quiche_crypto_logging",
    srcs = [
        "quiche/common/quiche_crypto_logging.cc",
    ],
    hdrs = [
        "quiche/common/quiche_crypto_logging.h",
    ],
    copts = quiche_copts,
    external_deps = ["ssl"],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_logging",
        "@com_google_absl//absl/status",
        "@com_google_absl//absl/strings",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_crypto_crypto_handshake_lib",
    srcs = [
        "quiche/quic/core/crypto/cert_compressor.cc",
        "quiche/quic/core/crypto/channel_id.cc",
        "quiche/quic/core/crypto/crypto_framer.cc",
        "quiche/quic/core/crypto/crypto_handshake.cc",
        "quiche/quic/core/crypto/crypto_handshake_message.cc",
        "quiche/quic/core/crypto/crypto_secret_boxer.cc",
        "quiche/quic/core/crypto/crypto_utils.cc",
        "quiche/quic/core/crypto/curve25519_key_exchange.cc",
        "quiche/quic/core/crypto/key_exchange.cc",
        "quiche/quic/core/crypto/p256_key_exchange.cc",
        "quiche/quic/core/crypto/quic_compressed_certs_cache.cc",
        "quiche/quic/core/crypto/transport_parameters.cc",
    ],
    hdrs = [
        "quiche/quic/core/crypto/cert_compressor.h",
        "quiche/quic/core/crypto/channel_id.h",
        "quiche/quic/core/crypto/crypto_framer.h",
        "quiche/quic/core/crypto/crypto_handshake.h",
        "quiche/quic/core/crypto/crypto_handshake_message.h",
        "quiche/quic/core/crypto/crypto_message_parser.h",
        "quiche/quic/core/crypto/crypto_secret_boxer.h",
        "quiche/quic/core/crypto/crypto_utils.h",
        "quiche/quic/core/crypto/curve25519_key_exchange.h",
        "quiche/quic/core/crypto/key_exchange.h",
        "quiche/quic/core/crypto/p256_key_exchange.h",
        "quiche/quic/core/crypto/proof_verifier.h",
        "quiche/quic/core/crypto/quic_compressed_certs_cache.h",
        "quiche/quic/core/crypto/transport_parameters.h",
    ],
    external_deps = [
        "ssl",
        "zlib",
    ],
    tags = [
        "pg3",
    ],
    deps = [
        ":quic_core_clock_lib",
        ":quic_core_connection_context_lib",
        ":quic_core_crypto_certificate_view_lib",
        ":quic_core_crypto_encryption_lib",
        ":quic_core_crypto_hkdf_lib",
        ":quic_core_crypto_proof_source_lib",
        ":quic_core_crypto_random_lib",
        ":quic_core_crypto_tls_handshake_lib",
        ":quic_core_data_lib",
        ":quic_core_error_codes_lib",
        ":quic_core_lru_cache_lib",
        ":quic_core_packets_lib",
        ":quic_core_proto_cached_network_parameters_proto_header",
        ":quic_core_proto_source_address_token_proto_header",
        ":quic_core_server_id_lib",
        ":quic_core_socket_address_coder_lib",
        ":quic_core_time_lib",
        ":quic_core_types_lib",
        ":quic_core_utils_lib",
        ":quic_core_versions_lib",
        ":quic_platform",
    ],
)

envoy_quic_cc_library(
    name = "quic_client_crypto_crypto_handshake_lib",
    srcs = [
        "quiche/quic/core/crypto/quic_client_session_cache.cc",
        "quiche/quic/core/crypto/quic_crypto_client_config.cc",
    ],
    hdrs = [
        "quiche/quic/core/crypto/quic_client_session_cache.h",
        "quiche/quic/core/crypto/quic_crypto_client_config.h",
    ],
    external_deps = [
        "zlib",
    ],
    tags = [
        "pg3",
    ],
    deps = [
        ":quic_client_crypto_tls_handshake_lib",
        ":quic_core_crypto_client_proof_source_lib",
        ":quic_core_crypto_crypto_handshake_lib",
        ":quiche_common_platform_client_stats",
    ],
)

envoy_quic_cc_library(
    name = "quic_server_crypto_crypto_handshake_lib",
    srcs = [
        "quiche/quic/core/crypto/quic_crypto_server_config.cc",
    ],
    hdrs = [
        "quiche/quic/core/crypto/quic_crypto_server_config.h",
    ],
    external_deps = [
        "ssl",
        "zlib",
    ],
    tags = [
        "pg3",
    ],
    deps = [
        ":quic_core_crypto_crypto_handshake_lib",
        ":quic_core_proto_crypto_server_config_proto_header",
        ":quic_core_server_id_lib",
        ":quic_server_crypto_tls_handshake_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_crypto_boring_utils_lib",
    hdrs = ["quiche/quic/core/crypto/boring_utils.h"],
    external_deps = ["ssl"],
    deps = [
        ":quic_platform_export",
        ":quiche_common_platform",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_crypto_certificate_view_lib",
    srcs = ["quiche/quic/core/crypto/certificate_view.cc"],
    hdrs = ["quiche/quic/core/crypto/certificate_view.h"],
    external_deps = ["ssl"],
    deps = [
        ":quic_core_crypto_boring_utils_lib",
        ":quic_core_types_lib",
        ":quic_platform",
        ":quic_platform_ip_address",
        ":quiche_common_platform",
        ":quiche_common_text_utils_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_crypto_encryption_lib",
    srcs = [
        "quiche/quic/core/crypto/aead_base_decrypter.cc",
        "quiche/quic/core/crypto/aead_base_encrypter.cc",
        "quiche/quic/core/crypto/aes_128_gcm_12_decrypter.cc",
        "quiche/quic/core/crypto/aes_128_gcm_12_encrypter.cc",
        "quiche/quic/core/crypto/aes_128_gcm_decrypter.cc",
        "quiche/quic/core/crypto/aes_128_gcm_encrypter.cc",
        "quiche/quic/core/crypto/aes_256_gcm_decrypter.cc",
        "quiche/quic/core/crypto/aes_256_gcm_encrypter.cc",
        "quiche/quic/core/crypto/aes_base_decrypter.cc",
        "quiche/quic/core/crypto/aes_base_encrypter.cc",
        "quiche/quic/core/crypto/chacha20_poly1305_decrypter.cc",
        "quiche/quic/core/crypto/chacha20_poly1305_encrypter.cc",
        "quiche/quic/core/crypto/chacha20_poly1305_tls_decrypter.cc",
        "quiche/quic/core/crypto/chacha20_poly1305_tls_encrypter.cc",
        "quiche/quic/core/crypto/chacha_base_decrypter.cc",
        "quiche/quic/core/crypto/chacha_base_encrypter.cc",
        "quiche/quic/core/crypto/null_decrypter.cc",
        "quiche/quic/core/crypto/null_encrypter.cc",
        "quiche/quic/core/crypto/quic_crypter.cc",
        "quiche/quic/core/crypto/quic_decrypter.cc",
        "quiche/quic/core/crypto/quic_encrypter.cc",
    ],
    hdrs = [
        "quiche/quic/core/crypto/aead_base_decrypter.h",
        "quiche/quic/core/crypto/aead_base_encrypter.h",
        "quiche/quic/core/crypto/aes_128_gcm_12_decrypter.h",
        "quiche/quic/core/crypto/aes_128_gcm_12_encrypter.h",
        "quiche/quic/core/crypto/aes_128_gcm_decrypter.h",
        "quiche/quic/core/crypto/aes_128_gcm_encrypter.h",
        "quiche/quic/core/crypto/aes_256_gcm_decrypter.h",
        "quiche/quic/core/crypto/aes_256_gcm_encrypter.h",
        "quiche/quic/core/crypto/aes_base_decrypter.h",
        "quiche/quic/core/crypto/aes_base_encrypter.h",
        "quiche/quic/core/crypto/chacha20_poly1305_decrypter.h",
        "quiche/quic/core/crypto/chacha20_poly1305_encrypter.h",
        "quiche/quic/core/crypto/chacha20_poly1305_tls_decrypter.h",
        "quiche/quic/core/crypto/chacha20_poly1305_tls_encrypter.h",
        "quiche/quic/core/crypto/chacha_base_decrypter.h",
        "quiche/quic/core/crypto/chacha_base_encrypter.h",
        "quiche/quic/core/crypto/crypto_protocol.h",
        "quiche/quic/core/crypto/null_decrypter.h",
        "quiche/quic/core/crypto/null_encrypter.h",
        "quiche/quic/core/crypto/quic_crypter.h",
        "quiche/quic/core/crypto/quic_decrypter.h",
        "quiche/quic/core/crypto/quic_encrypter.h",
    ],
    external_deps = ["ssl"],
    deps = [
        ":quic_core_crypto_hkdf_lib",
        ":quic_core_data_lib",
        ":quic_core_packets_lib",
        ":quic_core_tag_lib",
        ":quic_core_types_lib",
        ":quic_core_utils_lib",
        ":quic_platform_base",
        ":quiche_crypto_logging",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_crypto_hkdf_lib",
    srcs = ["quiche/quic/core/crypto/quic_hkdf.cc"],
    hdrs = ["quiche/quic/core/crypto/quic_hkdf.h"],
    deps = [
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_crypto_proof_source_lib",
    srcs = [
        "quiche/quic/core/crypto/proof_source.cc",
        "quiche/quic/core/crypto/quic_crypto_proof.cc",
    ],
    hdrs = [
        "quiche/quic/core/crypto/proof_source.h",
        "quiche/quic/core/crypto/quic_crypto_proof.h",
    ],
    deps = [
        ":quic_core_crypto_certificate_view_lib",
        ":quic_core_packets_lib",
        ":quic_core_versions_lib",
        ":quic_platform_base",
        ":quic_platform_export",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_crypto_proof_source_x509_lib",
    srcs = ["quiche/quic/core/crypto/proof_source_x509.cc"],
    hdrs = ["quiche/quic/core/crypto/proof_source_x509.h"],
    external_deps = [
        "ssl",
        "abseil_node_hash_map",
    ],
    deps = [
        ":quic_core_crypto_certificate_view_lib",
        ":quic_core_crypto_crypto_handshake_lib",
        ":quic_core_crypto_encryption_lib",
        ":quic_core_crypto_proof_source_lib",
        ":quic_core_data_lib",
        ":quic_platform_base",
        ":quiche_common_endian_lib",
        "@com_google_absl//absl/base:core_headers",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_crypto_client_proof_source_lib",
    srcs = [
        "quiche/quic/core/crypto/client_proof_source.cc",
    ],
    hdrs = [
        "quiche/quic/core/crypto/client_proof_source.h",
    ],
    deps = [
        ":quic_core_crypto_proof_source_lib",
        ":quic_platform_base",
    ],
)

envoy_cc_library(
    name = "quic_core_crypto_random_lib",
    hdrs = ["quiche/quic/core/crypto/quic_random.h"],
    copts = quiche_copts,
    external_deps = ["ssl"],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [":quiche_common_random_lib"],
)

envoy_quic_cc_library(
    name = "quic_core_crypto_tls_handshake_lib",
    srcs = [
        "quiche/quic/core/crypto/tls_connection.cc",
    ],
    hdrs = [
        "quiche/quic/core/crypto/tls_connection.h",
    ],
    external_deps = ["ssl"],
    deps = [
        ":quic_core_crypto_proof_source_lib",
        ":quic_core_types_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_server_crypto_tls_handshake_lib",
    srcs = [
        "quiche/quic/core/crypto/tls_server_connection.cc",
    ],
    hdrs = [
        "quiche/quic/core/crypto/tls_server_connection.h",
    ],
    external_deps = ["ssl"],
    deps = [
        ":quic_core_crypto_proof_source_lib",
        ":quic_core_crypto_tls_handshake_lib",
        ":quic_core_types_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_client_crypto_tls_handshake_lib",
    srcs = [
        "quiche/quic/core/crypto/tls_client_connection.cc",
    ],
    hdrs = [
        "quiche/quic/core/crypto/tls_client_connection.h",
    ],
    external_deps = ["ssl"],
    deps = [
        ":quic_core_crypto_tls_handshake_lib",
    ],
)

envoy_cc_library(
    name = "quiche_common_buffer_allocator_lib",
    srcs = [
        "quiche/common/quiche_buffer_allocator.cc",
        "quiche/common/simple_buffer_allocator.cc",
    ],
    hdrs = [
        "quiche/common/quiche_buffer_allocator.h",
        "quiche/common/simple_buffer_allocator.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_export",
        ":quiche_common_platform_iovec",
        ":quiche_common_platform_logging",
        ":quiche_common_platform_prefetch",
    ],
)

envoy_cc_library(
    name = "quiche_common_circular_deque_lib",
    hdrs = ["quiche/common/quiche_circular_deque.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_common_platform",
        ":quiche_common_platform_export",
    ],
)

envoy_cc_library(
    name = "quiche_common_random_lib",
    srcs = ["quiche/common/quiche_random.cc"],
    hdrs = ["quiche/common/quiche_random.h"],
    copts = quiche_copts,
    external_deps = ["ssl"],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [":quiche_common_platform_logging"],
)

envoy_cc_library(
    name = "quiche_common_status_utils",
    hdrs = ["quiche/common/quiche_status_utils.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        "@com_google_absl//absl/base:core_headers",
        "@com_google_absl//absl/status",
        "@com_google_absl//absl/strings",
    ],
)

envoy_cc_library(
    name = "quiche_common_wire_serialization",
    hdrs = ["quiche/common/wire_serialization.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_common_buffer_allocator_lib",
        ":quiche_common_lib",
        ":quiche_common_platform_logging",
        ":quiche_common_status_utils",
        "@com_google_absl//absl/status:statusor",
    ],
)

envoy_cc_library(
    name = "quiche_common_callbacks",
    hdrs = ["quiche/common/quiche_callbacks.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_export",
        "@com_google_absl//absl/functional:any_invocable",
        "@com_google_absl//absl/functional:function_ref",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_data_lib",
    srcs = [
        "quiche/quic/core/quic_data_reader.cc",
        "quiche/quic/core/quic_data_writer.cc",
    ],
    hdrs = [
        "quiche/quic/core/quic_data_reader.h",
        "quiche/quic/core/quic_data_writer.h",
    ],
    deps = [
        ":quic_core_constants_lib",
        ":quic_core_crypto_random_lib",
        ":quic_core_packets_lib",
        ":quic_core_types_lib",
        ":quic_platform_base",
    ],
)

envoy_cc_library(
    name = "quic_core_error_codes_lib",
    srcs = ["quiche/quic/core/quic_error_codes.cc"],
    hdrs = ["quiche/quic/core/quic_error_codes.h"],
    copts = quiche_copts,
    external_deps = ["ssl"],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_platform_base",
        ":quic_platform_export",
    ],
)

envoy_cc_library(
    name = "quic_core_flags_list_lib",
    hdrs = ["quiche/quic/core/quic_flags_list.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
)

envoy_cc_library(
    name = "quiche_protocol_flags_list_lib",
    hdrs = ["quiche/common/quiche_protocol_flags_list.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
)

envoy_quic_cc_library(
    name = "quic_core_framer_lib",
    srcs = ["quiche/quic/core/quic_framer.cc"],
    hdrs = ["quiche/quic/core/quic_framer.h"],
    deps = [
        ":quic_core_connection_id_generator_interface_lib",
        ":quic_core_constants_lib",
        ":quic_core_crypto_crypto_handshake_lib",
        ":quic_core_crypto_encryption_lib",
        ":quic_core_crypto_random_lib",
        ":quic_core_data_lib",
        ":quic_core_packets_lib",
        ":quic_core_socket_address_coder_lib",
        ":quic_core_stream_frame_data_producer_lib",
        ":quic_core_types_lib",
        ":quic_core_utils_lib",
        ":quic_core_versions_lib",
        ":quic_platform_base",
        ":quiche_common_text_utils_lib",
        "@com_google_absl//absl/cleanup",
    ],
)

envoy_cc_library(
    name = "quic_core_frames_frames_lib",
    srcs = [
        "quiche/quic/core/frames/quic_ack_frame.cc",
        "quiche/quic/core/frames/quic_ack_frequency_frame.cc",
        "quiche/quic/core/frames/quic_blocked_frame.cc",
        "quiche/quic/core/frames/quic_connection_close_frame.cc",
        "quiche/quic/core/frames/quic_crypto_frame.cc",
        "quiche/quic/core/frames/quic_frame.cc",
        "quiche/quic/core/frames/quic_goaway_frame.cc",
        "quiche/quic/core/frames/quic_handshake_done_frame.cc",
        "quiche/quic/core/frames/quic_max_streams_frame.cc",
        "quiche/quic/core/frames/quic_message_frame.cc",
        "quiche/quic/core/frames/quic_new_connection_id_frame.cc",
        "quiche/quic/core/frames/quic_new_token_frame.cc",
        "quiche/quic/core/frames/quic_padding_frame.cc",
        "quiche/quic/core/frames/quic_path_challenge_frame.cc",
        "quiche/quic/core/frames/quic_path_response_frame.cc",
        "quiche/quic/core/frames/quic_ping_frame.cc",
        "quiche/quic/core/frames/quic_retire_connection_id_frame.cc",
        "quiche/quic/core/frames/quic_rst_stream_frame.cc",
        "quiche/quic/core/frames/quic_stop_sending_frame.cc",
        "quiche/quic/core/frames/quic_stop_waiting_frame.cc",
        "quiche/quic/core/frames/quic_stream_frame.cc",
        "quiche/quic/core/frames/quic_streams_blocked_frame.cc",
        "quiche/quic/core/frames/quic_window_update_frame.cc",
    ],
    hdrs = [
        "quiche/quic/core/frames/quic_ack_frame.h",
        "quiche/quic/core/frames/quic_ack_frequency_frame.h",
        "quiche/quic/core/frames/quic_blocked_frame.h",
        "quiche/quic/core/frames/quic_connection_close_frame.h",
        "quiche/quic/core/frames/quic_crypto_frame.h",
        "quiche/quic/core/frames/quic_frame.h",
        "quiche/quic/core/frames/quic_goaway_frame.h",
        "quiche/quic/core/frames/quic_handshake_done_frame.h",
        "quiche/quic/core/frames/quic_inlined_frame.h",
        "quiche/quic/core/frames/quic_max_streams_frame.h",
        "quiche/quic/core/frames/quic_message_frame.h",
        "quiche/quic/core/frames/quic_mtu_discovery_frame.h",
        "quiche/quic/core/frames/quic_new_connection_id_frame.h",
        "quiche/quic/core/frames/quic_new_token_frame.h",
        "quiche/quic/core/frames/quic_padding_frame.h",
        "quiche/quic/core/frames/quic_path_challenge_frame.h",
        "quiche/quic/core/frames/quic_path_response_frame.h",
        "quiche/quic/core/frames/quic_ping_frame.h",
        "quiche/quic/core/frames/quic_retire_connection_id_frame.h",
        "quiche/quic/core/frames/quic_rst_stream_frame.h",
        "quiche/quic/core/frames/quic_stop_sending_frame.h",
        "quiche/quic/core/frames/quic_stop_waiting_frame.h",
        "quiche/quic/core/frames/quic_stream_frame.h",
        "quiche/quic/core/frames/quic_streams_blocked_frame.h",
        "quiche/quic/core/frames/quic_window_update_frame.h",
    ],
    copts = quiche_copts,
    # TODO: Work around initializer in anonymous union in fastbuild build.
    # Remove this after upstream fix.
    defines = select({
        "@envoy//bazel:windows_x86_64": ["QUIC_FRAME_DEBUG=0"],
        "//conditions:default": [],
    }),
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_core_constants_lib",
        ":quic_core_error_codes_lib",
        ":quic_core_interval_lib",
        ":quic_core_interval_set_lib",
        ":quic_core_types_lib",
        ":quic_core_versions_lib",
        ":quic_platform_base",
        ":quiche_common_buffer_allocator_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_http_http_constants_lib",
    srcs = ["quiche/quic/core/http/http_constants.cc"],
    hdrs = ["quiche/quic/core/http/http_constants.h"],
    deps = [":quic_core_types_lib"],
)

envoy_cc_library(
    name = "quiche_common_capsule_lib",
    srcs = ["quiche/common/capsule.cc"],
    hdrs = ["quiche/common/capsule.h"],
    copts = quiche_copts,
    repository = "@envoy",
    visibility = ["//visibility:public"],
    deps = [
        ":quic_core_data_lib",
        ":quic_core_http_http_frames_lib",
        ":quic_core_types_lib",
        ":quic_platform_base",
        ":quiche_common_buffer_allocator_lib",
        ":quiche_common_ip_address",
        ":quiche_common_wire_serialization",
        ":quiche_web_transport_web_transport_lib",
    ],
)

envoy_cc_library(
    name = "quiche_common_connect_udp_datagram_payload_lib",
    srcs = ["quiche/common/masque/connect_udp_datagram_payload.cc"],
    hdrs = ["quiche/common/masque/connect_udp_datagram_payload.h"],
    copts = quiche_copts,
    repository = "@envoy",
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_lib",
        ":quiche_common_platform_bug_tracker",
        ":quiche_common_platform_logging",
        "@com_google_absl//absl/strings",
    ],
)

envoy_cc_library(
    name = "quiche_common_quiche_stream_lib",
    srcs = [],
    hdrs = ["quiche/common/quiche_stream.h"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":quiche_common_platform_export",
        "@com_google_absl//absl/strings",
        "@com_google_absl//absl/types:span",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_http_client_lib",
    srcs = [
        "quiche/quic/core/http/quic_spdy_client_session.cc",
        "quiche/quic/core/http/quic_spdy_client_session_base.cc",
        "quiche/quic/core/http/quic_spdy_client_stream.cc",
    ],
    hdrs = [
        "quiche/quic/core/http/quic_spdy_client_session.h",
        "quiche/quic/core/http/quic_spdy_client_session_base.h",
        "quiche/quic/core/http/quic_spdy_client_stream.h",
    ],
    deps = [
        ":quic_client_session_lib",
        ":quic_core_alarm_lib",
        ":quic_core_crypto_encryption_lib",
        ":quic_core_http_server_initiated_spdy_stream_lib",
        ":quic_core_http_spdy_session_lib",
        ":quic_core_packets_lib",
        ":quic_core_qpack_qpack_streams_lib",
        ":quic_core_server_id_lib",
        ":quic_core_types_lib",
        ":quic_core_utils_lib",
        ":quic_platform_base",
        ":spdy_core_framer_lib",
        ":spdy_core_protocol_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_http_header_list_lib",
    srcs = ["quiche/quic/core/http/quic_header_list.cc"],
    hdrs = ["quiche/quic/core/http/quic_header_list.h"],
    deps = [
        ":quic_core_packets_lib",
        ":quic_core_qpack_qpack_header_table_lib",
        ":quic_platform_base",
        ":quiche_common_circular_deque_lib",
        ":spdy_core_headers_handler_interface_lib",
        ":spdy_core_http2_header_block_lib",
        ":spdy_core_protocol_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_http_http_decoder_lib",
    srcs = ["quiche/quic/core/http/http_decoder.cc"],
    hdrs = ["quiche/quic/core/http/http_decoder.h"],
    deps = [
        ":http2_constants_lib",
        ":quic_core_data_lib",
        ":quic_core_error_codes_lib",
        ":quic_core_http_http_frames_lib",
        ":quic_core_http_spdy_utils_lib",
        ":quic_core_types_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_http_http_encoder_lib",
    srcs = ["quiche/quic/core/http/http_encoder.cc"],
    hdrs = ["quiche/quic/core/http/http_encoder.h"],
    deps = [
        ":quic_core_data_lib",
        ":quic_core_error_codes_lib",
        ":quic_core_http_http_frames_lib",
        ":quic_core_http_spdy_utils_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_http_http_frames_lib",
    hdrs = ["quiche/quic/core/http/http_frames.h"],
    deps = [
        ":quic_core_http_http_constants_lib",
        ":quic_core_types_lib",
        ":quic_platform_base",
        ":spdy_core_framer_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_http_server_initiated_spdy_stream_lib",
    srcs = ["quiche/quic/core/http/quic_server_initiated_spdy_stream.cc"],
    hdrs = ["quiche/quic/core/http/quic_server_initiated_spdy_stream.h"],
    deps = [
        ":quic_core_http_spdy_session_lib",
        ":quic_core_types_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_http_spdy_session_lib",
    srcs = [
        "quiche/quic/core/http/quic_headers_stream.cc",
        "quiche/quic/core/http/quic_receive_control_stream.cc",
        "quiche/quic/core/http/quic_send_control_stream.cc",
        "quiche/quic/core/http/quic_spdy_session.cc",
        "quiche/quic/core/http/quic_spdy_stream.cc",
        "quiche/quic/core/http/web_transport_http3.cc",
        "quiche/quic/core/http/web_transport_stream_adapter.cc",
        "quiche/quic/core/web_transport_stats.cc",
    ],
    hdrs = [
        "quiche/quic/core/http/quic_headers_stream.h",
        "quiche/quic/core/http/quic_receive_control_stream.h",
        "quiche/quic/core/http/quic_send_control_stream.h",
        "quiche/quic/core/http/quic_spdy_session.h",
        "quiche/quic/core/http/quic_spdy_stream.h",
        "quiche/quic/core/http/web_transport_http3.h",
        "quiche/quic/core/http/web_transport_stream_adapter.h",
        "quiche/quic/core/web_transport_stats.h",
    ],
    deps = [
        ":http2_adapter_header_validator",
        ":quic_core_connection_lib",
        ":quic_core_crypto_crypto_handshake_lib",
        ":quic_core_error_codes_lib",
        ":quic_core_http_header_list_lib",
        ":quic_core_http_http_constants_lib",
        ":quic_core_http_http_decoder_lib",
        ":quic_core_http_http_encoder_lib",
        ":quic_core_http_spdy_stream_body_manager_lib",
        ":quic_core_http_spdy_utils_lib",
        ":quic_core_packets_lib",
        ":quic_core_proto_cached_network_parameters_proto_header",
        ":quic_core_qpack_qpack_decoded_headers_accumulator_lib",
        ":quic_core_qpack_qpack_decoder_lib",
        ":quic_core_qpack_qpack_decoder_stream_sender_lib",
        ":quic_core_qpack_qpack_encoder_lib",
        ":quic_core_qpack_qpack_encoder_stream_sender_lib",
        ":quic_core_qpack_qpack_streams_lib",
        ":quic_core_utils_lib",
        ":quic_core_versions_lib",
        ":quic_core_web_transport_interface_lib",
        ":quic_platform_base",
        ":quiche_common_capsule_lib",
        ":quiche_common_mem_slice_storage",
        ":quiche_common_structured_headers_lib",
        ":spdy_core_framer_lib",
        ":spdy_core_http2_deframer_lib",
        ":spdy_core_protocol_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_server_http_spdy_session_lib",
    srcs = [
        "quiche/quic/core/http/quic_server_session_base.cc",
        "quiche/quic/core/http/quic_spdy_server_stream_base.cc",
    ],
    hdrs = [
        "quiche/quic/core/http/quic_server_session_base.h",
        "quiche/quic/core/http/quic_spdy_server_stream_base.h",
    ],
    deps = [
        ":quic_core_http_spdy_session_lib",
        ":quic_server_session_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_http_spdy_stream_body_manager_lib",
    srcs = ["quiche/quic/core/http/quic_spdy_stream_body_manager.cc"],
    hdrs = ["quiche/quic/core/http/quic_spdy_stream_body_manager.h"],
    deps = [
        ":quic_core_http_http_decoder_lib",
        ":quic_core_session_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_http_spdy_utils_lib",
    srcs = ["quiche/quic/core/http/spdy_utils.cc"],
    hdrs = ["quiche/quic/core/http/spdy_utils.h"],
    deps = [
        ":quic_core_http_header_list_lib",
        ":quic_core_http_http_constants_lib",
        ":quic_core_packets_lib",
        ":quic_platform_base",
        ":spdy_core_framer_lib",
        ":spdy_core_protocol_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_idle_network_detector_lib",
    srcs = ["quiche/quic/core/quic_idle_network_detector.cc"],
    hdrs = ["quiche/quic/core/quic_idle_network_detector.h"],
    deps = [
        ":quic_core_alarm_factory_lib",
        ":quic_core_alarm_lib",
        ":quic_core_constants_lib",
        ":quic_core_one_block_arena_lib",
        ":quic_core_time_lib",
        ":quic_platform_export",
    ],
)

envoy_cc_library(
    name = "quic_core_interval_lib",
    hdrs = ["quiche/quic/core/quic_interval.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_platform_export",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_interval_deque_lib",
    hdrs = ["quiche/quic/core/quic_interval_deque.h"],
    deps = [
        ":quic_core_interval_lib",
        ":quic_core_types_lib",
        ":quic_platform",
        ":quiche_common_circular_deque_lib",
    ],
)

envoy_cc_library(
    name = "quic_core_interval_set_lib",
    hdrs = ["quiche/quic/core/quic_interval_set.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_core_interval_lib",
        ":quic_platform_base",
        ":quiche_common_platform_containers",
    ],
)

envoy_cc_library(
    name = "quic_core_io_event_loop",
    hdrs = select({
        "@envoy//bazel:windows_x86_64": [],
        "@envoy//bazel:disable_http3": [],
        "//conditions:default": ["quiche/quic/core/io/quic_event_loop.h"],
    }),
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = select({
        "@envoy//bazel:windows_x86_64": [],
        "@envoy//bazel:disable_http3": [],
        "//conditions:default": [
            ":quic_core_alarm_factory_lib",
            ":quic_core_clock_lib",
            ":quic_core_udp_socket_lib",
            "@com_google_absl//absl/base:core_headers",
        ],
    }),
)

envoy_cc_library(
    name = "quic_core_io_socket_lib",
    srcs = ["quiche/quic/core/io/socket.cc"],
    hdrs = [
        "quiche/quic/core/connecting_client_socket.h",
        "quiche/quic/core/io/socket.h",
        "quiche/quic/core/io/socket_internal.h",
        "quiche/quic/core/io/socket_posix.inc",
        "quiche/quic/core/io/socket_win.inc",
        "quiche/quic/core/socket_factory.h",
    ],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_core_types_lib",
        ":quic_platform_ip_address_family",
        ":quic_platform_socket_address",
        ":quiche_common_platform_export",
        ":quiche_common_platform_logging",
        "@com_google_absl//absl/base:core_headers",
        "@com_google_absl//absl/container:flat_hash_set",
        "@com_google_absl//absl/status",
        "@com_google_absl//absl/status:statusor",
        "@com_google_absl//absl/strings",
        "@com_google_absl//absl/types:span",
    ],
)

envoy_cc_library(
    name = "quic_core_io_event_loop_socket_factory_lib",
    srcs = select({
        "@envoy//bazel:windows_x86_64": [],
        "@envoy//bazel:disable_http3": [],
        "//conditions:default": [
            "quiche/quic/core/io/event_loop_connecting_client_socket.cc",
            "quiche/quic/core/io/event_loop_socket_factory.cc",
        ],
    }),
    hdrs = select({
        "@envoy//bazel:windows_x86_64": [],
        "@envoy//bazel:disable_http3": [],
        "//conditions:default": [
            "quiche/quic/core/io/event_loop_connecting_client_socket.h",
            "quiche/quic/core/io/event_loop_socket_factory.h",
        ],
    }),
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = select({
        "@envoy//bazel:windows_x86_64": [],
        "@envoy//bazel:disable_http3": [],
        "//conditions:default": [
            ":quic_core_io_event_loop",
            ":quic_core_io_socket_lib",
            ":quic_core_types_lib",
            ":quic_platform_socket_address",
            ":quiche_common_buffer_allocator_lib",
            ":quiche_common_platform",
            "@com_google_absl//absl/status:statusor",
            "@com_google_absl//absl/strings",
            "@com_google_absl//absl/types:optional",
            "@com_google_absl//absl/types:span",
            "@com_google_absl//absl/types:variant",
        ],
    }),
)

envoy_quic_cc_library(
    name = "quic_core_lru_cache_lib",
    hdrs = ["quiche/quic/core/quic_lru_cache.h"],
    deps = [":quic_platform_base"],
)

envoy_quic_cc_library(
    name = "quic_core_mtu_discovery_lib",
    srcs = ["quiche/quic/core/quic_mtu_discovery.cc"],
    hdrs = ["quiche/quic/core/quic_mtu_discovery.h"],
    deps = [
        ":quic_core_constants_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_one_block_arena_lib",
    srcs = ["quiche/quic/core/quic_one_block_arena.h"],
    deps = [
        ":quic_core_arena_scoped_ptr_lib",
        ":quic_core_types_lib",
        ":quic_platform_base",
    ],
)

envoy_cc_library(
    name = "quic_core_syscall_wrapper_lib",
    srcs = select({
        "@envoy//bazel:linux": ["quiche/quic/core/quic_syscall_wrapper.cc"],
        "//conditions:default": [],
    }),
    hdrs = select({
        "@envoy//bazel:linux": ["quiche/quic/core/quic_syscall_wrapper.h"],
        "//conditions:default": [],
    }),
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quic_platform_export",
    ],
)

envoy_cc_library(
    name = "quic_core_linux_socket_utils_lib",
    srcs = select({
        "@envoy//bazel:linux": ["quiche/quic/core/quic_linux_socket_utils.cc"],
        "//conditions:default": [],
    }),
    hdrs = select({
        "@envoy//bazel:linux": ["quiche/quic/core/quic_linux_socket_utils.h"],
        "//conditions:default": [],
    }),
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quic_core_packet_writer_lib",
        ":quic_core_syscall_wrapper_lib",
        ":quic_core_types_lib",
        ":quic_platform",
        ":quiche_common_callbacks",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_network_blackhole_detector_lib",
    srcs = ["quiche/quic/core/quic_network_blackhole_detector.cc"],
    hdrs = ["quiche/quic/core/quic_network_blackhole_detector.h"],
    deps = [
        ":quic_core_alarm_factory_lib",
        ":quic_core_alarm_lib",
        ":quic_core_constants_lib",
        ":quic_core_one_block_arena_lib",
        ":quic_core_time_lib",
        ":quic_platform_export",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_packet_creator_lib",
    srcs = ["quiche/quic/core/quic_packet_creator.cc"],
    hdrs = ["quiche/quic/core/quic_packet_creator.h"],
    deps = [
        ":quic_core_chaos_protector_lib",
        ":quic_core_coalesced_packet_lib",
        ":quic_core_constants_lib",
        ":quic_core_crypto_encryption_lib",
        ":quic_core_data_lib",
        ":quic_core_framer_lib",
        ":quic_core_packets_lib",
        ":quic_core_types_lib",
        ":quic_core_utils_lib",
        ":quic_core_versions_lib",
        ":quic_platform_base",
        ":quiche_common_circular_deque_lib",
        ":quiche_common_print_elements_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_packet_number_indexed_queue_lib",
    hdrs = ["quiche/quic/core/packet_number_indexed_queue.h"],
    deps = [
        ":quic_core_constants_lib",
        ":quic_core_types_lib",
        ":quic_platform_base",
        ":quiche_common_circular_deque_lib",
    ],
)

envoy_cc_library(
    name = "quic_core_packet_writer_lib",
    srcs = ["quiche/quic/core/quic_packet_writer_wrapper.cc"],
    hdrs = [
        "quiche/quic/core/quic_packet_writer.h",
        "quiche/quic/core/quic_packet_writer_wrapper.h",
    ],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_core_packets_lib",
        ":quic_core_types_lib",
        ":quic_platform_base",
    ],
)

envoy_cc_library(
    name = "quic_core_packets_lib",
    srcs = [
        "quiche/quic/core/quic_packets.cc",
        "quiche/quic/core/quic_write_blocked_list.cc",
    ],
    hdrs = [
        "quiche/quic/core/quic_packets.h",
        "quiche/quic/core/quic_write_blocked_list.h",
    ],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":http2_core_priority_write_scheduler_lib",
        ":quic_core_ack_listener_interface_lib",
        ":quic_core_bandwidth_lib",
        ":quic_core_constants_lib",
        ":quic_core_error_codes_lib",
        ":quic_core_frames_frames_lib",
        ":quic_core_time_lib",
        ":quic_core_types_lib",
        ":quic_core_utils_lib",
        ":quic_core_versions_lib",
        ":quic_platform",
        ":quic_platform_socket_address",
        ":quic_stream_priority_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_path_validator_lib",
    srcs = ["quiche/quic/core/quic_path_validator.cc"],
    hdrs = ["quiche/quic/core/quic_path_validator.h"],
    deps = [
        ":quic_core_alarm_factory_lib",
        ":quic_core_alarm_lib",
        ":quic_core_arena_scoped_ptr_lib",
        ":quic_core_clock_lib",
        ":quic_core_constants_lib",
        ":quic_core_crypto_random_lib",
        ":quic_core_one_block_arena_lib",
        ":quic_core_packet_writer_lib",
        ":quic_core_types_lib",
        ":quic_platform",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_ping_manager_lib",
    srcs = ["quiche/quic/core/quic_ping_manager.cc"],
    hdrs = ["quiche/quic/core/quic_ping_manager.h"],
    deps = [
        ":quic_core_alarm_factory_lib",
        ":quic_core_alarm_lib",
        ":quic_core_constants_lib",
        ":quic_core_one_block_arena_lib",
        ":quic_core_time_lib",
        ":quic_platform_export",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_process_packet_interface_lib",
    hdrs = ["quiche/quic/core/quic_process_packet_interface.h"],
    deps = [
        ":quic_core_packets_lib",
        ":quic_platform_base",
    ],
)

envoy_cc_library(
    name = "quic_core_protocol_flags_list_lib",
    hdrs = ["quiche/quic/core/quic_protocol_flags_list.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
)

envoy_quic_cc_library(
    name = "quic_core_qpack_blocking_manager_lib",
    srcs = ["quiche/quic/core/qpack/qpack_blocking_manager.cc"],
    hdrs = ["quiche/quic/core/qpack/qpack_blocking_manager.h"],
    deps = [
        ":quic_core_types_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_qpack_qpack_decoder_lib",
    srcs = ["quiche/quic/core/qpack/qpack_decoder.cc"],
    hdrs = ["quiche/quic/core/qpack/qpack_decoder.h"],
    deps = [
        ":quic_core_qpack_qpack_decoder_stream_sender_lib",
        ":quic_core_qpack_qpack_encoder_stream_receiver_lib",
        ":quic_core_qpack_qpack_header_table_lib",
        ":quic_core_qpack_qpack_progressive_decoder_lib",
        ":quic_core_types_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_qpack_qpack_encoder_lib",
    srcs = ["quiche/quic/core/qpack/qpack_encoder.cc"],
    hdrs = ["quiche/quic/core/qpack/qpack_encoder.h"],
    deps = [
        ":quic_core_qpack_blocking_manager_lib",
        ":quic_core_qpack_qpack_decoder_stream_receiver_lib",
        ":quic_core_qpack_qpack_encoder_stream_sender_lib",
        ":quic_core_qpack_qpack_header_table_lib",
        ":quic_core_qpack_qpack_index_conversions_lib",
        ":quic_core_qpack_qpack_instruction_encoder_lib",
        ":quic_core_qpack_qpack_instructions_lib",
        ":quic_core_qpack_qpack_required_insert_count_lib",
        ":quic_core_qpack_value_splitting_header_list_lib",
        ":quic_core_types_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_qpack_qpack_header_table_lib",
    srcs = ["quiche/quic/core/qpack/qpack_header_table.cc"],
    hdrs = ["quiche/quic/core/qpack/qpack_header_table.h"],
    deps = [
        ":quic_core_qpack_qpack_static_table_lib",
        ":quic_platform_base",
        ":quiche_common_circular_deque_lib",
        ":spdy_core_hpack_hpack_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_qpack_qpack_instruction_decoder_lib",
    srcs = ["quiche/quic/core/qpack/qpack_instruction_decoder.cc"],
    hdrs = ["quiche/quic/core/qpack/qpack_instruction_decoder.h"],
    deps = [
        ":http2_hpack_huffman_hpack_huffman_decoder_lib",
        ":http2_hpack_varint_hpack_varint_decoder_lib",
        ":quic_core_qpack_qpack_instructions_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_qpack_qpack_instructions_lib",
    srcs = ["quiche/quic/core/qpack/qpack_instructions.cc"],
    hdrs = ["quiche/quic/core/qpack/qpack_instructions.h"],
    deps = [":quic_platform_base"],
)

envoy_quic_cc_library(
    name = "quic_core_qpack_qpack_instruction_encoder_lib",
    srcs = ["quiche/quic/core/qpack/qpack_instruction_encoder.cc"],
    hdrs = ["quiche/quic/core/qpack/qpack_instruction_encoder.h"],
    deps = [
        ":http2_hpack_huffman_hpack_huffman_encoder_lib",
        ":http2_hpack_varint_hpack_varint_encoder_lib",
        ":quic_core_qpack_qpack_instructions_lib",
        ":quic_platform",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_qpack_qpack_progressive_decoder_lib",
    srcs = ["quiche/quic/core/qpack/qpack_progressive_decoder.cc"],
    hdrs = ["quiche/quic/core/qpack/qpack_progressive_decoder.h"],
    deps = [
        ":quic_core_qpack_qpack_decoder_stream_sender_lib",
        ":quic_core_qpack_qpack_encoder_stream_receiver_lib",
        ":quic_core_qpack_qpack_header_table_lib",
        ":quic_core_qpack_qpack_index_conversions_lib",
        ":quic_core_qpack_qpack_instruction_decoder_lib",
        ":quic_core_qpack_qpack_instructions_lib",
        ":quic_core_qpack_qpack_required_insert_count_lib",
        ":quic_core_types_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_qpack_qpack_required_insert_count_lib",
    srcs = ["quiche/quic/core/qpack/qpack_required_insert_count.cc"],
    hdrs = ["quiche/quic/core/qpack/qpack_required_insert_count.h"],
    deps = [":quic_platform_base"],
)

envoy_quic_cc_library(
    name = "quic_core_qpack_qpack_encoder_stream_sender_lib",
    srcs = ["quiche/quic/core/qpack/qpack_encoder_stream_sender.cc"],
    hdrs = ["quiche/quic/core/qpack/qpack_encoder_stream_sender.h"],
    deps = [
        ":quic_core_qpack_qpack_instruction_encoder_lib",
        ":quic_core_qpack_qpack_instructions_lib",
        ":quic_core_qpack_qpack_stream_sender_delegate_lib",
        ":quic_core_types_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_qpack_qpack_encoder_stream_receiver_lib",
    srcs = ["quiche/quic/core/qpack/qpack_encoder_stream_receiver.cc"],
    hdrs = ["quiche/quic/core/qpack/qpack_encoder_stream_receiver.h"],
    deps = [
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":quic_core_error_codes_lib",
        ":quic_core_qpack_qpack_instruction_decoder_lib",
        ":quic_core_qpack_qpack_instructions_lib",
        ":quic_core_qpack_qpack_stream_receiver_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_qpack_qpack_decoder_stream_sender_lib",
    srcs = ["quiche/quic/core/qpack/qpack_decoder_stream_sender.cc"],
    hdrs = ["quiche/quic/core/qpack/qpack_decoder_stream_sender.h"],
    deps = [
        ":quic_core_qpack_qpack_instruction_encoder_lib",
        ":quic_core_qpack_qpack_instructions_lib",
        ":quic_core_qpack_qpack_stream_sender_delegate_lib",
        ":quic_core_types_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_qpack_qpack_decoder_stream_receiver_lib",
    srcs = ["quiche/quic/core/qpack/qpack_decoder_stream_receiver.cc"],
    hdrs = ["quiche/quic/core/qpack/qpack_decoder_stream_receiver.h"],
    deps = [
        ":http2_decoder_decode_buffer_lib",
        ":http2_decoder_decode_status_lib",
        ":quic_core_qpack_qpack_instruction_decoder_lib",
        ":quic_core_qpack_qpack_instructions_lib",
        ":quic_core_qpack_qpack_stream_receiver_lib",
        ":quic_core_types_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_qpack_qpack_index_conversions_lib",
    srcs = ["quiche/quic/core/qpack/qpack_index_conversions.cc"],
    hdrs = ["quiche/quic/core/qpack/qpack_index_conversions.h"],
    deps = [
        ":quic_platform_base",
        ":quic_platform_export",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_qpack_qpack_static_table_lib",
    srcs = ["quiche/quic/core/qpack/qpack_static_table.cc"],
    hdrs = ["quiche/quic/core/qpack/qpack_static_table.h"],
    deps = [
        ":quic_platform_base",
        ":spdy_core_hpack_hpack_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_qpack_qpack_stream_receiver_lib",
    hdrs = ["quiche/quic/core/qpack/qpack_stream_receiver.h"],
    deps = [":quic_platform_base"],
)

envoy_quic_cc_library(
    name = "quic_core_qpack_qpack_streams_lib",
    srcs = [
        "quiche/quic/core/qpack/qpack_receive_stream.cc",
        "quiche/quic/core/qpack/qpack_send_stream.cc",
    ],
    hdrs = [
        "quiche/quic/core/qpack/qpack_receive_stream.h",
        "quiche/quic/core/qpack/qpack_send_stream.h",
    ],
    deps = [
        ":quic_core_qpack_qpack_stream_receiver_lib",
        ":quic_core_qpack_qpack_stream_sender_delegate_lib",
        ":quic_core_session_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_qpack_qpack_decoded_headers_accumulator_lib",
    srcs = ["quiche/quic/core/qpack/qpack_decoded_headers_accumulator.cc"],
    hdrs = ["quiche/quic/core/qpack/qpack_decoded_headers_accumulator.h"],
    deps = [
        ":quic_core_http_header_list_lib",
        ":quic_core_qpack_qpack_decoder_lib",
        ":quic_core_qpack_qpack_progressive_decoder_lib",
        ":quic_core_types_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_qpack_value_splitting_header_list_lib",
    srcs = ["quiche/quic/core/qpack/value_splitting_header_list.cc"],
    hdrs = ["quiche/quic/core/qpack/value_splitting_header_list.h"],
    deps = [
        ":quic_platform_base",
        ":spdy_core_http2_header_block_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_qpack_qpack_stream_sender_delegate_lib",
    hdrs = ["quiche/quic/core/qpack/qpack_stream_sender_delegate.h"],
    deps = [":quic_platform_base"],
)

envoy_quic_cc_library(
    name = "quic_core_received_packet_manager_lib",
    srcs = ["quiche/quic/core/quic_received_packet_manager.cc"],
    hdrs = ["quiche/quic/core/quic_received_packet_manager.h"],
    deps = [
        ":quic_core_config_lib",
        ":quic_core_congestion_control_rtt_stats_lib",
        ":quic_core_connection_stats_lib",
        ":quic_core_crypto_encryption_lib",
        ":quic_core_framer_lib",
        ":quic_core_packets_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_sent_packet_manager_lib",
    srcs = ["quiche/quic/core/quic_sent_packet_manager.cc"],
    hdrs = ["quiche/quic/core/quic_sent_packet_manager.h"],
    deps = [
        ":quic_core_congestion_control_congestion_control_lib",
        ":quic_core_congestion_control_general_loss_algorithm_lib",
        ":quic_core_congestion_control_pacing_sender_lib",
        ":quic_core_congestion_control_rtt_stats_lib",
        ":quic_core_congestion_control_uber_loss_algorithm_lib",
        ":quic_core_connection_stats_lib",
        ":quic_core_crypto_encryption_lib",
        ":quic_core_packets_lib",
        ":quic_core_proto_cached_network_parameters_proto_header",
        ":quic_core_sustained_bandwidth_recorder_lib",
        ":quic_core_transmission_info_lib",
        ":quic_core_types_lib",
        ":quic_core_unacked_packet_map_lib",
        ":quic_core_utils_lib",
        ":quic_platform_base",
        ":quiche_common_print_elements_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_web_transport_interface_lib",
    hdrs = ["quiche/quic/core/web_transport_interface.h"],
    deps = [
        ":quic_core_session_lib",
        ":quic_core_types_lib",
        ":quic_platform_export",
        ":quiche_web_transport_web_transport_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_server_id_lib",
    srcs = ["quiche/quic/core/quic_server_id.cc"],
    hdrs = ["quiche/quic/core/quic_server_id.h"],
    deps = [
        ":quic_platform_base",
        ":quiche_common_platform_googleurl",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_server_lib",
    srcs = [
        "quiche/quic/core/chlo_extractor.cc",
        "quiche/quic/core/quic_buffered_packet_store.cc",
        "quiche/quic/core/quic_dispatcher.cc",
        "quiche/quic/core/tls_chlo_extractor.cc",
    ],
    hdrs = [
        "quiche/quic/core/chlo_extractor.h",
        "quiche/quic/core/quic_buffered_packet_store.h",
        "quiche/quic/core/quic_dispatcher.h",
        "quiche/quic/core/tls_chlo_extractor.h",
    ],
    deps = [
        ":quic_core_alarm_factory_lib",
        ":quic_core_alarm_lib",
        ":quic_core_blocked_writer_interface_lib",
        ":quic_core_connection_id_generator_interface_lib",
        ":quic_core_connection_lib",
        ":quic_core_crypto_crypto_handshake_lib",
        ":quic_core_crypto_encryption_lib",
        ":quic_core_crypto_random_lib",
        ":quic_core_deterministic_connection_id_generator_lib",
        ":quic_core_framer_lib",
        ":quic_core_packets_lib",
        ":quic_core_process_packet_interface_lib",
        ":quic_core_time_lib",
        ":quic_core_time_wait_list_manager_lib",
        ":quic_core_types_lib",
        ":quic_core_utils_lib",
        ":quic_core_version_manager_lib",
        ":quic_platform",
        ":quic_server_session_lib",
        ":quiche_common_callbacks",
        ":quiche_common_text_utils_lib",
    ],
)

envoy_cc_library(
    name = "quic_stream_priority_lib",
    srcs = [
        "quiche/quic/core/quic_stream_priority.cc",
    ],
    hdrs = [
        "quiche/quic/core/quic_stream_priority.h",
    ],
    copts = quiche_copts,
    external_deps = ["ssl"],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_core_types_lib",
        ":quic_platform_export",
        ":quiche_common_platform_bug_tracker",
        ":quiche_common_structured_headers_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_session_lib",
    srcs = [
        "quiche/quic/core/legacy_quic_stream_id_manager.cc",
        "quiche/quic/core/quic_control_frame_manager.cc",
        "quiche/quic/core/quic_crypto_handshaker.cc",
        "quiche/quic/core/quic_crypto_stream.cc",
        "quiche/quic/core/quic_datagram_queue.cc",
        "quiche/quic/core/quic_flow_controller.cc",
        "quiche/quic/core/quic_session.cc",
        "quiche/quic/core/quic_stream.cc",
        "quiche/quic/core/quic_stream_id_manager.cc",
        "quiche/quic/core/quic_stream_sequencer.cc",
        "quiche/quic/core/tls_handshaker.cc",
        "quiche/quic/core/uber_quic_stream_id_manager.cc",
    ],
    hdrs = [
        "quiche/quic/core/handshaker_delegate_interface.h",
        "quiche/quic/core/legacy_quic_stream_id_manager.h",
        "quiche/quic/core/quic_control_frame_manager.h",
        "quiche/quic/core/quic_crypto_client_stream.h",  # required by tls_client_handshaker.h
        "quiche/quic/core/quic_crypto_handshaker.h",
        "quiche/quic/core/quic_crypto_stream.h",
        "quiche/quic/core/quic_datagram_queue.h",
        "quiche/quic/core/quic_flow_controller.h",
        "quiche/quic/core/quic_session.h",
        "quiche/quic/core/quic_stream.h",
        "quiche/quic/core/quic_stream_id_manager.h",
        "quiche/quic/core/quic_stream_sequencer.h",
        "quiche/quic/core/stream_delegate_interface.h",
        "quiche/quic/core/tls_client_handshaker.h",  # required by tls_handshaker.cc
        "quiche/quic/core/tls_handshaker.h",
        "quiche/quic/core/uber_quic_stream_id_manager.h",
    ],
    external_deps = ["ssl"],
    deps = [
        ":quic_client_crypto_crypto_handshake_lib",
        ":quic_core_config_lib",
        ":quic_core_connection_lib",
        ":quic_core_constants_lib",
        ":quic_core_crypto_crypto_handshake_lib",
        ":quic_core_crypto_encryption_lib",
        ":quic_core_crypto_random_lib",
        ":quic_core_crypto_tls_handshake_lib",
        ":quic_core_frames_frames_lib",
        ":quic_core_http_http_decoder_lib",
        ":quic_core_http_http_encoder_lib",
        ":quic_core_packet_creator_lib",
        ":quic_core_packets_lib",
        ":quic_core_server_id_lib",
        ":quic_core_session_notifier_interface_lib",
        ":quic_core_stream_frame_data_producer_lib",
        ":quic_core_stream_send_buffer_lib",
        ":quic_core_stream_sequencer_buffer_lib",
        ":quic_core_types_lib",
        ":quic_core_utils_lib",
        ":quic_core_versions_lib",
        ":quic_platform",
        ":quic_server_crypto_crypto_handshake_lib",
        ":quic_stream_priority_lib",
        ":quiche_common_callbacks",
        ":quiche_common_structured_headers_lib",
        ":quiche_common_text_utils_lib",
        ":spdy_core_protocol_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_client_session_lib",
    srcs = [
        "quiche/quic/core/quic_crypto_client_handshaker.cc",
        "quiche/quic/core/quic_crypto_client_stream.cc",
        "quiche/quic/core/tls_client_handshaker.cc",
    ],
    hdrs = [
        "quiche/quic/core/quic_crypto_client_handshaker.h",
        "quiche/quic/core/quic_crypto_client_stream.h",
        "quiche/quic/core/tls_client_handshaker.h",
    ],
    external_deps = ["ssl"],
    deps = [
        ":quic_client_crypto_crypto_handshake_lib",
        ":quic_core_session_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_server_session_lib",
    srcs = [
        "quiche/quic/core/quic_crypto_server_stream.cc",
        "quiche/quic/core/quic_crypto_server_stream_base.cc",
        "quiche/quic/core/tls_server_handshaker.cc",
    ],
    hdrs = [
        "quiche/quic/core/quic_crypto_server_stream.h",
        "quiche/quic/core/quic_crypto_server_stream_base.h",
        "quiche/quic/core/tls_server_handshaker.h",
    ],
    external_deps = ["ssl"],
    deps = [
        ":quic_core_session_lib",
        ":quic_server_crypto_crypto_handshake_lib",
        ":quic_server_crypto_tls_handshake_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_session_notifier_interface_lib",
    hdrs = ["quiche/quic/core/session_notifier_interface.h"],
    deps = [
        ":quic_core_frames_frames_lib",
        ":quic_core_time_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_socket_address_coder_lib",
    srcs = ["quiche/quic/core/quic_socket_address_coder.cc"],
    hdrs = ["quiche/quic/core/quic_socket_address_coder.h"],
    deps = [
        ":quic_platform_base",
        ":quic_platform_socket_address",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_stream_frame_data_producer_lib",
    hdrs = ["quiche/quic/core/quic_stream_frame_data_producer.h"],
    deps = [":quic_core_types_lib"],
)

envoy_quic_cc_library(
    name = "quic_core_stream_send_buffer_lib",
    srcs = ["quiche/quic/core/quic_stream_send_buffer.cc"],
    hdrs = ["quiche/quic/core/quic_stream_send_buffer.h"],
    deps = [
        ":quic_core_data_lib",
        ":quic_core_frames_frames_lib",
        ":quic_core_interval_deque_lib",
        ":quic_core_interval_lib",
        ":quic_core_interval_set_lib",
        ":quic_core_types_lib",
        ":quic_core_utils_lib",
        ":quic_platform_base",
        ":quiche_common_circular_deque_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_stream_sequencer_buffer_lib",
    srcs = ["quiche/quic/core/quic_stream_sequencer_buffer.cc"],
    hdrs = ["quiche/quic/core/quic_stream_sequencer_buffer.h"],
    deps = [
        ":quic_core_constants_lib",
        ":quic_core_interval_lib",
        ":quic_core_interval_set_lib",
        ":quic_core_packets_lib",
        ":quic_core_types_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_sustained_bandwidth_recorder_lib",
    srcs = ["quiche/quic/core/quic_sustained_bandwidth_recorder.cc"],
    hdrs = ["quiche/quic/core/quic_sustained_bandwidth_recorder.h"],
    deps = [
        ":quic_core_bandwidth_lib",
        ":quic_core_time_lib",
        ":quic_platform_base",
        ":quic_platform_export",
    ],
)

envoy_cc_library(
    name = "quic_core_tag_lib",
    srcs = ["quiche/quic/core/quic_tag.cc"],
    hdrs = ["quiche/quic/core/quic_tag.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_platform_base",
        ":quiche_common_text_utils_lib",
    ],
)

envoy_cc_library(
    name = "quic_core_time_lib",
    srcs = ["quiche/quic/core/quic_time.cc"],
    hdrs = ["quiche/quic/core/quic_time.h"],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [":quic_platform_base"],
)

envoy_quic_cc_library(
    name = "quic_core_time_accumulator_lib",
    hdrs = ["quiche/quic/core/quic_time_accumulator.h"],
    deps = [],
)

envoy_quic_cc_library(
    name = "quic_core_time_wait_list_manager_lib",
    srcs = ["quiche/quic/core/quic_time_wait_list_manager.cc"],
    hdrs = ["quiche/quic/core/quic_time_wait_list_manager.h"],
    deps = [
        ":quic_core_blocked_writer_interface_lib",
        ":quic_core_crypto_encryption_lib",
        ":quic_core_framer_lib",
        ":quic_core_packet_writer_lib",
        ":quic_core_packets_lib",
        ":quic_core_types_lib",
        ":quic_core_utils_lib",
        ":quic_platform",
        ":quic_server_session_lib",
        ":quiche_common_text_utils_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_transmission_info_lib",
    srcs = ["quiche/quic/core/quic_transmission_info.cc"],
    hdrs = ["quiche/quic/core/quic_transmission_info.h"],
    deps = [
        ":quic_core_ack_listener_interface_lib",
        ":quic_core_frames_frames_lib",
        ":quic_core_types_lib",
        ":quic_platform_export",
    ],
)

envoy_cc_library(
    name = "quic_core_types_lib",
    srcs = [
        "quiche/quic/core/quic_connection_id.cc",
        "quiche/quic/core/quic_packet_number.cc",
        "quiche/quic/core/quic_types.cc",
    ],
    hdrs = [
        "quiche/quic/core/quic_connection_id.h",
        "quiche/quic/core/quic_packet_number.h",
        "quiche/quic/core/quic_types.h",
    ],
    copts = quiche_copts,
    external_deps = ["ssl"],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_core_crypto_random_lib",
        ":quic_core_error_codes_lib",
        ":quic_core_time_lib",
        ":quic_platform_base",
        ":quiche_common_endian_lib",
        ":quiche_common_print_elements_lib",
        ":quiche_web_transport_web_transport_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_uber_received_packet_manager_lib",
    srcs = ["quiche/quic/core/uber_received_packet_manager.cc"],
    hdrs = ["quiche/quic/core/uber_received_packet_manager.h"],
    deps = [
        ":quic_core_received_packet_manager_lib",
        ":quic_core_utils_lib",
        ":quic_platform_base",
    ],
)

envoy_cc_library(
    name = "quic_core_udp_socket_lib",
    srcs = select({
        "@envoy//bazel:windows_x86_64": [],
        "//conditions:default": ["quiche/quic/core/quic_udp_socket.cc"],
    }),
    hdrs = select({
        "@envoy//bazel:windows_x86_64": [],
        "//conditions:default": [
            "quiche/quic/core/quic_udp_socket.h",
            "quiche/quic/core/quic_udp_socket_posix.inc",
        ],
    }),
    copts = quiche_copts + select({
        # On OSX/iOS, constants from RFC 3542 (e.g. IPV6_RECVPKTINFO) are not usable
        # without this define.
        "@envoy//bazel:apple": ["-D__APPLE_USE_RFC_3542"],
        "//conditions:default": [],
    }),
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quic_core_io_socket_lib",
        ":quic_core_types_lib",
        ":quic_core_utils_lib",
        ":quic_platform",
        ":quic_platform_udp_socket_platform",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_unacked_packet_map_lib",
    srcs = ["quiche/quic/core/quic_unacked_packet_map.cc"],
    hdrs = ["quiche/quic/core/quic_unacked_packet_map.h"],
    deps = [
        ":quic_core_connection_stats_lib",
        ":quic_core_packets_lib",
        ":quic_core_session_notifier_interface_lib",
        ":quic_core_transmission_info_lib",
        ":quic_core_utils_lib",
        ":quic_platform_base",
        ":quiche_common_circular_deque_lib",
    ],
)

envoy_cc_library(
    name = "quic_core_utils_lib",
    srcs = ["quiche/quic/core/quic_utils.cc"],
    hdrs = ["quiche/quic/core/quic_utils.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_core_constants_lib",
        ":quic_core_crypto_random_lib",
        ":quic_core_error_codes_lib",
        ":quic_core_frames_frames_lib",
        ":quic_core_types_lib",
        ":quic_core_versions_lib",
        ":quic_platform_base",
        ":quic_platform_socket_address",
        ":quiche_common_buffer_allocator_lib",
    ],
)

envoy_quic_cc_library(
    name = "quic_core_version_manager_lib",
    srcs = ["quiche/quic/core/quic_version_manager.cc"],
    hdrs = ["quiche/quic/core/quic_version_manager.h"],
    deps = [
        ":quic_core_versions_lib",
        ":quic_platform_base",
        ":quiche_common_endian_lib",
    ],
)

envoy_cc_library(
    name = "quic_core_versions_lib",
    srcs = ["quiche/quic/core/quic_versions.cc"],
    hdrs = ["quiche/quic/core/quic_versions.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_core_crypto_random_lib",
        ":quic_core_tag_lib",
        ":quic_core_types_lib",
        ":quic_platform_base",
        ":quiche_common_text_utils_lib",
    ],
)

envoy_quic_cc_test_library(
    name = "quic_test_tools_config_peer_lib",
    srcs = ["quiche/quic/test_tools/quic_config_peer.cc"],
    hdrs = ["quiche/quic/test_tools/quic_config_peer.h"],
    deps = [
        ":quic_core_config_lib",
        ":quic_core_packets_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_test_library(
    name = "quic_test_tools_connection_id_manager_peer_lib",
    hdrs = ["quiche/quic/test_tools/quic_connection_id_manager_peer.h"],
    deps = [":quic_core_connection_id_manager"],
)

envoy_quic_cc_test_library(
    name = "quic_test_tools_crypto_server_config_peer_lib",
    srcs = [
        "quiche/quic/test_tools/quic_crypto_server_config_peer.cc",
    ],
    hdrs = [
        "quiche/quic/test_tools/quic_crypto_server_config_peer.h",
    ],
    deps = [
        ":quic_core_crypto_crypto_handshake_lib",
        ":quic_test_tools_mock_clock_lib",
        ":quic_test_tools_mock_random_lib",
        ":quic_test_tools_test_utils_lib",
        ":quiche_common_platform",
    ],
)

envoy_quic_cc_test_library(
    name = "quic_test_tools_first_flight_lib",
    srcs = [
        "quiche/quic/test_tools/first_flight.cc",
    ],
    hdrs = [
        "quiche/quic/test_tools/first_flight.h",
    ],
    deps = [
        ":quic_core_config_lib",
        ":quic_core_connection_lib",
        ":quic_core_crypto_crypto_handshake_lib",
        ":quic_core_http_client_lib",
        ":quic_core_packet_writer_lib",
        ":quic_core_packets_lib",
        ":quic_core_types_lib",
        ":quic_core_versions_lib",
        ":quic_platform",
        ":quic_test_tools_test_utils_lib",
    ],
)

envoy_quic_cc_test_library(
    name = "quic_test_tools_flow_controller_peer_lib",
    srcs = [
        "quiche/quic/test_tools/quic_flow_controller_peer.cc",
    ],
    hdrs = [
        "quiche/quic/test_tools/quic_flow_controller_peer.h",
    ],
    deps = [
        ":quic_core_packets_lib",
        ":quic_core_session_lib",
    ],
)

envoy_quic_cc_test_library(
    name = "quic_test_tools_framer_peer_lib",
    srcs = ["quiche/quic/test_tools/quic_framer_peer.cc"],
    hdrs = ["quiche/quic/test_tools/quic_framer_peer.h"],
    deps = [
        ":quic_core_crypto_encryption_lib",
        ":quic_core_framer_lib",
        ":quic_core_packets_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_test_library(
    name = "quic_test_tools_interval_deque_peer_lib",
    hdrs = ["quiche/quic/test_tools/quic_interval_deque_peer.h"],
    deps = [
        ":quic_core_interval_deque_lib",
        ":quic_core_interval_lib",
    ],
)

envoy_quic_cc_test_library(
    name = "quic_test_tools_mock_clock_lib",
    srcs = ["quiche/quic/test_tools/mock_clock.cc"],
    hdrs = ["quiche/quic/test_tools/mock_clock.h"],
    deps = [
        ":quic_core_clock_lib",
        ":quic_core_time_lib",
    ],
)

envoy_quic_cc_test_library(
    name = "quic_test_tools_mock_random_lib",
    srcs = ["quiche/quic/test_tools/mock_random.cc"],
    hdrs = ["quiche/quic/test_tools/mock_random.h"],
    deps = [
        ":quic_core_crypto_random_lib",
        ":quic_platform_test",
    ],
)

envoy_quic_cc_test_library(
    name = "quic_test_tools_mock_syscall_wrapper_lib",
    srcs = ["quiche/quic/test_tools/quic_mock_syscall_wrapper.cc"],
    hdrs = ["quiche/quic/test_tools/quic_mock_syscall_wrapper.h"],
    deps = [
        ":quic_core_syscall_wrapper_lib",
        ":quic_platform_base",
        ":quic_platform_test",
    ],
)

envoy_quic_cc_test_library(
    name = "quic_test_tools_qpack_qpack_test_utils_lib",
    srcs = ["quiche/quic/test_tools/qpack/qpack_test_utils.cc"],
    hdrs = ["quiche/quic/test_tools/qpack/qpack_test_utils.h"],
    deps = [
        ":quic_core_qpack_qpack_encoder_lib",
        ":quic_core_qpack_qpack_stream_sender_delegate_lib",
        ":quic_platform_test",
    ],
)

envoy_quic_cc_test_library(
    name = "quic_test_tools_sent_packet_manager_peer_lib",
    srcs = ["quiche/quic/test_tools/quic_sent_packet_manager_peer.cc"],
    hdrs = ["quiche/quic/test_tools/quic_sent_packet_manager_peer.h"],
    deps = [
        ":quic_core_congestion_control_congestion_control_interface_lib",
        ":quic_core_packets_lib",
        ":quic_core_sent_packet_manager_lib",
        ":quic_test_tools_unacked_packet_map_peer_lib",
    ],
)

envoy_quic_cc_test_library(
    name = "quic_test_tools_server_session_base_peer",
    hdrs = [
        "quiche/quic/test_tools/quic_server_session_base_peer.h",
    ],
    deps = [
        ":quic_core_utils_lib",
        ":quic_server_http_spdy_session_lib",
    ],
)

envoy_quic_cc_test_library(
    name = "quic_test_tools_simple_quic_framer_lib",
    srcs = ["quiche/quic/test_tools/simple_quic_framer.cc"],
    hdrs = ["quiche/quic/test_tools/simple_quic_framer.h"],
    deps = [
        ":quic_core_crypto_encryption_lib",
        ":quic_core_framer_lib",
        ":quic_core_packets_lib",
        ":quic_platform_base",
    ],
)

envoy_quic_cc_test_library(
    name = "quic_test_tools_stream_send_buffer_peer_lib",
    srcs = ["quiche/quic/test_tools/quic_stream_send_buffer_peer.cc"],
    hdrs = ["quiche/quic/test_tools/quic_stream_send_buffer_peer.h"],
    deps = [
        ":quic_core_stream_send_buffer_lib",
        ":quic_test_tools_interval_deque_peer_lib",
    ],
)

envoy_quic_cc_test_library(
    name = "quic_test_tools_stream_peer_lib",
    srcs = ["quiche/quic/test_tools/quic_stream_peer.cc"],
    hdrs = ["quiche/quic/test_tools/quic_stream_peer.h"],
    deps = [
        ":quic_core_packets_lib",
        ":quic_core_session_lib",
        ":quic_core_stream_send_buffer_lib",
        ":quic_platform_base",
        ":quic_test_tools_flow_controller_peer_lib",
        ":quic_test_tools_stream_send_buffer_peer_lib",
    ],
)

envoy_quic_cc_test_library(
    name = "quic_test_tools_test_certificates_lib",
    srcs = ["quiche/quic/test_tools/test_certificates.cc"],
    hdrs = ["quiche/quic/test_tools/test_certificates.h"],
    deps = [
        ":quic_platform_base",
        ":quiche_common_platform",
    ],
)

envoy_quic_cc_test_library(
    name = "quic_test_tools_test_utils_lib",
    srcs = [
        "quiche/quic/test_tools/crypto_test_utils.cc",
        "quiche/quic/test_tools/mock_quic_session_visitor.cc",
        "quiche/quic/test_tools/mock_quic_time_wait_list_manager.cc",
        "quiche/quic/test_tools/quic_buffered_packet_store_peer.cc",
        "quiche/quic/test_tools/quic_connection_peer.cc",
        "quiche/quic/test_tools/quic_dispatcher_peer.cc",
        "quiche/quic/test_tools/quic_test_utils.cc",
    ],
    hdrs = [
        "quiche/quic/test_tools/crypto_test_utils.h",
        "quiche/quic/test_tools/mock_connection_id_generator.h",
        "quiche/quic/test_tools/mock_quic_session_visitor.h",
        "quiche/quic/test_tools/mock_quic_time_wait_list_manager.h",
        "quiche/quic/test_tools/quic_buffered_packet_store_peer.h",
        "quiche/quic/test_tools/quic_connection_peer.h",
        "quiche/quic/test_tools/quic_dispatcher_peer.h",
        "quiche/quic/test_tools/quic_test_utils.h",
    ],
    external_deps = ["ssl"],
    deps = [
        ":quic_client_session_lib",
        ":quic_core_congestion_control_congestion_control_interface_lib",
        ":quic_core_connection_lib",
        ":quic_core_connection_stats_lib",
        ":quic_core_crypto_crypto_handshake_lib",
        ":quic_core_crypto_encryption_lib",
        ":quic_core_crypto_proof_source_lib",
        ":quic_core_crypto_proof_source_x509_lib",
        ":quic_core_crypto_random_lib",
        ":quic_core_data_lib",
        ":quic_core_framer_lib",
        ":quic_core_http_client_lib",
        ":quic_core_packet_creator_lib",
        ":quic_core_packet_writer_lib",
        ":quic_core_packets_lib",
        ":quic_core_path_validator_lib",
        ":quic_core_received_packet_manager_lib",
        ":quic_core_sent_packet_manager_lib",
        ":quic_core_server_id_lib",
        ":quic_core_server_lib",
        ":quic_core_time_wait_list_manager_lib",
        ":quic_core_utils_lib",
        ":quic_platform",
        ":quic_platform_hostname_utils",
        ":quic_platform_test",
        ":quic_server_http_spdy_session_lib",
        ":quic_server_session_lib",
        ":quic_test_tools_config_peer_lib",
        ":quic_test_tools_connection_id_manager_peer_lib",
        ":quic_test_tools_framer_peer_lib",
        ":quic_test_tools_mock_clock_lib",
        ":quic_test_tools_mock_random_lib",
        ":quic_test_tools_sent_packet_manager_peer_lib",
        ":quic_test_tools_simple_quic_framer_lib",
        ":quic_test_tools_stream_peer_lib",
        ":quic_test_tools_test_certificates_lib",
        ":quiche_common_buffer_allocator_lib",
        ":quiche_common_callbacks",
        ":quiche_common_test_tools_test_utils_lib",
        ":spdy_core_framer_lib",
    ],
)

envoy_quic_cc_test_library(
    name = "quic_test_tools_session_peer_lib",
    srcs = [
        "quiche/quic/test_tools/quic_session_peer.cc",
    ],
    hdrs = [
        "quiche/quic/test_tools/quic_session_peer.h",
    ],
    deps = [
        ":quic_client_session_lib",
        ":quic_core_packets_lib",
        ":quic_core_utils_lib",
        ":quic_platform",
        ":quic_server_session_lib",
    ],
)

envoy_quic_cc_test_library(
    name = "quic_test_tools_unacked_packet_map_peer_lib",
    srcs = ["quiche/quic/test_tools/quic_unacked_packet_map_peer.cc"],
    hdrs = ["quiche/quic/test_tools/quic_unacked_packet_map_peer.h"],
    deps = [":quic_core_unacked_packet_map_lib"],
)

envoy_cc_library(
    name = "quiche_common_endian_lib",
    hdrs = ["quiche/common/quiche_endian.h"],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps =
        [
            ":quiche_common_platform_export",
        ],
)

envoy_cc_library(
    name = "quiche_common_platform_client_stats",
    hdrs = [
        "quiche/common/platform/api/quiche_client_stats.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [":quiche_common_platform_default_quiche_platform_impl_client_stats_impl_lib"],
)

envoy_quiche_platform_impl_cc_library(
    name = "quiche_common_platform_default_quiche_platform_impl_client_stats_impl_lib",
    hdrs = [
        "quiche/common/platform/default/quiche_platform_impl/quiche_client_stats_impl.h",
    ],
)

envoy_cc_test_library(
    name = "quiche_common_platform_system_event_loop",
    hdrs = [
        "quiche/common/platform/api/quiche_system_event_loop.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    deps = [":quiche_common_platform_default_quiche_platform_impl_system_event_loop_impl_lib"],
)

envoy_quiche_platform_impl_cc_test_library(
    name = "quiche_common_platform_default_quiche_platform_impl_system_event_loop_impl_lib",
    hdrs = [
        "quiche/common/platform/default/quiche_platform_impl/quiche_system_event_loop_impl.h",
    ],
)

envoy_cc_library(
    name = "quiche_common_platform_googleurl",
    hdrs = ["quiche/common/platform/api/quiche_googleurl.h"],
    repository = "@envoy",
    tags = ["nofips"],
    deps = [":quiche_common_platform_default_quiche_platform_impl_googleurl_impl_lib"],
)

envoy_quiche_platform_impl_cc_library(
    name = "quiche_common_platform_default_quiche_platform_impl_googleurl_impl_lib",
    hdrs = [
        "quiche/common/platform/default/quiche_platform_impl/quiche_googleurl_impl.h",
    ],
    deps = [
        "@com_googlesource_googleurl//url",
    ],
)

envoy_cc_library(
    name = "quiche_common_platform_iovec",
    hdrs = [
        "quiche/common/platform/api/quiche_iovec.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_bug_tracker",
        ":quiche_common_platform_export",
        "@envoy//source/common/quic/platform:quiche_platform_iovec_impl_lib",
    ],
)

envoy_cc_library(
    name = "quiche_common_platform_bug_tracker",
    hdrs = [
        "quiche/common/platform/api/quiche_bug_tracker.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_export",
    ] + select({
        "@platforms//os:android": [
            "@envoy//source/common/quic/platform/mobile_impl:mobile_quiche_bug_tracker_impl_lib",
        ],
        "@platforms//os:ios": [
            "@envoy//source/common/quic/platform/mobile_impl:mobile_quiche_bug_tracker_impl_lib",
        ],
        "//conditions:default": ["@envoy//source/common/quic/platform:quiche_logging_impl_lib"],
    }),
)

envoy_cc_library(
    name = "quiche_common_platform_logging",
    hdrs = [
        "quiche/common/platform/api/quiche_logging.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_export",
    ] + select({
        "@platforms//os:android": [
            ":quiche_common_mobile_quiche_logging_lib",
        ],
        "@platforms//os:ios": [
            ":quiche_common_mobile_quiche_logging_lib",
        ],
        "//conditions:default": ["@envoy//source/common/quic/platform:quiche_logging_impl_lib"],
    }),
)

envoy_cc_library(
    name = "quiche_common_platform_prefetch",
    hdrs = [
        "quiche/common/platform/api/quiche_prefetch.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_default_quiche_platform_impl_prefetch_impl_lib",
        ":quiche_common_platform_export",
    ],
)

envoy_quiche_platform_impl_cc_library(
    name = "quiche_common_platform_default_quiche_platform_impl_prefetch_impl_lib",
    hdrs = [
        "quiche/common/platform/default/quiche_platform_impl/quiche_prefetch_impl.h",
    ],
    deps = [
        ":quiche_common_platform_export",
    ],
)

envoy_quiche_platform_impl_cc_library(
    name = "quiche_common_mobile_quiche_logging_lib",
    srcs = [
        "quiche/common/platform/default/quiche_platform_impl/quiche_logging_impl.cc",
    ],
    hdrs = [
        "quiche/common/platform/default/quiche_platform_impl/quiche_logging_impl.h",
    ],
    deps = [
        "@com_google_absl//absl/flags:flag",
        "@com_google_absl//absl/log:absl_check",
        "@com_google_absl//absl/log:absl_log",
    ],
)

envoy_cc_library(
    name = "quiche_common_platform_mutex",
    srcs = [
        "quiche/common/platform/api/quiche_mutex.cc",
    ],
    hdrs = [
        "quiche/common/platform/api/quiche_mutex.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_default_quiche_platform_impl_mutex_impl_lib",
        ":quiche_common_platform_export",
    ],
)

envoy_quiche_platform_impl_cc_library(
    name = "quiche_common_platform_default_quiche_platform_impl_mutex_impl_lib",
    srcs = [
        "quiche/common/platform/default/quiche_platform_impl/quiche_mutex_impl.cc",
    ],
    hdrs = [
        "quiche/common/platform/default/quiche_platform_impl/quiche_mutex_impl.h",
    ],
    deps = [
        ":quiche_common_platform_export",
        "@com_google_absl//absl/synchronization",
    ],
)

envoy_cc_library(
    name = "quiche_common_platform_hostname_utils",
    srcs = [
        "quiche/common/platform/api/quiche_hostname_utils.cc",
    ],
    hdrs = [
        "quiche/common/platform/api/quiche_hostname_utils.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_export",
        ":quiche_common_platform_googleurl",
        ":quiche_common_platform_logging",
    ],
)

envoy_cc_test_library(
    name = "quiche_common_platform_thread",
    hdrs = [
        "quiche/common/platform/api/quiche_thread.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_common_platform_export",
        "@envoy//test/common/quic/platform:quiche_thread_impl_lib",
    ],
)

envoy_cc_test_library(
    name = "quiche_common_platform_test_output",
    hdrs = [
        "quiche/common/platform/api/quiche_test_output.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_common_platform_export",
        "@envoy//test/common/quic/platform:quiche_test_output_impl_lib",
    ],
)

envoy_cc_test_library(
    name = "quiche_common_platform_expect_bug",
    hdrs = [
        "quiche/common/platform/api/quiche_expect_bug.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_common_platform_export",
        "@envoy//test/common/quic/platform:quiche_expect_bug_impl_lib",
    ],
)

envoy_cc_library(
    name = "quiche_common_platform_udp_socket_platform",
    hdrs = select({
        "@envoy//bazel:linux": ["quiche/common/platform/api/quiche_udp_socket_platform_api.h"],
        "//conditions:default": [],
    }),
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_core_types_lib",
        ":quic_platform_ip_address_family",
        ":quiche_common_platform_default_quiche_platform_impl_udp_socket_platform_impl_lib",
        ":quiche_common_platform_export",
    ],
)

envoy_cc_library(
    name = "quiche_common_platform_server_stats",
    hdrs = ["quiche/common/platform/api/quiche_server_stats.h"],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_default_quiche_platform_impl_server_stats_impl_lib",
    ],
)

envoy_quiche_platform_impl_cc_library(
    name = "quiche_common_platform_default_quiche_platform_impl_server_stats_impl_lib",
    hdrs = [
        "quiche/common/platform/default/quiche_platform_impl/quiche_server_stats_impl.h",
    ],
)

envoy_cc_library(
    name = "quiche_common_platform_stack_trace",
    hdrs = [
        "quiche/common/platform/api/quiche_stack_trace.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_export",
        "@envoy//source/common/quic/platform:quiche_stack_trace_impl_lib",
    ],
)

envoy_cc_library(
    name = "quiche_common_platform_containers",
    hdrs = [
        "quiche/common/platform/api/quiche_containers.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_default_quiche_platform_impl_containers_impl_lib",
        ":quiche_common_platform_export",
    ],
)

envoy_quiche_platform_impl_cc_library(
    name = "quiche_common_platform_default_quiche_platform_impl_containers_impl_lib",
    hdrs = [
        "quiche/common/platform/default/quiche_platform_impl/quiche_containers_impl.h",
    ],
    deps = [
        ":quiche_common_platform_export",
    ],
)

envoy_quiche_platform_impl_cc_library(
    name = "quiche_common_platform_default_quiche_platform_impl_stream_buffer_allocator_impl_lib",
    hdrs = [
        "quiche/common/platform/default/quiche_platform_impl/quiche_stream_buffer_allocator_impl.h",
    ],
    deps = [
        ":quiche_common_platform_export",
    ],
)

envoy_cc_library(
    name = "quiche_common_platform_testvalue",
    hdrs = [
        "quiche/common/platform/api/quiche_testvalue.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_export",
    ],
)

envoy_cc_library(
    name = "quiche_common_platform",
    hdrs = [
        "quiche/common/platform/api/quiche_bug_tracker.h",
        "quiche/common/platform/api/quiche_command_line_flags.h",
        "quiche/common/platform/api/quiche_flag_utils.h",
        "quiche/common/platform/api/quiche_flags.h",
        "quiche/common/platform/api/quiche_mem_slice.h",
        "quiche/common/platform/api/quiche_reference_counted.h",
        "quiche/common/platform/api/quiche_time_utils.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_bug_tracker",
        ":quiche_common_platform_default_quiche_platform_impl_command_line_flags_impl_lib",
        ":quiche_common_platform_default_quiche_platform_impl_flag_utils_impl_lib",
        ":quiche_common_platform_default_quiche_platform_impl_reference_counted_impl_lib",
        ":quiche_common_platform_default_quiche_platform_impl_testvalue_impl_lib",
        ":quiche_common_platform_export",
        ":quiche_common_platform_logging",
        ":quiche_common_platform_prefetch",
        "@envoy//source/common/quic/platform:quic_base_impl_lib",
        "@envoy//source/common/quic/platform:quiche_flags_impl_lib",
        "@envoy//source/common/quic/platform:quiche_mem_slice_impl_lib",
        "@envoy//source/common/quic/platform:quiche_time_utils_impl_lib",
    ],
)

# Use the QUICHE default implementation once the WIN32 compiler error is resolved.
# envoy_quiche_platform_impl_cc_library(
#    name = "quiche_common_platform_default_quiche_platform_impl_export_impl_lib",
#    hdrs = [
#        "quiche/common/platform/default/quiche_platform_impl/quiche_export_impl.h",
#    ],
#)

envoy_quiche_platform_impl_cc_library(
    name = "quiche_common_platform_default_quiche_platform_impl_command_line_flags_impl_lib",
    hdrs = [
        "quiche/common/platform/default/quiche_platform_impl/quiche_command_line_flags_impl.h",
    ],
)

envoy_quiche_platform_impl_cc_library(
    name = "quiche_common_platform_default_quiche_platform_impl_flag_utils_impl_lib",
    hdrs = [
        "quiche/common/platform/default/quiche_platform_impl/quiche_flag_utils_impl.h",
    ],
)

envoy_quiche_platform_impl_cc_library(
    name = "quiche_common_platform_default_quiche_platform_impl_reference_counted_impl_lib",
    hdrs = [
        "quiche/common/platform/default/quiche_platform_impl/quiche_reference_counted_impl.h",
    ],
    deps = [
        ":quiche_common_platform_export",
    ],
)

envoy_quiche_platform_impl_cc_library(
    name = "quiche_common_platform_default_quiche_platform_impl_testvalue_impl_lib",
    hdrs = [
        "quiche/common/platform/default/quiche_platform_impl/quiche_testvalue_impl.h",
    ],
    deps = [
        ":quiche_common_platform_export",
    ],
)

envoy_quiche_platform_impl_cc_library(
    name = "quiche_common_platform_default_quiche_platform_impl_udp_socket_platform_impl_lib",
    hdrs = select({
        "@envoy//bazel:linux": ["quiche/common/platform/default/quiche_platform_impl/quiche_udp_socket_platform_impl.h"],
        "//conditions:default": [],
    }),
)

envoy_cc_library(
    name = "quiche_common_platform_export",
    hdrs = [
        "quiche/common/platform/api/quiche_export.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        "@envoy//source/common/quic/platform:quiche_export_impl_lib",
    ],
)

envoy_cc_test_library(
    name = "quiche_common_platform_test",
    hdrs = ["quiche/common/platform/api/quiche_test.h"],
    repository = "@envoy",
    tags = ["nofips"],
    deps = ["@envoy//test/common/quic/platform:quiche_test_impl_lib"],
)

envoy_cc_test(
    name = "quiche_common_mem_slice_test",
    srcs = ["quiche/common/platform/api/quiche_mem_slice_test.cc"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_common_buffer_allocator_lib",
        ":quiche_common_platform",
        ":quiche_common_platform_test",
    ],
)

envoy_cc_test(
    name = "quiche_common_time_utils_test",
    srcs = ["quiche/common/platform/api/quiche_time_utils_test.cc"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_common_platform",
        ":quiche_common_platform_test",
    ],
)

envoy_cc_library(
    name = "quiche_common_print_elements_lib",
    hdrs = ["quiche/common/print_elements.h"],
    external_deps = [
        "abseil_inlined_vector",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_common_platform_export",
    ],
)

envoy_cc_test_library(
    name = "quiche_common_test_tools_test_utils_lib",
    srcs = ["quiche/common/test_tools/quiche_test_utils.cc"],
    hdrs = [
        "quiche/common/test_tools/quiche_test_utils.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_common_platform",
        ":quiche_common_platform_googleurl",
        ":quiche_common_platform_iovec",
        ":quiche_common_platform_test",
        "@envoy//test/common/quic/platform:quiche_test_helpers_impl_lib",
        "@envoy//test/common/quic/platform:quiche_test_impl_lib",
    ],
)

envoy_cc_library(
    name = "quiche_common_text_utils_lib",
    srcs = ["quiche/common/quiche_text_utils.cc"],
    hdrs = ["quiche/common/quiche_text_utils.h"],
    external_deps = [
        "abseil_str_format",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_common_platform_export",
        "@com_google_absl//absl/hash",
    ],
)

envoy_cc_library(
    name = "quiche_common_lib",
    srcs = [
        "quiche/common/quiche_data_reader.cc",
        "quiche/common/quiche_data_writer.cc",
    ],
    hdrs = [
        "quiche/common/quiche_data_reader.h",
        "quiche/common/quiche_data_writer.h",
        "quiche/common/quiche_linked_hash_map.h",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_endian_lib",
        ":quiche_common_platform",
    ],
)

envoy_cc_library(
    name = "quiche_simple_arena_lib",
    srcs = ["quiche/common/quiche_simple_arena.cc"],
    hdrs = ["quiche/common/quiche_simple_arena.h"],
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_common_platform_export",
        ":quiche_common_platform_logging",
    ],
)

envoy_cc_library(
    name = "quiche_http_header_storage_lib",
    srcs = ["quiche/common/http/http_header_storage.cc"],
    hdrs = ["quiche/common/http/http_header_storage.h"],
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_common_platform_export",
        ":quiche_common_platform_logging",
        ":quiche_simple_arena_lib",
    ],
)

envoy_cc_library(
    name = "quiche_http_header_block_lib",
    srcs = ["quiche/common/http/http_header_block.cc"],
    hdrs = ["quiche/common/http/http_header_block.h"],
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_common_lib",
        ":quiche_common_platform_export",
        ":quiche_common_platform_logging",
        ":quiche_common_text_utils_lib",
        ":quiche_http_header_storage_lib",
    ],
)

envoy_cc_test(
    name = "quiche_http_header_block_test",
    srcs = ["quiche/common/http/http_header_block_test.cc"],
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_common_platform_test",
        ":quiche_http_header_block_lib",
        ":spdy_test_tools_test_utils_lib",
    ],
)

envoy_cc_library(
    name = "quiche_common_structured_headers_lib",
    srcs = ["quiche/common/structured_headers.cc"],
    hdrs = ["quiche/common/structured_headers.h"],
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_common_platform_export",
        ":quiche_common_platform_logging",
        "@com_google_absl//absl/algorithm:container",
        "@com_google_absl//absl/container:flat_hash_set",
        "@com_google_absl//absl/strings",
        "@com_google_absl//absl/strings:str_format",
        "@com_google_absl//absl/types:optional",
        "@com_google_absl//absl/types:span",
        "@com_google_absl//absl/types:variant",
    ],
)

envoy_cc_test(
    name = "quiche_common_test",
    srcs = [
        "quiche/common/quiche_linked_hash_map_test.cc",
        "quiche/common/quiche_mem_slice_storage_test.cc",
    ],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_common_lib",
        ":quiche_common_mem_slice_storage",
        ":quiche_common_platform_test",
    ],
)

envoy_cc_test(
    name = "http2_platform_api_test",
    srcs = [
        "quiche/http2/test_tools/http2_random_test.cc",
    ],
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":http2_test_tools_random",
        ":quiche_common_platform",
        ":quiche_common_test_tools_test_utils_lib",
    ],
)

envoy_cc_library(
    name = "quiche_common_mem_slice_storage",
    srcs = ["quiche/common/quiche_mem_slice_storage.cc"],
    hdrs = ["quiche/common/quiche_mem_slice_storage.h"],
    repository = "@envoy",
    visibility = ["//visibility:public"],
    deps = [
        ":quic_core_types_lib",
        ":quic_core_utils_lib",
        ":quic_platform_base",
        ":quiche_common_platform",
    ],
)

envoy_cc_test(
    name = "quic_core_batch_writer_batch_writer_test",
    srcs = select({
        "@envoy//bazel:linux": ["quiche/quic/core/batch_writer/quic_batch_writer_test.cc"],
        "//conditions:default": [],
    }),
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quic_core_batch_writer_batch_writer_test_lib",
        ":quic_core_batch_writer_gso_batch_writer_lib",
        ":quic_core_batch_writer_sendmmsg_batch_writer_lib",
        ":quic_platform",
    ],
)

envoy_cc_library(
    name = "quic_load_balancer_server_id_lib",
    srcs = ["quiche/quic/load_balancer/load_balancer_server_id.cc"],
    hdrs = ["quiche/quic/load_balancer/load_balancer_server_id.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quic_core_types_lib",
        ":quic_platform_bug_tracker",
        ":quic_platform_export",
    ],
)

envoy_quic_cc_library(
    name = "quic_load_balancer_config_lib",
    srcs = ["quiche/quic/load_balancer/load_balancer_config.cc"],
    hdrs = ["quiche/quic/load_balancer/load_balancer_config.h"],
    deps = [
        ":quic_core_types_lib",
        ":quic_core_utils_lib",
        ":quic_load_balancer_server_id_lib",
        ":quic_platform_bug_tracker",
        ":quic_platform_export",
    ],
)

envoy_quic_cc_library(
    name = "quic_load_balancer_encoder_lib",
    srcs = ["quiche/quic/load_balancer/load_balancer_encoder.cc"],
    hdrs = ["quiche/quic/load_balancer/load_balancer_encoder.h"],
    deps = [
        ":quic_core_connection_id_generator_interface_lib",
        ":quic_core_crypto_random_lib",
        ":quic_core_data_lib",
        ":quic_core_types_lib",
        ":quic_core_utils_lib",
        ":quic_load_balancer_config_lib",
        ":quic_load_balancer_server_id_lib",
        ":quic_platform_bug_tracker",
        ":quic_platform_export",
    ],
)

envoy_cc_library(
    name = "quiche_common_platform_lower_case_string",
    hdrs = ["quiche/common/platform/api/quiche_lower_case_string.h"],
    repository = "@envoy",
    tags = ["nofips"],
    deps = ["@envoy//source/common/quic/platform:quiche_lower_case_string_impl_lib"],
)

envoy_cc_library(
    name = "quiche_common_platform_header_policy",
    hdrs = ["quiche/common/platform/api/quiche_header_policy.h"],
    repository = "@envoy",
    tags = ["nofips"],
    deps = [":quiche_common_platform_default_quiche_platform_impl_header_policy_impl_lib"],
)

envoy_quiche_platform_impl_cc_library(
    name = "quiche_common_platform_default_quiche_platform_impl_header_policy_impl_lib",
    hdrs = ["quiche/common/platform/default/quiche_platform_impl/quiche_header_policy_impl.h"],
)

envoy_cc_library(
    name = "quiche_balsa_balsa_enums_lib",
    srcs = ["quiche/balsa/balsa_enums.cc"],
    hdrs = ["quiche/balsa/balsa_enums.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [":quiche_common_platform_export"],
)

envoy_cc_library(
    name = "quiche_balsa_balsa_visitor_interface_lib",
    hdrs = ["quiche/balsa/balsa_visitor_interface.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_balsa_balsa_enums_lib",
        ":quiche_common_platform_export",
    ],
)

envoy_cc_library(
    name = "quiche_balsa_noop_balsa_visitor_lib",
    hdrs = ["quiche/balsa/noop_balsa_visitor.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_balsa_balsa_visitor_interface_lib",
        ":quiche_common_platform_export",
    ],
)

envoy_cc_library(
    name = "quiche_balsa_standard_header_map_lib",
    srcs = ["quiche/balsa/standard_header_map.cc"],
    hdrs = ["quiche/balsa/standard_header_map.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_common_text_utils_lib",
        "@com_google_absl//absl/container:flat_hash_set",
        "@com_google_absl//absl/strings",
    ],
)

envoy_cc_library(
    name = "quiche_balsa_framer_interface_lib",
    hdrs = ["quiche/balsa/framer_interface.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = [":quiche_common_platform_export"],
)

envoy_cc_library(
    name = "quiche_balsa_http_validation_policy_lib",
    hdrs = ["quiche/balsa/http_validation_policy.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_common_platform_export",
        ":quiche_common_platform_logging",
    ],
)

envoy_cc_library(
    name = "quiche_balsa_header_api_lib",
    hdrs = ["quiche/balsa/header_api.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_common_callbacks",
        ":quiche_common_platform_export",
        ":quiche_common_platform_lower_case_string",
        "@com_google_absl//absl/strings",
    ],
)

envoy_cc_library(
    name = "quiche_balsa_simple_buffer_lib",
    srcs = ["quiche/balsa/simple_buffer.cc"],
    hdrs = ["quiche/balsa/simple_buffer.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_common_platform",
        ":quiche_common_platform_bug_tracker",
        ":quiche_common_platform_export",
        ":quiche_common_platform_logging",
        "@com_google_absl//absl/strings",
    ],
)

envoy_cc_test(
    name = "quiche_balsa_simple_buffer_test",
    srcs = ["quiche/balsa/simple_buffer_test.cc"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_balsa_simple_buffer_lib",
        ":quiche_common_platform_expect_bug",
        ":quiche_common_platform_test",
        "@com_google_absl//absl/strings",
    ],
)

envoy_cc_library(
    name = "quiche_balsa_header_properties_lib",
    srcs = ["quiche/balsa/header_properties.cc"],
    hdrs = ["quiche/balsa/header_properties.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_common_platform_export",
        ":quiche_common_text_utils_lib",
        "@com_google_absl//absl/container:flat_hash_set",
        "@com_google_absl//absl/strings",
    ],
)

envoy_cc_test(
    name = "quiche_balsa_header_properties_test",
    srcs = ["quiche/balsa/header_properties_test.cc"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_balsa_header_properties_lib",
        ":quiche_common_platform_test",
    ],
)

envoy_cc_library(
    name = "quiche_balsa_balsa_headers_lib",
    srcs = ["quiche/balsa/balsa_headers.cc"],
    hdrs = ["quiche/balsa/balsa_headers.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_balsa_balsa_enums_lib",
        ":quiche_balsa_header_api_lib",
        ":quiche_balsa_header_properties_lib",
        ":quiche_balsa_standard_header_map_lib",
        ":quiche_common_callbacks",
        ":quiche_common_platform_bug_tracker",
        ":quiche_common_platform_export",
        ":quiche_common_platform_header_policy",
        ":quiche_common_platform_logging",
        "@com_google_absl//absl/container:flat_hash_set",
        "@com_google_absl//absl/memory",
        "@com_google_absl//absl/strings",
    ],
)

envoy_cc_test(
    name = "quiche_balsa_balsa_headers_test",
    srcs = ["quiche/balsa/balsa_headers_test.cc"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":quiche_balsa_balsa_enums_lib",
        ":quiche_balsa_balsa_frame_lib",
        ":quiche_balsa_balsa_headers_lib",
        ":quiche_balsa_simple_buffer_lib",
        ":quiche_common_platform_expect_bug",
        ":quiche_common_platform_logging",
        ":quiche_common_platform_test",
        ":quiche_common_test_tools_test_utils_lib",
        "@com_google_absl//absl/base:core_headers",
        "@com_google_absl//absl/memory",
        "@com_google_absl//absl/strings",
        "@com_google_absl//absl/strings:str_format",
    ],
)

envoy_cc_library(
    name = "quiche_balsa_balsa_frame_lib",
    srcs = ["quiche/balsa/balsa_frame.cc"],
    hdrs = ["quiche/balsa/balsa_frame.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    visibility = ["//visibility:public"],
    deps = [
        ":quiche_balsa_balsa_enums_lib",
        ":quiche_balsa_balsa_headers_lib",
        ":quiche_balsa_balsa_visitor_interface_lib",
        ":quiche_balsa_framer_interface_lib",
        ":quiche_balsa_header_properties_lib",
        ":quiche_balsa_http_validation_policy_lib",
        ":quiche_balsa_noop_balsa_visitor_lib",
        ":quiche_common_platform",
        ":quiche_common_platform_bug_tracker",
        ":quiche_common_platform_export",
        ":quiche_common_platform_logging",
        "@com_google_absl//absl/strings",
    ],
)

envoy_cc_test(
    name = "quiche_balsa_balsa_frame_test",
    srcs = ["quiche/balsa/balsa_frame_test.cc"],
    copts = quiche_copts,
    repository = "@envoy",
    deps = [
        ":quiche_balsa_balsa_enums_lib",
        ":quiche_balsa_balsa_frame_lib",
        ":quiche_balsa_balsa_headers_lib",
        ":quiche_balsa_balsa_visitor_interface_lib",
        ":quiche_balsa_http_validation_policy_lib",
        ":quiche_balsa_noop_balsa_visitor_lib",
        ":quiche_balsa_simple_buffer_lib",
        ":quiche_common_platform_expect_bug",
        ":quiche_common_platform_logging",
        ":quiche_common_platform_test",
        "@com_google_absl//absl/flags:flag",
        "@com_google_absl//absl/strings",
        "@com_google_absl//absl/strings:str_format",
    ],
)

envoy_cc_library(
    name = "quiche_web_transport_web_transport_lib",
    hdrs = ["quiche/web_transport/web_transport.h"],
    copts = quiche_copts,
    repository = "@envoy",
    tags = ["nofips"],
    deps = [
        ":quiche_common_callbacks",
        ":quiche_common_platform_export",
        ":quiche_common_quiche_stream_lib",
        ":spdy_core_http2_header_block_lib",
        "@com_google_absl//absl/strings",
        "@com_google_absl//absl/time",
        "@com_google_absl//absl/types:span",
    ],
)
load("@rules_rust//rust:defs.bzl", "rust_static_library")

licenses(["notice"])  # Apache 2

package(default_visibility = ["//visibility:public"])

cc_library(
    name = "helpers_lib",
    srcs = [
        "crates/runtime/src/helpers.c",
    ],
    visibility = ["//visibility:private"],
)

# TODO(keith): This should be using rust_library https://github.com/bazelbuild/rules_rust/issues/1238
rust_static_library(
    name = "rust_c_api",
    srcs = glob(["crates/c-api/src/**/*.rs"]),
    crate_root = "crates/c-api/src/lib.rs",
    edition = "2018",
    proc_macro_deps = [
        "@proxy_wasm_cpp_host//bazel/cargo/wasmtime:wasmtime_c_api_macros",
    ],
    deps = [
        ":helpers_lib",
        "@proxy_wasm_cpp_host//bazel/cargo/wasmtime",
        "@proxy_wasm_cpp_host//bazel/cargo/wasmtime:anyhow",
        "@proxy_wasm_cpp_host//bazel/cargo/wasmtime:env_logger",
        "@proxy_wasm_cpp_host//bazel/cargo/wasmtime:once_cell",
    ],
)
licenses(["notice"])  # Apache 2

cc_library(
    name = "sqlparser",
    srcs = glob(["src/**/*.cpp"]),
    hdrs = glob([
        "include/**/*.h",
        "src/**/*.h",
    ]),
    defines = select({
        "@envoy//bazel:windows_x86_64": ["YY_NO_UNISTD_H"],
        "//conditions:default": [],
    }),
    visibility = ["//visibility:public"],
)
[package]
description = "Proxy-Wasm tests for Envoy"
name = "proxy-wasm-envoy-tests"
version = "0.0.1"
authors = ["Piotr Sikora <piotrsikora@google.com>"]
edition = "2018"

[dependencies]
protobuf = "2"

[profile.release]
lto = true
opt-level = 3
panic = "abort"

[package.metadata.raze]
package_aliases_dir = "."
workspace_path = "//bazel/external/cargo"
genmode = "Remote"

[[example]]
name = "grpc_call_rust"
path = "../../../test/extensions/filters/http/wasm/test_data/grpc_call_rust.rs"
crate-type = ["cdylib"]

[[example]]
name = "grpc_stream_rust"
path = "../../../test/extensions/filters/http/wasm/test_data/grpc_stream_rust.rs"
crate-type = ["cdylib"]
"""
@generated
cargo-raze generated Bazel file.

DO NOT EDIT! Replaced on runs of cargo-raze
"""

load("@bazel_tools//tools/build_defs/repo:git.bzl", "new_git_repository")  # buildifier: disable=load
load("@bazel_tools//tools/build_defs/repo:http.bzl", "http_archive")  # buildifier: disable=load
load("@bazel_tools//tools/build_defs/repo:utils.bzl", "maybe")  # buildifier: disable=load

def raze_fetch_remote_crates():
    """This function defines a collection of repos and should be called in a WORKSPACE file"""
    maybe(
        http_archive,
        name = "raze__protobuf__2_24_1",
        url = "https://crates.io/api/v1/crates/protobuf/2.24.1/download",
        type = "tar.gz",
        sha256 = "db50e77ae196458ccd3dc58a31ea1a90b0698ab1b7928d89f644c25d72070267",
        strip_prefix = "protobuf-2.24.1",
        build_file = Label("//bazel/external/cargo/remote:BUILD.protobuf-2.24.1.bazel"),
    )
# This file is automatically @generated by Cargo.
# It is not intended for manual editing.
[[package]]
name = "protobuf"
version = "2.24.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "db50e77ae196458ccd3dc58a31ea1a90b0698ab1b7928d89f644c25d72070267"

[[package]]
name = "proxy-wasm-envoy-tests"
version = "0.0.1"
dependencies = [
 "protobuf",
]
"""
@generated
cargo-raze generated Bazel file.

DO NOT EDIT! Replaced on runs of cargo-raze
"""

package(default_visibility = ["//visibility:public"])

licenses([
    "notice",  # See individual crates for specific licenses
])

# Aliased targets
alias(
    name = "protobuf",
    actual = "@raze__protobuf__2_24_1//:protobuf",
    tags = [
        "cargo-raze",
        "manual",
    ],
)

# Export file for Stardoc support
exports_files(
    glob([
        "**/*.bazel",
        "**/*.bzl",
    ]),
    visibility = ["//visibility:public"],
)

filegroup(
    name = "srcs",
    srcs = glob([
        "**/*.bazel",
        "**/*.bzl",
    ]),
    visibility = ["//visibility:public"],
)
"""
@generated
cargo-raze crate build file.

DO NOT EDIT! Replaced on runs of cargo-raze
"""

# buildifier: disable=load
load("@bazel_skylib//lib:selects.bzl", "selects")

# buildifier: disable=load
load(
    "@rules_rust//rust:defs.bzl",
    "rust_binary",
    "rust_library",
    "rust_proc_macro",
    "rust_test",
)

package(default_visibility = [
    # Public for visibility by "@raze__crate__version//" targets.
    #
    # Prefer access through "//bazel/external/cargo", which limits external
    # visibility to explicit Cargo.toml dependencies.
    "//visibility:public",
])

licenses([
    "notice",  # MIT from expression "MIT"
])

# Generated Targets
# buildifier: disable=out-of-order-load
# buildifier: disable=load-on-top
load(
    "@rules_rust//cargo:cargo_build_script.bzl",
    "cargo_build_script",
)

cargo_build_script(
    name = "protobuf_build_script",
    srcs = glob(["**/*.rs"]),
    build_script_env = {
    },
    crate_features = [
    ],
    crate_root = "build.rs",
    data = glob(["**"]),
    edition = "2018",
    rustc_flags = [
        "--cap-lints=allow",
    ],
    tags = [
        "cargo-raze",
        "manual",
    ],
    version = "2.24.1",
    visibility = ["//visibility:private"],
    deps = [
    ],
)

# Unsupported target "coded_input_stream" with type "bench" omitted

# Unsupported target "coded_output_stream" with type "bench" omitted

rust_library(
    name = "protobuf",
    srcs = glob(["**/*.rs"]),
    crate_features = [
    ],
    crate_root = "src/lib.rs",
    data = [],
    edition = "2018",
    rustc_flags = [
        "--cap-lints=allow",
    ],
    tags = [
        "cargo-raze",
        "crate-name=protobuf",
        "manual",
    ],
    version = "2.24.1",
    # buildifier: leave-alone
    deps = [
        ":protobuf_build_script",
    ],
)
# Export file for Stardoc support
exports_files(
    glob([
        "**/*.bazel",
        "**/*.bzl",
    ]),
    visibility = ["//visibility:public"],
)

filegroup(
    name = "srcs",
    srcs = glob([
        "**/*.bazel",
        "**/*.bzl",
    ]),
    visibility = ["//visibility:public"],
)
licenses(["notice"])  # Apache 2

cc_library(
    name = "tclap",
    hdrs = glob(["include/tclap/*.h"]),
    includes = ["include"],
    visibility = ["//visibility:public"],
)
licenses(["notice"])  # Apache 2

cc_library(
    name = "fmtlib",
    hdrs = glob([
        "include/fmt/*.h",
    ]),
    defines = ["FMT_HEADER_ONLY"],
    includes = ["include"],
    visibility = ["//visibility:public"],
)
licenses(["notice"])  # Apache 2

cc_library(
    name = "spdlog",
    hdrs = glob([
        "include/**/*.h",
    ]),
    defines = ["SPDLOG_FMT_EXTERNAL"],
    includes = ["include"],
    visibility = ["//visibility:public"],
    deps = ["@com_github_fmtlib_fmt//:fmtlib"],
)
/* Copyright Joyent, Inc. and other Node contributors. All rights reserved.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to
 * deal in the Software without restriction, including without limitation the
 * rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
 * sell copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 * IN THE SOFTWARE.
 */
#ifndef http_parser_h
#define http_parser_h
#ifdef __cplusplus
extern "C" {
#endif

/* Also update SONAME in the Makefile whenever you change these. */
#define HTTP_PARSER_VERSION_MAJOR 2
#define HTTP_PARSER_VERSION_MINOR 9
#define HTTP_PARSER_VERSION_PATCH 4

#include <stddef.h>
#if defined(_WIN32) && !defined(__MINGW32__) && \
  (!defined(_MSC_VER) || _MSC_VER<1600) && !defined(__WINE__)
#include <BaseTsd.h>
typedef __int8 int8_t;
typedef unsigned __int8 uint8_t;
typedef __int16 int16_t;
typedef unsigned __int16 uint16_t;
typedef __int32 int32_t;
typedef unsigned __int32 uint32_t;
typedef __int64 int64_t;
typedef unsigned __int64 uint64_t;
#elif (defined(__sun) || defined(__sun__)) && defined(__SunOS_5_9)
#include <sys/inttypes.h>
#else
#include <stdint.h>
#endif

/* Compile with -DHTTP_PARSER_STRICT=0 to make less checks, but run
 * faster
 */
#ifndef HTTP_PARSER_STRICT
# define HTTP_PARSER_STRICT 1
#endif

/* Maximium header size allowed. If the macro is not defined
 * before including this header then the default is used. To
 * change the maximum header size, define the macro in the build
 * environment (e.g. -DHTTP_MAX_HEADER_SIZE=<value>). To remove
 * the effective limit on the size of the header, define the macro
 * to a very large number (e.g. -DHTTP_MAX_HEADER_SIZE=0x7fffffff)
 */
#ifndef HTTP_MAX_HEADER_SIZE
# define HTTP_MAX_HEADER_SIZE (80*1024)
#endif

typedef struct http_parser http_parser;
typedef struct http_parser_settings http_parser_settings;


/* Callbacks should return non-zero to indicate an error. The parser will
 * then halt execution.
 *
 * The one exception is on_headers_complete. In a HTTP_RESPONSE parser
 * returning '1' from on_headers_complete will tell the parser that it
 * should not expect a body. This is used when receiving a response to a
 * HEAD request which may contain 'Content-Length' or 'Transfer-Encoding:
 * chunked' headers that indicate the presence of a body.
 *
 * Returning `2` from on_headers_complete will tell parser that it should not
 * expect neither a body nor any further responses on this connection. This is
 * useful for handling responses to a CONNECT request which may not contain
 * `Upgrade` or `Connection: upgrade` headers.
 *
 * http_data_cb does not return data chunks. It will be called arbitrarily
 * many times for each string. E.G. you might get 10 callbacks for "on_url"
 * each providing just a few characters more data.
 */
typedef int (*http_data_cb) (http_parser*, const char *at, size_t length);
typedef int (*http_cb) (http_parser*);


/* Status Codes */
#define HTTP_STATUS_MAP(XX)                                                 \
  XX(100, CONTINUE,                        Continue)                        \
  XX(101, SWITCHING_PROTOCOLS,             Switching Protocols)             \
  XX(102, PROCESSING,                      Processing)                      \
  XX(200, OK,                              OK)                              \
  XX(201, CREATED,                         Created)                         \
  XX(202, ACCEPTED,                        Accepted)                        \
  XX(203, NON_AUTHORITATIVE_INFORMATION,   Non-Authoritative Information)   \
  XX(204, NO_CONTENT,                      No Content)                      \
  XX(205, RESET_CONTENT,                   Reset Content)                   \
  XX(206, PARTIAL_CONTENT,                 Partial Content)                 \
  XX(207, MULTI_STATUS,                    Multi-Status)                    \
  XX(208, ALREADY_REPORTED,                Already Reported)                \
  XX(226, IM_USED,                         IM Used)                         \
  XX(300, MULTIPLE_CHOICES,                Multiple Choices)                \
  XX(301, MOVED_PERMANENTLY,               Moved Permanently)               \
  XX(302, FOUND,                           Found)                           \
  XX(303, SEE_OTHER,                       See Other)                       \
  XX(304, NOT_MODIFIED,                    Not Modified)                    \
  XX(305, USE_PROXY,                       Use Proxy)                       \
  XX(307, TEMPORARY_REDIRECT,              Temporary Redirect)              \
  XX(308, PERMANENT_REDIRECT,              Permanent Redirect)              \
  XX(400, BAD_REQUEST,                     Bad Request)                     \
  XX(401, UNAUTHORIZED,                    Unauthorized)                    \
  XX(402, PAYMENT_REQUIRED,                Payment Required)                \
  XX(403, FORBIDDEN,                       Forbidden)                       \
  XX(404, NOT_FOUND,                       Not Found)                       \
  XX(405, METHOD_NOT_ALLOWED,              Method Not Allowed)              \
  XX(406, NOT_ACCEPTABLE,                  Not Acceptable)                  \
  XX(407, PROXY_AUTHENTICATION_REQUIRED,   Proxy Authentication Required)   \
  XX(408, REQUEST_TIMEOUT,                 Request Timeout)                 \
  XX(409, CONFLICT,                        Conflict)                        \
  XX(410, GONE,                            Gone)                            \
  XX(411, LENGTH_REQUIRED,                 Length Required)                 \
  XX(412, PRECONDITION_FAILED,             Precondition Failed)             \
  XX(413, PAYLOAD_TOO_LARGE,               Payload Too Large)               \
  XX(414, URI_TOO_LONG,                    URI Too Long)                    \
  XX(415, UNSUPPORTED_MEDIA_TYPE,          Unsupported Media Type)          \
  XX(416, RANGE_NOT_SATISFIABLE,           Range Not Satisfiable)           \
  XX(417, EXPECTATION_FAILED,              Expectation Failed)              \
  XX(421, MISDIRECTED_REQUEST,             Misdirected Request)             \
  XX(422, UNPROCESSABLE_ENTITY,            Unprocessable Entity)            \
  XX(423, LOCKED,                          Locked)                          \
  XX(424, FAILED_DEPENDENCY,               Failed Dependency)               \
  XX(426, UPGRADE_REQUIRED,                Upgrade Required)                \
  XX(428, PRECONDITION_REQUIRED,           Precondition Required)           \
  XX(429, TOO_MANY_REQUESTS,               Too Many Requests)               \
  XX(431, REQUEST_HEADER_FIELDS_TOO_LARGE, Request Header Fields Too Large) \
  XX(451, UNAVAILABLE_FOR_LEGAL_REASONS,   Unavailable For Legal Reasons)   \
  XX(500, INTERNAL_SERVER_ERROR,           Internal Server Error)           \
  XX(501, NOT_IMPLEMENTED,                 Not Implemented)                 \
  XX(502, BAD_GATEWAY,                     Bad Gateway)                     \
  XX(503, SERVICE_UNAVAILABLE,             Service Unavailable)             \
  XX(504, GATEWAY_TIMEOUT,                 Gateway Timeout)                 \
  XX(505, HTTP_VERSION_NOT_SUPPORTED,      HTTP Version Not Supported)      \
  XX(506, VARIANT_ALSO_NEGOTIATES,         Variant Also Negotiates)         \
  XX(507, INSUFFICIENT_STORAGE,            Insufficient Storage)            \
  XX(508, LOOP_DETECTED,                   Loop Detected)                   \
  XX(510, NOT_EXTENDED,                    Not Extended)                    \
  XX(511, NETWORK_AUTHENTICATION_REQUIRED, Network Authentication Required) \

enum http_status
  {
#define XX(num, name, string) HTTP_STATUS_##name = num,
  HTTP_STATUS_MAP(XX)
#undef XX
  };


/* Request Methods */
#define HTTP_METHOD_MAP(XX)         \
  XX(0,  DELETE,      DELETE)       \
  XX(1,  GET,         GET)          \
  XX(2,  HEAD,        HEAD)         \
  XX(3,  POST,        POST)         \
  XX(4,  PUT,         PUT)          \
  /* pathological */                \
  XX(5,  CONNECT,     CONNECT)      \
  XX(6,  OPTIONS,     OPTIONS)      \
  XX(7,  TRACE,       TRACE)        \
  /* WebDAV */                      \
  XX(8,  COPY,        COPY)         \
  XX(9,  LOCK,        LOCK)         \
  XX(10, MKCOL,       MKCOL)        \
  XX(11, MOVE,        MOVE)         \
  XX(12, PROPFIND,    PROPFIND)     \
  XX(13, PROPPATCH,   PROPPATCH)    \
  XX(14, SEARCH,      SEARCH)       \
  XX(15, UNLOCK,      UNLOCK)       \
  XX(16, BIND,        BIND)         \
  XX(17, REBIND,      REBIND)       \
  XX(18, UNBIND,      UNBIND)       \
  XX(19, ACL,         ACL)          \
  /* subversion */                  \
  XX(20, REPORT,      REPORT)       \
  XX(21, MKACTIVITY,  MKACTIVITY)   \
  XX(22, CHECKOUT,    CHECKOUT)     \
  XX(23, MERGE,       MERGE)        \
  /* upnp */                        \
  XX(24, MSEARCH,     M-SEARCH)     \
  XX(25, NOTIFY,      NOTIFY)       \
  XX(26, SUBSCRIBE,   SUBSCRIBE)    \
  XX(27, UNSUBSCRIBE, UNSUBSCRIBE)  \
  /* RFC-5789 */                    \
  XX(28, PATCH,       PATCH)        \
  XX(29, PURGE,       PURGE)        \
  /* CalDAV */                      \
  XX(30, MKCALENDAR,  MKCALENDAR)   \
  /* RFC-2068, section 19.6.1.2 */  \
  XX(31, LINK,        LINK)         \
  XX(32, UNLINK,      UNLINK)       \
  /* icecast */                     \
  XX(33, SOURCE,      SOURCE)       \

enum http_method
  {
#define XX(num, name, string) HTTP_##name = num,
  HTTP_METHOD_MAP(XX)
#undef XX
  };


enum http_parser_type { HTTP_REQUEST, HTTP_RESPONSE, HTTP_BOTH };


/* Flag values for http_parser.flags field */
enum flags
  { F_CHUNKED               = 1 << 0
  , F_CONNECTION_KEEP_ALIVE = 1 << 1
  , F_CONNECTION_CLOSE      = 1 << 2
  , F_CONNECTION_UPGRADE    = 1 << 3
  , F_TRAILING              = 1 << 4
  , F_UPGRADE               = 1 << 5
  , F_SKIPBODY              = 1 << 6
  , F_CONTENTLENGTH         = 1 << 7
  };


/* Map for errno-related constants
 *
 * The provided argument should be a macro that takes 2 arguments.
 */
#define HTTP_ERRNO_MAP(XX)                                           \
  /* No error */                                                     \
  XX(OK, "success")                                                  \
                                                                     \
  /* Callback-related errors */                                      \
  XX(CB_message_begin, "the on_message_begin callback failed")       \
  XX(CB_url, "the on_url callback failed")                           \
  XX(CB_header_field, "the on_header_field callback failed")         \
  XX(CB_header_value, "the on_header_value callback failed")         \
  XX(CB_headers_complete, "the on_headers_complete callback failed") \
  XX(CB_body, "the on_body callback failed")                         \
  XX(CB_message_complete, "the on_message_complete callback failed") \
  XX(CB_status, "the on_status callback failed")                     \
  XX(CB_chunk_header, "the on_chunk_header callback failed")         \
  XX(CB_chunk_complete, "the on_chunk_complete callback failed")     \
                                                                     \
  /* Parsing-related errors */                                       \
  XX(INVALID_EOF_STATE, "stream ended at an unexpected time")        \
  XX(HEADER_OVERFLOW,                                                \
     "too many header bytes seen; overflow detected")                \
  XX(CLOSED_CONNECTION,                                              \
     "data received after completed connection: close message")      \
  XX(INVALID_VERSION, "invalid HTTP version")                        \
  XX(INVALID_STATUS, "invalid HTTP status code")                     \
  XX(INVALID_METHOD, "invalid HTTP method")                          \
  XX(INVALID_URL, "invalid URL")                                     \
  XX(INVALID_HOST, "invalid host")                                   \
  XX(INVALID_PORT, "invalid port")                                   \
  XX(INVALID_PATH, "invalid path")                                   \
  XX(INVALID_QUERY_STRING, "invalid query string")                   \
  XX(INVALID_FRAGMENT, "invalid fragment")                           \
  XX(LF_EXPECTED, "LF character expected")                           \
  XX(INVALID_HEADER_TOKEN, "invalid character in header")            \
  XX(INVALID_CONTENT_LENGTH,                                         \
     "invalid character in content-length header")                   \
  XX(UNEXPECTED_CONTENT_LENGTH,                                      \
     "unexpected content-length header")                             \
  XX(INVALID_CHUNK_SIZE,                                             \
     "invalid character in chunk size header")                       \
  XX(INVALID_CONSTANT, "invalid constant string")                    \
  XX(INVALID_INTERNAL_STATE, "encountered unexpected internal state")\
  XX(STRICT, "strict mode assertion failed")                         \
  XX(PAUSED, "parser is paused")                                     \
  XX(UNKNOWN, "an unknown error occurred")                           \
  XX(INVALID_TRANSFER_ENCODING,                                      \
     "request has invalid transfer-encoding")                        \


/* Define HPE_* values for each errno value above */
#define HTTP_ERRNO_GEN(n, s) HPE_##n,
enum http_errno {
  HTTP_ERRNO_MAP(HTTP_ERRNO_GEN)
};
#undef HTTP_ERRNO_GEN


/* Get an http_errno value from an http_parser */
#define HTTP_PARSER_ERRNO(p)            ((enum http_errno) (p)->http_errno)


struct http_parser {
  /** PRIVATE **/
  unsigned int type : 2;         /* enum http_parser_type */
  unsigned int flags : 8;       /* F_* values from 'flags' enum; semi-public */
  unsigned int state : 7;        /* enum state from http_parser.c */
  unsigned int header_state : 7; /* enum header_state from http_parser.c */
  unsigned int index : 5;        /* index into current matcher */
  unsigned int uses_transfer_encoding : 1; /* Transfer-Encoding header is present */
  unsigned int allow_chunked_length : 1; /* Allow headers with both
                                          * `Content-Length` and
                                          * `Transfer-Encoding: chunked` set */
  unsigned int lenient_http_headers : 1;

  uint32_t nread;          /* # bytes read in various scenarios */
  uint64_t content_length; /* # bytes in body. `(uint64_t) -1` (all bits one)
                            * if no Content-Length header.
                            */

  /** READ-ONLY **/
  unsigned short http_major;
  unsigned short http_minor;
  unsigned int status_code : 16; /* responses only */
  unsigned int method : 8;       /* requests only */
  unsigned int http_errno : 7;

  /* 1 = Upgrade header was present and the parser has exited because of that.
   * 0 = No upgrade header present.
   * Should be checked when http_parser_execute() returns in addition to
   * error checking.
   */
  unsigned int upgrade : 1;

  /** PUBLIC **/
  void *data; /* A pointer to get hook to the "connection" or "socket" object */
};


struct http_parser_settings {
  http_cb      on_message_begin;
  http_data_cb on_url;
  http_data_cb on_status;
  http_data_cb on_header_field;
  http_data_cb on_header_value;
  http_cb      on_headers_complete;
  http_data_cb on_body;
  http_cb      on_message_complete;
  /* When on_chunk_header is called, the current chunk length is stored
   * in parser->content_length.
   */
  http_cb      on_chunk_header;
  http_cb      on_chunk_complete;
};


enum http_parser_url_fields
  { UF_SCHEMA           = 0
  , UF_HOST             = 1
  , UF_PORT             = 2
  , UF_PATH             = 3
  , UF_QUERY            = 4
  , UF_FRAGMENT         = 5
  , UF_USERINFO         = 6
  , UF_MAX              = 7
  };


/* Result structure for http_parser_parse_url().
 *
 * Callers should index into field_data[] with UF_* values iff field_set
 * has the relevant (1 << UF_*) bit set. As a courtesy to clients (and
 * because we probably have padding left over), we convert any port to
 * a uint16_t.
 */
struct http_parser_url {
  uint16_t field_set;           /* Bitmask of (1 << UF_*) values */
  uint16_t port;                /* Converted UF_PORT string */

  struct {
    uint16_t off;               /* Offset into buffer in which field starts */
    uint16_t len;               /* Length of run in buffer */
  } field_data[UF_MAX];
};


/* Returns the library version. Bits 16-23 contain the major version number,
 * bits 8-15 the minor version number and bits 0-7 the patch level.
 * Usage example:
 *
 *   unsigned long version = http_parser_version();
 *   unsigned major = (version >> 16) & 255;
 *   unsigned minor = (version >> 8) & 255;
 *   unsigned patch = version & 255;
 *   printf("http_parser v%u.%u.%u\n", major, minor, patch);
 */
unsigned long http_parser_version(void);

void http_parser_init(http_parser *parser, enum http_parser_type type);


/* Initialize http_parser_settings members to 0
 */
void http_parser_settings_init(http_parser_settings *settings);


/* Executes the parser. Returns number of parsed bytes. Sets
 * `parser->http_errno` on error. */
size_t http_parser_execute(http_parser *parser,
                           const http_parser_settings *settings,
                           const char *data,
                           size_t len);


/* If http_should_keep_alive() in the on_headers_complete or
 * on_message_complete callback returns 0, then this should be
 * the last message on the connection.
 * If you are the server, respond with the "Connection: close" header.
 * If you are the client, close the connection.
 */
int http_should_keep_alive(const http_parser *parser);

/* Returns a string version of the HTTP method. */
const char *http_method_str(enum http_method m);

/* Returns a string version of the HTTP status code. */
const char *http_status_str(enum http_status s);

/* Return a string name of the given error */
const char *http_errno_name(enum http_errno err);

/* Return a string description of the given error */
const char *http_errno_description(enum http_errno err);

/* Initialize all http_parser_url members to 0 */
void http_parser_url_init(struct http_parser_url *u);

/* Parse a URL; return nonzero on failure */
int http_parser_parse_url(const char *buf, size_t buflen,
                          int is_connect,
                          struct http_parser_url *u);

/* Pause or un-pause the parser; a nonzero value pauses */
void http_parser_pause(http_parser *parser, int paused);

/* Checks if this is the final chunk of the body. */
int http_body_is_final(const http_parser *parser);

/* Change the maximum header size provided at compile time. */
void http_parser_set_max_header_size(uint32_t size);

#ifdef __cplusplus
}
#endif
#endif
This is a clone of the [http-parser](https://github.com/nodejs/http-parser)
repo at commit `4f15b7d510dc7c6361a26a7c6d2f7c3a17f8d878`. See GitHub issue
[#19749](https://github.com/envoyproxy/envoy/issues/19749) for more
information.
/* Copyright Joyent, Inc. and other Node contributors.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to
 * deal in the Software without restriction, including without limitation the
 * rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
 * sell copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 * IN THE SOFTWARE.
 */
#include "http_parser.h"
#include <assert.h>
#include <stdbool.h>
#include <stddef.h>
#include <ctype.h>
#include <string.h>
#include <limits.h>

static uint32_t max_header_size = HTTP_MAX_HEADER_SIZE;

#ifndef ULLONG_MAX
# define ULLONG_MAX ((uint64_t) -1) /* 2^64-1 */
#endif

#ifndef MIN
# define MIN(a,b) ((a) < (b) ? (a) : (b))
#endif

#ifndef ARRAY_SIZE
# define ARRAY_SIZE(a) (sizeof(a) / sizeof((a)[0]))
#endif

#ifndef BIT_AT
# define BIT_AT(a, i)                                                \
  (!!((unsigned int) (a)[(unsigned int) (i) >> 3] &                  \
   (1 << ((unsigned int) (i) & 7))))
#endif

#ifndef ELEM_AT
# define ELEM_AT(a, i, v) ((unsigned int) (i) < ARRAY_SIZE(a) ? (a)[(i)] : (v))
#endif

#define SET_ERRNO(e)                                                 \
do {                                                                 \
  parser->nread = nread;                                             \
  parser->http_errno = (e);                                          \
} while(0)

#define CURRENT_STATE() p_state
#define UPDATE_STATE(V) p_state = (enum state) (V);
#define RETURN(V)                                                    \
do {                                                                 \
  parser->nread = nread;                                             \
  parser->state = CURRENT_STATE();                                   \
  return (V);                                                        \
} while (0);
#define REEXECUTE()                                                  \
  goto reexecute;                                                    \


#ifdef __GNUC__
# define LIKELY(X) __builtin_expect(!!(X), 1)
# define UNLIKELY(X) __builtin_expect(!!(X), 0)
#else
# define LIKELY(X) (X)
# define UNLIKELY(X) (X)
#endif


/* Run the notify callback FOR, returning ER if it fails */
#define CALLBACK_NOTIFY_(FOR, ER)                                    \
do {                                                                 \
  assert(HTTP_PARSER_ERRNO(parser) == HPE_OK);                       \
                                                                     \
  if (LIKELY(settings->on_##FOR)) {                                  \
    parser->state = CURRENT_STATE();                                 \
    if (UNLIKELY(0 != settings->on_##FOR(parser))) {                 \
      SET_ERRNO(HPE_CB_##FOR);                                       \
    }                                                                \
    UPDATE_STATE(parser->state);                                     \
                                                                     \
    /* We either errored above or got paused; get out */             \
    if (UNLIKELY(HTTP_PARSER_ERRNO(parser) != HPE_OK)) {             \
      return (ER);                                                   \
    }                                                                \
  }                                                                  \
} while (0)

/* Run the notify callback FOR and consume the current byte */
#define CALLBACK_NOTIFY(FOR)            CALLBACK_NOTIFY_(FOR, p - data + 1)

/* Run the notify callback FOR and don't consume the current byte */
#define CALLBACK_NOTIFY_NOADVANCE(FOR)  CALLBACK_NOTIFY_(FOR, p - data)

/* Run data callback FOR with LEN bytes, returning ER if it fails */
#define CALLBACK_DATA_(FOR, LEN, ER)                                 \
do {                                                                 \
  assert(HTTP_PARSER_ERRNO(parser) == HPE_OK);                       \
                                                                     \
  if (FOR##_mark) {                                                  \
    if (LIKELY(settings->on_##FOR)) {                                \
      parser->state = CURRENT_STATE();                               \
      if (UNLIKELY(0 !=                                              \
                   settings->on_##FOR(parser, FOR##_mark, (LEN)))) { \
        SET_ERRNO(HPE_CB_##FOR);                                     \
      }                                                              \
      UPDATE_STATE(parser->state);                                   \
                                                                     \
      /* We either errored above or got paused; get out */           \
      if (UNLIKELY(HTTP_PARSER_ERRNO(parser) != HPE_OK)) {           \
        return (ER);                                                 \
      }                                                              \
    }                                                                \
    FOR##_mark = NULL;                                               \
  }                                                                  \
} while (0)

/* Run the data callback FOR and consume the current byte */
#define CALLBACK_DATA(FOR)                                           \
    CALLBACK_DATA_(FOR, p - FOR##_mark, p - data + 1)

/* Run the data callback FOR and don't consume the current byte */
#define CALLBACK_DATA_NOADVANCE(FOR)                                 \
    CALLBACK_DATA_(FOR, p - FOR##_mark, p - data)

/* Set the mark FOR; non-destructive if mark is already set */
#define MARK(FOR)                                                    \
do {                                                                 \
  if (!FOR##_mark) {                                                 \
    FOR##_mark = p;                                                  \
  }                                                                  \
} while (0)

/* Don't allow the total size of the HTTP headers (including the status
 * line) to exceed max_header_size.  This check is here to protect
 * embedders against denial-of-service attacks where the attacker feeds
 * us a never-ending header that the embedder keeps buffering.
 *
 * This check is arguably the responsibility of embedders but we're doing
 * it on the embedder's behalf because most won't bother and this way we
 * make the web a little safer.  max_header_size is still far bigger
 * than any reasonable request or response so this should never affect
 * day-to-day operation.
 */
#define COUNT_HEADER_SIZE(V)                                         \
do {                                                                 \
  nread += (uint32_t)(V);                                            \
  if (UNLIKELY(nread > max_header_size)) {                           \
    SET_ERRNO(HPE_HEADER_OVERFLOW);                                  \
    goto error;                                                      \
  }                                                                  \
} while (0)


#define PROXY_CONNECTION "proxy-connection"
#define CONNECTION "connection"
#define CONTENT_LENGTH "content-length"
#define TRANSFER_ENCODING "transfer-encoding"
#define UPGRADE "upgrade"
#define CHUNKED "chunked"
#define KEEP_ALIVE "keep-alive"
#define CLOSE "close"


static const char *method_strings[] =
  {
#define XX(num, name, string) #string,
  HTTP_METHOD_MAP(XX)
#undef XX
  };


/* Tokens as defined by rfc 2616. Also lowercases them.
 *        token       = 1*<any CHAR except CTLs or separators>
 *     separators     = "(" | ")" | "<" | ">" | "@"
 *                    | "," | ";" | ":" | "\" | <">
 *                    | "/" | "[" | "]" | "?" | "="
 *                    | "{" | "}" | SP | HT
 */
static const char tokens[256] = {
/*   0 nul    1 soh    2 stx    3 etx    4 eot    5 enq    6 ack    7 bel  */
        0,       0,       0,       0,       0,       0,       0,       0,
/*   8 bs     9 ht    10 nl    11 vt    12 np    13 cr    14 so    15 si   */
        0,       0,       0,       0,       0,       0,       0,       0,
/*  16 dle   17 dc1   18 dc2   19 dc3   20 dc4   21 nak   22 syn   23 etb */
        0,       0,       0,       0,       0,       0,       0,       0,
/*  24 can   25 em    26 sub   27 esc   28 fs    29 gs    30 rs    31 us  */
        0,       0,       0,       0,       0,       0,       0,       0,
/*  32 sp    33  !    34  "    35  #    36  $    37  %    38  &    39  '  */
       ' ',     '!',      0,      '#',     '$',     '%',     '&',    '\'',
/*  40  (    41  )    42  *    43  +    44  ,    45  -    46  .    47  /  */
        0,       0,      '*',     '+',      0,      '-',     '.',      0,
/*  48  0    49  1    50  2    51  3    52  4    53  5    54  6    55  7  */
       '0',     '1',     '2',     '3',     '4',     '5',     '6',     '7',
/*  56  8    57  9    58  :    59  ;    60  <    61  =    62  >    63  ?  */
       '8',     '9',      0,       0,       0,       0,       0,       0,
/*  64  @    65  A    66  B    67  C    68  D    69  E    70  F    71  G  */
        0,      'a',     'b',     'c',     'd',     'e',     'f',     'g',
/*  72  H    73  I    74  J    75  K    76  L    77  M    78  N    79  O  */
       'h',     'i',     'j',     'k',     'l',     'm',     'n',     'o',
/*  80  P    81  Q    82  R    83  S    84  T    85  U    86  V    87  W  */
       'p',     'q',     'r',     's',     't',     'u',     'v',     'w',
/*  88  X    89  Y    90  Z    91  [    92  \    93  ]    94  ^    95  _  */
       'x',     'y',     'z',      0,       0,       0,      '^',     '_',
/*  96  `    97  a    98  b    99  c   100  d   101  e   102  f   103  g  */
       '`',     'a',     'b',     'c',     'd',     'e',     'f',     'g',
/* 104  h   105  i   106  j   107  k   108  l   109  m   110  n   111  o  */
       'h',     'i',     'j',     'k',     'l',     'm',     'n',     'o',
/* 112  p   113  q   114  r   115  s   116  t   117  u   118  v   119  w  */
       'p',     'q',     'r',     's',     't',     'u',     'v',     'w',
/* 120  x   121  y   122  z   123  {   124  |   125  }   126  ~   127 del */
       'x',     'y',     'z',      0,      '|',      0,      '~',       0 };


static const int8_t unhex[256] =
  {-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1
  ,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1
  ,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1
  , 0, 1, 2, 3, 4, 5, 6, 7, 8, 9,-1,-1,-1,-1,-1,-1
  ,-1,10,11,12,13,14,15,-1,-1,-1,-1,-1,-1,-1,-1,-1
  ,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1
  ,-1,10,11,12,13,14,15,-1,-1,-1,-1,-1,-1,-1,-1,-1
  ,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1
  };


#if HTTP_PARSER_STRICT
# define T(v) 0
#else
# define T(v) v
#endif


static const uint8_t normal_url_char[32] = {
/*   0 nul    1 soh    2 stx    3 etx    4 eot    5 enq    6 ack    7 bel  */
        0    |   0    |   0    |   0    |   0    |   0    |   0    |   0,
/*   8 bs     9 ht    10 nl    11 vt    12 np    13 cr    14 so    15 si   */
        0    | T(2)   |   0    |   0    | T(16)  |   0    |   0    |   0,
/*  16 dle   17 dc1   18 dc2   19 dc3   20 dc4   21 nak   22 syn   23 etb */
        0    |   0    |   0    |   0    |   0    |   0    |   0    |   0,
/*  24 can   25 em    26 sub   27 esc   28 fs    29 gs    30 rs    31 us  */
        0    |   0    |   0    |   0    |   0    |   0    |   0    |   0,
/*  32 sp    33  !    34  "    35  #    36  $    37  %    38  &    39  '  */
        0    |   2    |   4    |   0    |   16   |   32   |   64   |  128,
/*  40  (    41  )    42  *    43  +    44  ,    45  -    46  .    47  /  */
        1    |   2    |   4    |   8    |   16   |   32   |   64   |  128,
/*  48  0    49  1    50  2    51  3    52  4    53  5    54  6    55  7  */
        1    |   2    |   4    |   8    |   16   |   32   |   64   |  128,
/*  56  8    57  9    58  :    59  ;    60  <    61  =    62  >    63  ?  */
        1    |   2    |   4    |   8    |   16   |   32   |   64   |   0,
/*  64  @    65  A    66  B    67  C    68  D    69  E    70  F    71  G  */
        1    |   2    |   4    |   8    |   16   |   32   |   64   |  128,
/*  72  H    73  I    74  J    75  K    76  L    77  M    78  N    79  O  */
        1    |   2    |   4    |   8    |   16   |   32   |   64   |  128,
/*  80  P    81  Q    82  R    83  S    84  T    85  U    86  V    87  W  */
        1    |   2    |   4    |   8    |   16   |   32   |   64   |  128,
/*  88  X    89  Y    90  Z    91  [    92  \    93  ]    94  ^    95  _  */
        1    |   2    |   4    |   8    |   16   |   32   |   64   |  128,
/*  96  `    97  a    98  b    99  c   100  d   101  e   102  f   103  g  */
        1    |   2    |   4    |   8    |   16   |   32   |   64   |  128,
/* 104  h   105  i   106  j   107  k   108  l   109  m   110  n   111  o  */
        1    |   2    |   4    |   8    |   16   |   32   |   64   |  128,
/* 112  p   113  q   114  r   115  s   116  t   117  u   118  v   119  w  */
        1    |   2    |   4    |   8    |   16   |   32   |   64   |  128,
/* 120  x   121  y   122  z   123  {   124  |   125  }   126  ~   127 del */
        1    |   2    |   4    |   8    |   16   |   32   |   64   |   0, };

#undef T

enum state
  { s_dead = 1 /* important that this is > 0 */

  , s_start_req_or_res
  , s_res_or_resp_H
  , s_start_res
  , s_res_H
  , s_res_HT
  , s_res_HTT
  , s_res_HTTP
  , s_res_http_major
  , s_res_http_dot
  , s_res_http_minor
  , s_res_http_end
  , s_res_first_status_code
  , s_res_status_code
  , s_res_status_start
  , s_res_status
  , s_res_line_almost_done

  , s_start_req

  , s_req_method
  , s_req_spaces_before_url
  , s_req_schema
  , s_req_schema_slash
  , s_req_schema_slash_slash
  , s_req_server_start
  , s_req_server
  , s_req_server_with_at
  , s_req_path
  , s_req_query_string_start
  , s_req_query_string
  , s_req_fragment_start
  , s_req_fragment
  , s_req_http_start
  , s_req_http_H
  , s_req_http_HT
  , s_req_http_HTT
  , s_req_http_HTTP
  , s_req_http_I
  , s_req_http_IC
  , s_req_http_major
  , s_req_http_dot
  , s_req_http_minor
  , s_req_http_end
  , s_req_line_almost_done

  , s_header_field_start
  , s_header_field
  , s_header_value_discard_ws
  , s_header_value_discard_ws_almost_done
  , s_header_value_discard_lws
  , s_header_value_start
  , s_header_value
  , s_header_value_lws

  , s_header_almost_done

  , s_chunk_size_start
  , s_chunk_size
  , s_chunk_parameters
  , s_chunk_size_almost_done

  , s_headers_almost_done
  , s_headers_done

  /* Important: 's_headers_done' must be the last 'header' state. All
   * states beyond this must be 'body' states. It is used for overflow
   * checking. See the PARSING_HEADER() macro.
   */

  , s_chunk_data
  , s_chunk_data_almost_done
  , s_chunk_data_done

  , s_body_identity
  , s_body_identity_eof

  , s_message_done
  };


#define PARSING_HEADER(state) (state <= s_headers_done)


enum header_states
  { h_general = 0
  , h_C
  , h_CO
  , h_CON

  , h_matching_connection
  , h_matching_proxy_connection
  , h_matching_content_length
  , h_matching_transfer_encoding
  , h_matching_upgrade

  , h_connection
  , h_content_length
  , h_content_length_num
  , h_content_length_ws
  , h_transfer_encoding
  , h_upgrade

  , h_matching_transfer_encoding_token_start
  , h_matching_transfer_encoding_chunked
  , h_matching_transfer_encoding_token

  , h_matching_connection_token_start
  , h_matching_connection_keep_alive
  , h_matching_connection_close
  , h_matching_connection_upgrade
  , h_matching_connection_token

  , h_transfer_encoding_chunked
  , h_connection_keep_alive
  , h_connection_close
  , h_connection_upgrade
  };

enum http_host_state
  {
    s_http_host_dead = 1
  , s_http_userinfo_start
  , s_http_userinfo
  , s_http_host_start
  , s_http_host_v6_start
  , s_http_host
  , s_http_host_v6
  , s_http_host_v6_end
  , s_http_host_v6_zone_start
  , s_http_host_v6_zone
  , s_http_host_port_start
  , s_http_host_port
};

/* Macros for character classes; depends on strict-mode  */
#define CR                  '\r'
#define LF                  '\n'
#define LOWER(c)            (unsigned char)(c | 0x20)
#define IS_ALPHA(c)         (LOWER(c) >= 'a' && LOWER(c) <= 'z')
#define IS_NUM(c)           ((c) >= '0' && (c) <= '9')
#define IS_ALPHANUM(c)      (IS_ALPHA(c) || IS_NUM(c))
#define IS_HEX(c)           (IS_NUM(c) || (LOWER(c) >= 'a' && LOWER(c) <= 'f'))
#define IS_MARK(c)          ((c) == '-' || (c) == '_' || (c) == '.' || \
  (c) == '!' || (c) == '~' || (c) == '*' || (c) == '\'' || (c) == '(' || \
  (c) == ')')
#define IS_USERINFO_CHAR(c) (IS_ALPHANUM(c) || IS_MARK(c) || (c) == '%' || \
  (c) == ';' || (c) == ':' || (c) == '&' || (c) == '=' || (c) == '+' || \
  (c) == '$' || (c) == ',')
#define IS_SCHEMA_CHAR(c)   (IS_ALPHANUM(c) || (c) == '.' || (c) == '-' || (c) == '+')

#define STRICT_TOKEN(c)     ((c == ' ') ? 0 : tokens[(unsigned char)c])

#if HTTP_PARSER_STRICT
#define TOKEN(c)            STRICT_TOKEN(c)
#define IS_URL_CHAR(c)      (BIT_AT(normal_url_char, (unsigned char)c))
#define IS_HOST_CHAR(c)     (IS_ALPHANUM(c) || (c) == '.' || (c) == '-')
#else
#define TOKEN(c)            tokens[(unsigned char)c]
#define IS_URL_CHAR(c)                                                         \
  (BIT_AT(normal_url_char, (unsigned char)c) || ((c) & 0x80))
#define IS_HOST_CHAR(c)                                                        \
  (IS_ALPHANUM(c) || (c) == '.' || (c) == '-' || (c) == '_')
#endif

/**
 * Verify that a char is a valid visible (printable) US-ASCII
 * character or %x80-FF
 **/
#define IS_HEADER_CHAR(ch)                                                     \
  (ch == CR || ch == LF || ch == 9 || ((unsigned char)ch > 31 && ch != 127))

#define start_state (parser->type == HTTP_REQUEST ? s_start_req : s_start_res)


#if HTTP_PARSER_STRICT
# define STRICT_CHECK(cond)                                          \
do {                                                                 \
  if (cond) {                                                        \
    SET_ERRNO(HPE_STRICT);                                           \
    goto error;                                                      \
  }                                                                  \
} while (0)
# define NEW_MESSAGE() (http_should_keep_alive(parser) ? start_state : s_dead)
#else
# define STRICT_CHECK(cond)
# define NEW_MESSAGE() start_state
#endif


/* Map errno values to strings for human-readable output */
#define HTTP_STRERROR_GEN(n, s) { "HPE_" #n, s },
static struct {
  const char *name;
  const char *description;
} http_strerror_tab[] = {
  HTTP_ERRNO_MAP(HTTP_STRERROR_GEN)
};
#undef HTTP_STRERROR_GEN

int http_message_needs_eof(const http_parser *parser);

/* Our URL parser.
 *
 * This is designed to be shared by http_parser_execute() for URL validation,
 * hence it has a state transition + byte-for-byte interface. In addition, it
 * is meant to be embedded in http_parser_parse_url(), which does the dirty
 * work of turning state transitions URL components for its API.
 *
 * This function should only be invoked with non-space characters. It is
 * assumed that the caller cares about (and can detect) the transition between
 * URL and non-URL states by looking for these.
 */
static enum state
parse_url_char(enum state s, const char ch)
{
  if (ch == ' ' || ch == '\r' || ch == '\n') {
    return s_dead;
  }

#if HTTP_PARSER_STRICT
  if (ch == '\t' || ch == '\f') {
    return s_dead;
  }
#endif

  switch (s) {
    case s_req_spaces_before_url:
      /* Proxied requests are followed by scheme of an absolute URI (alpha).
       * All methods except CONNECT are followed by '/' or '*'.
       */

      if (ch == '/' || ch == '*') {
        return s_req_path;
      }

      if (IS_ALPHA(ch)) {
        return s_req_schema;
      }

      break;

    case s_req_schema:
      if (IS_SCHEMA_CHAR(ch)) {
        return s;
      }

      if (ch == ':') {
        return s_req_schema_slash;
      }

      break;

    case s_req_schema_slash:
      if (ch == '/') {
        return s_req_schema_slash_slash;
      }

      break;

    case s_req_schema_slash_slash:
      if (ch == '/') {
        return s_req_server_start;
      }

      break;

    case s_req_server_with_at:
      if (ch == '@') {
        return s_dead;
      }

    /* fall through */
    case s_req_server_start:
    case s_req_server:
      if (ch == '/') {
        return s_req_path;
      }

      if (ch == '?') {
        return s_req_query_string_start;
      }

      if (ch == '@') {
        return s_req_server_with_at;
      }

      if (IS_USERINFO_CHAR(ch) || ch == '[' || ch == ']') {
        return s_req_server;
      }

      break;

    case s_req_path:
      if (IS_URL_CHAR(ch)) {
        return s;
      }

      switch (ch) {
        case '?':
          return s_req_query_string_start;

        case '#':
          return s_req_fragment_start;
      }

      break;

    case s_req_query_string_start:
    case s_req_query_string:
      if (IS_URL_CHAR(ch)) {
        return s_req_query_string;
      }

      switch (ch) {
        case '?':
          /* allow extra '?' in query string */
          return s_req_query_string;

        case '#':
          return s_req_fragment_start;
      }

      break;

    case s_req_fragment_start:
      if (IS_URL_CHAR(ch)) {
        return s_req_fragment;
      }

      switch (ch) {
        case '?':
          return s_req_fragment;

        case '#':
          return s;
      }

      break;

    case s_req_fragment:
      if (IS_URL_CHAR(ch)) {
        return s;
      }

      switch (ch) {
        case '?':
        case '#':
          return s;
      }

      break;

    default:
      break;
  }

  /* We should never fall out of the switch above unless there's an error */
  return s_dead;
}

size_t http_parser_execute (http_parser *parser,
                            const http_parser_settings *settings,
                            const char *data,
                            size_t len)
{
  char c, ch;
  int8_t unhex_val;
  const char *p = data;
  const char *header_field_mark = 0;
  const char *header_value_mark = 0;
  const char *url_mark = 0;
  const char *body_mark = 0;
  const char *status_mark = 0;
  enum state p_state = (enum state) parser->state;
  const unsigned int lenient = parser->lenient_http_headers;
  const unsigned int allow_chunked_length = parser->allow_chunked_length;

  uint32_t nread = parser->nread;

  /* We're in an error state. Don't bother doing anything. */
  if (HTTP_PARSER_ERRNO(parser) != HPE_OK) {
    return 0;
  }

  if (len == 0) {
    switch (CURRENT_STATE()) {
      case s_body_identity_eof:
        /* Use of CALLBACK_NOTIFY() here would erroneously return 1 byte read if
         * we got paused.
         */
        CALLBACK_NOTIFY_NOADVANCE(message_complete);
        return 0;

      case s_dead:
      case s_start_req_or_res:
      case s_start_res:
      case s_start_req:
        return 0;

      default:
        SET_ERRNO(HPE_INVALID_EOF_STATE);
        return 1;
    }
  }


  if (CURRENT_STATE() == s_header_field)
    header_field_mark = data;
  if (CURRENT_STATE() == s_header_value)
    header_value_mark = data;
  switch (CURRENT_STATE()) {
  case s_req_path:
  case s_req_schema:
  case s_req_schema_slash:
  case s_req_schema_slash_slash:
  case s_req_server_start:
  case s_req_server:
  case s_req_server_with_at:
  case s_req_query_string_start:
  case s_req_query_string:
  case s_req_fragment_start:
  case s_req_fragment:
    url_mark = data;
    break;
  case s_res_status:
    status_mark = data;
    break;
  default:
    break;
  }

  for (p=data; p != data + len; p++) {
    ch = *p;

    if (PARSING_HEADER(CURRENT_STATE()))
      COUNT_HEADER_SIZE(1);

reexecute:
    switch (CURRENT_STATE()) {

      case s_dead:
        /* this state is used after a 'Connection: close' message
         * the parser will error out if it reads another message
         */
        if (LIKELY(ch == CR || ch == LF))
          break;

        SET_ERRNO(HPE_CLOSED_CONNECTION);
        goto error;

      case s_start_req_or_res:
      {
        if (ch == CR || ch == LF)
          break;
        parser->flags = 0;
        parser->uses_transfer_encoding = 0;
        parser->content_length = ULLONG_MAX;

        if (ch == 'H') {
          UPDATE_STATE(s_res_or_resp_H);

          CALLBACK_NOTIFY(message_begin);
        } else {
          parser->type = HTTP_REQUEST;
          UPDATE_STATE(s_start_req);
          REEXECUTE();
        }

        break;
      }

      case s_res_or_resp_H:
        if (ch == 'T') {
          parser->type = HTTP_RESPONSE;
          UPDATE_STATE(s_res_HT);
        } else {
          if (UNLIKELY(ch != 'E')) {
            SET_ERRNO(HPE_INVALID_CONSTANT);
            goto error;
          }

          parser->type = HTTP_REQUEST;
          parser->method = HTTP_HEAD;
          parser->index = 2;
          UPDATE_STATE(s_req_method);
        }
        break;

      case s_start_res:
      {
        if (ch == CR || ch == LF)
          break;
        parser->flags = 0;
        parser->uses_transfer_encoding = 0;
        parser->content_length = ULLONG_MAX;

        if (ch == 'H') {
          UPDATE_STATE(s_res_H);
        } else {
          SET_ERRNO(HPE_INVALID_CONSTANT);
          goto error;
        }

        CALLBACK_NOTIFY(message_begin);
        break;
      }

      case s_res_H:
        STRICT_CHECK(ch != 'T');
        UPDATE_STATE(s_res_HT);
        break;

      case s_res_HT:
        STRICT_CHECK(ch != 'T');
        UPDATE_STATE(s_res_HTT);
        break;

      case s_res_HTT:
        STRICT_CHECK(ch != 'P');
        UPDATE_STATE(s_res_HTTP);
        break;

      case s_res_HTTP:
        STRICT_CHECK(ch != '/');
        UPDATE_STATE(s_res_http_major);
        break;

      case s_res_http_major:
        if (UNLIKELY(!IS_NUM(ch))) {
          SET_ERRNO(HPE_INVALID_VERSION);
          goto error;
        }

        parser->http_major = ch - '0';
        UPDATE_STATE(s_res_http_dot);
        break;

      case s_res_http_dot:
      {
        if (UNLIKELY(ch != '.')) {
          SET_ERRNO(HPE_INVALID_VERSION);
          goto error;
        }

        UPDATE_STATE(s_res_http_minor);
        break;
      }

      case s_res_http_minor:
        if (UNLIKELY(!IS_NUM(ch))) {
          SET_ERRNO(HPE_INVALID_VERSION);
          goto error;
        }

        parser->http_minor = ch - '0';
        UPDATE_STATE(s_res_http_end);
        break;

      case s_res_http_end:
      {
        if (UNLIKELY(ch != ' ')) {
          SET_ERRNO(HPE_INVALID_VERSION);
          goto error;
        }

        UPDATE_STATE(s_res_first_status_code);
        break;
      }

      case s_res_first_status_code:
      {
        if (!IS_NUM(ch)) {
          if (ch == ' ') {
            break;
          }

          SET_ERRNO(HPE_INVALID_STATUS);
          goto error;
        }
        parser->status_code = ch - '0';
        UPDATE_STATE(s_res_status_code);
        break;
      }

      case s_res_status_code:
      {
        if (!IS_NUM(ch)) {
          switch (ch) {
            case ' ':
              UPDATE_STATE(s_res_status_start);
              break;
            case CR:
            case LF:
              UPDATE_STATE(s_res_status_start);
              REEXECUTE();
              break;
            default:
              SET_ERRNO(HPE_INVALID_STATUS);
              goto error;
          }
          break;
        }

        parser->status_code *= 10;
        parser->status_code += ch - '0';

        if (UNLIKELY(parser->status_code > 999)) {
          SET_ERRNO(HPE_INVALID_STATUS);
          goto error;
        }

        break;
      }

      case s_res_status_start:
      {
        MARK(status);
        UPDATE_STATE(s_res_status);
        parser->index = 0;

        if (ch == CR || ch == LF)
          REEXECUTE();

        break;
      }

      case s_res_status:
        if (ch == CR) {
          UPDATE_STATE(s_res_line_almost_done);
          CALLBACK_DATA(status);
          break;
        }

        if (ch == LF) {
          UPDATE_STATE(s_header_field_start);
          CALLBACK_DATA(status);
          break;
        }

        break;

      case s_res_line_almost_done:
        STRICT_CHECK(ch != LF);
        UPDATE_STATE(s_header_field_start);
        break;

      case s_start_req:
      {
        if (ch == CR || ch == LF)
          break;
        parser->flags = 0;
        parser->uses_transfer_encoding = 0;
        parser->content_length = ULLONG_MAX;

        if (UNLIKELY(!IS_ALPHA(ch))) {
          SET_ERRNO(HPE_INVALID_METHOD);
          goto error;
        }

        parser->method = (enum http_method) 0;
        parser->index = 1;
        switch (ch) {
          case 'A': parser->method = HTTP_ACL; break;
          case 'B': parser->method = HTTP_BIND; break;
          case 'C': parser->method = HTTP_CONNECT; /* or COPY, CHECKOUT */ break;
          case 'D': parser->method = HTTP_DELETE; break;
          case 'G': parser->method = HTTP_GET; break;
          case 'H': parser->method = HTTP_HEAD; break;
          case 'L': parser->method = HTTP_LOCK; /* or LINK */ break;
          case 'M': parser->method = HTTP_MKCOL; /* or MOVE, MKACTIVITY, MERGE, M-SEARCH, MKCALENDAR */ break;
          case 'N': parser->method = HTTP_NOTIFY; break;
          case 'O': parser->method = HTTP_OPTIONS; break;
          case 'P': parser->method = HTTP_POST;
            /* or PROPFIND|PROPPATCH|PUT|PATCH|PURGE */
            break;
          case 'R': parser->method = HTTP_REPORT; /* or REBIND */ break;
          case 'S': parser->method = HTTP_SUBSCRIBE; /* or SEARCH, SOURCE */ break;
          case 'T': parser->method = HTTP_TRACE; break;
          case 'U': parser->method = HTTP_UNLOCK; /* or UNSUBSCRIBE, UNBIND, UNLINK */ break;
          default:
            SET_ERRNO(HPE_INVALID_METHOD);
            goto error;
        }
        UPDATE_STATE(s_req_method);

        CALLBACK_NOTIFY(message_begin);

        break;
      }

      case s_req_method:
      {
        const char *matcher;
        if (UNLIKELY(ch == '\0')) {
          SET_ERRNO(HPE_INVALID_METHOD);
          goto error;
        }

        matcher = method_strings[parser->method];
        if (ch == ' ' && matcher[parser->index] == '\0') {
          UPDATE_STATE(s_req_spaces_before_url);
        } else if (ch == matcher[parser->index]) {
          ; /* nada */
        } else if ((ch >= 'A' && ch <= 'Z') || ch == '-') {

          switch (parser->method << 16 | parser->index << 8 | ch) {
#define XX(meth, pos, ch, new_meth) \
            case (HTTP_##meth << 16 | pos << 8 | ch): \
              parser->method = HTTP_##new_meth; break;

            XX(POST,      1, 'U', PUT)
            XX(POST,      1, 'A', PATCH)
            XX(POST,      1, 'R', PROPFIND)
            XX(PUT,       2, 'R', PURGE)
            XX(CONNECT,   1, 'H', CHECKOUT)
            XX(CONNECT,   2, 'P', COPY)
            XX(MKCOL,     1, 'O', MOVE)
            XX(MKCOL,     1, 'E', MERGE)
            XX(MKCOL,     1, '-', MSEARCH)
            XX(MKCOL,     2, 'A', MKACTIVITY)
            XX(MKCOL,     3, 'A', MKCALENDAR)
            XX(SUBSCRIBE, 1, 'E', SEARCH)
            XX(SUBSCRIBE, 1, 'O', SOURCE)
            XX(REPORT,    2, 'B', REBIND)
            XX(PROPFIND,  4, 'P', PROPPATCH)
            XX(LOCK,      1, 'I', LINK)
            XX(UNLOCK,    2, 'S', UNSUBSCRIBE)
            XX(UNLOCK,    2, 'B', UNBIND)
            XX(UNLOCK,    3, 'I', UNLINK)
#undef XX
            default:
              SET_ERRNO(HPE_INVALID_METHOD);
              goto error;
          }
        } else {
          SET_ERRNO(HPE_INVALID_METHOD);
          goto error;
        }

        ++parser->index;
        break;
      }

      case s_req_spaces_before_url:
      {
        if (ch == ' ') break;

        MARK(url);
        if (parser->method == HTTP_CONNECT) {
          UPDATE_STATE(s_req_server_start);
        }

        UPDATE_STATE(parse_url_char(CURRENT_STATE(), ch));
        if (UNLIKELY(CURRENT_STATE() == s_dead)) {
          SET_ERRNO(HPE_INVALID_URL);
          goto error;
        }

        break;
      }

      case s_req_schema:
      case s_req_schema_slash:
      case s_req_schema_slash_slash:
      case s_req_server_start:
      {
        switch (ch) {
          /* No whitespace allowed here */
          case ' ':
          case CR:
          case LF:
            SET_ERRNO(HPE_INVALID_URL);
            goto error;
          default:
            UPDATE_STATE(parse_url_char(CURRENT_STATE(), ch));
            if (UNLIKELY(CURRENT_STATE() == s_dead)) {
              SET_ERRNO(HPE_INVALID_URL);
              goto error;
            }
        }

        break;
      }

      case s_req_server:
      case s_req_server_with_at:
      case s_req_path:
      case s_req_query_string_start:
      case s_req_query_string:
      case s_req_fragment_start:
      case s_req_fragment:
      {
        switch (ch) {
          case ' ':
            UPDATE_STATE(s_req_http_start);
            CALLBACK_DATA(url);
            break;
          case CR:
          case LF:
            parser->http_major = 0;
            parser->http_minor = 9;
            UPDATE_STATE((ch == CR) ?
              s_req_line_almost_done :
              s_header_field_start);
            CALLBACK_DATA(url);
            break;
          default:
            UPDATE_STATE(parse_url_char(CURRENT_STATE(), ch));
            if (UNLIKELY(CURRENT_STATE() == s_dead)) {
              SET_ERRNO(HPE_INVALID_URL);
              goto error;
            }
        }
        break;
      }

      case s_req_http_start:
        switch (ch) {
          case ' ':
            break;
          case 'H':
            UPDATE_STATE(s_req_http_H);
            break;
          case 'I':
            if (parser->method == HTTP_SOURCE) {
              UPDATE_STATE(s_req_http_I);
              break;
            }
            /* fall through */
          default:
            SET_ERRNO(HPE_INVALID_CONSTANT);
            goto error;
        }
        break;

      case s_req_http_H:
        STRICT_CHECK(ch != 'T');
        UPDATE_STATE(s_req_http_HT);
        break;

      case s_req_http_HT:
        STRICT_CHECK(ch != 'T');
        UPDATE_STATE(s_req_http_HTT);
        break;

      case s_req_http_HTT:
        STRICT_CHECK(ch != 'P');
        UPDATE_STATE(s_req_http_HTTP);
        break;

      case s_req_http_I:
        STRICT_CHECK(ch != 'C');
        UPDATE_STATE(s_req_http_IC);
        break;

      case s_req_http_IC:
        STRICT_CHECK(ch != 'E');
        UPDATE_STATE(s_req_http_HTTP);  /* Treat "ICE" as "HTTP". */
        break;

      case s_req_http_HTTP:
        STRICT_CHECK(ch != '/');
        UPDATE_STATE(s_req_http_major);
        break;

      case s_req_http_major:
        if (UNLIKELY(!IS_NUM(ch))) {
          SET_ERRNO(HPE_INVALID_VERSION);
          goto error;
        }

        parser->http_major = ch - '0';
        UPDATE_STATE(s_req_http_dot);
        break;

      case s_req_http_dot:
      {
        if (UNLIKELY(ch != '.')) {
          SET_ERRNO(HPE_INVALID_VERSION);
          goto error;
        }

        UPDATE_STATE(s_req_http_minor);
        break;
      }

      case s_req_http_minor:
        if (UNLIKELY(!IS_NUM(ch))) {
          SET_ERRNO(HPE_INVALID_VERSION);
          goto error;
        }

        parser->http_minor = ch - '0';
        UPDATE_STATE(s_req_http_end);
        break;

      case s_req_http_end:
      {
        if (ch == CR) {
          UPDATE_STATE(s_req_line_almost_done);
          break;
        }

        if (ch == LF) {
          UPDATE_STATE(s_header_field_start);
          break;
        }

        SET_ERRNO(HPE_INVALID_VERSION);
        goto error;
        break;
      }

      /* end of request line */
      case s_req_line_almost_done:
      {
        if (UNLIKELY(ch != LF)) {
          SET_ERRNO(HPE_LF_EXPECTED);
          goto error;
        }

        UPDATE_STATE(s_header_field_start);
        break;
      }

      case s_header_field_start:
      {
        if (ch == CR) {
          UPDATE_STATE(s_headers_almost_done);
          break;
        }

        if (ch == LF) {
          /* they might be just sending \n instead of \r\n so this would be
           * the second \n to denote the end of headers*/
          UPDATE_STATE(s_headers_almost_done);
          REEXECUTE();
        }

        c = TOKEN(ch);

        if (UNLIKELY(!c)) {
          SET_ERRNO(HPE_INVALID_HEADER_TOKEN);
          goto error;
        }

        MARK(header_field);

        parser->index = 0;
        UPDATE_STATE(s_header_field);

        switch (c) {
          case 'c':
            parser->header_state = h_C;
            break;

          case 'p':
            parser->header_state = h_matching_proxy_connection;
            break;

          case 't':
            parser->header_state = h_matching_transfer_encoding;
            break;

          case 'u':
            parser->header_state = h_matching_upgrade;
            break;

          default:
            parser->header_state = h_general;
            break;
        }
        break;
      }

      case s_header_field:
      {
        const char* start = p;
        for (; p != data + len; p++) {
          ch = *p;
          c = TOKEN(ch);

          if (!c)
            break;

          switch (parser->header_state) {
            case h_general: {
              size_t left = data + len - p;
              const char* pe = p + MIN(left, max_header_size);
              while (p+1 < pe && TOKEN(p[1])) {
                p++;
              }
              break;
            }

            case h_C:
              parser->index++;
              parser->header_state = (c == 'o' ? h_CO : h_general);
              break;

            case h_CO:
              parser->index++;
              parser->header_state = (c == 'n' ? h_CON : h_general);
              break;

            case h_CON:
              parser->index++;
              switch (c) {
                case 'n':
                  parser->header_state = h_matching_connection;
                  break;
                case 't':
                  parser->header_state = h_matching_content_length;
                  break;
                default:
                  parser->header_state = h_general;
                  break;
              }
              break;

            /* connection */

            case h_matching_connection:
              parser->index++;
              if (parser->index > sizeof(CONNECTION)-1
                  || c != CONNECTION[parser->index]) {
                parser->header_state = h_general;
              } else if (parser->index == sizeof(CONNECTION)-2) {
                parser->header_state = h_connection;
              }
              break;

            /* proxy-connection */

            case h_matching_proxy_connection:
              parser->index++;
              if (parser->index > sizeof(PROXY_CONNECTION)-1
                  || c != PROXY_CONNECTION[parser->index]) {
                parser->header_state = h_general;
              } else if (parser->index == sizeof(PROXY_CONNECTION)-2) {
                parser->header_state = h_connection;
              }
              break;

            /* content-length */

            case h_matching_content_length:
              parser->index++;
              if (parser->index > sizeof(CONTENT_LENGTH)-1
                  || c != CONTENT_LENGTH[parser->index]) {
                parser->header_state = h_general;
              } else if (parser->index == sizeof(CONTENT_LENGTH)-2) {
                parser->header_state = h_content_length;
              }
              break;

            /* transfer-encoding */

            case h_matching_transfer_encoding:
              parser->index++;
              if (parser->index > sizeof(TRANSFER_ENCODING)-1
                  || c != TRANSFER_ENCODING[parser->index]) {
                parser->header_state = h_general;
              } else if (parser->index == sizeof(TRANSFER_ENCODING)-2) {
                parser->header_state = h_transfer_encoding;
                parser->uses_transfer_encoding = 1;
              }
              break;

            /* upgrade */

            case h_matching_upgrade:
              parser->index++;
              if (parser->index > sizeof(UPGRADE)-1
                  || c != UPGRADE[parser->index]) {
                parser->header_state = h_general;
              } else if (parser->index == sizeof(UPGRADE)-2) {
                parser->header_state = h_upgrade;
              }
              break;

            case h_connection:
            case h_content_length:
            case h_transfer_encoding:
            case h_upgrade:
              if (ch != ' ') parser->header_state = h_general;
              break;

            default:
              assert(0 && "Unknown header_state");
              break;
          }
        }

        if (p == data + len) {
          --p;
          COUNT_HEADER_SIZE(p - start);
          break;
        }

        COUNT_HEADER_SIZE(p - start);

        if (ch == ':') {
          UPDATE_STATE(s_header_value_discard_ws);
          CALLBACK_DATA(header_field);
          break;
        }

        SET_ERRNO(HPE_INVALID_HEADER_TOKEN);
        goto error;
      }

      case s_header_value_discard_ws:
        if (ch == ' ' || ch == '\t') break;

        if (ch == CR) {
          UPDATE_STATE(s_header_value_discard_ws_almost_done);
          break;
        }

        if (ch == LF) {
          UPDATE_STATE(s_header_value_discard_lws);
          break;
        }

        /* fall through */

      case s_header_value_start:
      {
        MARK(header_value);

        UPDATE_STATE(s_header_value);
        parser->index = 0;

        c = LOWER(ch);

        switch (parser->header_state) {
          case h_upgrade:
            parser->flags |= F_UPGRADE;
            parser->header_state = h_general;
            break;

          case h_transfer_encoding:
            /* looking for 'Transfer-Encoding: chunked' */
            if ('c' == c) {
              parser->header_state = h_matching_transfer_encoding_chunked;
            } else {
              parser->header_state = h_matching_transfer_encoding_token;
            }
            break;

          /* Multi-value `Transfer-Encoding` header */
          case h_matching_transfer_encoding_token_start:
            break;

          case h_content_length:
            if (UNLIKELY(!IS_NUM(ch))) {
              SET_ERRNO(HPE_INVALID_CONTENT_LENGTH);
              goto error;
            }

            if (parser->flags & F_CONTENTLENGTH) {
              SET_ERRNO(HPE_UNEXPECTED_CONTENT_LENGTH);
              goto error;
            }

            parser->flags |= F_CONTENTLENGTH;
            parser->content_length = ch - '0';
            parser->header_state = h_content_length_num;
            break;

          /* when obsolete line folding is encountered for content length
           * continue to the s_header_value state */
          case h_content_length_ws:
            break;

          case h_connection:
            /* looking for 'Connection: keep-alive' */
            if (c == 'k') {
              parser->header_state = h_matching_connection_keep_alive;
            /* looking for 'Connection: close' */
            } else if (c == 'c') {
              parser->header_state = h_matching_connection_close;
            } else if (c == 'u') {
              parser->header_state = h_matching_connection_upgrade;
            } else {
              parser->header_state = h_matching_connection_token;
            }
            break;

          /* Multi-value `Connection` header */
          case h_matching_connection_token_start:
            break;

          default:
            parser->header_state = h_general;
            break;
        }
        break;
      }

      case s_header_value:
      {
        const char* start = p;
        enum header_states h_state = (enum header_states) parser->header_state;
        for (; p != data + len; p++) {
          ch = *p;
          if (ch == CR) {
            UPDATE_STATE(s_header_almost_done);
            parser->header_state = h_state;
            CALLBACK_DATA(header_value);
            break;
          }

          if (ch == LF) {
            UPDATE_STATE(s_header_almost_done);
            COUNT_HEADER_SIZE(p - start);
            parser->header_state = h_state;
            CALLBACK_DATA_NOADVANCE(header_value);
            REEXECUTE();
          }

          if (!lenient && !IS_HEADER_CHAR(ch)) {
            SET_ERRNO(HPE_INVALID_HEADER_TOKEN);
            goto error;
          }

          c = LOWER(ch);

          switch (h_state) {
            case h_general:
              {
                size_t left = data + len - p;
                const char* pe = p + MIN(left, max_header_size);

                for (; p != pe; p++) {
                  ch = *p;
                  if (ch == CR || ch == LF) {
                    --p;
                    break;
                  }
                  if (!lenient && !IS_HEADER_CHAR(ch)) {
                    SET_ERRNO(HPE_INVALID_HEADER_TOKEN);
                    goto error;
                  }
                }
                if (p == data + len)
                  --p;
                break;
              }

            case h_connection:
            case h_transfer_encoding:
              assert(0 && "Shouldn't get here.");
              break;

            case h_content_length:
              if (ch == ' ') break;
              h_state = h_content_length_num;
              /* fall through */

            case h_content_length_num:
            {
              uint64_t t;

              if (ch == ' ') {
                h_state = h_content_length_ws;
                break;
              }

              if (UNLIKELY(!IS_NUM(ch))) {
                SET_ERRNO(HPE_INVALID_CONTENT_LENGTH);
                parser->header_state = h_state;
                goto error;
              }

              t = parser->content_length;
              t *= 10;
              t += ch - '0';

              /* Overflow? Test against a conservative limit for simplicity. */
              if (UNLIKELY((ULLONG_MAX - 10) / 10 < parser->content_length)) {
                SET_ERRNO(HPE_INVALID_CONTENT_LENGTH);
                parser->header_state = h_state;
                goto error;
              }

              parser->content_length = t;
              break;
            }

            case h_content_length_ws:
              if (ch == ' ') break;
              SET_ERRNO(HPE_INVALID_CONTENT_LENGTH);
              parser->header_state = h_state;
              goto error;

            /* Transfer-Encoding: chunked */
            case h_matching_transfer_encoding_token_start:
              /* looking for 'Transfer-Encoding: chunked' */
              if ('c' == c) {
                h_state = h_matching_transfer_encoding_chunked;
              } else if (STRICT_TOKEN(c)) {
                /* TODO(indutny): similar code below does this, but why?
                 * At the very least it seems to be inconsistent given that
                 * h_matching_transfer_encoding_token does not check for
                 * `STRICT_TOKEN`
                 */
                h_state = h_matching_transfer_encoding_token;
              } else if (c == ' ' || c == '\t') {
                /* Skip lws */
              } else {
                h_state = h_general;
              }
              break;

            case h_matching_transfer_encoding_chunked:
              parser->index++;
              if (parser->index > sizeof(CHUNKED)-1
                  || c != CHUNKED[parser->index]) {
                h_state = h_matching_transfer_encoding_token;
              } else if (parser->index == sizeof(CHUNKED)-2) {
                h_state = h_transfer_encoding_chunked;
              }
              break;

            case h_matching_transfer_encoding_token:
              if (ch == ',') {
                h_state = h_matching_transfer_encoding_token_start;
                parser->index = 0;
              }
              break;

            case h_matching_connection_token_start:
              /* looking for 'Connection: keep-alive' */
              if (c == 'k') {
                h_state = h_matching_connection_keep_alive;
              /* looking for 'Connection: close' */
              } else if (c == 'c') {
                h_state = h_matching_connection_close;
              } else if (c == 'u') {
                h_state = h_matching_connection_upgrade;
              } else if (STRICT_TOKEN(c)) {
                h_state = h_matching_connection_token;
              } else if (c == ' ' || c == '\t') {
                /* Skip lws */
              } else {
                h_state = h_general;
              }
              break;

            /* looking for 'Connection: keep-alive' */
            case h_matching_connection_keep_alive:
              parser->index++;
              if (parser->index > sizeof(KEEP_ALIVE)-1
                  || c != KEEP_ALIVE[parser->index]) {
                h_state = h_matching_connection_token;
              } else if (parser->index == sizeof(KEEP_ALIVE)-2) {
                h_state = h_connection_keep_alive;
              }
              break;

            /* looking for 'Connection: close' */
            case h_matching_connection_close:
              parser->index++;
              if (parser->index > sizeof(CLOSE)-1 || c != CLOSE[parser->index]) {
                h_state = h_matching_connection_token;
              } else if (parser->index == sizeof(CLOSE)-2) {
                h_state = h_connection_close;
              }
              break;

            /* looking for 'Connection: upgrade' */
            case h_matching_connection_upgrade:
              parser->index++;
              if (parser->index > sizeof(UPGRADE) - 1 ||
                  c != UPGRADE[parser->index]) {
                h_state = h_matching_connection_token;
              } else if (parser->index == sizeof(UPGRADE)-2) {
                h_state = h_connection_upgrade;
              }
              break;

            case h_matching_connection_token:
              if (ch == ',') {
                h_state = h_matching_connection_token_start;
                parser->index = 0;
              }
              break;

            case h_transfer_encoding_chunked:
              if (ch != ' ') h_state = h_matching_transfer_encoding_token;
              break;

            case h_connection_keep_alive:
            case h_connection_close:
            case h_connection_upgrade:
              if (ch == ',') {
                if (h_state == h_connection_keep_alive) {
                  parser->flags |= F_CONNECTION_KEEP_ALIVE;
                } else if (h_state == h_connection_close) {
                  parser->flags |= F_CONNECTION_CLOSE;
                } else if (h_state == h_connection_upgrade) {
                  parser->flags |= F_CONNECTION_UPGRADE;
                }
                h_state = h_matching_connection_token_start;
                parser->index = 0;
              } else if (ch != ' ') {
                h_state = h_matching_connection_token;
              }
              break;

            default:
              UPDATE_STATE(s_header_value);
              h_state = h_general;
              break;
          }
        }
        parser->header_state = h_state;

        if (p == data + len)
          --p;

        COUNT_HEADER_SIZE(p - start);
        break;
      }

      case s_header_almost_done:
      {
        if (UNLIKELY(ch != LF)) {
          SET_ERRNO(HPE_LF_EXPECTED);
          goto error;
        }

        UPDATE_STATE(s_header_value_lws);
        break;
      }

      case s_header_value_lws:
      {
        if (ch == ' ' || ch == '\t') {
          if (parser->header_state == h_content_length_num) {
              /* treat obsolete line folding as space */
              parser->header_state = h_content_length_ws;
          }
          UPDATE_STATE(s_header_value_start);
          REEXECUTE();
        }

        /* finished the header */
        switch (parser->header_state) {
          case h_connection_keep_alive:
            parser->flags |= F_CONNECTION_KEEP_ALIVE;
            break;
          case h_connection_close:
            parser->flags |= F_CONNECTION_CLOSE;
            break;
          case h_transfer_encoding_chunked:
            parser->flags |= F_CHUNKED;
            break;
          case h_connection_upgrade:
            parser->flags |= F_CONNECTION_UPGRADE;
            break;
          default:
            break;
        }

        UPDATE_STATE(s_header_field_start);
        REEXECUTE();
      }

      case s_header_value_discard_ws_almost_done:
      {
        STRICT_CHECK(ch != LF);
        UPDATE_STATE(s_header_value_discard_lws);
        break;
      }

      case s_header_value_discard_lws:
      {
        if (ch == ' ' || ch == '\t') {
          UPDATE_STATE(s_header_value_discard_ws);
          break;
        } else {
          switch (parser->header_state) {
            case h_connection_keep_alive:
              parser->flags |= F_CONNECTION_KEEP_ALIVE;
              break;
            case h_connection_close:
              parser->flags |= F_CONNECTION_CLOSE;
              break;
            case h_connection_upgrade:
              parser->flags |= F_CONNECTION_UPGRADE;
              break;
            case h_transfer_encoding_chunked:
              parser->flags |= F_CHUNKED;
              break;
            case h_content_length:
              /* do not allow empty content length */
              SET_ERRNO(HPE_INVALID_CONTENT_LENGTH);
              goto error;
              break;
            default:
              break;
          }

          /* header value was empty */
          MARK(header_value);
          UPDATE_STATE(s_header_field_start);
          CALLBACK_DATA_NOADVANCE(header_value);
          REEXECUTE();
        }
      }

      case s_headers_almost_done:
      {
        STRICT_CHECK(ch != LF);

        if (parser->flags & F_TRAILING) {
          /* End of a chunked request */
          UPDATE_STATE(s_message_done);
          CALLBACK_NOTIFY_NOADVANCE(chunk_complete);
          REEXECUTE();
        }

        /* Cannot use transfer-encoding and a content-length header together
           per the HTTP specification. (RFC 7230 Section 3.3.3) */
        if ((parser->uses_transfer_encoding == 1) &&
            (parser->flags & F_CONTENTLENGTH)) {
          /* Allow it for lenient parsing as long as `Transfer-Encoding` is
           * not `chunked` or allow_length_with_encoding is set
           */
          if (parser->flags & F_CHUNKED) {
            if (!allow_chunked_length) {
              SET_ERRNO(HPE_UNEXPECTED_CONTENT_LENGTH);
              goto error;
            }
          } else if (!lenient) {
            SET_ERRNO(HPE_UNEXPECTED_CONTENT_LENGTH);
            goto error;
          }
        }

        UPDATE_STATE(s_headers_done);

        /* Set this here so that on_headers_complete() callbacks can see it */
        if ((parser->flags & F_UPGRADE) &&
            (parser->flags & F_CONNECTION_UPGRADE)) {
          /* For responses, "Upgrade: foo" and "Connection: upgrade" are
           * mandatory only when it is a 101 Switching Protocols response,
           * otherwise it is purely informational, to announce support.
           */
          parser->upgrade =
              (parser->type == HTTP_REQUEST || parser->status_code == 101);
        } else {
          parser->upgrade = (parser->method == HTTP_CONNECT);
        }

        /* Here we call the headers_complete callback. This is somewhat
         * different than other callbacks because if the user returns 1, we
         * will interpret that as saying that this message has no body. This
         * is needed for the annoying case of receiving a response to a HEAD
         * request.
         *
         * We'd like to use CALLBACK_NOTIFY_NOADVANCE() here but we cannot, so
         * we have to simulate it by handling a change in errno below.
         */
        if (settings->on_headers_complete) {
          switch (settings->on_headers_complete(parser)) {
            case 0:
              break;

            case 2:
              parser->upgrade = 1;

              /* fall through */
            case 1:
              parser->flags |= F_SKIPBODY;
              break;

            default:
              SET_ERRNO(HPE_CB_headers_complete);
              RETURN(p - data); /* Error */
          }
        }

        if (HTTP_PARSER_ERRNO(parser) != HPE_OK) {
          RETURN(p - data);
        }

        REEXECUTE();
      }

      case s_headers_done:
      {
        int hasBody;
        STRICT_CHECK(ch != LF);

        parser->nread = 0;
        nread = 0;

        hasBody = parser->flags & F_CHUNKED ||
          (parser->content_length > 0 && parser->content_length != ULLONG_MAX);
        if (parser->upgrade && (parser->method == HTTP_CONNECT ||
                                (parser->flags & F_SKIPBODY) || !hasBody)) {
          /* Exit, the rest of the message is in a different protocol. */
          UPDATE_STATE(NEW_MESSAGE());
          CALLBACK_NOTIFY(message_complete);
          RETURN((p - data) + 1);
        }

        if (parser->flags & F_SKIPBODY) {
          UPDATE_STATE(NEW_MESSAGE());
          CALLBACK_NOTIFY(message_complete);
        } else if (parser->flags & F_CHUNKED) {
          /* chunked encoding - ignore Content-Length header,
           * prepare for a chunk */
          UPDATE_STATE(s_chunk_size_start);
        } else if (parser->uses_transfer_encoding == 1) {
          if (parser->type == HTTP_REQUEST && !lenient) {
            /* RFC 7230 3.3.3 */

            /* If a Transfer-Encoding header field
             * is present in a request and the chunked transfer coding is not
             * the final encoding, the message body length cannot be determined
             * reliably; the server MUST respond with the 400 (Bad Request)
             * status code and then close the connection.
             */
            SET_ERRNO(HPE_INVALID_TRANSFER_ENCODING);
            RETURN(p - data); /* Error */
          } else {
            /* RFC 7230 3.3.3 */

            /* If a Transfer-Encoding header field is present in a response and
             * the chunked transfer coding is not the final encoding, the
             * message body length is determined by reading the connection until
             * it is closed by the server.
             */
            UPDATE_STATE(s_body_identity_eof);
          }
        } else {
          if (parser->content_length == 0) {
            /* Content-Length header given but zero: Content-Length: 0\r\n */
            UPDATE_STATE(NEW_MESSAGE());
            CALLBACK_NOTIFY(message_complete);
          } else if (parser->content_length != ULLONG_MAX) {
            /* Content-Length header given and non-zero */
            UPDATE_STATE(s_body_identity);
          } else {
            if (!http_message_needs_eof(parser)) {
              /* Assume content-length 0 - read the next */
              UPDATE_STATE(NEW_MESSAGE());
              CALLBACK_NOTIFY(message_complete);
            } else {
              /* Read body until EOF */
              UPDATE_STATE(s_body_identity_eof);
            }
          }
        }

        break;
      }

      case s_body_identity:
      {
        uint64_t to_read = MIN(parser->content_length,
                               (uint64_t) ((data + len) - p));

        assert(parser->content_length != 0
            && parser->content_length != ULLONG_MAX);

        /* The difference between advancing content_length and p is because
         * the latter will automaticaly advance on the next loop iteration.
         * Further, if content_length ends up at 0, we want to see the last
         * byte again for our message complete callback.
         */
        MARK(body);
        parser->content_length -= to_read;
        p += to_read - 1;

        if (parser->content_length == 0) {
          UPDATE_STATE(s_message_done);

          /* Mimic CALLBACK_DATA_NOADVANCE() but with one extra byte.
           *
           * The alternative to doing this is to wait for the next byte to
           * trigger the data callback, just as in every other case. The
           * problem with this is that this makes it difficult for the test
           * harness to distinguish between complete-on-EOF and
           * complete-on-length. It's not clear that this distinction is
           * important for applications, but let's keep it for now.
           */
          CALLBACK_DATA_(body, p - body_mark + 1, p - data);
          REEXECUTE();
        }

        break;
      }

      /* read until EOF */
      case s_body_identity_eof:
        MARK(body);
        p = data + len - 1;

        break;

      case s_message_done:
        UPDATE_STATE(NEW_MESSAGE());
        CALLBACK_NOTIFY(message_complete);
        if (parser->upgrade) {
          /* Exit, the rest of the message is in a different protocol. */
          RETURN((p - data) + 1);
        }
        break;

      case s_chunk_size_start:
      {
        assert(nread == 1);
        assert(parser->flags & F_CHUNKED);

        unhex_val = unhex[(unsigned char)ch];
        if (UNLIKELY(unhex_val == -1)) {
          SET_ERRNO(HPE_INVALID_CHUNK_SIZE);
          goto error;
        }

        parser->content_length = unhex_val;
        UPDATE_STATE(s_chunk_size);
        break;
      }

      case s_chunk_size:
      {
        uint64_t t;

        assert(parser->flags & F_CHUNKED);

        if (ch == CR) {
          UPDATE_STATE(s_chunk_size_almost_done);
          break;
        }

        unhex_val = unhex[(unsigned char)ch];

        if (unhex_val == -1) {
          if (ch == ';' || ch == ' ') {
            UPDATE_STATE(s_chunk_parameters);
            break;
          }

          SET_ERRNO(HPE_INVALID_CHUNK_SIZE);
          goto error;
        }

        t = parser->content_length;
        t *= 16;
        t += unhex_val;

        /* Overflow? Test against a conservative limit for simplicity. */
        if (UNLIKELY((ULLONG_MAX - 16) / 16 < parser->content_length)) {
          SET_ERRNO(HPE_INVALID_CONTENT_LENGTH);
          goto error;
        }

        parser->content_length = t;
        break;
      }

      case s_chunk_parameters:
      {
        assert(parser->flags & F_CHUNKED);
        /* just ignore this shit. TODO check for overflow */
        if (ch == CR) {
          UPDATE_STATE(s_chunk_size_almost_done);
          break;
        }
        break;
      }

      case s_chunk_size_almost_done:
      {
        assert(parser->flags & F_CHUNKED);
        STRICT_CHECK(ch != LF);

        parser->nread = 0;
        nread = 0;

        if (parser->content_length == 0) {
          parser->flags |= F_TRAILING;
          UPDATE_STATE(s_header_field_start);
        } else {
          UPDATE_STATE(s_chunk_data);
        }
        CALLBACK_NOTIFY(chunk_header);
        break;
      }

      case s_chunk_data:
      {
        uint64_t to_read = MIN(parser->content_length,
                               (uint64_t) ((data + len) - p));

        assert(parser->flags & F_CHUNKED);
        assert(parser->content_length != 0
            && parser->content_length != ULLONG_MAX);

        /* See the explanation in s_body_identity for why the content
         * length and data pointers are managed this way.
         */
        MARK(body);
        parser->content_length -= to_read;
        p += to_read - 1;

        if (parser->content_length == 0) {
          UPDATE_STATE(s_chunk_data_almost_done);
        }

        break;
      }

      case s_chunk_data_almost_done:
        assert(parser->flags & F_CHUNKED);
        assert(parser->content_length == 0);
        STRICT_CHECK(ch != CR);
        UPDATE_STATE(s_chunk_data_done);
        CALLBACK_DATA(body);
        break;

      case s_chunk_data_done:
        assert(parser->flags & F_CHUNKED);
        STRICT_CHECK(ch != LF);
        parser->nread = 0;
        nread = 0;
        UPDATE_STATE(s_chunk_size_start);
        CALLBACK_NOTIFY(chunk_complete);
        break;

      default:
        assert(0 && "unhandled state");
        SET_ERRNO(HPE_INVALID_INTERNAL_STATE);
        goto error;
    }
  }

  /* Run callbacks for any marks that we have leftover after we ran out of
   * bytes. There should be at most one of these set, so it's OK to invoke
   * them in series (unset marks will not result in callbacks).
   *
   * We use the NOADVANCE() variety of callbacks here because 'p' has already
   * overflowed 'data' and this allows us to correct for the off-by-one that
   * we'd otherwise have (since CALLBACK_DATA() is meant to be run with a 'p'
   * value that's in-bounds).
   */

  assert(((header_field_mark ? 1 : 0) +
          (header_value_mark ? 1 : 0) +
          (url_mark ? 1 : 0)  +
          (body_mark ? 1 : 0) +
          (status_mark ? 1 : 0)) <= 1);

  CALLBACK_DATA_NOADVANCE(header_field);
  CALLBACK_DATA_NOADVANCE(header_value);
  CALLBACK_DATA_NOADVANCE(url);
  CALLBACK_DATA_NOADVANCE(body);
  CALLBACK_DATA_NOADVANCE(status);

  RETURN(len);

error:
  if (HTTP_PARSER_ERRNO(parser) == HPE_OK) {
    SET_ERRNO(HPE_UNKNOWN);
  }

  RETURN(p - data);
}


/* Does the parser need to see an EOF to find the end of the message? */
int
http_message_needs_eof (const http_parser *parser)
{
  if (parser->type == HTTP_REQUEST) {
    return 0;
  }

  /* See RFC 2616 section 4.4 */
  if (parser->status_code / 100 == 1 || /* 1xx e.g. Continue */
      parser->status_code == 204 ||     /* No Content */
      parser->status_code == 304 ||     /* Not Modified */
      parser->flags & F_SKIPBODY) {     /* response to a HEAD request */
    return 0;
  }

  /* RFC 7230 3.3.3, see `s_headers_almost_done` */
  if ((parser->uses_transfer_encoding == 1) &&
      (parser->flags & F_CHUNKED) == 0) {
    return 1;
  }

  if ((parser->flags & F_CHUNKED) || parser->content_length != ULLONG_MAX) {
    return 0;
  }

  return 1;
}


int
http_should_keep_alive (const http_parser *parser)
{
  if (parser->http_major > 0 && parser->http_minor > 0) {
    /* HTTP/1.1 */
    if (parser->flags & F_CONNECTION_CLOSE) {
      return 0;
    }
  } else {
    /* HTTP/1.0 or earlier */
    if (!(parser->flags & F_CONNECTION_KEEP_ALIVE)) {
      return 0;
    }
  }

  return !http_message_needs_eof(parser);
}


const char *
http_method_str (enum http_method m)
{
  return ELEM_AT(method_strings, m, "<unknown>");
}

const char *
http_status_str (enum http_status s)
{
  switch (s) {
#define XX(num, name, string) case HTTP_STATUS_##name: return #string;
    HTTP_STATUS_MAP(XX)
#undef XX
    default: return "<unknown>";
  }
}

void
http_parser_init (http_parser *parser, enum http_parser_type t)
{
  void *data = parser->data; /* preserve application data */
  memset(parser, 0, sizeof(*parser));
  parser->data = data;
  parser->type = t;
  parser->state = (t == HTTP_REQUEST ? s_start_req : (t == HTTP_RESPONSE ? s_start_res : s_start_req_or_res));
  parser->http_errno = HPE_OK;
}

void
http_parser_settings_init(http_parser_settings *settings)
{
  memset(settings, 0, sizeof(*settings));
}

const char *
http_errno_name(enum http_errno err) {
  assert(((size_t) err) < ARRAY_SIZE(http_strerror_tab));
  return http_strerror_tab[err].name;
}

const char *
http_errno_description(enum http_errno err) {
  assert(((size_t) err) < ARRAY_SIZE(http_strerror_tab));
  return http_strerror_tab[err].description;
}

static enum http_host_state
http_parse_host_char(enum http_host_state s, const char ch) {
  switch(s) {
    case s_http_userinfo:
    case s_http_userinfo_start:
      if (ch == '@') {
        return s_http_host_start;
      }

      if (IS_USERINFO_CHAR(ch)) {
        return s_http_userinfo;
      }
      break;

    case s_http_host_start:
      if (ch == '[') {
        return s_http_host_v6_start;
      }

      if (IS_HOST_CHAR(ch)) {
        return s_http_host;
      }

      break;

    case s_http_host:
      if (IS_HOST_CHAR(ch)) {
        return s_http_host;
      }

    /* fall through */
    case s_http_host_v6_end:
      if (ch == ':') {
        return s_http_host_port_start;
      }

      break;

    case s_http_host_v6:
      if (ch == ']') {
        return s_http_host_v6_end;
      }

    /* fall through */
    case s_http_host_v6_start:
      if (IS_HEX(ch) || ch == ':' || ch == '.') {
        return s_http_host_v6;
      }

      if (s == s_http_host_v6 && ch == '%') {
        return s_http_host_v6_zone_start;
      }
      break;

    case s_http_host_v6_zone:
      if (ch == ']') {
        return s_http_host_v6_end;
      }

    /* fall through */
    case s_http_host_v6_zone_start:
      /* RFC 6874 Zone ID consists of 1*( unreserved / pct-encoded) */
      if (IS_ALPHANUM(ch) || ch == '%' || ch == '.' || ch == '-' || ch == '_' ||
          ch == '~') {
        return s_http_host_v6_zone;
      }
      break;

    case s_http_host_port:
    case s_http_host_port_start:
      if (IS_NUM(ch)) {
        return s_http_host_port;
      }

      break;

    default:
      break;
  }
  return s_http_host_dead;
}

static int
http_parse_host(const char * buf, struct http_parser_url *u, int found_at) {
  enum http_host_state s;

  const char *p;
  size_t buflen = u->field_data[UF_HOST].off + u->field_data[UF_HOST].len;

  assert(u->field_set & (1 << UF_HOST));

  u->field_data[UF_HOST].len = 0;

  s = found_at ? s_http_userinfo_start : s_http_host_start;

  for (p = buf + u->field_data[UF_HOST].off; p < buf + buflen; p++) {
    enum http_host_state new_s = http_parse_host_char(s, *p);

    if (new_s == s_http_host_dead) {
      return 1;
    }

    switch(new_s) {
      case s_http_host:
        if (s != s_http_host) {
          u->field_data[UF_HOST].off = (uint16_t)(p - buf);
        }
        u->field_data[UF_HOST].len++;
        break;

      case s_http_host_v6:
        if (s != s_http_host_v6) {
          u->field_data[UF_HOST].off = (uint16_t)(p - buf);
        }
        u->field_data[UF_HOST].len++;
        break;

      case s_http_host_v6_zone_start:
      case s_http_host_v6_zone:
        u->field_data[UF_HOST].len++;
        break;

      case s_http_host_port:
        if (s != s_http_host_port) {
          u->field_data[UF_PORT].off = (uint16_t)(p - buf);
          u->field_data[UF_PORT].len = 0;
          u->field_set |= (1 << UF_PORT);
        }
        u->field_data[UF_PORT].len++;
        break;

      case s_http_userinfo:
        if (s != s_http_userinfo) {
          u->field_data[UF_USERINFO].off = (uint16_t)(p - buf);
          u->field_data[UF_USERINFO].len = 0;
          u->field_set |= (1 << UF_USERINFO);
        }
        u->field_data[UF_USERINFO].len++;
        break;

      default:
        break;
    }
    s = new_s;
  }

  /* Make sure we don't end somewhere unexpected */
  switch (s) {
    case s_http_host_start:
    case s_http_host_v6_start:
    case s_http_host_v6:
    case s_http_host_v6_zone_start:
    case s_http_host_v6_zone:
    case s_http_host_port_start:
    case s_http_userinfo:
    case s_http_userinfo_start:
      return 1;
    default:
      break;
  }

  return 0;
}

void
http_parser_url_init(struct http_parser_url *u) {
  memset(u, 0, sizeof(*u));
}

int
http_parser_parse_url(const char *buf, size_t buflen, int is_connect,
                      struct http_parser_url *u)
{
  enum state s;
  const char *p;
  enum http_parser_url_fields uf, old_uf;
  int found_at = 0;

  if (buflen == 0) {
    return 1;
  }

  u->port = u->field_set = 0;
  s = is_connect ? s_req_server_start : s_req_spaces_before_url;
  old_uf = UF_MAX;

  for (p = buf; p < buf + buflen; p++) {
    s = parse_url_char(s, *p);

    /* Figure out the next field that we're operating on */
    switch (s) {
      case s_dead:
        return 1;

      /* Skip delimeters */
      case s_req_schema_slash:
      case s_req_schema_slash_slash:
      case s_req_server_start:
      case s_req_query_string_start:
      case s_req_fragment_start:
        continue;

      case s_req_schema:
        uf = UF_SCHEMA;
        break;

      case s_req_server_with_at:
        found_at = 1;

      /* fall through */
      case s_req_server:
        uf = UF_HOST;
        break;

      case s_req_path:
        uf = UF_PATH;
        break;

      case s_req_query_string:
        uf = UF_QUERY;
        break;

      case s_req_fragment:
        uf = UF_FRAGMENT;
        break;

      default:
        assert(false && "Unexpected state");
        return 1;
    }

    /* Nothing's changed; soldier on */
    if (uf == old_uf) {
      u->field_data[uf].len++;
      continue;
    }

    u->field_data[uf].off = (uint16_t)(p - buf);
    u->field_data[uf].len = 1;

    u->field_set |= (1 << uf);
    old_uf = uf;
  }

  /* host must be present if there is a schema */
  /* parsing http:///toto will fail */
  if ((u->field_set & (1 << UF_SCHEMA)) &&
      (u->field_set & (1 << UF_HOST)) == 0) {
    return 1;
  }

  if (u->field_set & (1 << UF_HOST)) {
    if (http_parse_host(buf, u, found_at) != 0) {
      return 1;
    }
  }

  /* CONNECT requests can only contain "hostname:port" */
  if (is_connect && u->field_set != ((1 << UF_HOST)|(1 << UF_PORT))) {
    return 1;
  }

  if (u->field_set & (1 << UF_PORT)) {
    uint16_t off;
    uint16_t len;
    const char* p;
    const char* end;
    unsigned long v;

    off = u->field_data[UF_PORT].off;
    len = u->field_data[UF_PORT].len;
    end = buf + off + len;

    /* NOTE: The characters are already validated and are in the [0-9] range */
    assert((size_t) (off + len) <= buflen && "Port number overflow");
    v = 0;
    for (p = buf + off; p < end; p++) {
      v *= 10;
      v += *p - '0';

      /* Ports have a max value of 2^16 */
      if (v > 0xffff) {
        return 1;
      }
    }

    u->port = (uint16_t) v;
  }

  return 0;
}

void
http_parser_pause(http_parser *parser, int paused) {
  /* Users should only be pausing/unpausing a parser that is not in an error
   * state. In non-debug builds, there's not much that we can do about this
   * other than ignore it.
   */
  if (HTTP_PARSER_ERRNO(parser) == HPE_OK ||
      HTTP_PARSER_ERRNO(parser) == HPE_PAUSED) {
    uint32_t nread = parser->nread; /* used by the SET_ERRNO macro */
    SET_ERRNO((paused) ? HPE_PAUSED : HPE_OK);
  } else {
    assert(0 && "Attempting to pause parser in error state");
  }
}

int
http_body_is_final(const struct http_parser *parser) {
    return parser->state == s_message_done;
}

unsigned long
http_parser_version(void) {
  return HTTP_PARSER_VERSION_MAJOR * 0x10000 |
         HTTP_PARSER_VERSION_MINOR * 0x00100 |
         HTTP_PARSER_VERSION_PATCH * 0x00001;
}

void
http_parser_set_max_header_size(uint32_t size) {
  max_header_size = size;
}
licenses(["notice"])  # Apache 2

cc_library(
    name = "http_parser",
    srcs = [
        "http_parser.c",
        "http_parser.h",
    ],
    hdrs = ["http_parser.h"],
    # This compiler flag is set to an arbtitrarily high number so
    # as to effectively disables the http_parser header limit, as
    # we do our own checks in the conn manager and codec.
    copts = ["-DHTTP_MAX_HEADER_SIZE=0x2000000"] + select({
        "@envoy//bazel:uhv_enabled": ["-DHTTP_PARSER_STRICT=0"],
        "//conditions:default": [],
    }),
    includes = ["."],
    visibility = ["//visibility:public"],
)
licenses(["notice"])  # Apache 2

cc_binary(
    name = "su-exec",
    srcs = ["su-exec.c"],
    visibility = ["//visibility:public"],
)
licenses(["notice"])  # Apache 2

cc_library(
    name = "crypto",
    srcs = [
        "crypto/libcrypto.a",
    ],
    hdrs = glob(["boringssl/include/openssl/*.h"]),
    defines = ["BORINGSSL_FIPS"],
    includes = ["boringssl/include"],
    visibility = ["//visibility:public"],
)

cc_library(
    name = "ssl",
    srcs = [
        "ssl/libssl.a",
    ],
    hdrs = glob(["boringssl/include/openssl/*.h"]),
    includes = ["boringssl/include"],
    visibility = ["//visibility:public"],
    deps = [":crypto"],
)

genrule(
    name = "build",
    srcs = glob(["boringssl/**"]),
    outs = [
        "crypto/libcrypto.a",
        "ssl/libssl.a",
    ],
    cmd = "$(location {}) $(location crypto/libcrypto.a) $(location ssl/libssl.a)".format("@envoy//bazel/external:boringssl_fips.genrule_cmd"),
    tools = ["@envoy//bazel/external:boringssl_fips.genrule_cmd"],
)
licenses(["notice"])  # Apache 2

package(default_visibility = ["//visibility:public"])

cc_library(
    name = "wasmtime_lib",
    hdrs = [
        "include/wasm.h",
    ],
    include_prefix = "wasmtime",
    deps = [
        "@com_github_wasmtime//:rust_c_api",
    ],
)
licenses(["notice"])  # Apache 2

cc_library(
    name = "libcircllhist",
    srcs = ["src/circllhist.c"],
    hdrs = [
        "src/circllhist.h",
    ],
    copts = select({
        "@envoy//bazel:windows_x86_64": ["-DWIN32"],
        "//conditions:default": [],
    }),
    includes = ["src"],
    visibility = ["//visibility:public"],
)
licenses(["notice"])  # Apache 2

cc_library(
    name = "rapidjson",
    hdrs = glob(["include/rapidjson/**/*.h"]),
    defines = ["RAPIDJSON_HAS_STDSTRING=1"],
    includes = ["include"],
    # rapidjson is only needed to build external dependency of the Zipkin tracer.
    # For Envoy source code plese use source/common/json/json_loader.h
    visibility = ["@io_opencensus_cpp//opencensus/exporters/trace/zipkin:__pkg__"],
)
# TODO(dio): Consider to remove compiler specific part of this patch when we solely compile the
# project using clang-cl. Tracked in https://github.com/envoyproxy/envoy/issues/11974.

diff --git a/base/compiler_specific.h b/base/compiler_specific.h
index 0174b6d..fb5b80d 100644
--- a/base/compiler_specific.h
+++ b/base/compiler_specific.h
@@ -7,10 +7,6 @@

 #include "build/build_config.h"

-#if defined(COMPILER_MSVC) && !defined(__clang__)
-#error "Only clang-cl is supported on Windows, see https://crbug.com/988071"
-#endif
-
 // This is a wrapper around `__has_cpp_attribute`, which can be used to test for
 // the presence of an attribute. In case the compiler does not support this
 // macro it will simply evaluate to 0.
@@ -398,7 +394,7 @@ inline constexpr bool AnalyzerAssumeTrue(bool arg) {
 #define CONSTINIT
 #endif

-#if defined(__clang__)
+#if defined(__clang__) && HAS_CPP_ATTRIBUTE(gsl::Pointer)
 #define GSL_OWNER [[gsl::Owner]]
 #define GSL_POINTER [[gsl::Pointer]]
 #else
diff --git a/base/containers/checked_iterators.h b/base/containers/checked_iterators.h
index dc8d2ba..9306697 100644
--- a/base/containers/checked_iterators.h
+++ b/base/containers/checked_iterators.h
@@ -237,9 +237,11 @@ using CheckedContiguousConstIterator = CheckedContiguousIterator<const T>;
 // [3] https://wg21.link/pointer.traits.optmem
 namespace std {

+#ifdef SUPPORTS_CPP_17_CONTIGUOUS_ITERATOR
 template <typename T>
 struct __is_cpp17_contiguous_iterator<::gurl_base::CheckedContiguousIterator<T>>
     : true_type {};
+#endif

 template <typename T>
 struct pointer_traits<::gurl_base::CheckedContiguousIterator<T>> {

# TODO(keith): Remove unused parameter workarounds when https://quiche-review.googlesource.com/c/googleurl/+/11180 lands

diff --git a/base/numerics/clamped_math_impl.h b/base/numerics/clamped_math_impl.h
index 10023f0..783f5da 100644
--- a/base/numerics/clamped_math_impl.h
+++ b/base/numerics/clamped_math_impl.h
@@ -36,6 +36,7 @@ template <typename T,
           typename std::enable_if<std::is_integral<T>::value &&
                                   !std::is_signed<T>::value>::type* = nullptr>
 constexpr T SaturatedNegWrapper(T value) {
+  (void)value; // unused
   return T(0);
 }

diff --git a/base/numerics/safe_conversions.h b/base/numerics/safe_conversions.h
index 4a9494e..ba44fa0 100644
--- a/base/numerics/safe_conversions.h
+++ b/base/numerics/safe_conversions.h
@@ -45,6 +45,7 @@ template <typename Dst, typename Src, typename Enable = void>
 struct IsValueInRangeFastOp {
   static constexpr bool is_supported = false;
   static constexpr bool Do(Src value) {
+    (void)value; // unused
     // Force a compile failure if instantiated.
     return CheckOnFailure::template HandleFailure<bool>();
   }
@@ -164,6 +165,7 @@ template <typename Dst, typename Src, typename Enable = void>
 struct SaturateFastOp {
   static constexpr bool is_supported = false;
   static constexpr Dst Do(Src value) {
+    (void)value; // unused
     // Force a compile failure if instantiated.
     return CheckOnFailure::template HandleFailure<Dst>();
   }
diff --git a/base/containers/span.h b/base/containers/span.h
index 40e325f..c66c183 100644
--- a/base/containers/span.h
+++ b/base/containers/span.h
@@ -125,7 +125,7 @@ using EnableIfSpanCompatibleContainerAndSpanIsDynamic =
 template <size_t Extent>
 class ExtentStorage {
  public:
-  constexpr explicit ExtentStorage(size_t size) noexcept {}
+  constexpr explicit ExtentStorage(size_t /*size*/) noexcept {}
   constexpr size_t size() const noexcept { return Extent; }
 };

diff --git a/polyfills/third_party/perfetto/include/perfetto/tracing/traced_value.h b/polyfills/third_party/perfetto/include/perfetto/tracing/traced_value.h
index 6d059f7..6339fa5 100644
--- a/polyfills/third_party/perfetto/include/perfetto/tracing/traced_value.h
+++ b/polyfills/third_party/perfetto/include/perfetto/tracing/traced_value.h
@@ -13,7 +13,7 @@ class TracedValue {
 };

 template <typename T>
-void WriteIntoTracedValue(TracedValue context, T&& value) {}
+void WriteIntoTracedValue(TracedValue /*context*/, T&& /*value*/) {}

 template <typename T, typename ResultType = void, class = void>
 struct check_traced_value_support {
diff --git a/build_config/build_config.bzl b/build_config/build_config.bzl
index 5960d2a..08295ff 100644
--- a/build_config/build_config.bzl
+++ b/build_config/build_config.bzl
@@ -7,6 +7,7 @@ _default_copts = select({
     "//conditions:default": [
         "-std=c++17",
         "-fno-strict-aliasing",
+        "-Wno-unused-parameter",
     ],
 })

diff --git a/url/url_canon_internal.h b/url/url_canon_internal.h
index 58ae144..467da0b 100644
--- a/url/url_canon_internal.h
+++ b/url/url_canon_internal.h
@@ -305,6 +305,7 @@ inline bool AppendUTF8EscapedChar(const char* str,
 // through it will point to the next character to be considered. On failure,
 // |*begin| will be unchanged.
 inline bool Is8BitChar(char c) {
+  (void)c; // unused
   return true;  // this case is specialized to avoid a warning
 }
 inline bool Is8BitChar(char16_t c) {

# TODO(keith): Remove when https://quiche-review.googlesource.com/c/googleurl/+/11200 lands

diff --git a/base/memory/raw_ptr_exclusion.h b/base/memory/raw_ptr_exclusion.h
index f881c04..4e4f7df 100644
--- a/base/memory/raw_ptr_exclusion.h
+++ b/base/memory/raw_ptr_exclusion.h
@@ -8,7 +8,7 @@
 #include "polyfills/base/allocator/buildflags.h"
 #include "build/build_config.h"

-#if defined(OFFICIAL_BUILD) && !BUILDFLAG(FORCE_ENABLE_RAW_PTR_EXCLUSION)
+#if !defined(__clang__) || (defined(OFFICIAL_BUILD) && !BUILDFLAG(FORCE_ENABLE_RAW_PTR_EXCLUSION))
 // The annotation changed compiler output and increased binary size so disable
 // for official builds.
 // TODO(crbug.com/1320670): Remove when issue is resolved.

# TODO(keith): Remove when https://quiche-review.googlesource.com/c/googleurl/+/11300/1 lands

diff --git a/build_config/BUILD b/build_config/BUILD
index 78ac01d..eeef238 100644
--- a/build_config/BUILD
+++ b/build_config/BUILD
@@ -5,11 +5,13 @@
 config_setting(
     name = "windows_x86_64",
     values = {"cpu": "x64_windows"},
+    visibility = ["//visibility:public"],
 )

 bool_flag(
     name = "system_icu",
     build_setting_default = True,
+    visibility = ["//visibility:public"],
 )

 config_setting(
@@ -17,4 +19,5 @@
     flag_values = {
         ":system_icu": "True",
     },
+    visibility = ["//visibility:public"],
 )
licenses(["notice"])  # Apache 2

cc_library(
    name = "xxhash",
    srcs = ["xxhash.c"],
    hdrs = [
        "xxh3.h",
        "xxhash.h",
    ],
    visibility = ["//visibility:public"],
)
licenses(["notice"])  # Apache 2

exports_files(["boringssl_fips.genrule_cmd"])

# Use a wrapper cc_library with an empty source source file to force
# compilation of other cc_library targets that only list *.a sources.
cc_library(
    name = "all_external",
    srcs = [":empty.cc"],
    defines = ["OPENTRACING_STATIC"],
    # TODO: external/io_opentracing_cpp/BUILD.bazel:19:1: Executing genrule
    # @io_opentracing_cpp//:generate_version_h failed - needs porting
    tags = ["skip_on_windows"],
    deps = [
        "@com_github_datadog_dd_trace_cpp//:dd_trace_cpp",
        "@com_google_googletest//:gtest",
        "@io_opentracing_cpp//:opentracing",
    ],
)

genrule(
    name = "empty_cc",
    outs = ["empty.cc"],
    cmd = "touch \"$(@D)/empty.cc\"",
    visibility = ["//visibility:public"],
)
load("@bazel_skylib//lib:selects.bzl", "selects")
load("@bazel_skylib//rules:common_settings.bzl", "bool_flag")
load("@envoy_api//bazel:repository_locations.bzl", API_REPOSITORY_LOCATIONS_SPEC = "REPOSITORY_LOCATIONS_SPEC")
load("@envoy_api//bazel:repository_locations_utils.bzl", "load_repository_locations_spec", "merge_dicts")
load("@envoy_toolshed//:macros.bzl", "json_data")
load("@envoy_toolshed//dependency:macros.bzl", "updater")
load("//bazel:envoy_build_system.bzl", "envoy_package")
load("//bazel:envoy_internal.bzl", "envoy_select_force_libcpp")
load(":repository_locations.bzl", "REPOSITORY_LOCATIONS_SPEC")

licenses(["notice"])  # Apache 2

envoy_package()

exports_files([
    "gen_sh_test_runner.sh",
    "sh_test_wrapper.sh",
    "test_for_benchmark_wrapper.sh",
    "repository_locations.bzl",
    "exported_symbols.txt",
])

sh_library(
    name = "volatile_env",
    srcs = ["volatile_env.sh"],
)

# Stamp derived from tree hash + dirty status if `BAZEL_VOLATILE_DIRTY`
# is set, otherwise the git commit
genrule(
    name = "volatile-scm-hash",
    outs = ["volatile-scm-hash.txt"],
    cmd = """
    grep BUILD_SCM_HASH bazel-out/volatile-status.txt > $@
    """,
    stamp = 1,
    tags = ["no-remote-exec"],
)

genrule(
    name = "gnu_build_id",
    outs = ["gnu_build_id.ldscript"],
    cmd = """
      echo --build-id=0x$$(
          grep -E "^BUILD_SCM_REVISION" bazel-out/volatile-status.txt \
        | sed 's/^BUILD_SCM_REVISION //') \
        > $@
    """,
    # Undocumented attr to depend on workspace status files.
    # https://github.com/bazelbuild/bazel/issues/4942
    stamp = 1,
)

# For macOS, which doesn't have GNU ld's `--build-id` flag.
genrule(
    name = "raw_build_id",
    outs = ["raw_build_id.ldscript"],
    cmd = """
      grep -E "^BUILD_SCM_REVISION" bazel-out/volatile-status.txt \
    | sed 's/^BUILD_SCM_REVISION //' \
    | tr -d '\\n' \\
    > $@
    """,
    # Undocumented attr to depend on workspace status files.
    # https://github.com/bazelbuild/bazel/issues/4942
    stamp = 1,
)

# A target to optionally link C++ standard library dynamically in sanitizer runs.
# TSAN doesn't support libc/libstdc++ static linking per doc:
#   http://releases.llvm.org/8.0.1/tools/clang/docs/ThreadSanitizer.html
cc_library(
    name = "dynamic_stdlib",
    linkopts = envoy_select_force_libcpp(
        ["-lc++"],
        ["-lstdc++"],
    ),
)

cc_library(
    name = "static_stdlib",
    linkopts = select({
        "//bazel:linux": ["-static-libgcc"],
        "//conditions:default": [],
    }),
)

config_setting(
    name = "windows_opt_build",
    values = {
        "cpu": "x64_windows",
        "compilation_mode": "opt",
    },
)

config_setting(
    name = "windows_dbg_build",
    values = {
        "cpu": "x64_windows",
        "compilation_mode": "dbg",
    },
)

config_setting(
    name = "windows_fastbuild_build",
    values = {
        "cpu": "x64_windows",
        "compilation_mode": "fastbuild",
    },
)

config_setting(
    name = "clang_cl_build",
    values = {
        "cpu": "x64_windows",
        "define": "clang_cl=1",
    },
)

config_setting(
    name = "clang_cl_opt_build",
    values = {
        "cpu": "x64_windows",
        "define": "clang_cl=1",
        "compilation_mode": "opt",
    },
)

config_setting(
    name = "clang_cl_dbg_build",
    values = {
        "cpu": "x64_windows",
        "define": "clang_cl=1",
        "compilation_mode": "dbg",
    },
)

config_setting(
    name = "clang_cl_fastbuild_build",
    values = {
        "cpu": "x64_windows",
        "define": "clang_cl=1",
        "compilation_mode": "fastbuild",
    },
)

config_setting(
    name = "opt_build",
    values = {"compilation_mode": "opt"},
)

config_setting(
    name = "fastbuild_build",
    values = {"compilation_mode": "fastbuild"},
)

config_setting(
    name = "dbg_build",
    values = {"compilation_mode": "dbg"},
)

config_setting(
    name = "no_debug_info",
    values = {"define": "no_debug_info=1"},
)

config_setting(
    name = "asan_build",
    values = {"define": "ENVOY_CONFIG_ASAN=1"},
)

config_setting(
    name = "tsan_build",
    values = {"define": "ENVOY_CONFIG_TSAN=1"},
)

config_setting(
    name = "msan_build",
    values = {"define": "ENVOY_CONFIG_MSAN=1"},
)

config_setting(
    name = "coverage_build",
    values = {"define": "ENVOY_CONFIG_COVERAGE=1"},
)

config_setting(
    name = "clang_build",
    flag_values = {
        "@bazel_tools//tools/cpp:compiler": "clang",
    },
)

config_setting(
    name = "clang_pch_build",
    values = {"define": "ENVOY_CLANG_PCH=1"},
)

config_setting(
    name = "gcc_build_gcc",
    flag_values = {
        "@bazel_tools//tools/cpp:compiler": "gcc",
    },
)

# This is needed due to a Bazel bug (https://github.com/bazelbuild/bazel/issues/12707)
config_setting(
    name = "gcc_build_compiler",
    flag_values = {
        "@bazel_tools//tools/cpp:compiler": "compiler",
    },
)

selects.config_setting_group(
    name = "gcc_build_compiler_on_linux",
    match_all = [
        ":gcc_build_compiler",
        ":linux",
    ],
)

selects.config_setting_group(
    name = "gcc_build",
    match_any = [
        ":gcc_build_gcc",
        ":gcc_build_compiler_on_linux",
    ],
)

config_setting(
    name = "dynamic_link_tests",
    values = {
        "define": "dynamic_link_tests=true",
    },
)

config_setting(
    name = "disable_tcmalloc",
    values = {"define": "tcmalloc=disabled"},
)

config_setting(
    name = "debug_tcmalloc",
    values = {"define": "tcmalloc=debug"},
)

config_setting(
    name = "gperftools_tcmalloc",
    values = {"define": "tcmalloc=gperftools"},
)

# As select() can't be nested we need these specialized settings to avoid ambiguity when choosing
# tcmalloc's flavor for x86_64 and aarch64 builds.
config_setting(
    name = "disable_tcmalloc_on_linux_x86_64",
    values = {
        "define": "tcmalloc=disabled",
        "cpu": "k8",
    },
)

config_setting(
    name = "gperftools_tcmalloc_on_linux_x86_64",
    values = {
        "define": "tcmalloc=gperftools",
        "cpu": "k8",
    },
)

config_setting(
    name = "debug_tcmalloc_on_linux_x86_64",
    values = {
        "define": "tcmalloc=debug",
        "cpu": "k8",
    },
)

config_setting(
    name = "disable_tcmalloc_on_linux_aarch64",
    values = {
        "define": "tcmalloc=disabled",
        "cpu": "aarch64",
    },
)

config_setting(
    name = "gperftools_tcmalloc_on_linux_aarch64",
    values = {
        "define": "tcmalloc=gperftools",
        "cpu": "aarch64",
    },
)

config_setting(
    name = "debug_tcmalloc_on_linux_aarch64",
    values = {
        "define": "tcmalloc=debug",
        "cpu": "aarch64",
    },
)

config_setting(
    name = "disable_signal_trace",
    values = {"define": "signal_trace=disabled"},
)

config_setting(
    name = "disable_library_autolink",
    values = {"define": "library_autolink=disabled"},
)

config_setting(
    name = "disable_object_dump_on_signal_trace",
    values = {"define": "object_dump_on_signal_trace=disabled"},
)

config_setting(
    name = "disable_deprecated_features",
    values = {"define": "deprecated_features=disabled"},
)

selects.config_setting_group(
    name = "disable_hot_restart_or_admin",
    match_any = [
        "//bazel:disable_hot_restart",
        "//bazel:disable_admin_functionality",
    ],
)

bool_flag(
    name = "http3",
    build_setting_default = True,
    # TODO(keith): make private again https://github.com/bazelbuild/bazel-skylib/issues/404
    # visibility = ["//visibility:private"],
)

config_setting(
    name = "disable_http3_setting",
    flag_values = {
        ":http3": "False",
    },
    # TODO(keith): make private again https://github.com/bazelbuild/bazel-skylib/issues/404
    # visibility = ["//visibility:private"],
)

selects.config_setting_group(
    name = "disable_http3",
    match_any = [
        ":disable_http3_setting",
        ":boringssl_fips",
    ],
)

config_setting(
    name = "disable_admin_html",
    values = {"define": "admin_html=disabled"},
)

config_setting(
    name = "disable_static_extension_registration",
    values = {"define": "static_extension_registration=disabled"},
)

config_setting(
    name = "disable_envoy_mobile_xds",
    values = {"define": "envoy_mobile_xds=disabled"},
)

config_setting(
    name = "disable_yaml",
    values = {"define": "envoy_yaml=disabled"},
)

# The goal here is to allow Envoy to build with this option but it is not yet
# complete.  See https://github.com/envoyproxy/envoy/issues/27412
config_setting(
    name = "disable_exceptions",
    values = {"define": "envoy_exceptions=disabled"},
)

config_setting(
    name = "disable_full_protos",
    values = {"define": "envoy_full_protos=disabled"},
)

config_setting(
    name = "disable_envoy_mobile_listener",
    values = {"define": "envoy_mobile_listener=disabled"},
)

config_setting(
    name = "disable_http_datagrams",
    values = {"define": "envoy_enable_http_datagrams=disabled"},
)

config_setting(
    name = "disable_logging",
    values = {"define": "enable_logging=disabled"},
)

config_setting(
    name = "disable_admin_functionality",
    values = {"define": "admin_functionality=disabled"},
)

config_setting(
    name = "disable_hot_restart_setting",
    values = {"define": "hot_restart=disabled"},
    # TODO(keith): make private again https://github.com/bazelbuild/bazel-skylib/issues/404
    # visibility = ["//visibility:private"],
)

selects.config_setting_group(
    name = "disable_hot_restart",
    match_any = [
        ":apple",
        ":disable_hot_restart_setting",
    ],
)

config_setting(
    name = "disable_google_grpc",
    values = {"define": "google_grpc=disabled"},
)

config_setting(
    name = "enable_path_normalization_by_default",
    values = {"define": "path_normalization_by_default=true"},
)

cc_proto_library(
    name = "grpc_health_proto",
    deps = ["@com_github_grpc_grpc//src/proto/grpc/health/v1:_health_proto_only"],
)

config_setting(
    name = "enable_exported_symbols",
    values = {"define": "exported_symbols=enabled"},
)

config_setting(
    name = "enable_log_debug_assert_in_release",
    values = {"define": "log_debug_assert_in_release=enabled"},
)

config_setting(
    name = "enable_log_fast_debug_assert_in_release",
    values = {"define": "log_fast_debug_assert_in_release=enabled"},
)

config_setting(
    name = "disable_known_issue_asserts",
    values = {"define": "disable_known_issue_asserts=true"},
)

config_setting(
    name = "enable_perf_annotation",
    values = {"define": "perf_annotation=enabled"},
)

config_setting(
    name = "enable_perf_tracing",
    values = {"define": "perf_tracing=enabled"},
)

config_setting(
    name = "force_libcpp",
    values = {"define": "force_libcpp=enabled"},
)

config_setting(
    name = "boringssl_fips",
    constraint_values = [
        "@platforms//os:linux",
    ],
    values = {"define": "boringssl=fips"},
)

config_setting(
    name = "boringssl_disabled",
    values = {"define": "boringssl=disabled"},
)

config_setting(
    name = "zlib_ng",
    constraint_values = [
        "@platforms//os:linux",
    ],
    values = {"define": "zlib=ng"},
)

# TODO: consider converting WAVM VM support to an extension (https://github.com/envoyproxy/envoy/issues/12574)
config_setting(
    name = "wasm_wavm",
    values = {"define": "wasm=wavm"},
)

config_setting(
    name = "wasm_v8",
    values = {"define": "wasm=v8"},
)

config_setting(
    name = "wasm_wamr",
    values = {"define": "wasm=wamr"},
)

config_setting(
    name = "wasm_wasmtime",
    values = {"define": "wasm=wasmtime"},
)

config_setting(
    name = "wasm_disabled",
    values = {"define": "wasm=disabled"},
)

# This config setting enables Universal Header Validator and disables
# HTTP header compliance checks in codecs.
# This setting is temporary to transition header validation into UHV without
# impacting production builds of Envoy.
# This setting is enabled for the bazel.compile_time_options CI target.
config_setting(
    name = "uhv_enabled",
    values = {"define": "uhv=enabled"},
)

# Alias pointing to the selected version of BoringSSL:
# - BoringSSL FIPS from @boringssl_fips//:ssl,
# - non-FIPS BoringSSL from @boringssl//:ssl.
alias(
    name = "boringssl",
    actual = select({
        "//bazel:boringssl_fips": "@boringssl_fips//:ssl",
        "//conditions:default": "@boringssl//:ssl",
    }),
)

alias(
    name = "boringcrypto",
    actual = select({
        "//bazel:boringssl_fips": "@boringssl_fips//:crypto",
        "//conditions:default": "@boringssl//:crypto",
    }),
)

config_setting(
    name = "linux_x86_64",
    values = {"cpu": "k8"},
)

config_setting(
    name = "linux_aarch64",
    values = {"cpu": "aarch64"},
)

config_setting(
    name = "linux_ppc",
    values = {"cpu": "ppc"},
)

config_setting(
    name = "linux_s390x",
    values = {"cpu": "s390x"},
)

config_setting(
    name = "linux_mips64",
    values = {"cpu": "mips64"},
)

config_setting(
    name = "windows_x86_64",
    values = {"cpu": "x64_windows"},
)

# Configuration settings to make doing selects for Apple vs non-Apple platforms
# easier. More details: https://docs.bazel.build/versions/master/configurable-attributes.html#config_settingaliasing
config_setting(
    name = "darwin",
    values = {"cpu": "darwin"},
)

config_setting(
    name = "darwin_x86_64",
    values = {"cpu": "darwin_x86_64"},
)

config_setting(
    name = "darwin_arm64",
    values = {"cpu": "darwin_arm64"},
)

config_setting(
    name = "ios_i386",
    values = {"cpu": "ios_i386"},
)

config_setting(
    name = "ios_x86_64",
    values = {"cpu": "ios_x86_64"},
)

config_setting(
    name = "ios_armv7",
    values = {"cpu": "ios_armv7"},
)

config_setting(
    name = "ios_armv7s",
    values = {"cpu": "ios_armv7s"},
)

config_setting(
    name = "ios_arm64",
    values = {"cpu": "ios_arm64"},
)

config_setting(
    name = "ios_sim_arm64",
    values = {"cpu": "ios_sim_arm64"},
)

config_setting(
    name = "ios_arm64e",
    values = {"cpu": "ios_arm64e"},
)

config_setting(
    name = "manual_stamp",
    values = {"define": "manual_stamp=manual_stamp"},
)

config_setting(
    name = "android",
    constraint_values = [
        "@platforms//os:android",
    ],
)

selects.config_setting_group(
    name = "android_opt",
    match_all = [
        ":opt_build",
        ":android",
    ],
)

config_setting(
    name = "android_logger",
    values = {"define": "logger=android"},
)

config_setting(
    name = "android_system_helper",
    values = {"define": "system-helper=android"},
)

config_setting(
    name = "libfuzzer_coverage",
    define_values = {
        "FUZZING_ENGINE": "libfuzzer",
        "ENVOY_CONFIG_COVERAGE": "1",
    },
)

config_setting(
    name = "libfuzzer",
    define_values = {"FUZZING_ENGINE": "libfuzzer"},
)

config_setting(
    name = "oss_fuzz",
    define_values = {"FUZZING_ENGINE": "oss-fuzz"},
)

alias(
    name = "fuzzing_engine",
    actual = select({
        ":libfuzzer": "@rules_fuzzing//fuzzing/engines:libfuzzer",
        ":oss_fuzz": "@rules_fuzzing_oss_fuzz//:oss_fuzz_engine",
        "//conditions:default": "//test/fuzz:fuzz_runner_engine",
    }),
)

selects.config_setting_group(
    name = "apple",
    match_any = [
        ":darwin",
        ":darwin_arm64",
        ":darwin_x86_64",
        ":ios_arm64",
        ":ios_arm64e",
        ":ios_armv7",
        ":ios_armv7s",
        ":ios_i386",
        ":ios_sim_arm64",
        ":ios_x86_64",
    ],
)

selects.config_setting_group(
    name = "darwin_any",
    match_any = [
        ":darwin",
        ":darwin_arm64",
        ":darwin_x86_64",
    ],
)

selects.config_setting_group(
    name = "apple_dbg",
    match_all = [
        ":apple",
        ":dbg_build",
    ],
)

selects.config_setting_group(
    name = "apple_opt",
    match_all = [
        ":opt_build",
        ":apple",
    ],
)

selects.config_setting_group(
    name = "apple_fastbuild",
    match_all = [
        ":apple",
        ":fastbuild_build",
    ],
)

selects.config_setting_group(
    name = "apple_non_opt",
    match_any = [
        ":apple_dbg",
        ":apple_fastbuild",
    ],
)

selects.config_setting_group(
    name = "linux",
    match_any = [
        ":linux_aarch64",
        ":linux_mips64",
        ":linux_ppc",
        ":linux_s390x",
        ":linux_x86_64",
    ],
)

selects.config_setting_group(
    name = "x86",
    match_any = [
        ":darwin_x86_64",
        ":ios_x86_64",
        ":linux_x86_64",
        ":windows_x86_64",
    ],
)

selects.config_setting_group(
    name = "not_x86",
    match_any = [
        ":darwin_arm64",
        ":ios_arm64",
        ":ios_arm64e",
        ":ios_armv7",
        ":ios_armv7s",
        ":ios_i386",
        ":ios_sim_arm64",
        ":linux_aarch64",
        ":linux_mips64",
        ":linux_ppc",
        ":linux_s390x",
    ],
)

selects.config_setting_group(
    name = "not_x86_or_wasm_disabled",
    match_any = [
        ":not_x86",
        ":wasm_disabled",
    ],
)

alias(
    name = "remote_jdk11",
    actual = "@bazel_tools//tools/jdk:remote_jdk11",
)

alias(
    name = "windows",
    actual = "@bazel_tools//src/conditions:windows",
)

json_data(
    name = "repository_locations",
    data = load_repository_locations_spec(REPOSITORY_LOCATIONS_SPEC),
)

json_data(
    name = "all_repository_locations",
    data = merge_dicts(
        load_repository_locations_spec(REPOSITORY_LOCATIONS_SPEC),
        load_repository_locations_spec(API_REPOSITORY_LOCATIONS_SPEC),
    ),
)

platform(
    name = "android_aarch64",
    constraint_values = [
        "@platforms//cpu:aarch64",
        "@platforms//os:android",
    ],
)

platform(
    name = "android_armeabi",
    constraint_values = [
        "@platforms//cpu:armv7",
        "@platforms//os:android",
    ],
)

platform(
    name = "android_x86",
    constraint_values = [
        "@platforms//cpu:x86_32",
        "@platforms//os:android",
    ],
)

platform(
    name = "android_x86_64",
    constraint_values = [
        "@platforms//cpu:x86_64",
        "@platforms//os:android",
    ],
)

platform(
    name = "macos_x86_64",
    constraint_values = [
        "@platforms//cpu:x86_64",
        "@platforms//os:macos",
    ],
)

platform(
    name = "macos_arm64",
    constraint_values = [
        "@platforms//cpu:arm64",
        "@platforms//os:macos",
    ],
)

platform(
    name = "ios_x86_64_platform",  # TODO(keith): Resolve duplicate name issue
    constraint_values = [
        "@platforms//cpu:x86_64",
        "@platforms//os:ios",
        "@build_bazel_apple_support//constraints:simulator",
    ],
)

platform(
    name = "ios_sim_arm64_platform",  # TODO(keith): Resolve duplicate name issue
    constraint_values = [
        "@platforms//cpu:arm64",
        "@platforms//os:ios",
        "@build_bazel_apple_support//constraints:simulator",
    ],
)

platform(
    name = "ios_arm64_platform",  # TODO(keith): Resolve duplicate name issue
    constraint_values = [
        "@platforms//cpu:arm64",
        "@platforms//os:ios",
        "@build_bazel_apple_support//constraints:device",
    ],
)

# A dependency required by python protobuf
# Envoy does not have any C++ code that includes python.h so this dummy
# target is enough. However if such code is added in the future when this
# should be changed to alias "@system_python//:python_headers"
cc_library(
    name = "python_headers",
    visibility = ["//visibility:public"],
)

# These can be run as follows:
#
# $ bazel run //bazel:update ENVOY_DEP NEW_VERSION
# $ bazel run //bazel:api-update API_DEP NEW_VERSION
updater(
    name = "update",
    data = ["//tools/dependency:check"],
    dependencies = "//tools/dependency:filtered-dependencies",
    post_script = ":version_update_post.sh",
    pydict = True,
    tags = ["skip_on_windows"],
    version_file = ":repository_locations.bzl",
)

updater(
    name = "api-update",
    data = ["//tools/dependency:check"],
    dependencies = "@envoy_api//bazel:repository_locations",
    post_script = ":version_update_post.sh",
    pydict = True,
    tags = ["skip_on_windows"],
    version_file = "@envoy_api//bazel:repository_locations.bzl",
    version_path_replace = "external/envoy_api:api",
)
diff --git a/bazel/emscripten_deps.bzl b/bazel/emscripten_deps.bzl
index 95801ba..95fdabd 100644
--- a/bazel/emscripten_deps.bzl
+++ b/bazel/emscripten_deps.bzl
@@ -69,31 +69,3 @@ def emscripten_deps(emscripten_version = "latest"):
             build_file = "@emsdk//emscripten_toolchain:emscripten.BUILD",
             type = "zip",
         )
-
-    if "emscripten_npm_linux" not in excludes:
-        npm_install(
-            name = "emscripten_npm_linux",
-            package_json = "@emscripten_bin_linux//:emscripten/package.json",
-            package_lock_json = "@emscripten_bin_linux//:emscripten/package-lock.json",
-        )
-
-    if "emscripten_npm_mac" not in excludes:
-        npm_install(
-            name = "emscripten_npm_mac",
-            package_json = "@emscripten_bin_mac//:emscripten/package.json",
-            package_lock_json = "@emscripten_bin_mac//:emscripten/package-lock.json",
-        )
-
-    if "emscripten_npm_mac_arm64" not in excludes:
-        npm_install(
-            name = "emscripten_npm_mac",
-            package_json = "@emscripten_bin_mac_arm64//:emscripten/package.json",
-            package_lock_json = "@emscripten_bin_mac_arm64//:emscripten/package-lock.json",
-        )
-
-    if "emscripten_npm_win" not in excludes:
-        npm_install(
-            name = "emscripten_npm_win",
-            package_json = "@emscripten_bin_win//:emscripten/package.json",
-            package_lock_json = "@emscripten_bin_win//:emscripten/package-lock.json",
-        )
diff --git a/bazel/emscripten_toolchain/BUILD.bazel b/bazel/emscripten_toolchain/BUILD.bazel
index eb36959..12dba37 100644
--- a/bazel/emscripten_toolchain/BUILD.bazel
+++ b/bazel/emscripten_toolchain/BUILD.bazel
@@ -13,7 +13,6 @@ filegroup(
         "env.sh",
         "env.bat",
         "@emsdk//:binaries",
-        "@emsdk//:node_modules",
         "@nodejs//:node_files",
     ],
 )
diff --git a/fuzzing/private/oss_fuzz/package.bzl b/fuzzing/private/oss_fuzz/package.bzl
index e5e9dc4..a3bb1b8 100644
--- a/fuzzing/private/oss_fuzz/package.bzl
+++ b/fuzzing/private/oss_fuzz/package.bzl
@@ -71,7 +71,7 @@ def _oss_fuzz_package_impl(ctx):
             if [[ -n "{options_path}" ]]; then
                 ln -s "$(pwd)/{options_path}" "$STAGING_DIR/{base_name}.options"
             fi
-            tar -chf "{output}" -C "$STAGING_DIR" .
+            tar -czhf "{output}" -C "$STAGING_DIR" .
         """.format(
             base_name = ctx.attr.base_name,
             binary_path = binary_info.binary_file.path,
diff --git a/fuzzing/tools/validate_dict.py b/fuzzing/tools/validate_dict.py
index d561e68..24e3adc 100644
--- a/fuzzing/tools/validate_dict.py
+++ b/fuzzing/tools/validate_dict.py
@@ -19,6 +19,11 @@ Validates and merges a set of fuzzing dictionary files into a single output.
 
 from absl import app
 from absl import flags
+
+import os
+import sys
+sys.path += [os.path.dirname(__file__)]
+
 from dict_validation import validate_line
 from sys import stderr
 
load("@com_google_googleapis//:repository_rules.bzl", "switched_rules_by_language")
load("@envoy_api//bazel:envoy_http_archive.bzl", "envoy_http_archive")
load("@envoy_api//bazel:external_deps.bzl", "load_repository_locations")
load(":dev_binding.bzl", "envoy_dev_binding")
load(":repository_locations.bzl", "PROTOC_VERSIONS", "REPOSITORY_LOCATIONS_SPEC")

PPC_SKIP_TARGETS = ["envoy.filters.http.lua"]

WINDOWS_SKIP_TARGETS = [
    "envoy.extensions.http.cache.file_system_http_cache",
    "envoy.filters.http.file_system_buffer",
    "envoy.filters.http.language",
    "envoy.filters.http.sxg",
    "envoy.tracers.dynamic_ot",
    "envoy.tracers.datadog",
    "envoy.tracers.opencensus",
    # Extensions that require CEL.
    "envoy.access_loggers.extension_filters.cel",
    "envoy.rate_limit_descriptors.expr",
    "envoy.filters.http.rate_limit_quota",
    "envoy.filters.http.ext_proc",
    "envoy.formatter.cel",
    "envoy.matching.inputs.cel_data_input",
    "envoy.matching.matchers.cel_matcher",
    # Wasm and RBAC extensions have a link dependency on CEL.
    "envoy.access_loggers.wasm",
    "envoy.bootstrap.wasm",
    "envoy.filters.http.wasm",
    "envoy.filters.network.wasm",
    "envoy.stat_sinks.wasm",
    # RBAC extensions have a link dependency on CEL.
    "envoy.filters.http.rbac",
    "envoy.filters.network.rbac",
    "envoy.rbac.matchers.upstream_ip_port",
]

NO_HTTP3_SKIP_TARGETS = [
    "envoy.quic.crypto_stream.server.quiche",
    "envoy.quic.deterministic_connection_id_generator",
    "envoy.quic.crypto_stream.server.quiche",
    "envoy.quic.proof_source.filter_chain",
]

# Make all contents of an external repository accessible under a filegroup.  Used for external HTTP
# archives, e.g. cares.
def _build_all_content(exclude = []):
    return """filegroup(name = "all", srcs = glob(["**"], exclude={}), visibility = ["//visibility:public"])""".format(repr(exclude))

BUILD_ALL_CONTENT = _build_all_content()

REPOSITORY_LOCATIONS = load_repository_locations(REPOSITORY_LOCATIONS_SPEC)

# Use this macro to reference any HTTP archive from bazel/repository_locations.bzl.
def external_http_archive(name, **kwargs):
    envoy_http_archive(
        name,
        locations = REPOSITORY_LOCATIONS,
        **kwargs
    )

def _default_envoy_build_config_impl(ctx):
    ctx.file("WORKSPACE", "")
    ctx.file("BUILD.bazel", "")
    ctx.symlink(ctx.attr.config, "extensions_build_config.bzl")

_default_envoy_build_config = repository_rule(
    implementation = _default_envoy_build_config_impl,
    attrs = {
        "config": attr.label(default = "@envoy//source/extensions:extensions_build_config.bzl"),
    },
)

def _envoy_repo_impl(repository_ctx):
    """This provides information about the Envoy repository

    You can access the current project and api versions and the path to the repository in
    .bzl/BUILD files as follows:

    ```starlark
    load("@envoy_repo//:version.bzl", "VERSION", "API_VERSION")
    ```

    `*VERSION` can be used to derive version-specific rules and can be passed
    to the rules.

    The `VERSION`s and also the local `PATH` to the repo can be accessed in
    python libraries/binaries. By adding `@envoy_repo` to `deps` they become
    importable through the `envoy_repo` namespace.

    As the `PATH` is local to the machine, it is generally only useful for
    jobs that will run locally.

    This can be useful, for example, for bazel run jobs to run bazel queries that cannot be run
    within the constraints of a `genquery`, or that otherwise need access to the repository
    files.

    Project and repo data can be accessed in JSON format using `@envoy_repo//:project`, eg:

    ```starlark
    load("@aspect_bazel_lib//lib:jq.bzl", "jq")

    jq(
        name = "project_version",
        srcs = ["@envoy_repo//:data"],
        out = "version.txt",
        args = ["-r"],
        filter = ".version",
    )

    ```

    """
    repo_version_path = repository_ctx.path(repository_ctx.attr.envoy_version)
    api_version_path = repository_ctx.path(repository_ctx.attr.envoy_api_version)
    version = repository_ctx.read(repo_version_path).strip()
    api_version = repository_ctx.read(api_version_path).strip()
    repository_ctx.file("version.bzl", "VERSION = '%s'\nAPI_VERSION = '%s'" % (version, api_version))
    repository_ctx.file("path.bzl", "PATH = '%s'" % repo_version_path.dirname)
    repository_ctx.file("__init__.py", "PATH = '%s'\nVERSION = '%s'\nAPI_VERSION = '%s'" % (repo_version_path.dirname, version, api_version))
    repository_ctx.file("WORKSPACE", "")
    repository_ctx.file("BUILD", '''
load("@rules_python//python:defs.bzl", "py_library")
load("@envoy//tools/base:envoy_python.bzl", "envoy_entry_point")
load("//:path.bzl", "PATH")

py_library(
    name = "envoy_repo",
    srcs = ["__init__.py"],
    visibility = ["//visibility:public"],
)

envoy_entry_point(
    name = "get_project_json",
    pkg = "envoy.base.utils",
    script = "envoy.project_data",
    init_data = [":__init__.py"],
)

genrule(
    name = "project",
    outs = ["project.json"],
    cmd = """
    $(location :get_project_json) $$(dirname $(location @envoy//:VERSION.txt)) > $@
    """,
    tools = [
        ":get_project_json",
        "@envoy//:VERSION.txt",
        "@envoy//changelogs",
    ],
    visibility = ["//visibility:public"],
)

envoy_entry_point(
    name = "release",
    args = [
        "release",
        PATH,
        "--release-message-path=$(location @envoy//changelogs:summary)",
    ],
    data = ["@envoy//changelogs:summary"],
    pkg = "envoy.base.utils",
    script = "envoy.project",
    init_data = [":__init__.py"],
)

envoy_entry_point(
    name = "dev",
    args = [
        "dev",
        PATH,
    ],
    pkg = "envoy.base.utils",
    script = "envoy.project",
    init_data = [":__init__.py"],
)

envoy_entry_point(
    name = "sync",
    args = [
        "sync",
        PATH,
    ],
    pkg = "envoy.base.utils",
    script = "envoy.project",
    init_data = [":__init__.py"],
)

envoy_entry_point(
    name = "publish",
    args = [
        "publish",
        PATH,
    ],
    pkg = "envoy.base.utils",
    script = "envoy.project",
    init_data = [":__init__.py"],
)

envoy_entry_point(
    name = "trigger",
    args = [
        "trigger",
        PATH,
    ],
    pkg = "envoy.base.utils",
    script = "envoy.project",
    init_data = [":__init__.py"],
)

''')

_envoy_repo = repository_rule(
    implementation = _envoy_repo_impl,
    attrs = {
        "envoy_version": attr.label(default = "@envoy//:VERSION.txt"),
        "envoy_api_version": attr.label(default = "@envoy//:API_VERSION.txt"),
    },
)

def envoy_repo():
    if "envoy_repo" not in native.existing_rules().keys():
        _envoy_repo(name = "envoy_repo")

# Bazel native C++ dependencies. For the dependencies that doesn't provide autoconf/automake builds.
def _cc_deps():
    external_http_archive("grpc_httpjson_transcoding")
    external_http_archive("com_google_protoconverter")
    external_http_archive("com_google_protofieldextraction")
    external_http_archive("ocp")
    native.bind(
        name = "path_matcher",
        actual = "@grpc_httpjson_transcoding//src:path_matcher",
    )
    native.bind(
        name = "grpc_transcoding",
        actual = "@grpc_httpjson_transcoding//src:transcoding",
    )

def _go_deps(skip_targets):
    # Keep the skip_targets check around until Istio Proxy has stopped using
    # it to exclude the Go rules.
    if "io_bazel_rules_go" not in skip_targets:
        external_http_archive(
            name = "io_bazel_rules_go",
            # TODO(wrowe, sunjayBhatia): remove when Windows RBE supports batch file invocation
            patch_args = ["-p1"],
            patches = ["@envoy//bazel:rules_go.patch"],
        )
        external_http_archive("bazel_gazelle")

def _rust_deps():
    external_http_archive(
        "rules_rust",
        patches = ["@envoy//bazel:rules_rust.patch"],
    )

def envoy_dependencies(skip_targets = []):
    # Add a binding for repository variables.
    envoy_repo()

    # Setup Envoy developer tools.
    envoy_dev_binding()

    # Treat Envoy's overall build config as an external repo, so projects that
    # build Envoy as a subcomponent can easily override the config.
    if "envoy_build_config" not in native.existing_rules().keys():
        _default_envoy_build_config(name = "envoy_build_config")

    # Setup external Bazel rules
    _foreign_cc_dependencies()

    # Binding to an alias pointing to the selected version of BoringSSL:
    # - BoringSSL FIPS from @boringssl_fips//:ssl,
    # - non-FIPS BoringSSL from @boringssl//:ssl.
    _boringssl()
    _boringssl_fips()
    native.bind(
        name = "ssl",
        actual = "@envoy//bazel:boringssl",
    )
    native.bind(
        name = "crypto",
        actual = "@envoy//bazel:boringcrypto",
    )

    # The long repo names (`com_github_fmtlib_fmt` instead of `fmtlib`) are
    # semi-standard in the Bazel community, intended to avoid both duplicate
    # dependencies and name conflicts.
    _com_github_axboe_liburing()
    _com_github_bazel_buildtools()
    _com_github_c_ares_c_ares()
    _com_github_openhistogram_libcircllhist()
    _com_github_cyan4973_xxhash()
    _com_github_datadog_dd_trace_cpp()
    _com_github_mirror_tclap()
    _com_github_envoyproxy_sqlparser()
    _com_github_fmtlib_fmt()
    _com_github_gabime_spdlog()
    _com_github_google_benchmark()
    _com_github_google_jwt_verify()
    _com_github_google_libprotobuf_mutator()
    _com_github_google_libsxg()
    _com_github_google_tcmalloc()
    _com_github_gperftools_gperftools()
    _com_github_grpc_grpc()
    _com_github_rules_proto_grpc()
    _com_github_unicode_org_icu()
    _com_github_intel_ipp_crypto_crypto_mb()
    _com_github_intel_ipp_crypto_crypto_mb_fips()
    _com_github_intel_qatlib()
    _com_github_intel_qatzip()
    _com_github_lz4_lz4()
    _com_github_jbeder_yaml_cpp()
    _com_github_libevent_libevent()
    _com_github_luajit_luajit()
    _com_github_nghttp2_nghttp2()
    _com_github_skyapm_cpp2sky()
    _com_github_nodejs_http_parser()
    _com_github_alibaba_hessian2_codec()
    _com_github_tencent_rapidjson()
    _com_github_nlohmann_json()
    _com_github_ncopa_suexec()
    _com_google_absl()
    _com_google_googletest()
    _com_google_protobuf()
    _io_opencensus_cpp()
    _com_github_curl()
    _com_github_envoyproxy_sqlparser()
    _v8()
    _com_googlesource_chromium_base_trace_event_common()
    _com_github_google_quiche()
    _com_googlesource_googleurl()
    _io_hyperscan()
    _io_vectorscan()
    _io_opentracing_cpp()
    _net_colm_open_source_colm()
    _net_colm_open_source_ragel()
    _net_zlib()
    _intel_dlb()
    _com_github_zlib_ng_zlib_ng()
    _org_boost()
    _org_brotli()
    _com_github_facebook_zstd()
    _re2()
    _upb()
    _proxy_wasm_cpp_sdk()
    _proxy_wasm_cpp_host()
    _emsdk()
    _rules_fuzzing()
    external_http_archive("proxy_wasm_rust_sdk")
    _com_google_cel_cpp()
    _com_github_google_perfetto()
    _utf8_range()
    _rules_ruby()
    external_http_archive("com_github_google_flatbuffers")
    external_http_archive("bazel_toolchains")
    external_http_archive("bazel_compdb")
    external_http_archive("envoy_build_tools")
    _com_github_maxmind_libmaxminddb()

    # TODO(keith): Remove patch when we update rules_pkg
    external_http_archive(
        "rules_pkg",
        patches = ["@envoy//bazel:rules_pkg.patch"],
    )
    external_http_archive("com_github_aignas_rules_shellcheck")
    external_http_archive(
        "aspect_bazel_lib",
        patch_args = ["-p1"],
        patches = ["@envoy//bazel:aspect.patch"],
    )

    _com_github_fdio_vpp_vcl()

    # Unconditional, since we use this only for compiler-agnostic fuzzing utils.
    _org_llvm_releases_compiler_rt()

    _cc_deps()
    _go_deps(skip_targets)
    _rust_deps()
    _kafka_deps()

    _org_llvm_llvm()
    _com_github_wamr()
    _com_github_wavm_wavm()
    _com_github_wasmtime()
    _com_github_wasm_c_api()

    switched_rules_by_language(
        name = "com_google_googleapis_imports",
        cc = True,
        go = True,
        python = True,
        grpc = True,
    )
    native.bind(
        name = "bazel_runfiles",
        actual = "@bazel_tools//tools/cpp/runfiles",
    )

def _boringssl():
    external_http_archive(
        name = "boringssl",
        patch_args = ["-p1"],
        patches = [
            "@envoy//bazel:boringssl_static.patch",
        ],
    )

def _boringssl_fips():
    external_http_archive(
        name = "boringssl_fips",
        build_file = "@envoy//bazel/external:boringssl_fips.BUILD",
    )

def _com_github_openhistogram_libcircllhist():
    external_http_archive(
        name = "com_github_openhistogram_libcircllhist",
        build_file = "@envoy//bazel/external:libcircllhist.BUILD",
    )
    native.bind(
        name = "libcircllhist",
        actual = "@com_github_openhistogram_libcircllhist//:libcircllhist",
    )

def _com_github_axboe_liburing():
    external_http_archive(
        name = "com_github_axboe_liburing",
        build_file_content = BUILD_ALL_CONTENT,
    )
    native.bind(
        name = "uring",
        actual = "@envoy//bazel/foreign_cc:liburing_linux",
    )

def _com_github_bazel_buildtools():
    # TODO(phlax): Add binary download
    #  cf: https://github.com/bazelbuild/buildtools/issues/367
    external_http_archive(
        name = "com_github_bazelbuild_buildtools",
    )

def _com_github_c_ares_c_ares():
    external_http_archive(
        name = "com_github_c_ares_c_ares",
        build_file_content = BUILD_ALL_CONTENT,
    )
    native.bind(
        name = "ares",
        actual = "@envoy//bazel/foreign_cc:ares",
    )

def _com_github_cyan4973_xxhash():
    external_http_archive(
        name = "com_github_cyan4973_xxhash",
        build_file = "@envoy//bazel/external:xxhash.BUILD",
    )
    native.bind(
        name = "xxhash",
        actual = "@com_github_cyan4973_xxhash//:xxhash",
    )

def _com_github_envoyproxy_sqlparser():
    external_http_archive(
        name = "com_github_envoyproxy_sqlparser",
        build_file = "@envoy//bazel/external:sqlparser.BUILD",
    )
    native.bind(
        name = "sqlparser",
        actual = "@com_github_envoyproxy_sqlparser//:sqlparser",
    )

def _com_github_mirror_tclap():
    external_http_archive(
        name = "com_github_mirror_tclap",
        build_file = "@envoy//bazel/external:tclap.BUILD",
        patch_args = ["-p1"],
    )
    native.bind(
        name = "tclap",
        actual = "@com_github_mirror_tclap//:tclap",
    )

def _com_github_fmtlib_fmt():
    external_http_archive(
        name = "com_github_fmtlib_fmt",
        build_file = "@envoy//bazel/external:fmtlib.BUILD",
    )
    native.bind(
        name = "fmtlib",
        actual = "@com_github_fmtlib_fmt//:fmtlib",
    )

def _com_github_gabime_spdlog():
    external_http_archive(
        name = "com_github_gabime_spdlog",
        build_file = "@envoy//bazel/external:spdlog.BUILD",
    )
    native.bind(
        name = "spdlog",
        actual = "@com_github_gabime_spdlog//:spdlog",
    )

def _com_github_google_benchmark():
    external_http_archive(
        name = "com_github_google_benchmark",
    )
    external_http_archive(
        name = "libpfm",
        build_file = "@com_github_google_benchmark//tools:libpfm.BUILD.bazel",
    )
    native.bind(
        name = "benchmark",
        actual = "@com_github_google_benchmark//:benchmark",
    )

def _com_github_google_libprotobuf_mutator():
    external_http_archive(
        name = "com_github_google_libprotobuf_mutator",
        build_file = "@envoy//bazel/external:libprotobuf_mutator.BUILD",
    )

def _com_github_google_libsxg():
    external_http_archive(
        name = "com_github_google_libsxg",
        build_file_content = BUILD_ALL_CONTENT,
    )

    native.bind(
        name = "libsxg",
        actual = "@envoy//bazel/foreign_cc:libsxg",
    )

def _com_github_unicode_org_icu():
    external_http_archive(
        name = "com_github_unicode_org_icu",
        patches = ["@envoy//bazel/foreign_cc:icu.patch"],
        patch_args = ["-p1"],
        build_file_content = BUILD_ALL_CONTENT,
    )

def _com_github_intel_ipp_crypto_crypto_mb():
    external_http_archive(
        name = "com_github_intel_ipp_crypto_crypto_mb",
        # Patch removes from CMakeLists.txt instructions to
        # to create dynamic *.so library target. Linker fails when linking
        # with boringssl_fips library. Envoy uses only static library
        # anyways, so created dynamic library would not be used anyways.
        patches = [
            "@envoy//bazel/foreign_cc:ipp-crypto-skip-dynamic-lib.patch",
            "@envoy//bazel/foreign_cc:ipp-crypto-bn2lebinpad.patch",
        ],
        patch_args = ["-p1"],
        build_file_content = BUILD_ALL_CONTENT,
    )

def _com_github_intel_ipp_crypto_crypto_mb_fips():
    # Temporary fix for building ipp-crypto when boringssl-fips is used.
    # Build will fail if bn2lebinpad patch is applied. Remove this archive
    # when upstream dependency fixes this issue.
    external_http_archive(
        name = "com_github_intel_ipp_crypto_crypto_mb_fips",
        # Patch removes from CMakeLists.txt instructions to
        # to create dynamic *.so library target. Linker fails when linking
        # with boringssl_fips library. Envoy uses only static library
        # anyways, so created dynamic library would not be used anyways.
        patches = ["@envoy//bazel/foreign_cc:ipp-crypto-skip-dynamic-lib.patch"],
        patch_args = ["-p1"],
        build_file_content = BUILD_ALL_CONTENT,
        # Use existing ipp-crypto repository location name to avoid redefinition.
        location_name = "com_github_intel_ipp_crypto_crypto_mb",
    )

def _com_github_intel_qatlib():
    external_http_archive(
        name = "com_github_intel_qatlib",
        build_file_content = BUILD_ALL_CONTENT,
    )

def _com_github_intel_qatzip():
    external_http_archive(
        name = "com_github_intel_qatzip",
        build_file_content = BUILD_ALL_CONTENT,
    )

def _com_github_lz4_lz4():
    external_http_archive(
        name = "com_github_lz4_lz4",
        build_file_content = BUILD_ALL_CONTENT,
    )

def _com_github_jbeder_yaml_cpp():
    external_http_archive(
        name = "com_github_jbeder_yaml_cpp",
    )
    native.bind(
        name = "yaml_cpp",
        actual = "@com_github_jbeder_yaml_cpp//:yaml-cpp",
    )

def _com_github_libevent_libevent():
    external_http_archive(
        name = "com_github_libevent_libevent",
        build_file_content = BUILD_ALL_CONTENT,
    )
    native.bind(
        name = "event",
        actual = "@envoy//bazel/foreign_cc:event",
    )

def _net_colm_open_source_colm():
    external_http_archive(
        name = "net_colm_open_source_colm",
        build_file_content = BUILD_ALL_CONTENT,
    )
    native.bind(
        name = "colm",
        actual = "@envoy//bazel/foreign_cc:colm",
    )

def _net_colm_open_source_ragel():
    external_http_archive(
        name = "net_colm_open_source_ragel",
        build_file_content = BUILD_ALL_CONTENT,
    )
    native.bind(
        name = "ragel",
        actual = "@envoy//bazel/foreign_cc:ragel",
    )

def _net_zlib():
    external_http_archive(
        name = "net_zlib",
        build_file_content = BUILD_ALL_CONTENT,
        patch_args = ["-p1"],
        patches = ["@envoy//bazel/foreign_cc:zlib.patch"],
    )

    native.bind(
        name = "zlib",
        actual = "@envoy//bazel/foreign_cc:zlib",
    )

    # Bind for grpc.
    native.bind(
        name = "madler_zlib",
        actual = "@envoy//bazel/foreign_cc:zlib",
    )

def _com_github_zlib_ng_zlib_ng():
    external_http_archive(
        name = "com_github_zlib_ng_zlib_ng",
        build_file_content = BUILD_ALL_CONTENT,
        patch_args = ["-p1"],
        patches = ["@envoy//bazel/foreign_cc:zlib_ng.patch"],
    )

# Boost in general is not approved for Envoy use, and the header-only
# dependency is only for the Hyperscan contrib package.
def _org_boost():
    external_http_archive(
        name = "org_boost",
        build_file_content = """
filegroup(
    name = "header",
    srcs = glob([
        "boost/**/*.h",
        "boost/**/*.hpp",
        "boost/**/*.ipp",
    ]),
    visibility = ["@envoy//contrib/hyperscan/matching/input_matchers/source:__pkg__"],
)
""",
    )

# If you're looking for envoy-filter-example / envoy_filter_example
# the hash is in ci/filter_example_setup.sh

def _org_brotli():
    external_http_archive(
        name = "org_brotli",
    )
    native.bind(
        name = "brotlienc",
        actual = "@org_brotli//:brotlienc",
    )
    native.bind(
        name = "brotlidec",
        actual = "@org_brotli//:brotlidec",
    )

def _com_github_facebook_zstd():
    external_http_archive(
        name = "com_github_facebook_zstd",
        build_file_content = BUILD_ALL_CONTENT,
    )

    native.bind(
        name = "zstd",
        actual = "@envoy//bazel/foreign_cc:zstd",
    )

def _com_google_cel_cpp():
    external_http_archive(
        "com_google_cel_cpp",
        patches = ["@envoy//bazel:cel-cpp.patch"],
        patch_args = ["-p1"],
    )

def _com_github_google_perfetto():
    external_http_archive(
        name = "com_github_google_perfetto",
        build_file_content = """
package(default_visibility = ["//visibility:public"])
cc_library(
    name = "perfetto",
    srcs = ["perfetto.cc"],
    hdrs = ["perfetto.h"],
)
""",
    )

def _com_github_nghttp2_nghttp2():
    external_http_archive(
        name = "com_github_nghttp2_nghttp2",
        build_file_content = BUILD_ALL_CONTENT,
        patch_args = ["-p1"],
        # This patch cannot be picked up due to ABI rules. Discussion at;
        # https://github.com/nghttp2/nghttp2/pull/1395
        # https://github.com/envoyproxy/envoy/pull/8572#discussion_r334067786
        patches = ["@envoy//bazel/foreign_cc:nghttp2.patch"],
    )
    native.bind(
        name = "nghttp2",
        actual = "@envoy//bazel/foreign_cc:nghttp2",
    )

def _io_hyperscan():
    external_http_archive(
        name = "io_hyperscan",
        build_file_content = BUILD_ALL_CONTENT,
        patch_args = ["-p1"],
        patches = ["@envoy//bazel/foreign_cc:hyperscan.patch"],
    )

def _io_vectorscan():
    external_http_archive(
        name = "io_vectorscan",
        build_file_content = BUILD_ALL_CONTENT,
        type = "tar.gz",
        patch_args = ["-p1"],
        patches = ["@envoy//bazel/foreign_cc:vectorscan.patch"],
    )

def _io_opentracing_cpp():
    external_http_archive(
        name = "io_opentracing_cpp",
        patch_args = ["-p1"],
        # Workaround for LSAN false positive in https://github.com/envoyproxy/envoy/issues/7647
        patches = ["@envoy//bazel:io_opentracing_cpp.patch"],
    )
    native.bind(
        name = "opentracing",
        actual = "@io_opentracing_cpp//:opentracing",
    )

def _com_github_datadog_dd_trace_cpp():
    external_http_archive("com_github_datadog_dd_trace_cpp")
    native.bind(
        name = "dd_trace_cpp",
        actual = "@com_github_datadog_dd_trace_cpp//:dd_trace_cpp",
    )

def _com_github_skyapm_cpp2sky():
    external_http_archive(
        name = "com_github_skyapm_cpp2sky",
    )
    external_http_archive(
        name = "skywalking_data_collect_protocol",
    )
    native.bind(
        name = "cpp2sky",
        actual = "@com_github_skyapm_cpp2sky//source:cpp2sky_data_lib",
    )

def _com_github_tencent_rapidjson():
    external_http_archive(
        name = "com_github_tencent_rapidjson",
        build_file = "@envoy//bazel/external:rapidjson.BUILD",
    )

def _com_github_nlohmann_json():
    external_http_archive(
        name = "com_github_nlohmann_json",
        build_file = "@envoy//bazel/external:json.BUILD",
    )
    native.bind(
        name = "json",
        actual = "@com_github_nlohmann_json//:json",
    )

def _com_github_nodejs_http_parser():
    native.bind(
        name = "http_parser",
        actual = "@envoy//bazel/external/http_parser",
    )

def _com_github_alibaba_hessian2_codec():
    external_http_archive("com_github_alibaba_hessian2_codec")
    native.bind(
        name = "hessian2_codec_object_codec_lib",
        actual = "@com_github_alibaba_hessian2_codec//hessian2/basic_codec:object_codec_lib",
    )
    native.bind(
        name = "hessian2_codec_codec_impl",
        actual = "@com_github_alibaba_hessian2_codec//hessian2:codec_impl_lib",
    )

def _com_github_ncopa_suexec():
    external_http_archive(
        name = "com_github_ncopa_suexec",
        build_file = "@envoy//bazel/external:su-exec.BUILD",
    )
    native.bind(
        name = "su-exec",
        actual = "@com_github_ncopa_suexec//:su-exec",
    )

def _com_google_googletest():
    external_http_archive(
        "com_google_googletest",
        patches = ["@envoy//bazel:googletest.patch"],
        patch_args = ["-p1"],
    )
    native.bind(
        name = "googletest",
        actual = "@com_google_googletest//:gtest",
    )

# TODO(jmarantz): replace the use of bind and external_deps with just
# the direct Bazel path at all sites.  This will make it easier to
# pull in more bits of abseil as needed, and is now the preferred
# method for pure Bazel deps.
def _com_google_absl():
    external_http_archive(
        name = "com_google_absl",
        patches = ["@envoy//bazel:abseil.patch"],
        patch_args = ["-p1"],
    )
    native.bind(
        name = "abseil_any",
        actual = "@com_google_absl//absl/types:any",
    )
    native.bind(
        name = "abseil_base",
        actual = "@com_google_absl//absl/base:base",
    )

    # Bind for grpc.
    native.bind(
        name = "absl-base",
        actual = "@com_google_absl//absl/base",
    )
    native.bind(
        name = "abseil_btree",
        actual = "@com_google_absl//absl/container:btree",
    )
    native.bind(
        name = "abseil_flat_hash_map",
        actual = "@com_google_absl//absl/container:flat_hash_map",
    )
    native.bind(
        name = "abseil_flat_hash_set",
        actual = "@com_google_absl//absl/container:flat_hash_set",
    )
    native.bind(
        name = "abseil_hash",
        actual = "@com_google_absl//absl/hash:hash",
    )
    native.bind(
        name = "abseil_hash_testing",
        actual = "@com_google_absl//absl/hash:hash_testing",
    )
    native.bind(
        name = "abseil_inlined_vector",
        actual = "@com_google_absl//absl/container:inlined_vector",
    )
    native.bind(
        name = "abseil_memory",
        actual = "@com_google_absl//absl/memory:memory",
    )
    native.bind(
        name = "abseil_node_hash_map",
        actual = "@com_google_absl//absl/container:node_hash_map",
    )
    native.bind(
        name = "abseil_node_hash_set",
        actual = "@com_google_absl//absl/container:node_hash_set",
    )
    native.bind(
        name = "abseil_str_format",
        actual = "@com_google_absl//absl/strings:str_format",
    )
    native.bind(
        name = "abseil_strings",
        actual = "@com_google_absl//absl/strings:strings",
    )
    native.bind(
        name = "abseil_int128",
        actual = "@com_google_absl//absl/numeric:int128",
    )
    native.bind(
        name = "abseil_optional",
        actual = "@com_google_absl//absl/types:optional",
    )
    native.bind(
        name = "abseil_synchronization",
        actual = "@com_google_absl//absl/synchronization:synchronization",
    )
    native.bind(
        name = "abseil_symbolize",
        actual = "@com_google_absl//absl/debugging:symbolize",
    )
    native.bind(
        name = "abseil_stacktrace",
        actual = "@com_google_absl//absl/debugging:stacktrace",
    )
    native.bind(
        name = "abseil_statusor",
        actual = "@com_google_absl//absl/status:statusor",
    )

    # Require abseil_time as an indirect dependency as it is needed by the
    # direct dependency jwt_verify_lib.
    native.bind(
        name = "abseil_time",
        actual = "@com_google_absl//absl/time:time",
    )

    # Bind for grpc.
    native.bind(
        name = "absl-time",
        actual = "@com_google_absl//absl/time:time",
    )

    native.bind(
        name = "abseil_algorithm",
        actual = "@com_google_absl//absl/algorithm:algorithm",
    )
    native.bind(
        name = "abseil_variant",
        actual = "@com_google_absl//absl/types:variant",
    )
    native.bind(
        name = "abseil_status",
        actual = "@com_google_absl//absl/status",
    )
    native.bind(
        name = "abseil_cleanup",
        actual = "@com_google_absl//absl/cleanup:cleanup",
    )

def _com_google_protobuf():
    external_http_archive(
        name = "rules_python",
    )

    for platform in PROTOC_VERSIONS:
        # Ideally we dont use a private build artefact as done here.
        # If `rules_proto` implements protoc toolchains in the future (currently it
        # is there, but is empty) we should remove these and use that rule
        # instead.
        external_http_archive(
            "com_google_protobuf_protoc_%s" % platform,
            build_file = "@rules_proto//proto/private:BUILD.protoc",
        )

    external_http_archive(
        "com_google_protobuf",
        patches = ["@envoy//bazel:protobuf.patch"],
        patch_args = ["-p1"],
    )

    native.bind(
        name = "protobuf",
        actual = "@com_google_protobuf//:protobuf",
    )
    native.bind(
        name = "protobuf_clib",
        actual = "@com_google_protobuf//:protoc_lib",
    )
    native.bind(
        name = "protocol_compiler",
        actual = "@com_google_protobuf//:protoc",
    )
    native.bind(
        name = "protoc",
        actual = "@com_google_protobuf//:protoc",
    )

    # Needed for `bazel fetch` to work with @com_google_protobuf
    # https://github.com/google/protobuf/blob/v3.6.1/util/python/BUILD#L6-L9
    native.bind(
        name = "python_headers",
        actual = "//bazel:python_headers",
    )

def _io_opencensus_cpp():
    external_http_archive(
        name = "io_opencensus_cpp",
    )
    native.bind(
        name = "opencensus_trace",
        actual = "@io_opencensus_cpp//opencensus/trace",
    )
    native.bind(
        name = "opencensus_trace_b3",
        actual = "@io_opencensus_cpp//opencensus/trace:b3",
    )
    native.bind(
        name = "opencensus_trace_cloud_trace_context",
        actual = "@io_opencensus_cpp//opencensus/trace:cloud_trace_context",
    )
    native.bind(
        name = "opencensus_trace_grpc_trace_bin",
        actual = "@io_opencensus_cpp//opencensus/trace:grpc_trace_bin",
    )
    native.bind(
        name = "opencensus_trace_trace_context",
        actual = "@io_opencensus_cpp//opencensus/trace:trace_context",
    )
    native.bind(
        name = "opencensus_exporter_ocagent",
        actual = "@io_opencensus_cpp//opencensus/exporters/trace/ocagent:ocagent_exporter",
    )
    native.bind(
        name = "opencensus_exporter_stdout",
        actual = "@io_opencensus_cpp//opencensus/exporters/trace/stdout:stdout_exporter",
    )
    native.bind(
        name = "opencensus_exporter_stackdriver",
        actual = "@io_opencensus_cpp//opencensus/exporters/trace/stackdriver:stackdriver_exporter",
    )
    native.bind(
        name = "opencensus_exporter_zipkin",
        actual = "@io_opencensus_cpp//opencensus/exporters/trace/zipkin:zipkin_exporter",
    )

def _com_github_curl():
    # The usage by AWS extensions common utilities is deprecated and will be removed by Q3 2024 after
    # the deprecation period of 2 releases. Please DO NOT USE curl dependency for any new or existing extensions.
    # See https://github.com/envoyproxy/envoy/issues/11816 & https://github.com/envoyproxy/envoy/pull/30731.
    external_http_archive(
        name = "com_github_curl",
        build_file_content = BUILD_ALL_CONTENT + """
cc_library(name = "curl", visibility = ["//visibility:public"], deps = ["@envoy//bazel/foreign_cc:curl"])
""",
        # Patch curl 7.74.0 and later due to CMake's problematic implementation of policy `CMP0091`
        # and introduction of libidn2 dependency which is inconsistently available and must
        # not be a dynamic dependency on linux.
        # Upstream patches submitted: https://github.com/curl/curl/pull/6050 & 6362
        # TODO(https://github.com/envoyproxy/envoy/issues/11816): This patch is obsoleted
        # by elimination of the curl dependency.
        patches = ["@envoy//bazel/foreign_cc:curl.patch"],
        patch_args = ["-p1"],
    )
    native.bind(
        name = "curl",
        actual = "@envoy//bazel/foreign_cc:curl",
    )

def _v8():
    external_http_archive(
        name = "v8",
        patches = [
            "@envoy//bazel:v8.patch",
            "@envoy//bazel:v8_include.patch",
        ],
        patch_args = ["-p1"],
    )
    native.bind(
        name = "wee8",
        actual = "@v8//:wee8",
    )

def _com_googlesource_chromium_base_trace_event_common():
    external_http_archive(
        name = "com_googlesource_chromium_base_trace_event_common",
        build_file = "@v8//:bazel/BUILD.trace_event_common",
    )
    native.bind(
        name = "base_trace_event_common",
        actual = "@com_googlesource_chromium_base_trace_event_common//:trace_event_common",
    )

def _com_github_google_quiche():
    external_http_archive(
        name = "com_github_google_quiche",
        patch_cmds = ["find quiche/ -type f -name \"*.bazel\" -delete"],
        build_file = "@envoy//bazel/external:quiche.BUILD",
    )
    native.bind(
        name = "quiche_common_platform",
        actual = "@com_github_google_quiche//:quiche_common_platform",
    )
    native.bind(
        name = "quiche_http2_adapter",
        actual = "@com_github_google_quiche//:http2_adapter",
    )
    native.bind(
        name = "quiche_http2_protocol",
        actual = "@com_github_google_quiche//:http2_adapter_http2_protocol",
    )
    native.bind(
        name = "quiche_http2_test_tools",
        actual = "@com_github_google_quiche//:http2_adapter_mock_http2_visitor",
    )
    native.bind(
        name = "quiche_quic_platform",
        actual = "@com_github_google_quiche//:quic_platform",
    )
    native.bind(
        name = "quiche_quic_platform_base",
        actual = "@com_github_google_quiche//:quic_platform_base",
    )
    native.bind(
        name = "quiche_spdy_hpack",
        actual = "@com_github_google_quiche//:spdy_core_hpack_hpack_lib",
    )
    native.bind(
        name = "quiche_http2_hpack_decoder",
        actual = "@com_github_google_quiche//:http2_hpack_decoder_hpack_decoder_lib",
    )

def _com_googlesource_googleurl():
    external_http_archive(
        name = "com_googlesource_googleurl",
        patches = ["@envoy//bazel/external:googleurl.patch"],
        patch_args = ["-p1"],
    )

def _org_llvm_releases_compiler_rt():
    external_http_archive(
        name = "org_llvm_releases_compiler_rt",
        build_file = "@envoy//bazel/external:compiler_rt.BUILD",
    )

def _com_github_grpc_grpc():
    external_http_archive(
        name = "com_github_grpc_grpc",
        patch_args = ["-p1"],
        patches = ["@envoy//bazel:grpc.patch"],
    )
    external_http_archive("build_bazel_rules_apple")

    # Rebind some stuff to match what the gRPC Bazel is expecting.
    native.bind(
        name = "protobuf_headers",
        actual = "@com_google_protobuf//:protobuf_headers",
    )
    native.bind(
        name = "libssl",
        actual = "//external:ssl",
    )
    native.bind(
        name = "libcrypto",
        actual = "//external:crypto",
    )
    native.bind(
        name = "cares",
        actual = "//external:ares",
    )

    native.bind(
        name = "grpc",
        actual = "@com_github_grpc_grpc//:grpc++",
    )

    native.bind(
        name = "grpc_health_proto",
        actual = "@envoy//bazel:grpc_health_proto",
    )

    native.bind(
        name = "grpc_alts_fake_handshaker_server",
        actual = "@com_github_grpc_grpc//test/core/tsi/alts/fake_handshaker:fake_handshaker_lib",
    )

    native.bind(
        name = "grpc_alts_handshaker_proto",
        actual = "@com_github_grpc_grpc//test/core/tsi/alts/fake_handshaker:handshaker_proto",
    )

    native.bind(
        name = "grpc_alts_transport_security_common_proto",
        actual = "@com_github_grpc_grpc//test/core/tsi/alts/fake_handshaker:transport_security_common_proto",
    )

    native.bind(
        name = "upb_collections_lib",
        actual = "@upb//:collections",
    )

    native.bind(
        name = "upb_lib_descriptor",
        actual = "@upb//:descriptor_upb_proto",
    )

    native.bind(
        name = "upb_lib_descriptor_reflection",
        actual = "@upb//:descriptor_upb_proto_reflection",
    )

    native.bind(
        name = "upb_textformat_lib",
        actual = "@upb//:textformat",
    )

    native.bind(
        name = "upb_json_lib",
        actual = "@upb//:json",
    )

    native.bind(
        name = "upb_reflection",
        actual = "@upb//:reflection",
    )

    native.bind(
        name = "upb_generated_code_support__only_for_generated_code_do_not_use__i_give_permission_to_break_me",
        actual = "@upb//:generated_code_support__only_for_generated_code_do_not_use__i_give_permission_to_break_me",
    )

def _com_github_rules_proto_grpc():
    external_http_archive("com_github_rules_proto_grpc")

def _re2():
    external_http_archive("com_googlesource_code_re2")

    native.bind(
        name = "re2",
        actual = "@com_googlesource_code_re2//:re2",
    )

def _upb():
    external_http_archive(
        name = "upb",
        patch_args = ["-p1"],
        patches = ["@envoy//bazel:upb.patch"],
    )

    native.bind(
        name = "upb_lib",
        actual = "@upb//:upb",
    )

def _proxy_wasm_cpp_sdk():
    external_http_archive(name = "proxy_wasm_cpp_sdk")

def _proxy_wasm_cpp_host():
    external_http_archive(
        name = "proxy_wasm_cpp_host",
        patch_args = ["-p1"],
        patches = [
            "@envoy//bazel:proxy_wasm_cpp_host.patch",
        ],
    )

def _emsdk():
    external_http_archive(
        name = "emsdk",
        patch_args = ["-p2"],
        patches = ["@envoy//bazel:emsdk.patch"],
    )

def _com_github_google_jwt_verify():
    external_http_archive("com_github_google_jwt_verify")

    native.bind(
        name = "jwt_verify_lib",
        actual = "@com_github_google_jwt_verify//:jwt_verify_lib",
    )

    native.bind(
        name = "simple_lru_cache_lib",
        actual = "@com_github_google_jwt_verify//:simple_lru_cache_lib",
    )

def _com_github_luajit_luajit():
    external_http_archive(
        name = "com_github_luajit_luajit",
        build_file_content = BUILD_ALL_CONTENT,
        patches = ["@envoy//bazel/foreign_cc:luajit.patch"],
        patch_args = ["-p1"],
        patch_cmds = ["chmod u+x build.py"],
    )

    native.bind(
        name = "luajit",
        actual = "@envoy//bazel/foreign_cc:luajit",
    )

def _com_github_google_tcmalloc():
    external_http_archive(
        name = "com_github_google_tcmalloc",
    )

    native.bind(
        name = "tcmalloc",
        actual = "@com_github_google_tcmalloc//tcmalloc",
    )
    native.bind(
        name = "tcmalloc_profile_marshaler",
        actual = "@com_github_google_tcmalloc//tcmalloc:profile_marshaler",
    )
    native.bind(
        name = "tcmalloc_malloc_extension",
        actual = "@com_github_google_tcmalloc//tcmalloc:malloc_extension",
    )

def _com_github_gperftools_gperftools():
    external_http_archive(
        name = "com_github_gperftools_gperftools",
        build_file_content = BUILD_ALL_CONTENT,
    )
    native.bind(
        name = "gperftools",
        actual = "@envoy//bazel/foreign_cc:gperftools",
    )

def _org_llvm_llvm():
    external_http_archive(
        name = "org_llvm_llvm",
        build_file_content = BUILD_ALL_CONTENT,
        patch_args = ["-p1"],
        patches = ["@envoy//bazel/foreign_cc:llvm.patch"],
    )
    native.bind(
        name = "llvm",
        actual = "@envoy//bazel/foreign_cc:llvm",
    )

def _com_github_wamr():
    external_http_archive(
        name = "com_github_wamr",
        build_file_content = BUILD_ALL_CONTENT,
    )
    native.bind(
        name = "wamr",
        actual = "@envoy//bazel/foreign_cc:wamr",
    )

def _com_github_wavm_wavm():
    external_http_archive(
        name = "com_github_wavm_wavm",
        build_file_content = BUILD_ALL_CONTENT,
    )
    native.bind(
        name = "wavm",
        actual = "@envoy//bazel/foreign_cc:wavm",
    )

def _com_github_wasmtime():
    external_http_archive(
        name = "com_github_wasmtime",
        build_file = "@envoy//bazel/external:wasmtime.BUILD",
    )

def _com_github_wasm_c_api():
    external_http_archive(
        name = "com_github_wasm_c_api",
        build_file = "@envoy//bazel/external:wasm-c-api.BUILD",
    )
    native.bind(
        name = "wasmtime",
        actual = "@com_github_wasm_c_api//:wasmtime_lib",
    )

    # This isn't needed in builds with a single Wasm engine, but "bazel query"
    # complains about a missing dependency, so point it at the regular target.
    native.bind(
        name = "prefixed_wasmtime",
        actual = "@com_github_wasm_c_api//:wasmtime_lib",
    )

def _intel_dlb():
    external_http_archive(
        name = "intel_dlb",
        build_file_content = """
filegroup(
    name = "libdlb",
    srcs = glob([
        "dlb/libdlb/**",
    ]),
    visibility = ["@envoy//contrib/dlb/source:__pkg__"],
)
""",
    )

def _rules_fuzzing():
    external_http_archive(
        name = "rules_fuzzing",
        repo_mapping = {
            "@fuzzing_py_deps": "@fuzzing_pip3",
        },
        # TODO(asraa): Try this fix for OSS-Fuzz build failure on tar command.
        patch_args = ["-p1"],
        patches = ["@envoy//bazel:rules_fuzzing.patch"],
    )

def _kafka_deps():
    # This archive contains Kafka client source code.
    # We are using request/response message format files to generate parser code.
    KAFKASOURCE_BUILD_CONTENT = """
filegroup(
    name = "request_protocol_files",
    srcs = glob(["*Request.json"]),
    visibility = ["//visibility:public"],
)
filegroup(
    name = "response_protocol_files",
    srcs = glob(["*Response.json"]),
    visibility = ["//visibility:public"],
)
    """
    external_http_archive(
        name = "kafka_source",
        build_file_content = KAFKASOURCE_BUILD_CONTENT,
    )

    # This archive provides Kafka C/CPP client used by mesh filter to communicate with upstream
    # Kafka clusters.
    external_http_archive(
        name = "confluentinc_librdkafka",
        build_file_content = BUILD_ALL_CONTENT,
        # (adam.kotwasinski) librdkafka bundles in cJSON, which is also bundled in by libvppinfra.
        # For now, let's just drop this dependency from Kafka, as it's used only for monitoring.
        patches = ["@envoy//bazel/foreign_cc:librdkafka.patch"],
        patch_args = ["-p1"],
    )
    native.bind(
        name = "librdkafka",
        actual = "@envoy//bazel/foreign_cc:librdkafka",
    )

    # This archive provides Kafka (and Zookeeper) binaries, that are used during Kafka integration
    # tests.
    external_http_archive(
        name = "kafka_server_binary",
        build_file_content = BUILD_ALL_CONTENT,
    )

    # This archive provides Kafka client in Python, so we can use it to interact with Kafka server
    # during integration tests.
    external_http_archive(
        name = "kafka_python_client",
        build_file_content = BUILD_ALL_CONTENT,
    )

def _com_github_fdio_vpp_vcl():
    external_http_archive(
        name = "com_github_fdio_vpp_vcl",
        build_file_content = _build_all_content(exclude = ["**/*doc*/**", "**/examples/**", "**/plugins/**"]),
        patches = ["@envoy//bazel/foreign_cc:vpp_vcl.patch"],
    )

def _utf8_range():
    external_http_archive("utf8_range")

def _rules_ruby():
    external_http_archive("rules_ruby")

def _foreign_cc_dependencies():
    external_http_archive("rules_foreign_cc")

def _com_github_maxmind_libmaxminddb():
    external_http_archive(
        name = "com_github_maxmind_libmaxminddb",
        build_file_content = BUILD_ALL_CONTENT,
    )
    native.bind(
        name = "maxmind",
        actual = "@envoy//bazel/foreign_cc:maxmind_linux_darwin",
    )
#!/bin/bash -e

TEST_BINARY=$1
shift

# Clear existing corpus if previous run wasn't in sandbox
rm -rf fuzz_corpus

mkdir -p fuzz_corpus/seed_corpus
cp -r "$@" fuzz_corpus/seed_corpus

# TODO(asraa): When fuzz targets are stable, remove error suppression and run coverage while fuzzing.
LLVM_PROFILE_FILE='' ${TEST_BINARY} fuzz_corpus -seed="${FUZZ_CORPUS_SEED:-1}" -max_total_time="${FUZZ_CORPUS_TIME:-60}" -max_len=2048 -rss_limit_mb=8192 -timeout=30 || :

# Passing files instead of a directory will run fuzzing as a regression test.
# TODO(asraa): Remove manual `|| :`, but this shouldn't be necessary.
_CORPUS="$(find fuzz_corpus -type f)"
while read -r line; do CORPUS+=("$line"); done \
    <<< "$_CORPUS"
${TEST_BINARY} "${CORPUS[@]}" -rss_limit_mb=8192 || :
licenses(["notice"])  # Apache 2

exports_files(["fuzz_coverage_wrapper.sh"])
load("@rules_python//python:pip.bzl", "pip_parse")
load("@python3_11//:defs.bzl", "interpreter")
load("@envoy_toolshed//:packages.bzl", "load_packages")

def envoy_python_dependencies():
    # TODO(phlax): rename base_pip3 -> pip3 and remove this
    load_packages()
    pip_parse(
        name = "base_pip3",
        python_interpreter_target = interpreter,
        requirements_lock = "@envoy//tools/base:requirements.txt",
        extra_pip_args = ["--require-hashes"],
    )

    pip_parse(
        name = "dev_pip3",
        python_interpreter_target = interpreter,
        requirements_lock = "@envoy//tools/dev:requirements.txt",
        extra_pip_args = ["--require-hashes"],
    )

    pip_parse(
        name = "fuzzing_pip3",
        python_interpreter_target = interpreter,
        requirements_lock = "@rules_fuzzing//fuzzing:requirements.txt",
        extra_pip_args = ["--require-hashes"],
    )
diff --git a/BUILD.bazel b/BUILD.bazel
index 0f6e41e3a..c0d2bbccf 100644
--- a/BUILD.bazel
+++ b/BUILD.bazel
@@ -454,14 +454,79 @@ cc_library(
     visibility = ["//visibility:public"],
 )

+# Envoy: Patch
+
 cc_binary(
-    name = "protoc",
+    name = "compiled_protoc",
     copts = COPTS,
     linkopts = LINK_OPTS,
     visibility = ["//visibility:public"],
     deps = ["//src/google/protobuf/compiler:protoc_lib"],
 )

+# Lifted from `rules_proto`
+config_setting(
+    name = "linux-aarch_64",
+    constraint_values = [
+        "@platforms//os:linux",
+        "@platforms//cpu:aarch64",
+    ],
+)
+
+config_setting(
+    name = "linux-x86_64",
+    constraint_values = [
+        "@platforms//os:linux",
+        "@platforms//cpu:x86_64",
+    ],
+)
+
+config_setting(
+    name = "osx-aarch_64",
+    constraint_values = [
+        "@platforms//os:osx",
+        "@platforms//cpu:aarch64",
+    ],
+)
+
+config_setting(
+    name = "osx-x86_64",
+    constraint_values = [
+        "@platforms//os:osx",
+        "@platforms//cpu:x86_64",
+    ],
+)
+
+config_setting(
+    name = "win64",
+    constraint_values = [
+        "@platforms//os:windows",
+        "@platforms//cpu:x86_64",
+    ],
+)
+
+# Use precompiled binaries where possible.
+alias(
+    name = "protoc",
+    actual = select({
+        ":linux-aarch_64": "@com_google_protobuf_protoc_linux_aarch_64//:protoc",
+        ":linux-x86_64": "@com_google_protobuf_protoc_linux_x86_64//:protoc",
+        ":osx-aarch_64": "@com_google_protobuf_protoc_osx_aarch_64//:protoc",
+        ":osx-x86_64": "@com_google_protobuf_protoc_osx_x86_64//:protoc",
+        ":win64": "@com_google_protobuf_protoc_win64//:protoc",
+        "//conditions:default": ":compiled_protoc",
+    }),
+    visibility = ["//visibility:public"],
+)
+
+alias(
+    name = "protobuf_python_genproto",
+    actual = "//python:well_known_types_py_pb2_genproto",
+    visibility = ["//visibility:public"],
+)
+
+# /Envoy: Patch
+
 cc_binary(
     name = "protoc_static",
     copts = COPTS,
diff --git a/python/google/protobuf/__init__.py b/python/google/protobuf/__init__.py
index e7555ee10..a93beb1c5 100644
--- a/python/google/protobuf/__init__.py
+++ b/python/google/protobuf/__init__.py
@@ -31,3 +31,10 @@
 # Copyright 2007 Google Inc. All Rights Reserved.

 __version__ = '4.23.4'
+
+
+if __name__ != '__main__':
+    try:
+        __import__('pkg_resources').declare_namespace(__name__)
+    except ImportError:
+        __path__ = __import__('pkgutil').extend_path(__path__, __name__)
diff --git a/src/google/protobuf/io/BUILD.bazel b/src/google/protobuf/io/BUILD.bazel
--- a/src/google/protobuf/io/BUILD.bazel
+++ b/src/google/protobuf/io/BUILD.bazel
@@ -138,7 +138,7 @@ cc_library(
         "@com_google_absl//absl/log:absl_log",
     ] + select({
         "//build_defs:config_msvc": [],
-        "//conditions:default": ["@zlib//:zlib"],
+        "//conditions:default": ["//external:zlib"],
     }),
 )

diff --git a/src/google/protobuf/port_def.inc b/src/google/protobuf/port_def.inc
--- a/src/google/protobuf/port_def.inc	2023-06-27 01:17:34.917105764 +0000
+++ b/src/google/protobuf/port_def.inc	2023-06-27 01:18:12.069060142 +0000
@@ -1004,7 +1004,7 @@
 #pragma clang diagnostic ignored "-Wshorten-64-to-32"
 // Turn on -Wdeprecated-enum-enum-conversion. This deprecation comes in C++20
 // via http://wg21.link/p1120r0.
-#pragma clang diagnostic error "-Wdeprecated-enum-enum-conversion"
+// #pragma clang diagnostic error "-Wdeprecated-enum-enum-conversion"
 // This error has been generally flaky, but we need to disable it specifically
 // to fix https://github.com/protocolbuffers/protobuf/issues/12313
 #pragma clang diagnostic ignored "-Wunused-parameter"
diff --git a/src/google/protobuf/map.h b/src/google/protobuf/map.h
--- a/src/google/protobuf/map.h	2023-06-30 14:32:34.892148233 +0000
+++ b/src/google/protobuf/map.h	2023-06-30 14:35:37.447992493 +0000
@@ -883,7 +883,7 @@
         TreeConvert(b);
       }
       ABSL_DCHECK(TableEntryIsTree(b))
-          << (void*)table_[b] << " " << (uintptr_t)table_[b];
+          << reinterpret_cast<void*>(table_[b]) << " " << static_cast<uintptr_t>(table_[b]);
       InsertUniqueInTree(b, node);
       index_of_first_non_null_ = (std::min)(index_of_first_non_null_, b);
     }
diff --git a/src/google/protobuf/map_field.h b/src/google/protobuf/map_field.h
--- a/src/google/protobuf/map_field.h	2023-06-30 17:14:18.934528580 +0000
+++ b/src/google/protobuf/map_field.h	2023-06-30 17:14:52.098500807 +0000
@@ -345,7 +345,7 @@

  protected:
   // "protected" stops users from deleting a `MapFieldBase *`
-  ~MapFieldBase();
+  virtual ~MapFieldBase();

  public:
   // Returns reference to internal repeated field. Data written using
diff --git a/src/google/protobuf/compiler/BUILD.bazel b/src/google/protobuf/compiler/BUILD.bazel
--- a/src/google/protobuf/compiler/BUILD.bazel
+++ b/src/google/protobuf/compiler/BUILD.bazel
@@ -306,7 +306,7 @@
     srcs = ["retention.cc"],
     hdrs = ["retention.h"],
     include_prefix = "google/protobuf/compiler",
-    visibility = ["//src/google/protobuf:__subpackages__"],
+    visibility = ["//visibility:public"],
     deps = [
         "//src/google/protobuf:protobuf_nowkt",
         "@com_google_absl//absl/types:span",

diff --git a/src/google/protobuf/port_def.inc b/src/google/protobuf/port_def.inc
index 1c6a24945..c27d0bf2a 100644
--- a/src/google/protobuf/port_def.inc
+++ b/src/google/protobuf/port_def.inc
@@ -1062,6 +1062,9 @@ static_assert(PROTOBUF_ABSL_MIN(20230125, 3),
 #pragma warning(disable: 4125)
 #endif

+#if defined(__GNUC__)
+#pragma GCC diagnostic ignored "-Wundef"
+#endif
 #if PROTOBUF_ENABLE_DEBUG_LOGGING_MAY_LEAK_PII
 #define PROTOBUF_DEBUG true
 #else
# An example config which accepts HTTP/3 and forwards the requests upstream over TCP.
# This includes a TCP listener which advertises that HTTP/3 is available via the alt-svc header
admin:
  address:
    socket_address:
      protocol: TCP
      address: 0.0.0.0
      port_value: 9901
static_resources:
  listeners:
  - name: listener_tcp
    address:
      socket_address:
        protocol: TCP
        address: 0.0.0.0
        port_value: 10000
    filter_chains:
    - transport_socket:
        name: envoy.transport_sockets.tls
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.DownstreamTlsContext
          common_tls_context:
            tls_certificates:
            - certificate_chain:
                filename: certs/servercert.pem
              private_key:
                filename: certs/serverkey.pem
      filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          codec_type: HTTP2
          stat_prefix: ingress_http
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              response_headers_to_add:
              - header:
                  key: alt-svc
                  value: h3=":10000"; ma=86400, h3-29=":10000"; ma=86400
              domains: ["*"]
              routes:
              - match:
                  prefix: "/"
                route:
                  host_rewrite_literal: www.envoyproxy.io
                  cluster: service_envoyproxy_io
          http3_protocol_options:
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router

  - name: listener_udp
    address:
      socket_address:
        protocol: UDP
        address: 0.0.0.0
        port_value: 10000
    udp_listener_config:
      quic_options: {}
      downstream_socket_config:
        prefer_gro: true
    filter_chains:
    - transport_socket:
        name: envoy.transport_sockets.quic
        typed_config:
          '@type': type.googleapis.com/envoy.extensions.transport_sockets.quic.v3.QuicDownstreamTransport
          downstream_tls_context:
            common_tls_context:
              tls_certificates:
              - certificate_chain:
                  filename: certs/servercert.pem
                private_key:
                  filename: certs/serverkey.pem
      filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          codec_type: HTTP3
          stat_prefix: ingress_http
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains: ["*"]
              routes:
              - match:
                  prefix: "/"
                route:
                  host_rewrite_literal: www.envoyproxy.io
                  cluster: service_envoyproxy_io
          http3_protocol_options:
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
  clusters:
  - name: service_envoyproxy_io
    connect_timeout: 30s
    type: LOGICAL_DNS
    # Comment out the following line to test on v6 networks
    dns_lookup_family: V4_ONLY
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: service_envoyproxy_io
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: www.envoyproxy.io
                port_value: 443
    transport_socket:
      name: envoy.transport_sockets.tls
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
        sni: www.envoyproxy.io
{% macro ingress_sampled_log() -%}
  log_format: {text_format_source: {inline_string: "[%START_TIME%] \"%REQ(:METHOD)% %REQ(X-ENVOY-ORIGINAL-PATH?:PATH):256% %PROTOCOL%\" %RESPONSE_CODE% %RESPONSE_FLAGS% %BYTES_RECEIVED% %BYTES_SENT% %DURATION% %RESP(X-ENVOY-UPSTREAM-SERVICE-TIME)% \"%REQ(X-FORWARDED-FOR)%\" \"%REQ(USER-AGENT)%\" \"%REQ(X-REQUEST-ID)%\" \"%REQ(:AUTHORITY)%\"\n"}}
{% endmacro %}

{% macro ingress_full() -%}
  log_format: {text_format_source: {inline_string: "[%START_TIME%] \"%REQ(:METHOD)% %REQ(X-ENVOY-ORIGINAL-PATH?:PATH)% %PROTOCOL%\" %RESPONSE_CODE% %RESPONSE_FLAGS% %BYTES_RECEIVED% %BYTES_SENT% %DURATION% %RESP(X-ENVOY-UPSTREAM-SERVICE-TIME)% \"%REQ(X-FORWARDED-FOR)%\" \"%REQ(USER-AGENT)%\" \"%REQ(X-REQUEST-ID)%\" \"%REQ(:AUTHORITY)%\"\n"}}
{% endmacro %}

{% macro egress_error_log() -%}
  log_format: {text_format_source: {inline_string: "[%START_TIME%] \"%REQ(:METHOD)% %REQ(X-ENVOY-ORIGINAL-PATH?:PATH):256% %PROTOCOL%\" %RESPONSE_CODE% %RESPONSE_FLAGS% %BYTES_RECEIVED% %BYTES_SENT% %DURATION% %RESP(X-ENVOY-UPSTREAM-SERVICE-TIME)% \"%REQ(X-FORWARDED-FOR)%\" \"%REQ(USER-AGENT)%\" \"%REQ(X-REQUEST-ID)%\" \"%REQ(:AUTHORITY)%\" \"%UPSTREAM_HOST%\"\n"}}
{% endmacro %}

{% macro egress_error_amazon_service() -%}
  log_format: {text_format_source: { inline_string: "[%START_TIME%] \"%REQ(:METHOD)% %REQ(X-ENVOY-ORIGINAL-PATH?:PATH):256% %PROTOCOL%\" %RESPONSE_CODE% %RESPONSE_FLAGS% %BYTES_RECEIVED% %BYTES_SENT% %DURATION% %RESP(X-ENVOY-UPSTREAM-SERVICE-TIME)% \"%REQ(X-FORWARDED-FOR)%\" \"%REQ(USER-AGENT)%\" \"%REQ(X-REQUEST-ID)%\" \"%REQ(:AUTHORITY)%\" \"%UPSTREAM_HOST%\" \"%RESP(X-AMZN-RequestId)%\"\n"}}
{% endmacro %}
# An example config which accepts HTTP/1 requests over TCP and forwards them to google using HTTP/3
admin:
  address:
    socket_address:
      protocol: TCP
      address: 0.0.0.0
      port_value: 9901
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        protocol: TCP
        address: 0.0.0.0
        port_value: 10000
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          stat_prefix: ingress_http
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains: ["*"]
              routes:
              - match:
                  prefix: "/"
                route:
                  host_rewrite_literal: www.google.com
                  cluster: service_google
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
  clusters:
  - name: service_google
    connect_timeout: 30s
    type: LOGICAL_DNS
    # Comment out the following line to test on v6 networks
    dns_lookup_family: V4_ONLY
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: service_google
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: www.google.com
                port_value: 443
    typed_extension_protocol_options:
      envoy.extensions.upstreams.http.v3.HttpProtocolOptions:
        "@type": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions
        explicit_http_config:
          http3_protocol_options: {}
        common_http_protocol_options:
          idle_timeout: 1s
    transport_socket:
      name: envoy.transport_sockets.quic
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.transport_sockets.quic.v3.QuicUpstreamTransport
        upstream_tls_context:
          sni: www.google.com
# This configuration listens on port 9999 and creates TCP connections to port 10000 using an
# intermediate internal listener.
bootstrap_extensions:
- name: envoy.bootstrap.internal_listener
  typed_config:
    "@type": type.googleapis.com/envoy.extensions.bootstrap.internal_listener.v3.InternalListener
static_resources:
  listeners:
  - name: ingress
    address:
      socket_address:
        protocol: TCP
        address: 127.0.0.1
        port_value: 9999
    filter_chains:
    - filters:
      - name: tcp
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.tcp_proxy.v3.TcpProxy
          stat_prefix: ingress
          cluster: encap_cluster
  - name: encap
    internal_listener: {}
    filter_chains:
    - filters:
      - name: tcp
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.tcp_proxy.v3.TcpProxy
          stat_prefix: encap
          cluster: cluster_0
  clusters:
  - name: encap_cluster
    load_assignment:
      cluster_name: encap_cluster
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              envoy_internal_address:
                server_listener_name: encap
  - name: cluster_0
    load_assignment:
      cluster_name: cluster_0
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: 127.0.0.1
                port_value: 10000
{% import 'routing_helper.template.yaml' as helper -%}
{% import 'access_log_format_helper.template.yaml' as access_log_helper -%}
{% macro ingress_listener(protocol, address, port_value) -%}
- address:
    socket_address:
      protocol: {{protocol}}
      address: {{address}}
      port_value: {{port_value}}
  traffic_direction: INBOUND
  filter_chains:
  - filters:
    - name: envoy.filters.network.http_connection_manager
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
        codec_type: AUTO
        stat_prefix: ingress_http
        route_config:
          name: local_route
          virtual_hosts:
          - name: local_service
            domains:
            - "*"
            routes:
            - match:
                prefix: "/"
                headers:
                - name: content-type
                  string_match:
                    exact: application/grpc
              route:
                cluster: local_service_grpc
            - match:
                prefix: "/"
              route:
                cluster: local_service
        http_filters:
        - name: envoy.filters.http.health_check
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.filters.http.health_check.v3.HealthCheck
            pass_through_mode: true
            headers:
              - name: ":path"
                string_match:
                  exact: "/healthcheck"
            cache_time: 2.5s
        - name: envoy.filters.http.buffer
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.filters.http.buffer.v3.Buffer
            max_request_bytes: 5242880
        - name: envoy.filters.http.router
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
        access_log:
        - name: envoy.access_loggers.file
          filter:
            not_health_check_filter:  {}
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.access_loggers.file.v3.FileAccessLog
            path: "/var/log/envoy/ingress_http.log"
            {{ access_log_helper.ingress_full()|indent(10)}}
        - name: envoy.access_loggers.file
          filter:
            and_filter:
              filters:
                - or_filter:
                    filters:
                    - status_code_filter:
                        comparison:
                          op: GE
                          value:
                            default_value: 400
                            runtime_key: access_log.access_error.status
                    - status_code_filter:
                        comparison:
                          op: EQ
                          value:
                            default_value: 0
                            runtime_key: access_log.access_error.status
                    - duration_filter:
                        comparison:
                          op: GE
                          value:
                            default_value: 2000
                            runtime_key: access_log.access_error.duration
                - not_health_check_filter: {}
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.access_loggers.file.v3.FileAccessLog
            path: "/var/log/envoy/ingress_http_error.log"
            {{ access_log_helper.ingress_sampled_log()|indent(10)}}
        - name: envoy.access_loggers.file
          filter:
            and_filter:
              filters:
              - not_health_check_filter: {}
              - runtime_filter:
                  runtime_key:  access_log.ingress_http
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.access_loggers.file.v3.FileAccessLog
            path: "/var/log/envoy/ingress_http_sampled.log"
            {{ access_log_helper.ingress_sampled_log()|indent(10)}}
        common_http_protocol_options:
          idle_timeout: 840s
{% endmacro -%}
static_resources:
  listeners:
  {{ ingress_listener("tcp", "0.0.0.0", 9211) | indent(2)}}
  - address:
      socket_address:
        protocol: TCP
        port_value: 9001
        address: 127.0.0.1
    traffic_direction: OUTBOUND
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          codec_type: AUTO
          stat_prefix: egress_http
          route_config:
            name: local_route
            virtual_hosts:
            {% for service, options in internal_virtual_hosts.items() %}
            - name: {{ service }}
              domains:
              - {{ service }}
              routes:
              - match:
                  prefix: "/"
                route:
                  {{ helper.make_route_internal(service, options)|indent(16) }}
            {% endfor %}
          add_user_agent: true
          common_http_protocol_options:
            idle_timeout: 840s
          access_log:
          - name: envoy.access_loggers.file
            filter:
              or_filter:
                filters:
                  - status_code_filter:
                      comparison:
                        op: GE
                        value:
                          default_value: 400
                          runtime_key: access_log.access_error.status
                  - duration_filter:
                      comparison:
                        op: GE
                        value:
                          default_value: 2000
                          runtime_key: access_log.access_error.duration
                  - traceable_filter: {}
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.access_loggers.file.v3.FileAccessLog
              path: "/var/log/envoy/egress_http_error.log"
              {{ access_log_helper.egress_error_log()|indent(10) }}
          use_remote_address: true
          http_filters:
          - name: envoy.filters.http.ratelimit
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.ratelimit.v3.RateLimit
              domain: envoy_service_to_service
              rate_limit_service:
                 transport_api_version: V3
                 grpc_service:
                    envoy_grpc:
                       cluster_name: ratelimit
          - name: envoy.filters.http.grpc_http1_bridge
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.grpc_http1_bridge.v3.Config
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
  - address:
      socket_address:
        protocol: TCP
        port_value: 9002
        address: 127.0.0.1
    traffic_direction: OUTBOUND
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          codec_type: AUTO
          stat_prefix: egress_http
          rds:
            config_source:
               resource_api_version: V3
               api_config_source:
                 api_type: GRPC
                 transport_api_version: V3
                 grpc_services:
                   envoy_grpc:
                     cluster_name: "rds"
            route_config_name: rds_config_for_listener_1
          add_user_agent: true
          common_http_protocol_options:
            idle_timeout: 840s
          access_log:
          - name: envoy.access_loggers.file
            filter:
              or_filter:
                filters:
                  - status_code_filter:
                      comparison:
                        op: GE
                        value:
                          default_value: 400
                          runtime_key: access_log.access_error.status
                  - duration_filter:
                      comparison:
                        op: GE
                        value:
                          default_value: 2000
                          runtime_key: access_log.access_error.duration
                  - traceable_filter: {}
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.access_loggers.file.v3.FileAccessLog
              path: "/var/log/envoy/egress_http_error.log"
              {{ access_log_helper.egress_error_log()|indent(10) }}
          use_remote_address: true
          http_filters:
          - name: envoy.filters.http.ratelimit
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.ratelimit.v3.RateLimit
              domain: envoy_service_to_service
              rate_limit_service:
                 transport_api_version: V3
                 grpc_service:
                    envoy_grpc:
                       cluster_name: ratelimit
          - name: envoy.filters.http.grpc_http1_bridge
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.grpc_http1_bridge.v3.Config
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
  {% if external_virtual_hosts|length > 0 or mongos_servers|length > 0 %}{% endif -%}
  {% for mapping in external_virtual_hosts -%}
  - name: "{{ mapping['address']}}"
    address:
      socket_address:
        address: "{{ mapping['address'] }}"
        protocol: TCP
        port_value: 9901
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          codec_type: AUTO
          common_http_protocol_options:
            idle_timeout: 840s
          stat_prefix: egress_{{ mapping['name'] }}
          #update access_logs here
          route_config:
            virtual_hosts:
            {% for host in mapping['hosts'] %}
            - name: egress_{{ host['name'] }}
              domains:
              - "{{ host['domain'] }}"
              routes:
              - match:
                  prefix: "/"
                route:
                  cluster: egress_{{ host['name'] }}
                  retry_policy:
                    retry_on: connect-failure
                  {% if host.get('host_rewrite', False) %}
                  host_rewrite_literal: "{{host['host_rewrite']}}"
                  {% endif %}
            {% endfor %}
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
          access_log:
          - name: envoy.access_loggers.file
            filter:
              or_filter:
                filters:
                  - status_code_filter:
                      comparison:
                        op: GE
                        value:
                          default_value: 400
                          runtime_key: access_log.access_error.status
                  - status_code_filter:
                      comparison:
                        op: EQ
                        value:
                          default_value: 0
                          runtime_key: access_log.access_error.status
                  {% if mapping.get('log_high_latency_requests', True) %}
                  - duration_filter:
                      comparison:
                        op: GE
                        value:
                          default_value: 2000
                          runtime_key: access_log.access_error.duration
                  {% endif %}
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.access_loggers.file.v3.FileAccessLog
              path: "/var/log/envoy/egress_{{ mapping['name'] }}_http_error.log"
              {% if mapping.get('is_amzn_service', False) -%}
              {{ access_log_helper.egress_error_amazon_service()|indent(10) }}
              {% else -%}
              {{ access_log_helper.egress_error_log()|indent(10) }}
              {% endif %}
  {% if (mongos_servers|length > 0) or (mongos_servers|length == 0 and not loop.last ) %}{% endif -%}
  {% endfor -%}
  {% for key, value in mongos_servers.items() -%}
  - name : "{{ value['address'] }}"
    address:
      socket_address:
        address: "{{ value['address'] }}"
        protocol: TCP
        port_value: 9003
    filter_chains:
    - filters:
      - name: envoy.filters.network.tcp_proxy
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.tcp_proxy.v3.TcpProxy
          stat_prefix: mongo_{{ key }}
          cluster: mongo_{{ key }}
      - name: envoy.filters.network.mongo_proxy
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.mongo_proxy.v3.MongoProxy
          stat_prefix: "{{ key }}"
          access_log: "/var/log/envoy/mongo_{{ key }}.log"
      {% if value.get('ratelimit', False) %}
      - name: envoy.filters.network.ratelimit
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.ratelimit.v3.RateLimit
          stat_prefix: "{{ key }}"
          domain: envoy_mongo_cps
          descriptors:
            entries:
            - key: database
              value: "{{ key }}"
      {% endif %}
  {% endfor -%}
  clusters:
  {% for service, options in internal_virtual_hosts.items() -%}
  - {{ helper.internal_cluster_definition(service, options)|indent(2)}}
  {% endfor -%}
  {% for mapping in external_virtual_hosts -%}
  {% for host in mapping['hosts'] -%}
  - name: egress_{{ host['name'] }}
    {% if host.get('ssl', False) %}
    transport_socket:
      name: envoy.transport_sockets.tls
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
        common_tls_context:
          validation_context:
            trusted_ca:
              filename: certs/cacert.pem
            {% if host.get('verify_subject_alt_name', False) %}
            match_typed_subject_alt_names:
            - san_type: DNS
              matcher:
                exact: "{{host['verify_subject_alt_name'] }}"
            {% endif %}
        {% if host.get('sni', False) %}
        sni: "{{ host['sni'] }}"
        {% endif %}
    connect_timeout: 1s
    {% else %}
    connect_timeout: 0.25s
    {% endif %}
    type: LOGICAL_DNS
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: egress_{{ host['name'] }}
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: {{ host['remote_address'] }}
                port_value: {{ host['port_value'] }}
                protocol: {{ host['protocol'] }}
  {% endfor -%}
  {% endfor -%}
  {% for key, value in mongos_servers.items() -%}
  - name: mongo_{{ key }}
    connect_timeout: 0.25s
    type: STRICT_DNS
    lb_policy: RANDOM
    load_assignment:
      cluster_name: mongo_{{ key }}
      endpoints:
      - lb_endpoints:
        {% for server in value['hosts'] -%}
        - endpoint:
            address:
              socket_address:
                address: {{ server['address'] }}
                port_value: {{ server['port_value'] }}
                protocol: {{ server['protocol'] }}
        {% endfor -%}
  {% endfor %}
  - name: main_website
    connect_timeout: 0.25s
    type: LOGICAL_DNS
    # Comment out the following line to test on v6 networks
    dns_lookup_family: V4_ONLY
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: main_website
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: main_website.com
                port_value: 443
                protocol: TCP
    transport_socket:
      name: envoy.transport_sockets.tls
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
        sni: www.main_website.com
  - name: local_service
    connect_timeout: 0.25s
    type: STATIC
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: main_website
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: 127.0.0.1
                port_value: 8080
                protocol: TCP
    circuit_breakers:
      thresholds:
        max_pending_requests: 30
        max_connections: 100
  - name: local_service_grpc
    connect_timeout: 0.25s
    type: STATIC
    lb_policy: ROUND_ROBIN
    typed_extension_protocol_options:
      envoy.extensions.upstreams.http.v3.HttpProtocolOptions:
        "@type": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions
        explicit_http_config:
          http2_protocol_options: {}
    load_assignment:
      cluster_name: local_service_grpc
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: 127.0.0.1
                port_value: 8081
                protocol: TCP
    circuit_breakers:
      thresholds:
        max_requests: 200
    dns_lookup_family: V4_ONLY
  - name: rds
    connect_timeout: 0.25s
    type: STRICT_DNS
    lb_policy: ROUND_ROBIN
    typed_extension_protocol_options:
      envoy.extensions.upstreams.http.v3.HttpProtocolOptions:
        "@type": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions
        explicit_http_config:
          http2_protocol_options:
            connection_keepalive:
              interval: 30s
              timeout: 5s
    load_assignment:
      cluster_name: rds
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: rds.yourcompany.net
                port_value: 80
                protocol: TCP
    dns_lookup_family: V4_ONLY
  - name: statsd
    connect_timeout: 0.25s
    type: STATIC
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: statsd
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: 127.0.0.1
                port_value: 8125
                protocol: TCP
    dns_lookup_family: V4_ONLY
  - name: cds_cluster
    connect_timeout: 0.25s
    type: STRICT_DNS
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: cds_cluster
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: cds.yourcompany.net
                port_value: 80
                protocol: TCP
  - name: sds
    connect_timeout: 0.25s
    type: STRICT_DNS
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: sds
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: discovery.yourcompany.net
                port_value: 80
                protocol: TCP
dynamic_resources:
  cds_config:
    resource_api_version: V3
    api_config_source:
      api_type: REST
      transport_api_version: V3
      cluster_names:
      - cds_cluster
      refresh_delay: 30s
cluster_manager: {}
flags_path: "/etc/envoy/flags"
stats_sinks:
  - name: envoy.stat_sinks.statsd
    typed_config:
      "@type": type.googleapis.com/envoy.config.metrics.v3.StatsdSink
      tcp_cluster_name: statsd
layered_runtime:
  layers:
    - name: root
      disk_layer:
        symlink_root: /srv/configset/envoydata/current
        subdirectory: envoy
    - name: override
      disk_layer:
        symlink_root: /srv/configset/envoydata/current
        subdirectory: envoy_override
        append_service_cluster: true
    - name: admin
      admin_layer: {}
admin:
  address:
    socket_address:
      protocol: TCP
      address: 0.0.0.0
      port_value: 9901
admin:
  address:
    socket_address:
      protocol: TCP
      address: 127.0.0.1
      port_value: 9901
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        protocol: TCP
        address: 0.0.0.0
        port_value: 10000
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          stat_prefix: ingress_http
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains: ["*"]
              routes:
              - match:
                  prefix: "/"
                route:
                  host_rewrite: www.google.com
                  cluster: service_google
                  cors:
                    allow_origin:
                    - "test-origin-1"
          http_filters:
          - name: envoy.filters.http.router
  clusters:
  - name: service_google
    connect_timeout: 0.25s
    type: LOGICAL_DNS
    # Comment out the following line to test on v6 networks
    dns_lookup_family: V4_ONLY
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: service_google
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: www.google.com
                port_value: 443
    transport_socket:
      name: envoy.transport_sockets.tls
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
        sni: www.google.com
tracing:
  http:
    name: envoy.tracers.zipkin
    config:
      collector_cluster: service_google
      collector_endpoint: /api/v1/spans
      collector_endpoint_version: HTTP_JSON_V1
layered_runtime:
  layers:
  - name: static_layer
    static_layer:
      envoy.deprecated_features:envoy.config.trace.v2.ZipkinConfig.HTTP_JSON_V1: true
      envoy.deprecated_features:envoy.api.v2.route.CorsPolicy.allow_origin: true
# This configuration takes incoming data on port 10000 and encapsulates it in a CONNECT
# request which is sent upstream port 10001.
# It can be used to test TCP tunneling as described in
# https://envoyproxy.io/docs/envoy/latest/intro/arch_overview/http/upgrades
# and running `curl -H 'Host: www.google.com' --resolve www.google.com:10000:127.0.0.1 https://www.google.com:10000`

admin:
  address:
    socket_address:
      protocol: TCP
      address: 127.0.0.1
      port_value: 9903
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        protocol: TCP
        address: 127.0.0.1
        port_value: 10000
    filter_chains:
    - filters:
      - name: tcp
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.tcp_proxy.v3.TcpProxy
          stat_prefix: tcp_stats
          cluster: "cluster_0"
          tunneling_config:
            hostname: host.com:443
            headers_to_add:
            - header:
                key: original_dst_port
                value: "%DOWNSTREAM_LOCAL_PORT%"
  clusters:
  - name: cluster_0
    connect_timeout: 5s
    # This ensures HTTP/2 CONNECT is used for establishing the tunnel.
    typed_extension_protocol_options:
      envoy.extensions.upstreams.http.v3.HttpProtocolOptions:
        "@type": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions
        explicit_http_config:
          http2_protocol_options: {}
    load_assignment:
      cluster_name: cluster_0
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: 127.0.0.1
                port_value: 10001
import jinja2
import os
import shutil
import sys

SCRIPT_DIR = os.path.dirname(__file__)
OUT_DIR = sys.argv[1]

#
# About this script: Envoy configurations needed for a complete infrastructure are complicated.
# This script demonstrates how to programatically build Envoy configurations using jinja templates.
# This is roughly how we build our configurations at Lyft. The three configurations demonstrated
# here (front proxy, double proxy, and service to service) are also very close approximations to
# what we use at Lyft in production. They give a demonstration of how to configure most Envoy
# features. Along with the configuration guide it should be possible to modify them for different
# use cases.
#

# This is the set of internal services that front Envoy will route to. Each cluster referenced
# in envoy_router.template.json must be specified here. It is a dictionary of dictionaries.
# Options can be specified for each cluster if needed. See make_route_internal() in
# routing_helper.template.json for the types of options supported.
front_envoy_clusters = {'service1': {}, 'service2': {}, 'service3': {}, 'ratelimit': {}}

# This is the set of internal services that local Envoys will route to. All services that will be
# accessed via the 9001 egress port need to be listed here. It is a dictionary of dictionaries.
# Options can be specified for each cluster if needed. See make_route_internal() in
# routing_helper.template.json for the types of options supported.
service_to_service_envoy_clusters = {
    'ratelimit': {},
    'service1': {
        'service_to_service_rate_limit': True
    },
    'service3': {}
}

# This is a list of external hosts that can be accessed from local Envoys. Each external service has
# its own port. This is because some SDKs don't make it easy to use host based routing. Below
# we demonstrate setting up proxying for DynamoDB. In the config, this ends up using the HTTP
# DynamoDB statistics filter, as well as generating a special access log which includes the
# X-AMZN-RequestId response header.
external_virtual_hosts = [{
    'name': 'dynamodb_iad',
    'address': "127.0.0.1",
    'protocol': "TCP",
    'port_value': "9204",
    'hosts': [{
        'name': 'dynamodb_iad',
        'domain': '*',
        'remote_address': 'dynamodb.us-east-1.amazonaws.com',
        'protocol': 'TCP',
        'port_value': '443',
        'verify_subject_alt_name': ['dynamodb.us-east-1.amazonaws.com'],
        'ssl': True
    }],
    'is_amzn_service': True,
    'cluster_type': 'logical_dns'
}]

# This is the set of mongo clusters that local Envoys can talk to. Each database defines a set of
# mongos routers to talk to, and whether the global rate limit service should be called for new
# connections. Many organizations will not be interested in the mongo feature. Setting this to
# an empty dictionary will remove all mongo configuration. The configuration is a useful example
# as it demonstrates how to setup TCP proxy and the network rate limit filter.
mongos_servers = {
    'somedb': {
        'address': "127.0.0.1",
        'protocol': "TCP",
        'port_value': 27019,
        'hosts': [
            {
                'port_value': 27817,
                'address': 'router1.yourcompany.net',
                'protocol': 'TCP'
            },
            {
                'port_value': 27817,
                'address': 'router2.yourcompany.net',
                'protocol': 'TCP'
            },
            {
                'port_value': 27817,
                'address': 'router3.yourcompany.net',
                'protocol': 'TCP'
            },
            {
                'port_value': 27817,
                'address': 'router4.yourcompany.net',
                'protocol': 'TCP'
            },
        ],
        'ratelimit': True
    }
}


def generate_config(template_path, template, output_file, **context):
    """ Generate a final config file based on a template and some context. """
    env = jinja2.Environment(
        loader=jinja2.FileSystemLoader(template_path, followlinks=True),
        undefined=jinja2.StrictUndefined)
    raw_output = env.get_template(template).render(**context)
    with open(output_file, 'w') as fh:
        fh.write(raw_output)


# TODO(sunjayBhatia, wrowe): Avoiding tracing extensions until they build on Windows
tracing_enabled = os.name != 'nt'

# Generate a demo config for the main front proxy. This sets up both HTTP and HTTPS listeners,
# as well as a listener for the double proxy to connect to via SSL client authentication.
generate_config(
    SCRIPT_DIR,
    'envoy_front_proxy.template.yaml',
    '{}/envoy_front_proxy.yaml'.format(OUT_DIR),
    clusters=front_envoy_clusters,
    tracing=tracing_enabled)

# Generate a demo config for the double proxy. This sets up both an HTTP and HTTPS listeners,
# and backhauls the traffic to the main front proxy.
generate_config(
    SCRIPT_DIR,
    'envoy_double_proxy.template.yaml',
    '{}/envoy_double_proxy.yaml'.format(OUT_DIR),
    tracing=tracing_enabled)

# Generate a demo config for the service to service (local) proxy. This sets up several different
# listeners:
# 9211: Main ingress listener for service to service traffic.
# 9001: Main egress listener for service to service traffic. Applications use this port to send
#       requests to other services.
# optional external service ports: built from external_virtual_hosts above. Each external host
#                                  that Envoy proxies to listens on its own port.
# optional mongo ports: built from mongos_servers above.
generate_config(
    SCRIPT_DIR,
    'envoy_service_to_service.template.yaml',
    '{}/envoy_service_to_service.yaml'.format(OUT_DIR),
    internal_virtual_hosts=service_to_service_envoy_clusters,
    external_virtual_hosts=external_virtual_hosts,
    mongos_servers=mongos_servers)

shutil.copy(os.path.join(SCRIPT_DIR, 'envoyproxy_io_proxy.yaml'), OUT_DIR)
shutil.copy(os.path.join(SCRIPT_DIR, 'encapsulate_in_http1_connect.yaml'), OUT_DIR)
shutil.copy(os.path.join(SCRIPT_DIR, 'encapsulate_in_http2_connect.yaml'), OUT_DIR)
shutil.copy(os.path.join(SCRIPT_DIR, 'terminate_http1_connect.yaml'), OUT_DIR)
shutil.copy(os.path.join(SCRIPT_DIR, 'terminate_http2_connect.yaml'), OUT_DIR)
# This configuration terminates a CONNECT request and sends the CONNECT payload upstream.
# It can be used to test TCP tunneling as described in
# https://envoyproxy.io/docs/envoy/latest/intro/arch_overview/http/upgrades
# or used to test CONNECT to domain such as www.google.com, by running `curl -k -v -x 127.0.0.1:10001 https://www.google.com.
#
# To test the CONNECT to tcp address 127.0.0.1:10003, run
# `curl -k -v -x 127.0.0.1:10001 --proxy-header "foo: bar" https://127.0.0.1:10003`.
admin:
  address:
    socket_address:
      protocol: TCP
      address: 127.0.0.1
      port_value: 9902
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        protocol: TCP
        address: 127.0.0.1
        port_value: 10001
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          stat_prefix: ingress_http
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains:
              - "*"
              routes:
              - match:
                  connect_matcher:
                    {}
                  headers:
                  - name: foo
                    string_match:
                      exact: bar
                route:
                  cluster: local_original_dst
                  upgrade_configs:
                  - upgrade_type: CONNECT
                    connect_config:
                      {}
              - match:
                  connect_matcher:
                    {}
                route:
                  cluster: service_google
                  upgrade_configs:
                  - upgrade_type: CONNECT
                    connect_config:
                      {}
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
          http_protocol_options: {}
          upgrade_configs:
          - upgrade_type: CONNECT
  clusters:
  - name: service_google
    connect_timeout: 0.25s
    type: LOGICAL_DNS
    # Comment out the following line to test on v6 networks
    dns_lookup_family: V4_ONLY
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: service_google
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: www.google.com
                port_value: 443
  - name: local_original_dst
    connect_timeout: 0.25s
    type: ORIGINAL_DST
    lb_policy: CLUSTER_PROVIDED
    original_dst_lb_config:
      use_http_header: true
      http_header_name: ":authority"
admin:
  address:
    socket_address:
      protocol: TCP
      address: 0.0.0.0
      port_value: 9901
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        protocol: TCP
        address: 0.0.0.0
        port_value: 10000
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          stat_prefix: ingress_http
          access_log:
          - name: envoy.access_loggers.stdout
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.access_loggers.stream.v3.StdoutAccessLog
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains: ["*"]
              routes:
              - match:
                  prefix: "/"
                route:
                  host_rewrite_literal: www.envoyproxy.io
                  cluster: service_envoyproxy_io
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
  clusters:
  - name: service_envoyproxy_io
    type: LOGICAL_DNS
    # Comment out the following line to test on v6 networks
    dns_lookup_family: V4_ONLY
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: service_envoyproxy_io
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: www.envoyproxy.io
                port_value: 443
    transport_socket:
      name: envoy.transport_sockets.tls
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
        sni: www.envoyproxy.io
{%- macro listener(protocol, address, port_value, tls, proxy_proto, tracing) -%}
- name: listener_created_from_configgen
  address:
    socket_address:
      protocol: {{protocol}}
      address: {{address}}
      port_value: {{port_value}}
  {% if proxy_proto %}
  listener_filters:
  - name: envoy.filters.listener.proxy_protocol
    typed_config:
      "@type": type.googleapis.com/envoy.extensions.filters.listener.proxy_protocol.v3.ProxyProtocol
  {% endif %}
  filter_chains:
  - filter_chain_match: {}
    {% if tls %}
    transport_socket:
      name: envoy.transport_sockets.tls
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.DownstreamTlsContext
        common_tls_context:
          tls_certificates:
          - certificate_chain:
              filename: certs/servercert.pem
            private_key:
              filename: certs/serverkey.pem
          validation_context: {}
          alpn_protocols:
          - h2
          - http/1.1
    {% endif %}
    filters:
    - name: envoy.filters.network.http_connection_manager
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
        codec_type: AUTO
        stat_prefix: router
        route_config:
          name: local_route
          virtual_hosts:
          - name: local_service
            domains: ["*"]
            routes:
            - match:
                prefix: "/"
              route:
                cluster: backhaul
                #Generally allow front proxy to control timeout and use this as a backstop
                timeout: 20s
        http_filters:
        - name: envoy.filters.http.health_check
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.filters.http.health_check.v3.HealthCheck
            pass_through_mode: false
            headers:
              - string_match:
                  exact: /healthcheck
                name: :path
        - name: envoy.filters.http.buffer
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.filters.http.buffer.v3.Buffer
            max_request_bytes: 5242880
        - name: envoy.filters.http.router
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
        common_http_protocol_options:
          idle_timeout: 840s
        access_log:
        - name: envoy.access_loggers.file
          filter:
            or_filter:
              filters:
                - status_code_filter:
                    comparison:
                      op: GE
                      value:
                        default_value: 500
                        runtime_key: access_log.access_error.status
                - duration_filter:
                    comparison:
                      op: GE
                      value:
                        default_value: 1000
                        runtime_key: access_log.access_error.duration
                - traceable_filter: {}
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.access_loggers.file.v3.FileAccessLog
            path: /var/log/envoy/access_error.log
            log_format:
              text_format_source:
                inline_string: "[%START_TIME%] \"%REQ(:METHOD)% %REQ(X-ENVOY-ORIGINAL-PATH?:PATH)% %PROTOCOL%\" %RESPONSE_CODE% %RESPONSE_FLAGS% %BYTES_RECEIVED% %BYTES_SENT% %DURATION% %RESP(X-ENVOY-UPSTREAM-SERVICE-TIME)% \"%REQ(X-FORWARDED-FOR)%\" \"%REQ(USER-AGENT)%\" \"%REQ(X-REQUEST-ID)%\" \"%REQ(:AUTHORITY)%\" \"%REQ(X-LYFT-USER-ID)%\" \"%RESP(GRPC-STATUS)%\"\n"
        {% if proxy_proto %}
        use_remote_address: true
        {%endif -%}
{% endmacro -%}
static_resources:
  listeners:
  # TCP listener for external port 443 (TLS). Assumes a TCP LB in front such as ELB which
  # supports proxy proto
  {{ listener("TCP", "0.0.0.0",9300,True, True, tracing)|indent(2) }}
  # TCP listener for external port 80 (non-TLS). Assumes a TCP LB in front such as ELB which
  # supports proxy proto.
  {{ listener("TCP", "0.0.0.0",9301,False, True, tracing)|indent(2) }}
  clusters:
  - name: statsd
    type: STATIC
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: statsd
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: 127.0.0.1
                port_value: 8125
                protocol: TCP
  - name: backhaul
    type: STRICT_DNS
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: backhaul
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: front-proxy.yourcompany.net
                port_value: 9400
                protocol: TCP
    transport_socket:
      name: envoy.transport_sockets.tls
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
        common_tls_context:
          tls_certificates:
          - certificate_chain:
              filename: certs/clientcert.pem
            private_key:
              filename: certs/clientkey.pem
          validation_context:
            trusted_ca:
              filename: certs/cacert.pem
            match_typed_subject_alt_names:
            - san_type: DNS
              matcher:
                exact: "front-proxy.yourcompany.net"
    typed_extension_protocol_options:
      envoy.extensions.upstreams.http.v3.HttpProtocolOptions:
        "@type": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions
        explicit_http_config:
          http2_protocol_options: {}
        common_http_protocol_options:
          # There are so few connections going back
          # that we can get some imbalance. Until we come up
          # with a better solution just limit the requests
          # so we can cycle and get better spread.
          max_requests_per_connection: 25000
flags_path: "/etc/envoy/flags"
stats_sinks:
- name: envoy.stat_sinks.statsd
  typed_config:
    "@type": type.googleapis.com/envoy.config.metrics.v3.StatsdSink
    tcp_cluster_name: statsd
layered_runtime:
  layers:
    - name: root
      disk_layer:
        symlink_root: /srv/configset/envoydata/current
        subdirectory: envoy
    - name: override
      disk_layer:
        symlink_root: /srv/configset/envoydata/current
        subdirectory: envoy_override
        append_service_cluster: true
    - name: admin
      admin_layer: {}
admin:
  address:
    socket_address:
      protocol: TCP
      address: 127.0.0.1
      port_value: 9901
# This configuration terminates h2 CONNECT on port 10001 and then chains an HTTP filter that always responds with 200 using
# an internal listener.
bootstrap_extensions:
- name: envoy.bootstrap.internal_listener
  typed_config:
    "@type": type.googleapis.com/envoy.extensions.bootstrap.internal_listener.v3.InternalListener
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        protocol: TCP
        address: 127.0.0.1
        port_value: 10001
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          stat_prefix: ingress_http
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains:
              - "*"
              routes:
              - match:
                  connect_matcher:
                    {}
                route:
                  cluster: decap_cluster
                  upgrade_configs:
                  - upgrade_type: CONNECT
                    connect_config:
                      {}
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
          http2_protocol_options:
            allow_connect: true
          upgrade_configs:
          - upgrade_type: CONNECT
  - name: decap
    internal_listener: {}
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          stat_prefix: ingress_http
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains: ["*"]
              routes:
              - match:
                  prefix: "/"
                direct_response:
                  status: 200
                  body:
                    inline_string: "Hello, world!\n"
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
  clusters:
  - name: decap_cluster
    load_assignment:
      cluster_name: decap_cluster
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              envoy_internal_address:
                server_listener_name: decap
{% import 'routing_helper.template.yaml' as helper -%}
{% macro router_file_content() -%}{% include kwargs['router_file'] -%}{% endmacro -%}
{% macro listener(protocol, address, port_value, proxy_proto, tls, tracing) -%}
  name: not_required_for_static_listeners
  address:
    socket_address:
      protocol: {{protocol}}
      address: {{address}}
      port_value: {{port_value}}
  {% if proxy_proto %}
  listener_filters:
  - name: envoy.filters.listener.proxy_protocol
    typed_config:
      "@type": type.googleapis.com/envoy.extensions.filters.listener.proxy_protocol.v3.ProxyProtocol
  {% endif %}
  filter_chains:
  {% if tls %}
  - transport_socket:
      name: envoy.transport_sockets.tls
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.DownstreamTlsContext
        common_tls_context:
          alpn_protocols: h2,http/1.1
          tls_certificates:
          - certificate_chain:
              filename: certs/servercert.pem
            private_key:
              filename: certs/serverkey.pem
          {% if kwargs.get('pin_double_proxy_client', False) %}
          validation_context:
            trusted_ca:
              filename: certs/cacert.pm
            #This should be the hash of the /etc/envoy/envoy-double-proxy.pem cert used in the
            #double proxy configuration.
            verify_certificate_hash: "0000000000000000000000000000000000000000000000000000000000000000"
          {% endif %}
  {%endif %}
    filters:
    - name: envoy.filters.network.http_connection_manager
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
        codec_type: AUTO
        stat_prefix: router
        {% if proxy_proto -%}
        use_remote_address: true
        {%endif-%}
        stat_prefix: ingress_http
        route_config:
          {{ router_file_content(router_file='envoy_router.template.yaml')|indent(10) }}
        http_filters:
        - name: envoy.filters.http.health_check
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.filters.http.health_check.v3.HealthCheck
            pass_through_mode: false
            headers:
              - name: ":path"
                string_match:
                  exact: "/healthcheck"
        - name: envoy.filters.http.buffer
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.filters.http.buffer.v3.Buffer
            max_request_bytes: 5242880
        - name: envoy.filters.http.ratelimit
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.filters.http.ratelimit.v3.RateLimit
            domain: envoy_front
            request_type: external
            rate_limit_service:
              transport_api_version: V3
              grpc_service:
                envoy_grpc:
                  cluster_name: ratelimit
        - name: envoy.filters.http.router
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
        add_user_agent: true
        common_http_protocol_options:
          idle_timeout: 840s
        access_log:
        - name: envoy.access_loggers.file
          filter:
            or_filter:
              filters:
                - status_code_filter:
                    comparison:
                      op: GE
                      value:
                        default_value: 500
                        runtime_key: access_log.access_error.status
                - duration_filter:
                    comparison:
                      op: GE
                      value:
                        default_value: 1000
                        runtime_key: access_log.access_error.duration
                - traceable_filter: {}
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.access_loggers.file.v3.FileAccessLog
            path: "/var/log/envoy/access_error.log"
            log_format:
              text_format_source:
                inline_string: "[%START_TIME%] \"%REQ(:METHOD)% %REQ(X-ENVOY-ORIGINAL-PATH?:PATH)% %PROTOCOL%\" %RESPONSE_CODE% %RESPONSE_FLAGS% %BYTES_RECEIVED% %BYTES_SENT% %DURATION% %RESP(X-ENVOY-UPSTREAM-SERVICE-TIME)% \"%REQ(X-FORWARDED-FOR)%\" \"%REQ(USER-AGENT)%\" \"%REQ(X-REQUEST-ID)%\" \"%REQ(:AUTHORITY)%\" \"%REQ(X-LYFT-USER-ID)%\" \"%RESP(GRPC-STATUS)%\"\n"
{% endmacro -%}
static_resources:
  listeners:
    # TCP listeners for public HTTP/HTTPS endpoints. Assumes a TCP LB in front such as ELB which
    # supports proxy proto.
  - {{ listener("TCP", "0.0.0.0", "9300", True, True, tracing)|indent(2) }}
  - {{ listener("TCP", "0.0.0.0", "9301", True, True, tracing)|indent(2) }}
    # TCP listener for backhaul traffic from the double proxy.
    # See envoy_double_proxy.template.json
  - {{ listener("TCP", "0.0.0.0", "9400", True, True, tracing, pin_double_proxy_client=True)|indent(2) }}
  clusters:
  - name: sds
    type: STRICT_DNS
    connect_timeout: 0.25s
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: sds
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: discovery.yourcompany.net
                port_value: 80
                protocol: TCP
  - name: statsd
    type: STATIC
    connect_timeout: 0.25s
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: statsd
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: 127.0.0.1
                port_value: 8125
                protocol: TCP
  {% for service, options in clusters.items() -%}
  - {{ helper.internal_cluster_definition(service, options)|indent(2) }}
  {% endfor %}
cluster_manager:
  outlier_detection:
    event_log_path: /var/log/envoy/outlier_events.log
flags_path: /etc/envoy/flags
layered_runtime:
  layers:
    - name: root
      disk_layer:
        symlink_root: /srv/configset/envoydata/current
        subdirectory: envoy
    - name: override
      disk_layer:
        symlink_root: /srv/configset/envoydata/current
        subdirectory: envoy_override
        append_service_cluster: true
    - name: admin
      admin_layer: {}
admin:
  address:
    socket_address:
      protocol: TCP
      address: 0.0.0.0
      port_value: 9901
admin:
  address:
    socket_address:
      address: 127.0.0.1
      port_value: 9901

static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        address: 192.168.42.1
        port_value: 10000
    freebind: true
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          stat_prefix: ingress_http
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains: ["*"]
              routes:
              - match: {prefix: "/"}
                route: {cluster: service_local}
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
  clusters:
  - name: service_local
    connect_timeout: 30s
    type: STATIC
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: service_local
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: 127.0.0.1
                port_value: 10001
# TODO(htuch): Figure out how to do end-to-end testing with
# outgoing connections and free bind.
#    upstream_bind_config:
#      source_address:
#        address: 192.168.43.1
#      freebind: true
# Freebind testing

To manually validate the `IP_FREEBIND` behavior in Envoy, you can launch Envoy with
[freebind.yaml](freebind.yaml).

The listener free bind behavior can be verified with:

1. `envoy -c ./configs/freebind/freebind.yaml -l trace`
2. `sudo ifconfig lo:1 192.168.42.1/30 up`
3. `nc -v -l 0.0.0.0 10001`

To cleanup run `sudo ifconfig lo:1 down`.

TODO(htuch): Steps to verify upstream behavior.
[supervisord]
nodaemon=true
logfile=/var/log/supervisor/supervisord.log

[program:envoy-edge]
command=launch_envoy.sh -c /etc/envoy/envoy-edge.yaml %(ENV_ENVOY_EDGE_EXTRA_ARGS)s
  --log-format "(edge)[%%Y-%%m-%%d %%T.%%e][%%t][%%l][%%n] %%v" --base-id 0
redirect_stderr=true
stdout_logfile_maxbytes=0
stdout_logfile=/dev/stdout

[program:envoy-origin]
command=launch_envoy.sh -c /etc/envoy/envoy-origin.yaml %(ENV_ENVOY_ORIGIN_EXTRA_ARGS)s
  --log-format "(origin)[%%Y-%%m-%%d %%T.%%e][%%t][%%l][%%n] %%v" --base-id 1
redirect_stderr=true
stdout_logfile_maxbytes=0
stdout_logfile=/dev/stdout
#!/bin/bash

cd /etc/envoy || exit
envoy "$@"
overload_manager:
  refresh_interval: 0.25s
  resource_monitors:
  - name: "envoy.resource_monitors.fixed_heap"
    typed_config:
      "@type": type.googleapis.com/envoy.extensions.resource_monitors.fixed_heap.v3.FixedHeapConfig
      max_heap_size_bytes: 1073741824  # 1 GiB
  actions:
  - name: "envoy.overload_actions.shrink_heap"
    triggers:
    - name: "envoy.resource_monitors.fixed_heap"
      threshold:
        value: 0.95
  - name: "envoy.overload_actions.stop_accepting_requests"
    triggers:
    - name: "envoy.resource_monitors.fixed_heap"
      threshold:
        value: 0.98

static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        protocol: TCP
        address: 0.0.0.0
        port_value: 10002
    per_connection_buffer_limit_bytes: 32768
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          stat_prefix: ingress_http
          use_remote_address: true
          common_http_protocol_options:
            idle_timeout: 3600s  # 1 hour
            headers_with_underscores_action: REJECT_REQUEST
          http2_protocol_options:
            max_concurrent_streams: 100
            initial_stream_window_size: 65536  # 64 KiB
            initial_connection_window_size: 1048576  # 1 MiB
          stream_idle_timeout: 300s  # 5 mins, must be disabled for long-lived and streaming requests
          request_timeout: 300s  # 5 mins, must be disabled for long-lived and streaming requests
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains: ["*"]
              routes:
              - match:
                  path: "/blockedz"
                direct_response:
                  status: 200
                  body:
                    inline_string: "hidden treasure\n"
              - match:
                  prefix: "/"
                direct_response:
                  status: 200
                  body:
                    inline_string: "normal\n"
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
overload_manager:
  refresh_interval: 0.25s
  resource_monitors:
  - name: "envoy.resource_monitors.fixed_heap"
    typed_config:
      "@type": type.googleapis.com/envoy.extensions.resource_monitors.fixed_heap.v3.FixedHeapConfig
      # TODO: Tune for your system.
      max_heap_size_bytes: 1073741824  # 1 GiB
  actions:
  - name: "envoy.overload_actions.shrink_heap"
    triggers:
    - name: "envoy.resource_monitors.fixed_heap"
      threshold:
        value: 0.90
  - name: "envoy.overload_actions.stop_accepting_requests"
    triggers:
    - name: "envoy.resource_monitors.fixed_heap"
      threshold:
        value: 0.95

static_resources:
  listeners:
  - name: listener_https
    address:
      socket_address:
        protocol: TCP
        address: 0.0.0.0
        port_value: 10000
    per_connection_buffer_limit_bytes: 32768  # 32 KiB
    # Uncomment if Envoy is behind a load balancer that exposes client IP address using the PROXY protocol.
    # listener_filters:
    # - name: envoy.filters.listener.proxy_protocol
    #   typed_config:
    #     "@type": type.googleapis.com/envoy.extensions.filters.listener.proxy_protocol.v3.ProxyProtocol
    filter_chains:
    - transport_socket:
        name: envoy.transport_sockets.tls
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.DownstreamTlsContext
          common_tls_context:
            tls_certificates:
            - certificate_chain: {filename: "certs/servercert.pem"}
              private_key: {filename: "certs/serverkey.pem"}
      filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          stat_prefix: ingress_http
          use_remote_address: true
          common_http_protocol_options:
            idle_timeout: 3600s  # 1 hour
            headers_with_underscores_action: REJECT_REQUEST
          http2_protocol_options:
            max_concurrent_streams: 100
            initial_stream_window_size: 65536  # 64 KiB
            initial_connection_window_size: 1048576  # 1 MiB
          stream_idle_timeout: 300s  # 5 mins, must be disabled for long-lived and streaming requests
          request_timeout: 300s  # 5 mins, must be disabled for long-lived and streaming requests
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains: ["*"]
              # The exact route table is not super important in this example (this is the model
              # for the Google VRP scenario).
              routes:
              - match:
                  prefix: "/content"
                route:
                  cluster: service_foo
                  idle_timeout: 15s  # must be disabled for long-lived and streaming requests
              - match:
                  prefix: "/"
                direct_response:
                  status: 403
                  body:
                    inline_string: "denied\n"
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
  clusters:
  - name: service_foo
    connect_timeout: 5s
    per_connection_buffer_limit_bytes: 32768  # 32 KiB
    load_assignment:
      cluster_name: service_foo
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: 127.0.0.1
                port_value: 10002
    typed_extension_protocol_options:
      envoy.extensions.upstreams.http.v3.HttpProtocolOptions:
        "@type": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions
        explicit_http_config:
          http2_protocol_options:
            initial_stream_window_size: 65536  # 64 KiB
            initial_connection_window_size: 1048576  # 1 MiB
# This configuration takes incoming data on port 10000 and encapsulates it in a CONNECT
# request which is sent upstream port 10001.
# It can be used to test UDP tunneling as described in
# https://envoyproxy.io/docs/envoy/latest/intro/arch_overview/http/upgrades

admin:
  address:
    socket_address:
      protocol: TCP
      address: 127.0.0.1
      port_value: 9903
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        protocol: UDP
        address: 127.0.0.1
        port_value: 10000
    listener_filters:
    - name: envoy.filters.udp_listener.udp_proxy
      typed_config:
        '@type': type.googleapis.com/envoy.extensions.filters.udp.udp_proxy.v3.UdpProxyConfig
        stat_prefix: foo
        matcher:
          on_no_match:
            action:
              name: route
              typed_config:
                '@type': type.googleapis.com/envoy.extensions.filters.udp.udp_proxy.v3.Route
                cluster: cluster_0
        session_filters:
        - name: envoy.filters.udp.session.http_capsule
          typed_config:
            '@type': type.googleapis.com/envoy.extensions.filters.udp.udp_proxy.session.http_capsule.v3.FilterConfig
        tunneling_config:
          # note: proxy_host supports string substitution, for example setting "%FILTER_STATE(proxy.host.key:PLAIN)%"
          # will take the target host value from the session's filter state.
          proxy_host: proxy.host.com
          # note: target_host supports string substitution, for example setting "%FILTER_STATE(target.host.key:PLAIN)%"
          # will take the target host value from the session's filter state.
          target_host: target.host.com
          # note: The target port value can be overridden per-session by setting the required port value for
          # the filter state key ``udp.connect.target_port``.
          default_target_port: 443
          retry_options:
            max_connect_attempts: 2
          buffer_options:
            max_buffered_datagrams: 1024
            max_buffered_bytes: 16384
          headers_to_add:
          - header:
              key: original_dst_port
              value: "%DOWNSTREAM_LOCAL_PORT%"

  clusters:
  - name: cluster_0
    connect_timeout: 5s
    typed_extension_protocol_options:
      envoy.extensions.upstreams.http.v3.HttpProtocolOptions:
        "@type": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions
        explicit_http_config:
          http2_protocol_options: {}
    load_assignment:
      cluster_name: cluster_0
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: 127.0.0.1
                port_value: 10001
# This configuration terminates a POST request and sends the POST payload upstream.
# It can be used to test TCP tunneling as described in
# https://envoyproxy.io/docs/envoy/latest/intro/arch_overview/http/upgrades
# or used to test POST directly, by running `curl -k -v -x 127.0.0.1:10001 https://www.google.com`
admin:
  address:
    socket_address:
      protocol: TCP
      address: 127.0.0.1
      port_value: 9902
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        protocol: TCP
        address: 127.0.0.1
        port_value: 10001
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          stat_prefix: ingress_http
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains:
              - "*"
              routes:
              - match:
                  prefix: "/"
                  headers:
                  - name: ":method"
                    string_match:
                      exact: "POST"
                route:
                  cluster: service_google
                  upgrade_configs:
                  - upgrade_type: CONNECT
                    connect_config:
                      allow_post: true
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
          http2_protocol_options:
            allow_connect: true
  clusters:
  - name: service_google
    connect_timeout: 0.25s
    type: LOGICAL_DNS
    # Comment out the following line to test on v6 networks
    dns_lookup_family: V4_ONLY
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: service_google
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: www.google.com
                port_value: 443
static_resources:
  listeners:
  - address:
      socket_address:
        address: 0.0.0.0
        port_value: 10000
    traffic_direction: OUTBOUND
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          stat_prefix: ingress_http
          route_config:
            name: local_service
            virtual_hosts:
            - name: backend
              domains:
              - "*"
              routes:
              - match:
                  prefix: "/"
                route:
                  cluster: cluster1
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
          codec_type: AUTO
    listener_filters:
    - name: envoy.filters.listener.original_dst
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.filters.listener.original_dst.v3.OriginalDst
  clusters:
  - name: cluster1
    type: ORIGINAL_DST
    connect_timeout: 6s
    lb_policy: CLUSTER_PROVIDED
    dns_lookup_family: V4_ONLY
cluster_manager: {}
admin:
  address:
    socket_address:
      address: 127.0.0.1
      port_value: 9901
# Original destination cluster configuration and testing

An original destination cluster forwards requests to the same destination
the request was going to before being redirected to Envoy using an
iptables REDIRECT rule. `proxy_config.yaml` contains an example Envoy
configuration demonstrating the use of an original destination
cluster. `netns_setup.sh` and `netns_cleanup.sh` are provided as
examples for setting up and cleaning up, respectively, a network
namespace and the required iptables rule to redirect traffic to Envoy.

# Setting up

`netns_setup.sh` takes two arguments: the name of the new network
namespace and the prefix that is to be redirected. Envoy listener port
is set to 10000, which matches the configuration in
`proxy_config.yaml`.

This creates a network namespace `ns1` and redirects traffic from
there to Envoy listening on port 10000 if the destination address of
the traffic matches `173.194.222.0/24` :

```
sudo ./configs/original-dst-cluster/netns_setup.sh ns1 173.194.222.0/24
```

# Building and running Envoy

Build Envoy with debug options, so that the behavior can be better
observed from the logs:

```
bazel build //source/exe:envoy-static -c dbg
```

Then you should run Envoy with the provided example configuration:

```
bazel-out/local-dbg/bin/source/exe/envoy-static -c configs/original-dst-cluster/proxy_config.yaml -l debug
```

When running you should see periodical messages like `Cleaning up
stale original dst hosts.`

# Generating traffic

Next we generate traffic from the new network namespace hitting the
redirect rule. Run this from another terminal:

```
sudo ip netns exec ns1 curl -v 173.194.222.106:80
```

Most likely you'll see `301 Moved` in the curl response. In the rare
case of upstream connection timeout you'll see `503 Service
Unavailable` instead. The connection timeout setting on the
proxy_config.yaml is set to 6 seconds to make this less likely, but if
no host with the destination address exist then you will get this
response no matter how long the timeout setting.

You should see lines with `Adding host 173.194.222.106:80` being
logged by each Envoy thread, followed by `Keeping active host
173.194.222.106:80` and eventually `Removing stale host
173.194.222.106:80`, again multiple times, once from each Envoy
thread.

# Cleaning up

To properly remove the added network namespace and the iptables
configuration run `netns_cleanup.sh` with the same arguments as
the setup before:

```
sudo ./configs/original-dst-cluster/netns_cleanup.sh ns1 173.194.222.0/24
```

Finally, stop Envoy with `^C`.
#!/usr/bin/env bash
#
# Cleanup network namespace after testing Envoy original_dst cluster
#

NETNS=$1
TARGET_IP=$2
ENVOY_PORT=10000

# remove iptables rule
iptables -t nat -D PREROUTING --src 0/0 --dst "$TARGET_IP" -p tcp --dport 80 -j REDIRECT --to-ports "$ENVOY_PORT"

# delete network namespace
ip netns delete "$NETNS"

# delete veth pair
ip link del "$NETNS-veth0" type veth peer name "$NETNS-veth1"
#!/usr/bin/env bash
#
# Example setup network namespace for testing Envoy original_dst cluster
# Clean up with the cleanup script with the same arguments.
#
# Test with:
# $sudo ip netns exec ${NETNS} curl -v ${TARGET_IP}:80
#
set -e

# name of the network namespace
NETNS=$1

# IP address or prefix that will be redirected
TARGET_IP=$2

# Local Envoy Listener port number
ENVOY_PORT=10000

# Create veth pair
ip link add "$NETNS-veth0" type veth peer name "$NETNS-veth1"
ifconfig "$NETNS-veth0" 10.0.200.2/24 up

# Create network namespace
ip netns add "$NETNS"
# Move veth peer to the namespace
ip link set "$NETNS-veth1" netns "$NETNS"

# Configure network namespace
ip netns exec "$NETNS" ifconfig lo 127.0.0.1 up
ip netns exec "$NETNS" ifconfig "$NETNS-veth1" 10.0.200.1/24 up
ip netns exec "$NETNS" ip route add default via 10.0.200.2

#configure iptables REDIRECT in the PREROUTING hook of the root name space nat table.
iptables -t nat -I PREROUTING --src 0/0 --dst "$TARGET_IP" -p tcp --dport 80 -j REDIRECT --to-ports "$ENVOY_PORT"
admin:
  address:
    socket_address:
      protocol: TCP
      address: 0.0.0.0
      port_value: 9901
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        protocol: TCP
        address: 0.0.0.0
        port_value: 10000
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          stat_prefix: ingress_http
          access_log:
          - name: envoy.access_loggers.stdout
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.access_loggers.stream.v3.StdoutAccessLog
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains: ["*"]
              routes:
              - match:
                  prefix: "/"
                route:
                  host_rewrite_literal: www.envoyproxy.io
                  cluster: service_envoyproxy_io
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
  clusters:
  - name: service_envoyproxy_io
    type: LOGICAL_DNS
    # Comment out the following line to test on v6 networks
    dns_lookup_family: V4_ONLY
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: service_envoyproxy_io
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: www.envoyproxy.io
                port_value: 443
    typed_extension_protocol_options:
      envoy.extensions.upstreams.http.v3.HttpProtocolOptions:
        "@type": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions
        explicit_http_config:
          http2_protocol_options:
            {}
        http_filters:
        - name: buffer
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.filters.http.buffer.v3.Buffer
            max_request_bytes: 5242880
        - name: envoy.filters.http.upstream_codec
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.filters.http.upstream_codec.v3.UpstreamCodec
    transport_socket:
      name: envoy.transport_sockets.tls
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
        sni: www.envoyproxy.io
# This configuration terminates a CONNECT request and sends the CONNECT payload upstream.
# It can be used to test TCP tunneling as described in
# https://envoyproxy.io/docs/envoy/latest/intro/arch_overview/http/upgrades
# or used to test CONNECT directly, by running `curl -k -v -x 127.0.0.1:10001 https://www.google.com`
admin:
  address:
    socket_address:
      protocol: TCP
      address: 127.0.0.1
      port_value: 9902
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        protocol: TCP
        address: 127.0.0.1
        port_value: 10001
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          stat_prefix: ingress_http
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains:
              - "*"
              routes:
              - match:
                  connect_matcher:
                    {}
                route:
                  cluster: service_google
                  upgrade_configs:
                  - upgrade_type: CONNECT
                    connect_config:
                      {}
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
          http2_protocol_options:
            allow_connect: true
          upgrade_configs:
          - upgrade_type: CONNECT
  clusters:
  - name: service_google
    connect_timeout: 0.25s
    type: LOGICAL_DNS
    # Comment out the following line to test on v6 networks
    dns_lookup_family: V4_ONLY
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: service_google
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: www.google.com
                port_value: 443
# This will forward CONNECT requests from a downstream connecting on 127.0.0.1:10001
# to an upstream listening on 127.0.0.1:10002
admin:
  address:
    socket_address:
      protocol: TCP
      address: 127.0.0.1
      port_value: 9902
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        protocol: TCP
        address: 127.0.0.1
        port_value: 10001
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          stat_prefix: ingress_http
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains:
              - "*"
              routes:
              - match:
                  connect_matcher:
                    {}
                route:
                  cluster: cluster_0
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
          http2_protocol_options:
            allow_connect: true
          upgrade_configs:
          - upgrade_type: CONNECT
  clusters:
  - name: cluster_0
    connect_timeout: 5s
    typed_extension_protocol_options:
      envoy.extensions.upstreams.http.v3.HttpProtocolOptions:
        "@type": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions
        explicit_http_config:
          http2_protocol_options: {}
    load_assignment:
      cluster_name: cluster_0
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: 127.0.0.1
                port_value: 10002
import argparse

import pathlib
import sys

from yaml.scanner import ScannerError

from google.protobuf.json_format import ParseError

from envoy.base.utils import ProtobufValidator

# TODO (phlax): move this to `envoy.code.check`


def main():
    errors = []
    parser = argparse.ArgumentParser()
    parser.add_argument('paths', nargs="+")
    parser.add_argument('--descriptor_path')
    parsed = parser.parse_args(sys.argv[1:])
    protobuf = ProtobufValidator(parsed.descriptor_path)

    for example in parsed.paths:
        try:
            protobuf.validate_yaml(pathlib.Path(example).read_text())
        except (ParseError, KeyError, ScannerError) as e:
            errors.append(example)
            print(f"\nERROR (validation failed): {example}\n{e}\n\n")

    if errors:
        raise SystemExit(f"ERROR: some configuration files ({len(errors)}) failed to validate")


if __name__ == "__main__":
    main()
# An example config which accepts HTTP/1 requests over TCP and forwards them to google using HTTP/3
admin:
  address:
    socket_address:
      protocol: TCP
      address: 0.0.0.0
      port_value: 9901
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        protocol: TCP
        address: 0.0.0.0
        port_value: 10000
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          scheme_header_transformation:
            scheme_to_overwrite: https
          stat_prefix: ingress_http
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains: ["*"]
              routes:
              - match:
                  prefix: "/"
                route:
                  host_rewrite_literal: www.google.com
                  cluster: service_google
          http_filters:
          - name: alternate_protocols_cache
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.alternate_protocols_cache.v3.FilterConfig
              alternate_protocols_cache_options:
                name: default_alternate_protocols_cache
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
  clusters:
  - name: service_google
    connect_timeout: 30s
    type: LOGICAL_DNS
    # Comment out the following line to test on v6 networks
    dns_lookup_family: V4_ONLY
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: service_google
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: www.google.com
                port_value: 443
    typed_extension_protocol_options:
      envoy.extensions.upstreams.http.v3.HttpProtocolOptions:
        "@type": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions
        auto_config:
          http3_protocol_options: {}
          alternate_protocols_cache_options:
            name: default_alternate_protocols_cache
        common_http_protocol_options:
          idle_timeout: 1s
    transport_socket:
      name: envoy.transport_sockets.quic
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.transport_sockets.quic.v3.QuicUpstreamTransport
        upstream_tls_context:
          sni: www.google.com
# This will forward CONNECT-UDP requests from a downstream connecting on 127.0.0.1:10001 to an
# upstream listening on 127.0.0.1:10002.
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        protocol: UDP
        address: 127.0.0.1
        port_value: 10001
    udp_listener_config:
      quic_options: {}
      downstream_socket_config:
        prefer_gro: true
    filter_chains:
    - transport_socket:
        name: envoy.transport_sockets.quic
        typed_config:
          '@type': type.googleapis.com/envoy.extensions.transport_sockets.quic.v3.QuicDownstreamTransport
          downstream_tls_context:
            common_tls_context:
              tls_certificates:
              - certificate_chain:
                  filename: certs/servercert.pem
                private_key:
                  filename: certs/serverkey.pem
      filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          codec_type: HTTP3
          stat_prefix: ingress_http
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains:
              - "*"
              routes:
              - match:
                  connect_matcher:
                    {}
                route:
                  cluster: cluster_0
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
          http3_protocol_options:
            allow_extended_connect: true
          upgrade_configs:
          - upgrade_type: CONNECT-UDP
  clusters:
  - name: cluster_0
    typed_extension_protocol_options:
      envoy.extensions.upstreams.http.v3.HttpProtocolOptions:
        "@type": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions
        explicit_http_config:
          http3_protocol_options:
            allow_extended_connect: true
    load_assignment:
      cluster_name: cluster_0
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: 127.0.0.1
                port_value: 10002
    transport_socket:
      name: envoy.transport_sockets.quic
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.transport_sockets.quic.v3.QuicUpstreamTransport
        upstream_tls_context:
          common_tls_context:
            tls_certificates:
            - certificate_chain:
                filename: certs/servercert.pem
              private_key:
                filename: certs/serverkey.pem
# This configuration takes incoming data on port 10000 and encapsulates it in a POST
# request which is sent upstream port 10001.
# It can be used to test TCP tunneling as described in
# https://envoyproxy.io/docs/envoy/latest/intro/arch_overview/http/upgrades
# and running `curl -H 'Host: www.google.com' --resolve www.google.com:10000:127.0.0.1 https://www.google.com:10000`

admin:
  address:
    socket_address:
      protocol: TCP
      address: 127.0.0.1
      port_value: 9903
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        protocol: TCP
        address: 127.0.0.1
        port_value: 10000
    filter_chains:
    - filters:
      - name: tcp
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.tcp_proxy.v3.TcpProxy
          stat_prefix: tcp_stats
          cluster: "cluster_0"
          tunneling_config:
            hostname: host.com:443
            use_post: true
  clusters:
  - name: cluster_0
    connect_timeout: 5s
    # This ensures HTTP/2 POST is used for establishing the tunnel.
    typed_extension_protocol_options:
      envoy.extensions.upstreams.http.v3.HttpProtocolOptions:
        "@type": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions
        explicit_http_config:
          http2_protocol_options: {}
    load_assignment:
      cluster_name: cluster_0
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: 127.0.0.1
                port_value: 10001
#!/bin/bash

set -e

CONFIGGEN="$1"
shift
TARGETFILE="$1"
shift
OUT_DIR="$1"
shift

mkdir -p "$OUT_DIR/certs"
mkdir -p "$OUT_DIR/lib"
mkdir -p "$OUT_DIR/protos"

if [[ "$CONFIGGEN" != "NO_CONFIGGEN" ]]; then
  "$CONFIGGEN" "$OUT_DIR"
fi

for FILE in "$@"; do
  case "$FILE" in
  *.pem|*.der)
    cp "$FILE" "$OUT_DIR/certs"
    ;;
  *.lua|*.wasm|*.so)
    cp "$FILE" "$OUT_DIR/lib"
    ;;
  *.pb)
    cp "$FILE" "$OUT_DIR/protos"
    ;;
  *)

    FILENAME="$(echo "$FILE" | sed -e 's/.*examples\///g')"
    # Configuration filenames may conflict. To avoid this we use the full path.
    cp "$FILE" "$OUT_DIR/${FILENAME//\//_}"
    ;;
  esac
done

# tar is having issues with -C for some reason so just cd into OUT_DIR.
# Ignore files that don't exist so this script works for both core and contrib.
# shellcheck disable=SC2046
# shellcheck disable=SC2035
# TODO(mattklein123): I can't make this work when using the shellcheck suggestions. Try
# to fix this.
(cd "$OUT_DIR"; tar -hcf "$TARGETFILE" -- $(ls *.yaml certs/*.pem certs/*.der protos/*.pb lib/*.so lib/*.wasm lib/*.lua 2>/dev/null))
# This configuration takes incoming HTTP requests on port 10000 and encapsulates it in a CONNECT
# request which is sent upstream port 10001.
# `curl -H 'Host: www.google.com' --resolve www.google.com:10000:127.0.0.1 https://www.google.com:10000`
bootstrap_extensions:
- name: envoy.bootstrap.internal_listener
  typed_config:
    "@type": type.googleapis.com/envoy.extensions.bootstrap.internal_listener.v3.InternalListener
static_resources:
  listeners:
  - name: http
    address:
      socket_address:
        protocol: TCP
        address: 127.0.0.1
        port_value: 10000
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          stat_prefix: ingress_http
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains: ["*"]
              routes:
              - match:
                  prefix: "/"
                route:
                  cluster: encap_cluster
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
  - name: encap
    internal_listener: {}
    filter_chains:
    - filters:
      - name: tcp
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.tcp_proxy.v3.TcpProxy
          stat_prefix: tcp_stats
          cluster: cluster_0
          tunneling_config:
            hostname: host.com:443
  clusters:
  - name: encap_cluster
    load_assignment:
      cluster_name: encap_cluster
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              envoy_internal_address:
                server_listener_name: encap
  - name: cluster_0
    # This ensures HTTP/2 CONNECT is used for establishing the tunnel.
    typed_extension_protocol_options:
      envoy.extensions.upstreams.http.v3.HttpProtocolOptions:
        "@type": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions
        explicit_http_config:
          http2_protocol_options: {}
    load_assignment:
      cluster_name: cluster_0
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: 127.0.0.1
                port_value: 10001
admin:
  address:
    socket_address:
      protocol: TCP
      address: 0.0.0.0
      port_value: 9901
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        protocol: TCP
        address: 0.0.0.0
        port_value: 10000
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          scheme_header_transformation:
            scheme_to_overwrite: https
          stat_prefix: ingress_http
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains: ["*"]
              routes:
              - match:
                  prefix: "/"
                route:
                  host_rewrite_literal: www.envoyproxy.io
                  cluster: service_envoyproxy_io
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
  clusters:
  - name: service_envoyproxy_io
    connect_timeout: 30s
    type: LOGICAL_DNS
    # Comment out the following line to test on v6 networks
    dns_lookup_family: V4_ONLY
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: service_envoyproxy_io
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: www.envoyproxy.io
                port_value: 443
    transport_socket:
      name: envoy.transport_sockets.tls
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
        sni: www.envoyproxy.io
admin:
  address:
    socket_address:
      protocol: TCP
      address: 0.0.0.0
      port_value: 9901
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        protocol: TCP
        address: 0.0.0.0
        port_value: 10000
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          stat_prefix: ingress_http
          access_log:
          - name: envoy.access_loggers.stdout
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.access_loggers.stream.v3.StdoutAccessLog
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains: ["*"]
              routes:
              - match:
                  prefix: "/"
                route:
                  host_rewrite_literal: www.envoyproxy.io
                  cluster: service_envoyproxy_io
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
  clusters:
  - name: service_envoyproxy_io
    type: LOGICAL_DNS
    # Comment out the following line to test on v6 networks
    dns_lookup_family: V4_ONLY
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: service_envoyproxy_io
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: www.envoyproxy.io
                port_value: 443
    transport_socket:
      name: envoy.transport_sockets.tap
      typed_config:
        '@type': type.googleapis.com/envoy.extensions.transport_sockets.tap.v3.Tap
        common_config:
          admin_config:
            config_id: api-gateway
        transport_socket:
          name: envoy.transport_sockets.tls
          typed_config:
            '@type': type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
            allow_renegotiation: true
            common_tls_context:
              tls_params:
                tls_minimum_protocol_version: TLSv1_2
            sni: "service"
load("@base_pip3//:requirements.bzl", "requirement")
load("@rules_python//python:defs.bzl", "py_binary")
load(
    "//bazel:envoy_build_system.bzl",
    "envoy_package",
)

licenses(["notice"])  # Apache 2

envoy_package()

exports_files([
    "google-vrp/envoy-edge.yaml",
])

py_binary(
    name = "configgen",
    srcs = ["configgen.py"],
    data = glob([
        "*.yaml",
    ]),
    deps = [
        requirement("jinja2"),
    ],
)

filegroup(
    name = "configs",
    srcs = glob(
        [
            "**/*.yaml",
        ],
        exclude = [
            "using_deprecated_config.yaml",
            "**/*.template.yaml",
            "freebind/freebind.yaml",
            "envoy-tap-config.yaml",
            "envoy-demo.yaml",
        ],
    ) + select({
        "//bazel:apple": ["envoy-demo.yaml"],
        "//bazel:windows_x86_64": [],
        "//bazel:disable_admin_functionality": [],
        "//conditions:default": [
            "envoy-demo.yaml",
            "envoy-tap-config.yaml",
            "freebind/freebind.yaml",
        ],
    }),
)

genrule(
    name = "example_configs",
    srcs = [
        ":configs",
        "//examples:configs",
        "//examples:certs",
        "//examples:lua",
        "//examples/wasm-cc:configs",
        "//docs:configs",
        "//docs:proto_examples",
        "//test/config/integration/certs",
    ],
    outs = ["example_configs.tar"],
    cmd = (
        "$(location configgen.sh) $(location configgen) example_configs.tar $(@D) " +
        "$(locations :configs) " +
        "$(locations //examples:configs) " +
        "$(locations //examples:certs) " +
        "$(locations //examples:lua) " +
        "$(locations //examples/wasm-cc:configs) " +
        "$(locations //docs:configs) " +
        "$(locations //docs:proto_examples) " +
        "$(locations //test/config/integration/certs)"
    ),
    tools = [
        "configgen.sh",
        ":configgen",
    ],
)

genrule(
    name = "example_contrib_configs",
    srcs = [
        "//docs:contrib_configs",
        "//contrib:configs",
        "//examples:contrib_configs",
        "//examples:certs",
        "//test/config/integration/certs",
    ],
    outs = ["example_contrib_configs.tar"],
    cmd = (
        "$(location configgen.sh) NO_CONFIGGEN example_contrib_configs.tar $(@D) " +
        "$(locations //contrib:configs) " +
        "$(locations //docs:contrib_configs) " +
        "$(locations //examples:contrib_configs) " +
        "$(locations //examples:certs) " +
        "$(locations //test/config/integration/certs)"
    ),
    tools = [
        "configgen.sh",
        ":configgen",
    ],
)

py_binary(
    name = "example_configs_validation",
    srcs = ["example_configs_validation.py"],
    args = (
        "--descriptor_path=$(location @envoy_api//:v3_proto_set)",
        "$(locations :configs) ",
        "$(locations //examples:configs) ",
        "$(locations //docs:configs) ",
    ),
    data = [
        ":configs",
        "//docs:configs",
        "//examples:configs",
        "@envoy_api//:v3_proto_set",
    ],
    deps = [requirement("envoy.base.utils")],
)
{% import 'routing_helper.template.yaml' as helper with context -%}
name: local_route
virtual_hosts:
- name: www
  domains:
  - www.yourcompany.com
  routes:
  - match:
      prefix: "/foo/bar"
      runtime_fraction:
        default_value:
          numerator: 0
          denominator: HUNDRED
        runtime_key: routing.www.use_service_2
    route:
      {{ helper.make_route('service2')|indent(4) }}
  - match:
      prefix: "/"
    route:
      {{ helper.make_route('service1')|indent(4) }}
  require_tls: ALL
  rate_limits:
    actions:
      remote_address: {}
- name: www_redirect
  domains:
  - wwww.yourcompany.net
  routes:
  - match:
      prefix: "/"
    redirect:
      host_redirect: www.yourcompany.net
  require_tls: ALL
  rate_limits:
  - actions:
      remote_address: {}
- name: api
  domains:
  - api.yourcompany.net
  routes:
  - match:
      path: "/foo/bar"
    route:
      {{ helper.make_route('service3')|indent(4) }}
  - match:
      prefix: "/"
    route:
      {{ helper.make_route('service1')|indent(4) }}
  require_tls: EXTERNAL_ONLY
  rate_limits:
  - actions:
      remote_address: {}
{%- macro make_route_internal(cluster, options) %}
  cluster: {{ cluster }}
  {%- if 'timeout' in options -%}
  timeout: {{ options['timeout'] }},
  {% endif %}
  retry_policy:
    retry_on: 5xx
{%- endmacro %}
{%- macro make_route(cluster) -%}
  {{ make_route_internal(cluster, clusters.get(cluster, {})) }}
{%- endmacro -%}
{%- macro internal_cluster_definition(service, options) -%}
  name: {{ service }}
  connect_timeout: 0.250s
  type: EDS
  eds_cluster_config:
    eds_config:
      resource_api_version: V3
      api_config_source:
        api_type: REST
        transport_api_version: V3
        cluster_names:
        - sds
        refresh_delay: 30s
    service_name: {{ service }}
  lb_policy: LEAST_REQUEST
  {% if 'max_requests' in options -%}
  circuit_breakers:
    thresholds:
    - priority: DEFAULT
      max_requests: {{ options['max_requests'] }}
  {% endif -%}
  health_checks:
  - http_health_check:
      path: /healthcheck
      service_name_matcher:
        prefix: accidents
    timeout: 2s
    interval: 5s
    interval_jitter: 5s
    unhealthy_threshold: 2
    healthy_threshold: 2
  outlier_detection:
    success_rate_stdev_factor: 1900
  typed_extension_protocol_options:
    envoy.extensions.upstreams.http.v3.HttpProtocolOptions:
      "@type": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions
      explicit_http_config:
        http2_protocol_options: {}
{% endmacro -%}
# This configuration takes incoming data on port 10000,10002 and encapsulates it in a CONNECT
# request which is sent upstream port 10001. The difference is that if the data was from port
# 10002, Envoy adds a "foo: bar" header in the CONNECT request.
# Seeing this "foo: bar" header, another Envoy running with the configuration ``terminate_http1_connect.yaml``
# will terminate the CONNECT request and establish tcp connection to 127.0.0.1:10003.
#
# It can be used to test TCP tunneling as described in
# https://envoyproxy.io/docs/envoy/latest/intro/arch_overview/http/upgrades
# and running `curl -x 127.0.0.1:10000 https://www.google.com`,
# or running `curl -H 'Host: www.google.com' --resolve www.google.com:10000:127.0.0.1 https://www.google.com:10000`

admin:
  address:
    socket_address:
      protocol: TCP
      address: 127.0.0.1
      port_value: 9903
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        protocol: TCP
        address: 127.0.0.1
        port_value: 10000
    filter_chains:
    - filters:
      - name: tcp
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.tcp_proxy.v3.TcpProxy
          stat_prefix: tcp_stats
          cluster: "cluster_0"
          tunneling_config:
            hostname: host.com:443
  - name: listener_1
    address:
      socket_address:
        protocol: TCP
        address: 127.0.0.1
        port_value: 10002
    filter_chains:
    - filters:
      - name: tcp
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.tcp_proxy.v3.TcpProxy
          stat_prefix: tcp_stats
          cluster: "cluster_0"
          tunneling_config:
            # The upstream request content would be ``CONNECT 127.0.0.1:10003 HTTP/1.1``.
            hostname: 127.0.0.1:10003
            headers_to_add:
            - header:
                key: foo
                value: bar
  clusters:
  - name: cluster_0
    connect_timeout: 5s
    # This ensures HTTP/1.1 CONNECT is used for establishing the tunnel.
    typed_extension_protocol_options:
      envoy.extensions.upstreams.http.v3.HttpProtocolOptions:
        "@type": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions
        explicit_http_config:
          http_protocol_options: {}
    load_assignment:
      cluster_name: cluster_0
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: 127.0.0.1
                port_value: 10001
# This configuration terminates a CONNECT-UDP request and sends UDP payloads directly over UDP to the target.
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        protocol: UDP
        address: 127.0.0.1
        port_value: 10001
    udp_listener_config:
      quic_options: {}
      downstream_socket_config:
        prefer_gro: true
    filter_chains:
    - transport_socket:
        name: envoy.transport_sockets.quic
        typed_config:
          '@type': type.googleapis.com/envoy.extensions.transport_sockets.quic.v3.QuicDownstreamTransport
          downstream_tls_context:
            common_tls_context:
              tls_certificates:
              - certificate_chain:
                  filename: certs/servercert.pem
                private_key:
                  filename: certs/serverkey.pem
      filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          codec_type: HTTP3
          stat_prefix: ingress_http
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains:
              - "*"
              routes:
              - match:
                  connect_matcher:
                    {}
                route:
                  cluster: service_google
                  upgrade_configs:
                  - upgrade_type: CONNECT-UDP
                    connect_config:
                      {}
          http_filters:
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
          http3_protocol_options:
            allow_extended_connect: true
          upgrade_configs:
          - upgrade_type: CONNECT-UDP
  clusters:
  - name: service_google
    type: LOGICAL_DNS
    # Comment out the following line to test on v6 networks
    dns_lookup_family: V4_ONLY
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: service_google
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: www.google.com
                port_value: 443
# This configuration terminates a CONNECT-UDP request and sends UDP payloads directly over UDP to the target.
# The configured dynamic forward proxy enables DNS resolution at the proxy to suppot arbitrary target domain names.
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        protocol: UDP
        address: 127.0.0.1
        port_value: 10001
    udp_listener_config:
      quic_options: {}
      downstream_socket_config:
        prefer_gro: true
    filter_chains:
    - transport_socket:
        name: envoy.transport_sockets.quic
        typed_config:
          '@type': type.googleapis.com/envoy.extensions.transport_sockets.quic.v3.QuicDownstreamTransport
          downstream_tls_context:
            common_tls_context:
              tls_certificates:
              - certificate_chain:
                  filename: certs/servercert.pem
                private_key:
                  filename: certs/serverkey.pem
      filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          codec_type: HTTP3
          stat_prefix: ingress_http
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains:
              - "*"
              routes:
              - match:
                  connect_matcher:
                    {}
                route:
                  cluster: dynamic_forward_proxy_cluster
                  upgrade_configs:
                  - upgrade_type: CONNECT-UDP
                    connect_config:
                      {}
          http_filters:
          - name: envoy.filters.http.dynamic_forward_proxy
            typed_config:
              '@type': type.googleapis.com/envoy.extensions.filters.http.dynamic_forward_proxy.v3.FilterConfig
              dns_cache_config:
                name: dynamic_forward_proxy_cache_config
                dns_lookup_family: V4_ONLY
          - name: envoy.filters.http.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
          http3_protocol_options:
            allow_extended_connect: true
          upgrade_configs:
          - upgrade_type: CONNECT-UDP
  clusters:
  - name: dynamic_forward_proxy_cluster
    lb_policy: CLUSTER_PROVIDED
    cluster_type:
      name: envoy.clusters.dynamic_forward_proxy
      typed_config:
        '@type': type.googleapis.com/envoy.extensions.clusters.dynamic_forward_proxy.v3.ClusterConfig
        dns_cache_config:
          name: dynamic_forward_proxy_cache_config
          dns_lookup_family: V4_ONLY
---
Language:        Cpp
AccessModifierOffset: -2
ColumnLimit: 100
DerivePointerAlignment: false
PointerAlignment: Left
SortIncludes: false
TypenameMacros: ['STACK_OF']
...

---
Language: Proto
ColumnLimit: 100
SpacesInContainerLiterals: false
AllowShortFunctionsOnASingleLine: false
ReflowComments: false
...
name: Mobile/iOS tests

permissions:
  contents: read

on:
  workflow_run:
    workflows:
    - Request
    types:
    - completed


jobs:
  load:
    secrets:
      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}
      app-id: ${{ secrets.ENVOY_CI_APP_ID }}
      lock-app-key: ${{ secrets.ENVOY_CI_MUTEX_APP_KEY }}
      lock-app-id: ${{ secrets.ENVOY_CI_MUTEX_APP_ID }}
    permissions:
      actions: read
      contents: read
      packages: read
      pull-requests: read
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    uses: ./.github/workflows/_load.yml
    with:
      cache-docker: false
      check-name: mobile-ios-tests

  tests:
    permissions:
      contents: read
      packages: read
    uses: ./.github/workflows/_run.yml
    if: ${{ fromJSON(needs.load.outputs.request).run.mobile-ios-tests }}
    needs: load
    name: ios-tests
    with:
      args: ${{ matrix.args }}
      command: ./bazelw
      container-command:
      request: ${{ needs.load.outputs.request }}
      runs-on: macos-12
      source: |
        # TODO(fredyw): A workaround since mobile/WORKSPACE requires Android SDK to be available
        # and the GitHub Action runner image no longer includes Android SDK 30:
        # https://github.com/actions/runner-images/issues/8952
        ./ci/mac_ci_setup.sh --android
      steps-post: ${{ matrix.steps-post }}
      target: ${{ matrix.target }}
      timeout-minutes: ${{ matrix.timeout-minutes }}
      trusted: ${{ fromJSON(needs.load.outputs.trusted) }}
      working-directory: mobile
    strategy:
      fail-fast: false
      matrix:
        include:
        - name: Run swift library tests
          args: >-
            test
            --config=mobile-remote-ci-macos-ios-swift
            //test/swift/...
          target: swift-tests
          timeout-minutes: 120
        - name: Run Objective-C library tests
          args: >-
            test
            --config=mobile-remote-ci-macos-ios-obj-c
            //test/objective-c/...
            //test/cc/unit:envoy_config_test
          target: c-and-objc-tests
          timeout-minutes: 120

  request:
    secrets:
      app-id: ${{ secrets.ENVOY_CI_APP_ID }}
      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}
    permissions:
      actions: read
      contents: read
      pull-requests: read
    if: >-
      ${{ always()
          && github.event.workflow_run.conclusion == 'success'
          && fromJSON(needs.load.outputs.request).run.mobile-ios-tests }}
    needs:
    - load
    - tests
    uses: ./.github/workflows/_finish.yml
    with:
      needs: ${{ toJSON(needs) }}
name: CodeQL/push

permissions:
  contents: read

on:
  push:
    paths:
    - include/**
    - source/common/**
    branches-ignore:
    - dependabot/**
  pull_request:

concurrency:
  group: ${{ github.head_ref-github.workflow || github.run_id }}
  cancel-in-progress: true

env:
  SEARCH_FOLDER: //source/common/...


jobs:
  CodeQL-Build:
    permissions:
      actions: read
      contents: read
      # for github/codeql-action/analyze to upload SARIF results
      security-events: write
      pull-requests: read
    runs-on: ubuntu-20.04
    if: github.repository == 'envoyproxy/envoy'
    steps:
    - name: Checkout repository
      uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11  # v4.1.1
      with:
        fetch-depth: 2

    - name: Get build targets
      run: |
        # TODO(phlax): Shift this to an action
        compare_head () {
            while IFS= read -r line; do
                if [[ -n "$line" ]]; then
                    bazel query "rdeps($SEARCH_FOLDER, $line, 1)"  2> /dev/null
                fi
            done < <(git diff --name-only HEAD "${1}" -- source/* include/*)
        }
        if [[ "$GIT_EVENT" == "pull_request" ]]; then
            git fetch "${GITHUB_SERVER_URL}/${GITHUB_REPOSITORY}" main 2> /dev/null
            TO_OTHER=FETCH_HEAD
        else
            TO_OTHER=HEAD^1
        fi
        BUILD_TARGETS="$(compare_head "$TO_OTHER" | grep -v '\.cc\|\.h' | sort -u | head -n 3)"
        echo 'BUILD_TARGETS<<EOF' >> $GITHUB_ENV
        echo "$BUILD_TARGETS" >> $GITHUB_ENV
        echo 'EOF' >> $GITHUB_ENV
      env:
        GIT_EVENT: ${{ github.event_name }}

    - name: Free disk space
      if: ${{ env.BUILD_TARGETS != '' }}
      uses: envoyproxy/toolshed/gh-actions/diskspace@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      with:
        to_remove: |
          /usr/local/lib/android

    - name: Initialize CodeQL
      if: ${{ env.BUILD_TARGETS != '' }}
      uses: github/codeql-action/init@cdcdbb579706841c47f7063dda365e292e5cad7a  # codeql-bundle-v2.13.4
      with:
        languages: cpp

    - name: Install deps
      if: ${{ env.BUILD_TARGETS != '' }}
      shell: bash
      run: |
       sudo apt-get update --error-on=any
       sudo apt-get install --yes libtool cmake automake autoconf make ninja-build curl unzip virtualenv openjdk-11-jdk build-essential libc++1
       # Note: the llvm/clang version should match the version specifed in:
       #  - bazel/repository_locations.bzl
       #  - .github/workflows/codeql-daily.yml
       #  - https://github.com/envoyproxy/envoy-build-tools/blob/main/build_container/build_container_ubuntu.sh#L84
       mkdir -p bin/clang14
       cd bin/clang14
       wget https://github.com/llvm/llvm-project/releases/download/llvmorg-14.0.0/clang+llvm-14.0.0-x86_64-linux-gnu-ubuntu-18.04.tar.xz
       tar -xf clang+llvm-14.0.0-x86_64-linux-gnu-ubuntu-18.04.tar.xz --strip-components 1
       export PATH=bin/clang14/bin:$PATH

    - name: Build
      if: ${{ env.BUILD_TARGETS != '' }}
      run: |
       bazel/setup_clang.sh bin/clang14
       bazel shutdown
       bazel build \
           -c fastbuild \
           --spawn_strategy=local \
           --discard_analysis_cache \
           --nouse_action_cache \
           --config clang \
           --config libc++ \
           $BUILD_TARGETS
       echo -e "Built targets...\n$BUILD_TARGETS"

    - name: Clean Artifacts
      if: ${{ env.BUILD_TARGETS != '' }}
      run: |
        git clean -xdf

    - name: Perform CodeQL Analysis
      if: ${{ env.BUILD_TARGETS != '' }}
      uses: github/codeql-action/analyze@cdcdbb579706841c47f7063dda365e292e5cad7a  # codeql-bundle-v2.13.4
name: Envoy/macOS

permissions:
  contents: read

on:
  workflow_run:
    workflows:
    - Request
    types:
    - completed

concurrency:
  group: ${{ github.head_ref || github.run_id }}-${{ github.workflow }}
  cancel-in-progress: true


jobs:
  load:
    secrets:
      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}
      app-id: ${{ secrets.ENVOY_CI_APP_ID }}
      lock-app-key: ${{ secrets.ENVOY_CI_MUTEX_APP_KEY }}
      lock-app-id: ${{ secrets.ENVOY_CI_MUTEX_APP_ID }}
    permissions:
      actions: read
      contents: read
      packages: read
      pull-requests: read
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    uses: ./.github/workflows/_load.yml
    with:
      cache-docker: false
      check-name: macos

  macos:
    permissions:
      contents: read
      packages: read
    secrets:
      rbe-key: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
    if: ${{ fromJSON(needs.load.outputs.request).run.build-macos }}
    needs:
    - load
    uses: ./.github/workflows/_run.yml
    name: CI ${{ matrix.name || matrix.target }}
    with:
      command:
      container-command:
      request: ${{ needs.load.outputs.request }}
      runs-on: macos-12-xl
      steps-post:
      steps-pre: ${{ matrix.steps-pre }}
      target: ${{ matrix.target }}
      trusted: ${{ fromJSON(needs.load.outputs.trusted) }}
    strategy:
      fail-fast: false
      matrix:
        include:
        - target: ci/mac_ci_steps.sh
          name: macOS
          steps-pre: |
            - run: ./ci/mac_ci_setup.sh
              shell: bash
              name: Setup macos
          source: |
            GCP_SERVICE_ACCOUNT_KEY_PATH=$(mktemp -t gcp_service_account.XXXXXX.json)
            bash -c "echo \"${RBE_KEY}\" | base64 --decode > \"${GCP_SERVICE_ACCOUNT_KEY_PATH}\""
            _BAZEL_BUILD_EXTRA_OPTIONS=(
              --remote_download_toplevel
              --flaky_test_attempts=2
              --config=cache-google
              --config=ci
              --google_credentials=${GCP_SERVICE_ACCOUNT_KEY_PATH})
            export BAZEL_BUILD_EXTRA_OPTIONS=${_BAZEL_BUILD_EXTRA_OPTIONS[*]}

  request:
    permissions:
      actions: read
      contents: read
      pull-requests: read
    secrets:
      app-id: ${{ secrets.ENVOY_CI_APP_ID }}
      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}
    if: >-
      ${{ always()
          && github.event.workflow_run.conclusion == 'success'
          && fromJSON(needs.load.outputs.request).run.build-macos }}
    needs:
    - load
    - macos
    uses: ./.github/workflows/_finish.yml
    with:
      needs: ${{ toJSON(needs) }}
name: Verify

permissions:
  contents: read

on:
  workflow_call:
    inputs:
      request:
        type: string
        required: true
      trusted:
        type: boolean
        required: true

concurrency:
  group: >-
    ${{ github.actor != 'trigger-release-envoy[bot]'
        && github.event.inputs.head_ref
        || github.run_id
    }}-${{ github.event.workflow.id }}-verify
  cancel-in-progress: true


jobs:
  verify:
    permissions:
      contents: read
      packages: read
    name: ${{ matrix.name || matrix.target }}
    uses: ./.github/workflows/_run.yml
    with:
      cache-build-image:
      container-command:
      rbe: ${{ matrix.rbe }}
      request: ${{ inputs.request }}
      runs-on: envoy-x64-small
      steps-pre: ${{ matrix.steps-pre }}
      source: ${{ matrix.source }}
      target: ${{ matrix.target }}
      trusted: ${{ inputs.trusted }}
    strategy:
      fail-fast: false
      matrix:
        include:
        - name: examples
          target: verify_examples
          source: |
            export NO_BUILD_SETUP=1
          rbe: false
          steps-pre: |
            - id: url
              uses: envoyproxy/toolshed/gh-actions/jq@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
              with:
                options: -Rr
                input: >-
                  ${{ inputs.trusted
                      && fromJSON(inputs.request).request.sha
                      || fromJSON(inputs.request).request.ref }}
                filter: |
                  .[:7] as $sha
                  | if ${{ inputs.trusted }} then
                      "envoy-postsubmit"
                    else
                      "envoy-pr"
                    end
                  | . as $bucket
                  | "https://storage.googleapis.com/\($bucket)/\($sha)"
            - uses: envoyproxy/toolshed/gh-actions/docker/fetch@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
              with:
                url: %{{ steps.url.outputs.value }}/docker/envoy.tar
                variant: dev
            - uses: envoyproxy/toolshed/gh-actions/docker/fetch@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
              with:
                url: %{{ steps.url.outputs.value }}/docker/envoy-contrib.tar
                variant: contrib-dev
            - uses: envoyproxy/toolshed/gh-actions/docker/fetch@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
              with:
                url: %{{ steps.url.outputs.value }}/docker/envoy-google-vrp.tar
                variant: google-vrp-dev
            - run: docker images | grep envoy
              shell: bash
            - run: |
                # Install expected host packages
                export DEBIAN_FRONTEND=noninteractive
                sudo apt-get -qq update -y
                sudo apt-get -qq install -y --no-install-recommends expect gettext whois
                pip install -r ./.github/workflows/verify-requirements.txt
              shell: bash
name: Mobile CI

permissions:
  contents: read

on:
  workflow_call:
    secrets:
      app-id:
      app-key:
      rbe-key:
      ssh-key-extra:
    inputs:
      args:
        type: string
      catch-errors:
        type: boolean
        default: false
      checkout-extra:
        type: string
        default:
      command:
        type: string
        default: ./bazelw
      container:
        type: string
      container-output:
        type: string
        default:
      container-command:
        type: string
        default: >-
          docker run
          --volume=${PWD}:/source
          --volume=${TMP_ENTRYPOINT}:/tmp/mobile-entrypoint.sh
          --volume=/tmp/cache:/root/.cache
          --volume=/tmp/container-output:/tmp/container-output
          --workdir=/source/mobile
          --entrypoint=/tmp/mobile-entrypoint.sh
          -e GITHUB_TOKEN
          -e CC
          -e CXX
          -e COVERAGE_THRESHOLD
          -e BAZEL_BUILD_OPTION_LIST
          -e MOBILE_DOCS_CHECKOUT_DIR
      diskspace-hack:
        type: boolean
        default: false
      downloads:
        type: string
        default:
      entrypoint:
        type: string
        default:
      entrypoint-DEFAULT:
        type: string
        default: |
          #!/bin/bash -e
          export PATH=/opt/llvm/bin:$PATH
          exec "$@"
      error-match:
        type: string
        default: |
          ERROR
          error:
          Error:
      notice-match:
        type: string
        default: |
          NOTICE
          Streaming build results
      output-path:
        type: string
        default: /tmp/container-output
      rbe:
        type: boolean
        default: true
      ref:
        type: string
      request:
        type: string
        required: true
      runs-on:
        type: string
      skip:
        type: boolean
        default: false
      source:
        type: string
        default:
      steps-pre:
        type: string
      steps-pre-name:
        type: string
      steps-post:
        type: string
        default:
      steps-post-name:
        type: string
      target:
        type: string
        required: true
      temp-dir:
        type: string
      timeout-minutes:
        type: number
      trusted:
        type: boolean
        default: false
      upload-name:
        type: string
      upload-path:
        type: string
      warning-match:
        type: string
        default: |
          WARNING
          warning:
          Warning:


jobs:
  ci:
    uses: ./.github/workflows/_run.yml
    name: ${{ inputs.target }}
    permissions:
      contents: read
      packages: read
    secrets:
      ssh-key-extra: ${{ secrets.ssh-key-extra }}
    with:
      args: ${{ inputs.args }}
      rbe: ${{ inputs.rbe }}
      # This always just caches the main build image, the mobile one is layered on top
      cache-build-image: ${{ fromJSON(inputs.request).request.build-image.default }}
      catch-errors: ${{ inputs.catch-errors }}
      container-command: ${{ inputs.container-command }} ${{ inputs.container || fromJSON(inputs.request).request.build-image.default }}
      container-output: ${{ inputs.container-output }}
      command: ${{ inputs.command }}
      entrypoint: ${{ inputs.entrypoint || inputs.entrypoint-DEFAULT }}
      downloads: ${{ inputs.downloads }}
      error-match: ${{ inputs.error-match }}
      notice-match: ${{ inputs.notice-match }}
      output-path: ${{ inputs.output-path }}
      request: ${{ inputs.request }}
      source: ${{ inputs.source }}
      steps-pre: ${{ inputs.steps-pre }}
      steps-post: ${{ inputs.steps-post }}
      target: ${{ inputs.target }}
      trusted: ${{ fromJSON(inputs.request).request.trusted }}
      upload-name: ${{ inputs.upload-name }}
      upload-path: ${{ inputs.upload-path }}
      warning-match: ${{ inputs.warning-match }}
name: Mobile/iOS build

permissions:
  contents: read

on:
  workflow_run:
    workflows:
    - Request
    types:
    - completed


jobs:
  load:
    secrets:
      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}
      app-id: ${{ secrets.ENVOY_CI_APP_ID }}
      lock-app-key: ${{ secrets.ENVOY_CI_MUTEX_APP_KEY }}
      lock-app-id: ${{ secrets.ENVOY_CI_MUTEX_APP_ID }}
    permissions:
      actions: read
      contents: read
      packages: read
      pull-requests: read
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    uses: ./.github/workflows/_load.yml
    with:
      cache-docker: false
      check-name: mobile-ios

  build:
    permissions:
      contents: read
      packages: read
    uses: ./.github/workflows/_run.yml
    if: ${{ fromJSON(needs.load.outputs.request).run.mobile-ios }}
    needs: load
    name: ios-build
    with:
      args: ${{ matrix.args }}
      command: ./bazelw
      container-command:
      request: ${{ needs.load.outputs.request }}
      runs-on: macos-12
      source: |
        # TODO(fredyw): A workaround since mobile/WORKSPACE requires Android SDK to be available
        # and the GitHub Action runner image no longer includes Android SDK 30:
        # https://github.com/actions/runner-images/issues/8952
        ./ci/mac_ci_setup.sh --android
        ./bazelw shutdown
      steps-post: ${{ matrix.steps-post }}
      target: ${{ matrix.target }}
      timeout-minutes: ${{ matrix.timeout-minutes }}
      trusted: ${{ fromJSON(needs.load.outputs.trusted) }}
      working-directory: mobile
    strategy:
      fail-fast: false
      matrix:
        include:
        - name: Build Envoy.framework distributable
          args: >-
            build
            --config=mobile-remote-ci-macos-ios
            //library/swift:ios_framework
          target: ios
          timeout-minutes: 120

  hello-world:
    permissions:
      contents: read
      packages: read
    uses: ./.github/workflows/_run.yml
    if: ${{ fromJSON(needs.load.outputs.request).run.mobile-ios }}
    needs:
    - load
    - build
    name: ios-hello-world
    with:
      args: >-
        build
        ${{ matrix.args || '--config=mobile-remote-ci-macos-ios' }}
        ${{ matrix.app }}
      command: ./bazelw
      container-command:
      request: ${{ needs.load.outputs.request }}
      runs-on: macos-12
      source: |
        # TODO(fredyw): A workaround since mobile/WORKSPACE requires Android SDK to be available
        # and the GitHub Action runner image no longer includes Android SDK 30:
        # https://github.com/actions/runner-images/issues/8952
        ./ci/mac_ci_setup.sh --android
        ./bazelw shutdown
      steps-post: |
        - uses: envoyproxy/toolshed/gh-actions/envoy/ios/post@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
          with:
            app: ${{ matrix.app }}
            args: ${{ matrix.args || '--config=mobile-remote-ci-macos-ios' }}
            expected: received headers with status ${{ matrix.expected-status }}
      target: ${{ matrix.target }}
      timeout-minutes: ${{ matrix.timeout-minutes }}
      trusted: ${{ fromJSON(needs.load.outputs.trusted) }}
      working-directory: mobile
    strategy:
      fail-fast: false
      matrix:
        include:
        - name: Build swift hello world
          app: //examples/swift/hello_world:app
          expected-status: 200
          target: swift-hello-world
          timeout-minutes: 50

  apps:
    permissions:
      contents: read
      packages: read
    uses: ./.github/workflows/_run.yml
    if: ${{ fromJSON(needs.load.outputs.request).run.mobile-ios-all }}
    needs:
    - load
    - build
    name: ios-apps
    with:
      args: >-
        build
        ${{ matrix.args || '--config=mobile-remote-ci-macos-ios' }}
        ${{ matrix.app }}
      command: ./bazelw
      container-command:
      request: ${{ needs.load.outputs.request }}
      runs-on: macos-12
      source: |
        # TODO(fredyw): A workaround since mobile/WORKSPACE requires Android SDK to be available
        # and the GitHub Action runner image no longer includes Android SDK 30:
        # https://github.com/actions/runner-images/issues/8952
        ./ci/mac_ci_setup.sh --android
      steps-post: |
        - uses: envoyproxy/toolshed/gh-actions/envoy/ios/post@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
          with:
            app: ${{ matrix.app }}
            args: ${{ matrix.args || '--config=mobile-remote-ci-macos-ios' }}
            expected: >-
              ${{ matrix.expected
                  || format('received headers with status {0}', matrix.expected-status) }}
      target: ${{ matrix.target }}
      timeout-minutes: 50
      trusted: ${{ fromJSON(needs.load.outputs.trusted) }}
      working-directory: mobile
    strategy:
      fail-fast: false
      matrix:
        include:
        - name: Build swift baseline app
          app: //test/swift/apps/baseline:app
          expected-status: 301
          target: swift-baseline-app
        - name: Build swift experimental app
          args: >-
            --config=mobile-remote-ci-macos-ios-admin
          app: //test/swift/apps/experimental:app
          expected-status: 200
          target: swift-experimental-app
        - name: Build swift async await
          app: //examples/swift/async_await:app
          expected: >-
            \[2\] Uploaded 7 MB of data
          target: swift-async-await
        - name: Build objc hello world
          app: //examples/objective-c/hello_world:app
          expected-status: 301
          target: objc-hello-world

  request:
    secrets:
      app-id: ${{ secrets.ENVOY_CI_APP_ID }}
      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}
    permissions:
      actions: read
      contents: read
      pull-requests: read
    if: >-
      ${{ always()
          && github.event.workflow_run.conclusion == 'success'
          && fromJSON(needs.load.outputs.request).run.mobile-ios }}
    needs:
    - load
    - build
    - hello-world
    - apps
    uses: ./.github/workflows/_finish.yml
    with:
      needs: ${{ toJSON(needs) }}
name: Mobile/Release

permissions:
  contents: read

on:
  workflow_dispatch:
  schedule:
  # Mondays at 1pm UTC (8am EST)
  - cron: "0 13 * * 1"

jobs:
  env:
    secrets:
      lock-app-key: ${{ secrets.ENVOY_CI_MUTEX_APP_KEY }}
      lock-app-id: ${{ secrets.ENVOY_CI_MUTEX_APP_ID }}
    permissions:
      contents: read
    uses: ./.github/workflows/_load_env.yml

  release:
    permissions:
      contents: read
      packages: read
    if: >-
      ${{
          (github.repository == 'envoyproxy/envoy'
           || vars.ENVOY_CI)
          && (github.event.schedule
              || !contains(github.actor, '[bot]'))
      }}
    needs: env
    uses: ./.github/workflows/_mobile_container_ci.yml
    with:
      args: ${{ matrix.args }}
      container: ${{ fromJSON(needs.env.outputs.build-image).mobile }}
      container-output: |
        "bazel-bin/library/kotlin/io/envoyproxy/envoymobile/${{ matrix.output }}.aar": build/
        "bazel-bin/library/kotlin/io/envoyproxy/envoymobile/${{ matrix.output }}-pom.xml": build/
        "bazel-bin/library/kotlin/io/envoyproxy/envoymobile/${{ matrix.output }}-sources.jar": build/
        "bazel-bin/library/kotlin/io/envoyproxy/envoymobile/${{ matrix.output }}-javadoc.jar": build/
      request: ${{ needs.env.outputs.request }}
      steps-pre: |
        - run: |
            mkdir /tmp/mobile
            VERSION="0.5.0.$(date '+%Y%m%d')"
            echo "VERSION=${VERSION}" >> $GITHUB_ENV
          shell: bash
      steps-post: |
        - run: |
            mkdir /tmp/output
          shell: bash
        - name: Tar artifacts
          run: >-
            tar
            -czhf
            /tmp/output/${{ matrix.output }}_android_aar_sources.tar.gz
            -C
            /tmp/container-output/build
            .
          shell: bash
      target: ${{ matrix.target }}
      upload-name: ${{ matrix.output }}_android_aar_sources
      upload-path: /tmp/output/${{ matrix.output }}_android_aar_sources.tar.gz
    strategy:
      fail-fast: false
      matrix:
        include:
        - target: android-release
          args: >-
            build
            --config=mobile-remote-release-clang-android-publish
            --define=pom_version=$VERSION
            //:android_dist
          output: envoy
        - target: xds-release
          args: >-
            build
            --config=mobile-remote-release-clang-android-publish-xds
            --define=pom_version=$VERSION
            //:android_xds_dist
          output: envoy_xds

  deploy:
    needs: release
    permissions:
      contents: read
      packages: read
    runs-on: ubuntu-22.04
    timeout-minutes: 20
    strategy:
      fail-fast: false
      matrix:
        include:
        - output: envoy
        - output: envoy_xds
    steps:
    - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11  # v4.1.1
      with:
        fetch-depth: 0
    - name: Add safe directory
      run: git config --global --add safe.directory /__w/envoy/envoy
    - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a  # v3.0.2
      with:
        name: ${{ matrix.output }}_android_aar_sources
        path: .
    - name: Expand archive
      run: |
        tar -xf ${{ matrix.output }}_android_aar_sources.tar.gz
    - name: 'Configure gpg signing'
      env:
        GPG_KEY: ${{ secrets.EM_GPG_KEY }}
        GPG_KEY_NAME: ${{ secrets.EM_GPG_KEY_NAME }}
        GPG_PASSPHRASE: ${{ secrets.EM_GPG_PASSPHRASE }}
      run: |
        # https://github.com/keybase/keybase-issues/issues/2798
        export GPG_TTY=$(tty)
        # Import gpg keys and warm the passphrase to avoid the gpg
        # passphrase prompt when initating a deploy
        # `--pinentry-mode=loopback` could be needed to ensure we
        # suppress the gpg prompt
        echo $GPG_KEY | base64 --decode > signing-key
        gpg --passphrase $GPG_PASSPHRASE --batch --import signing-key
        shred signing-key

        gpg --pinentry-mode=loopback --passphrase $GPG_PASSPHRASE -ab ${{ matrix.output }}.aar
        gpg --pinentry-mode=loopback --passphrase $GPG_PASSPHRASE -ab ${{ matrix.output }}-pom.xml
        gpg --pinentry-mode=loopback --passphrase $GPG_PASSPHRASE -ab ${{ matrix.output }}-javadoc.jar
        gpg --pinentry-mode=loopback --passphrase $GPG_PASSPHRASE -ab ${{ matrix.output }}-sources.jar
    - name: 'Release to sonatype repository'
      env:
        READWRITE_USER: ${{ secrets.EM_SONATYPE_USER }}
        READWRITE_API_KEY: ${{ secrets.EM_SONATYPE_PASSWORD }}
        SONATYPE_PROFILE_ID: ${{ secrets.EM_SONATYPE_PROFILE_ID }}
      run: |
        version="0.5.0.$(date '+%Y%m%d')"
        python mobile/ci/sonatype_nexus_upload.py \
          --profile_id=$SONATYPE_PROFILE_ID \
          --artifact_id=${{ matrix.output }} \
          --version=$version \
          --files \
            ${{ matrix.output }}.aar \
            ${{ matrix.output }}-pom.xml \
            ${{ matrix.output }}-sources.jar \
            ${{ matrix.output }}-javadoc.jar \
          --signed_files \
            ${{ matrix.output }}.aar.asc \
            ${{ matrix.output }}-pom.xml.asc \
            ${{ matrix.output }}-sources.jar.asc \
            ${{ matrix.output }}-javadoc.jar.asc
# This workflow is triggered by azp currently
# Once arm/x64 build jobs are shifted to github, this can be triggered
#  by on: workflow_run
name: Envoy/Publish & verify

permissions:
  contents: read

on:
  # This runs untrusted code, do not expose secrets in the verify job
  workflow_dispatch:
    inputs:
      ref:
        description: "Git SHA ref to checkout"
      sha:
        description: "Git SHA of commit HEAD (ie last commit of PR)"
      head_ref:
        description: "Ref for grouping PRs"

concurrency:
  group: >-
    ${{ github.actor != 'trigger-release-envoy[bot]'
        && github.event.inputs.head_ref
        || github.run_id
    }}-${{ github.event.workflow.id }}
  cancel-in-progress: true

jobs:
  load:
    secrets:
      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}
      app-id: ${{ secrets.ENVOY_CI_APP_ID }}
      lock-app-key: ${{ secrets.ENVOY_CI_MUTEX_APP_KEY }}
      lock-app-id: ${{ secrets.ENVOY_CI_MUTEX_APP_ID }}
    permissions:
      actions: read
      contents: read
      packages: read
      pull-requests: read
    if: >-
      ${{
          (github.repository == 'envoyproxy/envoy'
           || vars.ENVOY_CI)
          && (!contains(github.actor, '[bot]')
              || github.actor == 'trigger-workflow-envoy[bot]'
              || github.actor == 'trigger-release-envoy[bot]')
      }}
    uses: ./.github/workflows/_load.yml
    with:
      check-name: publish
      head-sha: ${{ inputs.sha }}

  publish:
    secrets:
      ENVOY_CI_SYNC_APP_ID: ${{ fromJSON(needs.load.outputs.trusted) && secrets.ENVOY_CI_SYNC_APP_ID || '' }}
      ENVOY_CI_SYNC_APP_KEY: ${{ fromJSON(needs.load.outputs.trusted) && secrets.ENVOY_CI_SYNC_APP_KEY || '' }}
      ENVOY_CI_PUBLISH_APP_ID: ${{ fromJSON(needs.load.outputs.trusted) && secrets.ENVOY_CI_PUBLISH_APP_ID || '' }}
      ENVOY_CI_PUBLISH_APP_KEY:  ${{ fromJSON(needs.load.outputs.trusted) && secrets.ENVOY_CI_PUBLISH_APP_KEY || '' }}
    permissions:
      contents: read
      packages: read
    if: ${{ fromJSON(needs.load.outputs.request).run.publish }}
    needs:
    - load
    uses: ./.github/workflows/_stage_publish.yml
    name: Publish
    with:
      request: ${{ needs.load.outputs.request }}
      trusted: ${{ fromJSON(needs.load.outputs.trusted) }}

  verify:
    permissions:
      contents: read
      packages: read
    if: ${{ fromJSON(needs.load.outputs.request).run.verify }}
    needs:
    - load
    uses: ./.github/workflows/_stage_verify.yml
    name: Verify
    with:
      request: ${{ needs.load.outputs.request }}
      trusted: ${{ fromJSON(needs.load.outputs.trusted) }}

  request:
    secrets:
      app-id: ${{ secrets.ENVOY_CI_APP_ID }}
      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}
    permissions:
      actions: read
      contents: read
      pull-requests: read
    if: >-
      ${{ always()
          && (fromJSON(needs.load.outputs.request).run.publish
              || fromJSON(needs.load.outputs.request).run.verify) }}
    needs:
    - load
    - publish
    - verify
    uses: ./.github/workflows/_finish.yml
    with:
      needs: ${{ toJSON(needs) }}
#
# This file is autogenerated by pip-compile with Python 3.11
# by the following command:
#
#    pip-compile --allow-unsafe --generate-hashes verify-requirements.in
#
argcomplete==3.2.1 \
    --hash=sha256:30891d87f3c1abe091f2142613c9d33cac84a5e15404489f033b20399b691fec \
    --hash=sha256:437f67fb9b058da5a090df505ef9be0297c4883993f3f56cb186ff087778cfb4
    # via yq
pyyaml==6.0.1 \
    --hash=sha256:04ac92ad1925b2cff1db0cfebffb6ffc43457495c9b3c39d3fcae417d7125dc5 \
    --hash=sha256:062582fca9fabdd2c8b54a3ef1c978d786e0f6b3a1510e0ac93ef59e0ddae2bc \
    --hash=sha256:0d3304d8c0adc42be59c5f8a4d9e3d7379e6955ad754aa9d6ab7a398b59dd1df \
    --hash=sha256:1635fd110e8d85d55237ab316b5b011de701ea0f29d07611174a1b42f1444741 \
    --hash=sha256:184c5108a2aca3c5b3d3bf9395d50893a7ab82a38004c8f61c258d4428e80206 \
    --hash=sha256:18aeb1bf9a78867dc38b259769503436b7c72f7a1f1f4c93ff9a17de54319b27 \
    --hash=sha256:1d4c7e777c441b20e32f52bd377e0c409713e8bb1386e1099c2415f26e479595 \
    --hash=sha256:1e2722cc9fbb45d9b87631ac70924c11d3a401b2d7f410cc0e3bbf249f2dca62 \
    --hash=sha256:1fe35611261b29bd1de0070f0b2f47cb6ff71fa6595c077e42bd0c419fa27b98 \
    --hash=sha256:28c119d996beec18c05208a8bd78cbe4007878c6dd15091efb73a30e90539696 \
    --hash=sha256:326c013efe8048858a6d312ddd31d56e468118ad4cdeda36c719bf5bb6192290 \
    --hash=sha256:40df9b996c2b73138957fe23a16a4f0ba614f4c0efce1e9406a184b6d07fa3a9 \
    --hash=sha256:42f8152b8dbc4fe7d96729ec2b99c7097d656dc1213a3229ca5383f973a5ed6d \
    --hash=sha256:49a183be227561de579b4a36efbb21b3eab9651dd81b1858589f796549873dd6 \
    --hash=sha256:4fb147e7a67ef577a588a0e2c17b6db51dda102c71de36f8549b6816a96e1867 \
    --hash=sha256:50550eb667afee136e9a77d6dc71ae76a44df8b3e51e41b77f6de2932bfe0f47 \
    --hash=sha256:510c9deebc5c0225e8c96813043e62b680ba2f9c50a08d3724c7f28a747d1486 \
    --hash=sha256:5773183b6446b2c99bb77e77595dd486303b4faab2b086e7b17bc6bef28865f6 \
    --hash=sha256:596106435fa6ad000c2991a98fa58eeb8656ef2325d7e158344fb33864ed87e3 \
    --hash=sha256:6965a7bc3cf88e5a1c3bd2e0b5c22f8d677dc88a455344035f03399034eb3007 \
    --hash=sha256:69b023b2b4daa7548bcfbd4aa3da05b3a74b772db9e23b982788168117739938 \
    --hash=sha256:6c22bec3fbe2524cde73d7ada88f6566758a8f7227bfbf93a408a9d86bcc12a0 \
    --hash=sha256:704219a11b772aea0d8ecd7058d0082713c3562b4e271b849ad7dc4a5c90c13c \
    --hash=sha256:7e07cbde391ba96ab58e532ff4803f79c4129397514e1413a7dc761ccd755735 \
    --hash=sha256:81e0b275a9ecc9c0c0c07b4b90ba548307583c125f54d5b6946cfee6360c733d \
    --hash=sha256:855fb52b0dc35af121542a76b9a84f8d1cd886ea97c84703eaa6d88e37a2ad28 \
    --hash=sha256:8d4e9c88387b0f5c7d5f281e55304de64cf7f9c0021a3525bd3b1c542da3b0e4 \
    --hash=sha256:9046c58c4395dff28dd494285c82ba00b546adfc7ef001486fbf0324bc174fba \
    --hash=sha256:9eb6caa9a297fc2c2fb8862bc5370d0303ddba53ba97e71f08023b6cd73d16a8 \
    --hash=sha256:a0cd17c15d3bb3fa06978b4e8958dcdc6e0174ccea823003a106c7d4d7899ac5 \
    --hash=sha256:afd7e57eddb1a54f0f1a974bc4391af8bcce0b444685d936840f125cf046d5bd \
    --hash=sha256:b1275ad35a5d18c62a7220633c913e1b42d44b46ee12554e5fd39c70a243d6a3 \
    --hash=sha256:b786eecbdf8499b9ca1d697215862083bd6d2a99965554781d0d8d1ad31e13a0 \
    --hash=sha256:ba336e390cd8e4d1739f42dfe9bb83a3cc2e80f567d8805e11b46f4a943f5515 \
    --hash=sha256:baa90d3f661d43131ca170712d903e6295d1f7a0f595074f151c0aed377c9b9c \
    --hash=sha256:bc1bf2925a1ecd43da378f4db9e4f799775d6367bdb94671027b73b393a7c42c \
    --hash=sha256:bd4af7373a854424dabd882decdc5579653d7868b8fb26dc7d0e99f823aa5924 \
    --hash=sha256:bf07ee2fef7014951eeb99f56f39c9bb4af143d8aa3c21b1677805985307da34 \
    --hash=sha256:bfdf460b1736c775f2ba9f6a92bca30bc2095067b8a9d77876d1fad6cc3b4a43 \
    --hash=sha256:c8098ddcc2a85b61647b2590f825f3db38891662cfc2fc776415143f599bb859 \
    --hash=sha256:d2b04aac4d386b172d5b9692e2d2da8de7bfb6c387fa4f801fbf6fb2e6ba4673 \
    --hash=sha256:d483d2cdf104e7c9fa60c544d92981f12ad66a457afae824d146093b8c294c54 \
    --hash=sha256:d858aa552c999bc8a8d57426ed01e40bef403cd8ccdd0fc5f6f04a00414cac2a \
    --hash=sha256:e7d73685e87afe9f3b36c799222440d6cf362062f78be1013661b00c5c6f678b \
    --hash=sha256:f003ed9ad21d6a4713f0a9b5a7a0a79e08dd0f221aff4525a2be4c346ee60aab \
    --hash=sha256:f22ac1c3cac4dbc50079e965eba2c1058622631e526bd9afd45fedd49ba781fa \
    --hash=sha256:faca3bdcf85b2fc05d06ff3fbc1f83e1391b3e724afa3feba7d13eeab355484c \
    --hash=sha256:fca0e3a251908a499833aa292323f32437106001d436eca0e6e7833256674585 \
    --hash=sha256:fd1592b3fdf65fff2ad0004b5e363300ef59ced41c2e6b3a99d4089fa8c5435d \
    --hash=sha256:fd66fc5d0da6d9815ba2cebeb4205f95818ff4b79c3ebe268e75d961704af52f
    # via yq
tomlkit==0.12.3 \
    --hash=sha256:75baf5012d06501f07bee5bf8e801b9f343e7aac5a92581f20f80ce632e6b5a4 \
    --hash=sha256:b0a645a9156dc7cb5d3a1f0d4bab66db287fcb8e0430bdd4664a095ea16414ba
    # via yq
xmltodict==0.13.0 \
    --hash=sha256:341595a488e3e01a85a9d8911d8912fd922ede5fecc4dce437eb4b6c8d037e56 \
    --hash=sha256:aa89e8fd76320154a40d19a0df04a4695fb9dc5ba977cbb68ab3e4eb225e7852
    # via yq
yq==3.2.3 \
    --hash=sha256:29c8fe1d36b4f64163f4d01314c6ae217539870f610216dee6025dfb5eafafb1 \
    --hash=sha256:b50c91894dad9894d1d36ea77d5722d5495cac9482d2351e55089360a90709ae
    # via -r verify-requirements.in
# This file must live on every branch and pass necessary secrets and permissions
#   to initiate the request
name: Request

permissions:
  contents: read

on:
  pull_request_target:
  push:
    branches:
    - main
    - release/v*

concurrency:
  group: |
    ${{ github.head_ref
        || github.run_id
    }}-${{ github.workflow }}-request
  cancel-in-progress: true


jobs:
  request:
    # For branches this can be pinned to a specific version if required
    # NB: `uses` cannot be dynamic so it _must_ be hardcoded anywhere it is read
    uses: envoyproxy/envoy/.github/workflows/_request.yml@main
    if: ${{ vars.ENVOY_CI || github.repository == 'envoyproxy/envoy' }}
    permissions:
      actions: read
      contents: read
      # required for engflow/bazel caching (not yet used)
      packages: read
      # required to fetch merge commit
      pull-requests: read
    secrets:
      # these are required to start checks
      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}
      app-id: ${{ secrets.ENVOY_CI_APP_ID }}
name: Mobile/ASAN

permissions:
  contents: read

on:
  workflow_run:
    workflows:
    - Request
    types:
    - completed

concurrency:
  group: ${{ github.head_ref || github.run_id }}-${{ github.workflow }}
  cancel-in-progress: true


jobs:
  load:
    secrets:
      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}
      app-id: ${{ secrets.ENVOY_CI_APP_ID }}
      lock-app-key: ${{ secrets.ENVOY_CI_MUTEX_APP_KEY }}
      lock-app-id: ${{ secrets.ENVOY_CI_MUTEX_APP_ID }}
    permissions:
      actions: read
      contents: read
      packages: read
      pull-requests: read
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    uses: ./.github/workflows/_load.yml
    with:
      check-name: mobile-asan

  asan:
    permissions:
      contents: read
      packages: read
    name: asan
    uses: ./.github/workflows/_mobile_container_ci.yml
    if: ${{ fromJSON(needs.load.outputs.request).run.mobile-asan }}
    needs: load
    with:
      args: >-
        test
        --config=mobile-remote-ci-linux-asan
        //test/common/...
      request: ${{ needs.load.outputs.request }}
      target: asan
      timeout-minutes: 180

  request:
    secrets:
      app-id: ${{ secrets.ENVOY_CI_APP_ID }}
      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}
    permissions:
      actions: read
      contents: read
    if: >-
      ${{ always()
          && github.event.workflow_run.conclusion == 'success'
          && fromJSON(needs.load.outputs.request).run.mobile-asan }}
    needs:
    - load
    - asan
    uses: ./.github/workflows/_finish.yml
    with:
      needs: ${{ toJSON(needs) }}
name: Envoy/Prechecks

permissions:
  contents: read

on:
  workflow_run:
    workflows:
    - Request
    types:
    - completed

concurrency:
  group: ${{ github.head_ref || github.run_id }}-${{ github.workflow }}
  cancel-in-progress: true

env:
  CI_DEBUG: ${{ vars.CI_DEBUG }}


jobs:
  load:
    secrets:
      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}
      app-id: ${{ secrets.ENVOY_CI_APP_ID }}
      lock-app-key: ${{ secrets.ENVOY_CI_MUTEX_APP_KEY }}
      lock-app-id: ${{ secrets.ENVOY_CI_MUTEX_APP_ID }}
    permissions:
      actions: read
      contents: read
      packages: read
      pull-requests: read
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    uses: ./.github/workflows/_load.yml
    with:
      check-name: prechecks

  deps:
    permissions:
      actions: read
      contents: read
      packages: read
      pull-requests: read
    name: Precheck (${{ fromJSON(needs.load.outputs.request).summary.title }})
    uses: ./.github/workflows/_precheck_deps.yml
    if: ${{ fromJSON(needs.load.outputs.request).run.precheck-deps }}
    needs:
    - load
    with:
      dependency-review: ${{ github.event_name == 'pull_request_target' && github.repository == 'envoyproxy/envoy' }}
      request: ${{ needs.load.outputs.request }}
      trusted: ${{ fromJSON(needs.load.outputs.trusted) }}

  request:
    secrets:
      app-id: ${{ secrets.ENVOY_CI_APP_ID }}
      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}
    permissions:
      actions: read
      contents: read
      pull-requests: read
    if: >-
      ${{ always()
          && github.event.workflow_run.conclusion == 'success'
          && fromJSON(needs.load.outputs.request).run.precheck-deps }}
    needs:
    - load
    - deps
    uses: ./.github/workflows/_finish.yml
    with:
      needs: ${{ toJSON(needs) }}
name: Envoy/Windows

permissions:
  contents: read

on:
  workflow_run:
    workflows:
    - Request
    types:
    - completed

concurrency:
  group: ${{ github.head_ref || github.run_id }}-${{ github.workflow }}
  cancel-in-progress: true


jobs:
  load:
    secrets:
      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}
      app-id: ${{ secrets.ENVOY_CI_APP_ID }}
      lock-app-key: ${{ secrets.ENVOY_CI_MUTEX_APP_KEY }}
      lock-app-id: ${{ secrets.ENVOY_CI_MUTEX_APP_ID }}
    permissions:
      actions: read
      contents: read
      packages: read
      pull-requests: read
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    uses: ./.github/workflows/_load.yml
    with:
      cache-docker: false
      check-name: windows

  windows:
    permissions:
      contents: read
      packages: read
    secrets:
      rbe-key: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
    if: ${{ fromJSON(needs.load.outputs.request).run.build-windows }}
    needs:
    - load
    uses: ./.github/workflows/_run.yml
    name: CI ${{ matrix.name || matrix.target }}
    with:
      command:
      request: ${{ needs.load.outputs.request }}
      runs-on: envoy-win19-small
      source: |
        export ENVOY_SHARED_TMP_DIR="C:\Users\runner\AppData\Local\Temp\bazel-shared"
        export ENVOY_DOCKER_BUILD_DIR="C:\Users\runner\AppData\Local\Temp"
        mkdir -p "$ENVOY_SHARED_TMP_DIR"
        GCP_SERVICE_ACCOUNT_KEY_PATH=$(mktemp -p "${ENVOY_SHARED_TMP_DIR}" -t gcp_service_account.XXXXXX.json)
        bash -c "echo \"${RBE_KEY}\" | base64 --decode > \"${GCP_SERVICE_ACCOUNT_KEY_PATH}\""
        _BAZEL_BUILD_EXTRA_OPTIONS=(
          --config=remote-ci
          --config=rbe-google
          --config=remote-msvc-cl
          --google_credentials=${GCP_SERVICE_ACCOUNT_KEY_PATH}
          --jobs=75
          --flaky_test_attempts=2)
        export BAZEL_BUILD_EXTRA_OPTIONS=${_BAZEL_BUILD_EXTRA_OPTIONS[*]}
      steps-post:
      target: ${{ matrix.target }}
      temp-dir: 'C:\Users\runner\AppData\Local\Temp\bazel-shared'
      trusted: ${{ fromJSON(needs.load.outputs.trusted) }}
      upload-name: windows.release
      upload-path: 'C:\Users\runner\AppData\Local\Temp\envoy'
    strategy:
      fail-fast: false
      matrix:
        include:
        - target: ci/windows_ci_steps.sh
          name: Windows 2019

  docker:
    needs:
    - load
    - windows
    strategy:
      fail-fast: false
      matrix:
        include:
        - target: windows2019
          name: Windows 2019
          runs-on: envoy-win19-small
          build-type: windows
          image-base: mcr.microsoft.com/windows/servercore
          image-tag: ltsc2019
        - target: windows2022
          name: Windows 2022
          runs-on: envoy-win22-small
          build-type: windows-ltsc2022
          image-base: mcr.microsoft.com/windows/nanoserver
          image-tag: ltsc2022
    runs-on: ${{ matrix.runs-on }}
    steps:
    - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11  # v4.1.1
      with:
        ref: ${{ needs.load.outputs.repo_ref  }}
    - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a  # v3.0.2
      with:
        name: windows.release
    - run: |
        # Convert to Unix-style path so tar doesn't think drive letter is a hostname
        STAGING_DIR="$(echo $PWD | tr -d ':' | tr '\\' '/')"
        mkdir -p windows/amd64 && tar zxf "${STAGING_DIR}/envoy_binary.tar.gz" -C ./windows/amd64
        CI_SHA1=$(git rev-parse head)
        export CI_SHA1
        ci/docker_ci.sh
      shell: bash
      env:
        CI_BRANCH: ${{ github.ref }}
        DOCKERHUB_USERNAME: ${{ fromJSON(needs.load.outputs.trusted) && secrets.DOCKERHUB_USERNAME || '' }}
        DOCKERHUB_PASSWORD: ${{ fromJSON(needs.load.outputs.trusted) && secrets.DOCKERHUB_PASSWORD || '' }}
        WINDOWS_BUILD_TYPE: ${{ matrix.build-type }}
        WINDOWS_IMAGE_BASE: ${{ matrix.image-base }}
        WINDOWS_IMAGE_TAG: ${{ matrix.image-tag }}
  request:
    permissions:
      actions: read
      contents: read
      pull-requests: read
    secrets:
      app-id: ${{ secrets.ENVOY_CI_APP_ID }}
      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}
    if: >-
      ${{ always()
          && github.event.workflow_run.conclusion == 'success'
          && fromJSON(needs.load.outputs.request).run.build-windows }}
    needs:
    - load
    - windows
    - docker
    uses: ./.github/workflows/_finish.yml
    with:
      needs: ${{ toJSON(needs) }}
name: Prune stale

permissions:
  contents: read

on:
  workflow_dispatch:
  schedule:
  - cron: '0 */4 * * *'

jobs:
  prune_stale:
    if: >-
      ${{
          github.repository == 'envoyproxy/envoy'
          && (github.event.schedule
              || !contains(github.actor, '[bot]'))
      }}
    permissions:
      issues: write  # for actions/stale to close stale issues
      pull-requests: write  # for actions/stale to close stale PRs
    name: Prune stale
    runs-on: ubuntu-22.04

    steps:
    - name: Prune Stale
      uses: actions/stale@28ca1036281a5e5922ead5184a1bbf96e5fc984e  # v9.0.0
      with:
        repo-token: ${{ secrets.GITHUB_TOKEN }}
        # Different amounts of days for issues/PRs are not currently supported but there is a PR
        # open for it: https://github.com/actions/stale/issues/214
        days-before-stale: 30
        days-before-close: 7
        stale-issue-message: >
          This issue has been automatically marked as stale because it has not had activity in the
          last 30 days. It will be closed in the next 7 days unless it is tagged "help wanted" or "no stalebot" or other activity
          occurs. Thank you for your contributions.
        close-issue-message: >
          This issue has been automatically closed because it has not had activity in the
          last 37 days. If this issue is still valid, please ping a maintainer and ask them to label it as "help wanted" or "no stalebot".
          Thank you for your contributions.
        stale-pr-message: >
          This pull request has been automatically marked as stale because it has not had
          activity in the last 30 days. It will be closed in 7 days if no further activity occurs. Please
          feel free to give a status update now, ping for review, or re-open when it's ready.
          Thank you for your contributions!
        close-pr-message: >
          This pull request has been automatically closed because it has not had
          activity in the last 37 days. Please feel free to give a status update now, ping for review, or re-open when it's ready.
          Thank you for your contributions!
        stale-issue-label: 'stale'
        exempt-issue-labels: 'no stalebot,help wanted'
        stale-pr-label: 'stale'
        exempt-pr-labels: 'no stalebot'
        operations-per-run: 500
        ascending: true
name: Workflow/complete

permissions:
  contents: read


on:
  # Do not run untrusted code here
  workflow_call:
    secrets:
      app-id:
        required: true
      app-key:
        required: true
    inputs:
      needs:
        type: string
        required: true
      template-check-text:
        type: string
        default: |
          ## \($icon) Check run finished (\($outcome.name) \($outcome.icon))

          ## The check run can be viewed here:

          # \($icon) \($run_link)

env:
  CI_DEBUG: ${{ vars.CI_DEBUG && true || false }}


jobs:
  complete:
    runs-on: ubuntu-22.04
    permissions:
      actions: read
      contents: read
    steps:
    - uses: envoyproxy/toolshed/gh-actions/jq@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      name: Incoming data
      id: needs
      with:
        input: |
          check_name: ${{ fromJSON(inputs.needs).load.outputs.check-name }}
          repo: ${{ github.repository }}
          run_id: ${{ github.run_id }}
          outcomes: ${{ toJSON(fromJSON(inputs.needs).*.result) }}
          load: ${{ toJSON(fromJSON(inputs.needs).load.outputs) }}
        input-format: yaml
        print-result: ${{ fromJSON(env.CI_DEBUG || 'false') && true || false }}
        filter: |
          .repo as $repo
          | .run_id as $run_id
          | .needs as $result
          | .check_name as $check_name
          | .load as $load
          | $load["check-id"] as $check_id
          | $load["run-id"] as $workflow_id
          | (.load.request | fromjson) as $request
          | $request.config.envoy.icon as $icon
          | .outcomes
          | if any(. == "failure") then
              {name: "failure", icon: ":x:"}
            elif any(. == "cancelled") then
              {name: "cancelled", icon: ""}
            elif all(. == "skipped") then
              {name: "skipped", icon: ""}
            else
              {name: "success", icon: ":heavy_check_mark:"}
            end
          | . as $outcome
          | "\($request.check.name) (\($request.summary.title))" as $run_link_text
          | "[\($run_link_text)](https://github.com/\($repo)/actions/runs/\($run_id))" as $run_link
          | "${{ inputs.template-check-text }}" as $text
          | {"summary-title": "\($icon) \($request.check.name) complete (\($outcome.name))",
             "check-id": $check_id,
             conclusion: $outcome.name,
             checks: {
               ($check_name): {
                 name: $request.check.name,
                 head_sha: $request.request.sha,
                 status: "completed",
                 conclusion: $outcome.name,
                 external_id: "\($run_id)",
                 output: {
                   title: "\($request.check.name) (\($outcome.name))",
                   summary: "Check has finished",
                   text: $text}}}}

    - uses: envoyproxy/toolshed/gh-actions/jq@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      name: Print summary
      with:
        input: ${{ toJSON(steps.needs.outputs.value).summary-title }}
        filter: |
          "## \(.)"
        options: -Rr
        output-path: GITHUB_STEP_SUMMARY
    - uses: envoyproxy/toolshed/gh-actions/appauth@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      name: Appauth
      id: appauth
      with:
        app_id: ${{ secrets.app-id }}
        key: ${{ secrets.app-key }}
    - uses: envoyproxy/toolshed/gh-actions/github/checks@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      name: Update check
      with:
        action: update
        checks: ${{ toJSON(fromJSON(steps.needs.outputs.value).checks) }}
        token: ${{ steps.appauth.outputs.token }}

    # This is necessary to ensure that any retests have their checks updated
    - name: Fail the job
      if: ${{ fromJSON(steps.needs.outputs.value).conclusion != 'success' }}
      run: |
        exit 1
name: Envoy/dependency

permissions:
  contents: read

on:
  schedule:
  - cron: '0 8 * * *'
  workflow_dispatch:
    inputs:
      task:
        description: Select a task
        required: true
        default: bazel
        type: choice
        options:
        - bazel
        - bazel-api
        - build-image
        - check
      dependency:
        description: Dependency to update (if applicable)
      version:
        description: Version to set (optional)
      pr:
        type: boolean
        default: true
      pr-message:
        description: Additional message for PR, eg to fix an issue (optional)

concurrency:
  group: ${{ github.head_ref || github.run_id }}-${{ github.workflow }}
  cancel-in-progress: true

env:
  COMMITTER_NAME: dependency-envoy[bot]
  COMMITTER_EMAIL: 148525496+dependency-envoy[bot]@users.noreply.github.com

jobs:
  update-bazel:
    if: >-
      ${{
           github.event_name == 'workflow_dispatch'
           && startsWith(inputs.task, 'bazel')
      }}
    name: >-
      Update dep
      (${{ inputs.pr && 'PR/' || '' }}${{ inputs.task == 'bazel' && 'bazel' || 'bazel/api' }}/${{ inputs.dependency }}/${{ inputs.version }})
    runs-on: ubuntu-22.04
    steps:
    - id: appauth
      name: Appauth
      uses: envoyproxy/toolshed/gh-actions/appauth@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      with:
        app_id: ${{ secrets.ENVOY_CI_DEP_APP_ID }}
        key: ${{ secrets.ENVOY_CI_DEP_APP_KEY }}
    - id: checkout
      name: Checkout Envoy repository
      uses: envoyproxy/toolshed/gh-actions/github/checkout@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      with:
        token: ${{ steps.appauth.outputs.token }}
    - uses: envoyproxy/toolshed/gh-actions/bson@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      id: update
      name: Update dependency (${{ inputs.dependency }})
      with:
        input: |
          dependency: ${{ inputs.dependency }}
          task: ${{ inputs.task }}
          version: "${{ inputs.version }}"
        input-format: yaml
        filter: |
          .version as $version
          | .dependency as $dependency
          | .task as $task
          | (try ($version | validate::sha(40) | .[:7])
             catch $version) as $version_short
          | {}
          | if $task == "bazel" then
              .
              | .task = "bazel"
              | .target = "update"
            else
              .
              | .task = "api/bazel"
              | .target = "api-update"
            end
          | .task as $task
          | .target as $target
          | ("
          echo \"Updating(\($task)): \($dependency) -> \($version_short)\"
          bazel run --config=ci //bazel:\($target) \($dependency) \($version)
          OUTPUT=\($version_short)
          " | bash::output)
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    - uses: envoyproxy/toolshed/gh-actions/upload/diff@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      name: Upload diff
      with:
        name: ${{ inputs.dependency }}-${{ steps.update.outputs.output }}
    - name: Create a PR
      if: ${{ inputs.pr }}
      uses: envoyproxy/toolshed/gh-actions/github/pr@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      with:
        base: main
        body: |
          Created by Envoy dependency bot for @${{ github.actor }}

          ${{ inputs.pr-message }}
        branch: >-
          dependency/${{ inputs.task }}/${{ inputs.dependency }}/${{ steps.update.outputs.output }}
        commit-message: |
          ${{ inputs.task == 'bazel' && 'deps' || 'deps/api' }}: Bump `${{ inputs.dependency }}` -> ${{ steps.update.outputs.output }}

          Signed-off-by: ${{ env.COMMITTER_NAME }} <${{ env.COMMITTER_EMAIL }}>
        committer-name: ${{ env.COMMITTER_NAME }}
        committer-email: ${{ env.COMMITTER_EMAIL }}
        title: >-
          ${{ inputs.task == 'bazel' && 'deps' || 'deps/api' }}: Bump `${{ inputs.dependency }}`
          -> ${{ steps.update.outputs.output }}
        GITHUB_TOKEN: ${{ steps.appauth.outputs.token }}

  update-build-image:
    if: >-
      ${{
           github.event_name == 'workflow_dispatch'
           && github.event.inputs.task == 'build-image'
      }}
    name: Update build image (PR)
    runs-on: ubuntu-22.04
    steps:
    - id: appauth
      name: Appauth
      uses: envoyproxy/toolshed/gh-actions/appauth@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      with:
        app_id: ${{ secrets.ENVOY_CI_DEP_APP_ID }}
        key: ${{ secrets.ENVOY_CI_DEP_APP_KEY }}
    - uses: envoyproxy/toolshed/gh-actions/github/checkout@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      id: checkout
      name: Checkout Envoy repository
      with:
        config: |
          path: envoy
          fetch-depth: 0
        token: ${{ steps.appauth.outputs.token }}
    - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11  # v4.1.1
      name: Checkout Envoy build tools repository
      with:
        repository: envoyproxy/envoy-build-tools
        path: build-tools
        fetch-depth: 0
    - run: |
        shas=(
            tag
            sha
            mobile-sha
            gcr-sha)
        for sha in "${shas[@]}"; do
            current_sha=$(bazel run --config=ci //tools/dependency:build-image-sha "$sha")
            echo "${sha}=${current_sha}" >> "$GITHUB_OUTPUT"
        done
      id: current
      name: Current SHAs
      working-directory: envoy
    - run: |
        if [[ -z "$CONTAINER_TAG" ]]; then
            # get current build image version
            CONTAINER_TAG=$(git log -1 --pretty=format:"%H" "./docker")
        fi
        echo "tag=${CONTAINER_TAG}" >> "$GITHUB_OUTPUT"
        echo "tag_short=${CONTAINER_TAG::7}" >> "$GITHUB_OUTPUT"
      env:
        CONTAINER_TAG: ${{ inputs.version }}
      id: build-tools
      name: Build image SHA
      working-directory: build-tools

    - name: Check Docker SHAs
      id: build-images
      uses: envoyproxy/toolshed/gh-actions/docker/shas@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      with:
        images: |
           sha: envoyproxy/envoy-build-ubuntu:${{ steps.build-tools.outputs.tag }}
           mobile-sha: envoyproxy/envoy-build-ubuntu:mobile-${{ steps.build-tools.outputs.tag }}
           gcr-sha: gcr.io/envoy-ci/envoy-build:${{ steps.build-tools.outputs.tag }}

    - run: |
        SHA_REPLACE=(
            "$CURRENT_ENVOY_TAG:$ENVOY_TAG"
            "$CURRENT_ENVOY_SHA:${{ fromJSON(steps.build-images.outputs.shas).sha }}"
            "$CURRENT_ENVOY_MOBILE_SHA:${{ fromJSON(steps.build-images.outputs.shas).mobile-sha }}"
            "$CURRENT_ENVOY_GCR_SHA:${{ fromJSON(steps.build-images.outputs.shas).gcr-sha }}")
        echo "replace=${SHA_REPLACE[*]}" >> "$GITHUB_OUTPUT"
      name: Find SHAs to replace
      id: shas
      env:
        ENVOY_TAG: ${{ steps.build-tools.outputs.tag }}
        CURRENT_ENVOY_TAG: ${{ steps.current.outputs.tag }}
        CURRENT_ENVOY_SHA: ${{ steps.current.outputs.sha }}
        CURRENT_ENVOY_MOBILE_SHA: ${{ steps.current.outputs.mobile-sha }}
        CURRENT_ENVOY_GCR_SHA: ${{ steps.current.outputs.gcr-sha }}
    - run: |
        echo "${SHA_REPLACE}" | xargs bazel run --config=ci @envoy_toolshed//sha:replace "${PWD}"
      env:
        SHA_REPLACE: ${{ steps.shas.outputs.replace }}
      name: Update SHAs
      working-directory: envoy
    - name: Create a PR
      uses: envoyproxy/toolshed/gh-actions/github/pr@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      with:
        base: main
        body: Created by Envoy dependency bot
        branch: dependency-envoy/build-image/latest
        committer-name: ${{ env.COMMITTER_NAME }}
        committer-email: ${{ env.COMMITTER_EMAIL }}
        commit-message: |
          deps: Bump build images -> `${{ steps.build-tools.outputs.tag_short }}`

          Signed-off-by: ${{ env.COMMITTER_NAME }} <${{ env.COMMITTER_EMAIL }}>
        title: 'deps: Bump build images -> `${{ steps.build-tools.outputs.tag_short }}`'
        GITHUB_TOKEN: ${{ steps.appauth.outputs.token }}
        working-directory: envoy

  scheduled:
    runs-on: ubuntu-22.04
    if: >-
      ${{
          github.repository == 'envoyproxy/envoy'
          && (github.event.schedule
              || (!contains(github.actor, '[bot]')
                  && inputs.task == 'check'))
      }}
    permissions:
      contents: read
      issues: write
    steps:
    - name: Checkout repository
      uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11  # v4.1.1
    - name: Run dependency checker
      run: |
        TODAY_DATE=$(date -u -I"date")
        export TODAY_DATE
        bazel run --config=ci //tools/dependency:check --action_env=TODAY_DATE -- -c release_issues --fix
        bazel run --config=ci //tools/dependency:check --action_env=TODAY_DATE -- -c cves -w error
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
name: Cache prime (docker)

permissions:
  contents: read

on:
  workflow_call:
    secrets:
      app-id:
        required: true
      app-key:
        required: true
    inputs:
      image-tag:
        type: string
        required: true
      request:
        type: string
        required: true
      lock-repository:
        type: string
        default: envoyproxy/ci-mutex

## Docker cache
#
# This workflow will only prime the cache, and should be done separately first, prior
# to any jobs that require it.
#
# For a job that does, you can restore with something like:
#
#    steps:
#    - uses: envoyproxy/toolshed/gh-actions/docker/cache/restore@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
#      with:
#        key: "${{ needs.env.outputs.build-image }}"
#


jobs:
  docker:
    runs-on: ubuntu-22.04
    steps:
    - uses: envoyproxy/toolshed/gh-actions/appauth@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      id: appauth
      name: Appauth (mutex lock)
      with:
        app_id: ${{ secrets.app-id }}
        key: ${{ secrets.app-key }}
    - uses: envoyproxy/toolshed/gh-actions/docker/cache/prime@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      id: docker
      name: Prime Docker cache (${{ inputs.image-tag }})
      with:
        image-tag: ${{ inputs.image-tag }}
        lock-token: ${{ steps.appauth.outputs.token }}
        lock-repository: ${{ inputs.lock-repository }}
    - uses: envoyproxy/toolshed/gh-actions/jq@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      id: data
      name: Cache data
      with:
        input-format: yaml
        input: |
          cached: ${{ steps.docker.outputs.cached }}
          key: ${{ inputs.image-tag }}
    - uses: envoyproxy/toolshed/gh-actions/json/table@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      name: Summary
      with:
        json: ${{ steps.data.outputs.value }}
        output-path: GITHUB_STEP_SUMMARY
        title: >-
          Cache (Docker x64)
name: Request/incoming

permissions:
  contents: read

on:
  workflow_call:
    secrets:
      app-id:
        required: true
      app-key:
        required: true

    # Defaults are set .github/config.yml on the `main` branch.
    inputs:
      config-file:
        type: string
        default: ./.github/config.yml

concurrency:
  group: |
    ${{ github.actor != 'trigger-release-envoy[bot]'
        && github.head_ref
        || github.run_id
    }}-${{ github.workflow }}-env-prime
  cancel-in-progress: true

env:
  CI_DEBUG: ${{ (vars.CI_DEBUG || vars.RUNNER_DEBUG) && true || false }}


jobs:
  incoming:
    if: ${{ github.repository == 'envoyproxy/envoy' || vars.ENVOY_CI }}
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      pull-requests: read
    outputs:
      env: ${{ steps.data.outputs.value }}
      config: ${{ steps.config.outputs.config }}
    steps:
    - uses: envoyproxy/toolshed/gh-actions/jq@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      id: started
      name: Create timestamp
      with:
        options: -r
        filter: |
          now
    - uses: envoyproxy/toolshed/gh-actions/github/checkout@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      id: checkout
      name: Checkout Envoy repository
      with:
        pr: ${{ github.event.number }}
        branch: ${{ github.ref_name }}
        config: |
          fetch-depth: ${{ startsWith(github.event_name, 'pull_request') && 1 || 2 }}
    # This step *LOOKS AT* the repo at the point requested
    # Its essential that this _job_ *MUST NOT EXECUTE ANY CODE FROM THE CHECKED OUT REPO*
    # *ALL* variables collected should be treated as untrusted and should be sanitized before
    # use
    - name: Generate environment variables from commit
      uses: envoyproxy/toolshed/gh-actions/envoy/ci/request@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      id: env
      with:
        branch-name: ${{ steps.checkout.outputs.branch-name }}
        config-file: ${{ inputs.config-file }}
        merge-commit: ${{ steps.checkout.outputs.merge-commit }}
        started: ${{ steps.started.outputs.value }}
        token: ${{ secrets.GITHUB_TOKEN }}
        vars: ${{ toJSON(vars) }}
    - name: Request summary
      id: summary
      uses: envoyproxy/toolshed/gh-actions/github/env/summary@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      with:
        actor: ${{ toJSON(fromJSON(steps.env.outputs.data).request.actor) }}
        base-sha: ${{ fromJSON(steps.env.outputs.data).request.base-sha }}
        link: ${{ format('https://github.com/{0}/actions/runs/{1}', github.repository, github.run_id) }}
        output-path: GITHUB_STEP_SUMMARY
        pr: ${{ github.event.number }}
        data: ${{ steps.env.outputs.data }}
        tables: ${{ toJSON(fromJSON(steps.env.outputs.data).config.tables) }}
        icon: ${{ fromJSON(steps.env.outputs.data).config.envoy.icon }}
        message: ${{ fromJSON(steps.env.outputs.data).request.message }}
        ref: ${{ fromJSON(steps.env.outputs.data).request.ref }}
        sha: ${{ fromJSON(steps.env.outputs.data).request.sha }}
        target-branch: ${{ fromJSON(steps.env.outputs.data).request.target-branch }}

    - name: Environment data
      uses: envoyproxy/toolshed/gh-actions/jq@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      id: data
      with:
        input: |
          env: ${{ steps.env.outputs.data }}
          title: ${{ steps.summary.outputs.title }}
          link: ${{ format('https://github.com/{0}/actions/runs/{1}', github.repository, github.run_id) }}
          summary: ${{ steps.summary.outputs.summary }}
        input-format: yaml
        filter: |
          .title as $title
          | .env.config.envoy.icon as $icon
          | .link as $link
          | "\($icon) Request ([\($title)](\($link)))" as $linkedTitle
          |  .summary as $summary
          | .env
          | .summary = {
              $summary,
              $title,
              $link,
              "linked-title": $linkedTitle}
          | del(.config.tables)

  checks:
    if: ${{ github.repository == 'envoyproxy/envoy' || vars.ENVOY_CI }}
    needs: incoming
    uses: ./.github/workflows/_start.yml
    secrets:
      app-id: ${{ secrets.app-id }}
      app-key: ${{ secrets.app-key }}
    with:
      env: ${{ needs.incoming.outputs.env }}
name: Envoy/release

permissions:
  contents: read

on:
  release:
    types:
    - published
    branches:
    - main
    - release/v*
  workflow_dispatch:
    inputs:
      task:
        description: Select a task
        required: true
        default: create-release
        type: choice
        options:
        - create-release
        - sync-version-histories
      pr:
        type: boolean
        default: true
        description: Create a PR
      pr-message:
        description: Additional message for PR, eg to fix an issue or additional signoff (optional)
      wip:
        type: boolean
        default: false
        description: WIP
      author:
        description: >-
          Author: User/email, eg 'Myname <me@mymail.com>'
          (used by create-release, default: `changelogs/summary.md` last committer)
      summary:
        type: boolean
        default: true
        description: Use changelog summary (required to publish release)

env:
  COMMITTER_NAME: publish-envoy[bot]
  COMMITTER_EMAIL: 140627008+publish-envoy[bot]@users.noreply.github.com


jobs:
  ## Triggerable actions

  # Create a release commit, when landed this will publish.
  create_release:
    runs-on: ubuntu-22.04
    if: github.event_name == 'workflow_dispatch' && inputs.task == 'create-release'
    name: Create release
    steps:
    - id: appauth
      name: App auth
      uses: envoyproxy/toolshed/gh-actions/appauth@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      with:
        app_id: ${{ secrets.ENVOY_CI_PUBLISH_APP_ID }}
        key: ${{ secrets.ENVOY_CI_PUBLISH_APP_KEY }}

    - id: checkout
      name: Checkout Envoy repository
      uses: envoyproxy/toolshed/gh-actions/github/checkout@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      with:
        committer-name: ${{ env.COMMITTER_NAME }}
        committer-email: ${{ env.COMMITTER_EMAIL }}
        strip-prefix: release/
        token: ${{ steps.appauth.outputs.token }}
    - run: |
        if [[ ! -s "changelogs/summary.md" ]]; then
            if [[ "${{ inputs.summary }}" == "false" ]]; then
                echo "::warning::Changelog summary (changelogs/summary.md) is empty!"
                exit 0
            fi
            echo "::error::Changelog summary (changelogs/summary.md) is empty!"
            exit 1
        fi
        COMMITTER=$(git log -n 1 --format='%an <%ae>' -- changelogs/summary.md)
        echo "committer=${COMMITTER}" >> $GITHUB_OUTPUT
      id: changelog
      name: Check changelog summary
    - if: ${{ inputs.author }}
      name: Validate signoff email
      uses: envoyproxy/toolshed/gh-actions/email/validate@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      with:
        email: ${{ inputs.author }}
    - uses: envoyproxy/toolshed/gh-actions/github/run@2b4b266dbf6e410f2e8a05abf0dcd8ad13e6ecac  # actions-v0.2.23
      name: Create release
      with:
        source: |
          BAZEL_ARGS=(--)
          BAZEL_RUN_ARGS=(--config=ci)
          if [[ -n "${{ inputs.author }}" ]]; then
              BAZEL_ARGS+=(
                  "--release-author=${{ inputs.author }}"
                  "--signoff=${{ steps.changelog.outputs.committer }}")
          else
              BAZEL_ARGS+=("--release-author=${{ steps.changelo