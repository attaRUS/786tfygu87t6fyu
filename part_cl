d was extracted so that raw-pointer vector does not appear in real code.
  virtual ConsumerAssignmentConstPtr assignConsumerPartitions(RdKafka::KafkaConsumer& consumer,
                                                              const std::string& topic,
                                                              const int32_t partitions) const PURE;
};

using RawKafkaConfig = std::map<std::string, std::string>;

} // namespace Mesh
} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/kafka/filters/network/source/mesh/config.h"

#include "envoy/registry/registry.h"
#include "envoy/server/filter_config.h"
#include "envoy/stats/scope.h"

#ifndef WIN32
#include "contrib/kafka/filters/network/source/mesh/shared_consumer_manager.h"
#include "contrib/kafka/filters/network/source/mesh/shared_consumer_manager_impl.h"
#include "contrib/kafka/filters/network/source/mesh/upstream_config.h"
#include "contrib/kafka/filters/network/source/mesh/upstream_kafka_facade.h"
#include "contrib/kafka/filters/network/source/mesh/filter.h"
#else
#include "envoy/common/exception.h"
#endif

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {
namespace Mesh {

// The mesh filter doesn't do anything special, it just sets up the shared entities.
// Any extra configuration validation is done in UpstreamKafkaConfiguration constructor.
Network::FilterFactoryCb KafkaMeshConfigFactory::createFilterFactoryFromProtoTyped(
    const KafkaMeshProtoConfig& config, Server::Configuration::FactoryContext& context) {

#ifdef WIN32
  throw EnvoyException("Kafka mesh filter is not supported on Windows");
#else
  // Shared configuration (tells us where the upstream clusters are).
  const UpstreamKafkaConfigurationSharedPtr configuration =
      std::make_shared<UpstreamKafkaConfigurationImpl>(config);

  auto& server_context = context.serverFactoryContext();

  // Shared upstream facade (connects us to upstream Kafka clusters).
  const UpstreamKafkaFacadeSharedPtr upstream_kafka_facade =
      std::make_shared<UpstreamKafkaFacadeImpl>(*configuration, server_context.threadLocal(),
                                                server_context.api().threadFactory());

  // Manager for consumers shared across downstream connections
  // (connects us to upstream Kafka clusters).
  const RecordCallbackProcessorSharedPtr shared_consumer_manager =
      std::make_shared<SharedConsumerManagerImpl>(*configuration,
                                                  server_context.api().threadFactory());

  return [configuration, upstream_kafka_facade,
          shared_consumer_manager](Network::FilterManager& filter_manager) -> void {
    Network::ReadFilterSharedPtr filter = std::make_shared<KafkaMeshFilter>(
        *configuration, *upstream_kafka_facade, *shared_consumer_manager);
    filter_manager.addReadFilter(filter);
  };
#endif
}

/**
 * Static registration for the Kafka filter. @see RegisterFactory.
 */
REGISTER_FACTORY(KafkaMeshConfigFactory, Server::Configuration::NamedNetworkFilterConfigFactory);

} // namespace Mesh
} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/kafka/filters/network/source/kafka_response_parser.h"

#include "absl/strings/str_cat.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

const ResponseParserResolver& ResponseParserResolver::getDefaultInstance() {
  CONSTRUCT_ON_FIRST_USE(ResponseParserResolver);
}

ResponseParseResponse ResponseHeaderParser::parse(absl::string_view& data) {
  length_deserializer_.feed(data);
  if (!length_deserializer_.ready()) {
    return ResponseParseResponse::stillWaiting();
  }

  correlation_id_deserializer_.feed(data);
  if (!correlation_id_deserializer_.ready()) {
    return ResponseParseResponse::stillWaiting();
  }

  if (!context_->api_info_set_) {
    // We have consumed first two response header fields: payload length and correlation id.
    context_->remaining_response_size_ = length_deserializer_.get();
    context_->remaining_response_size_ -= sizeof(context_->correlation_id_);
    context_->correlation_id_ = correlation_id_deserializer_.get();

    // We have correlation id now, so we can see what is the expected response api key & version.
    const ExpectedResponseSpec spec = getResponseSpec(context_->correlation_id_);
    context_->api_key_ = spec.first;
    context_->api_version_ = spec.second;

    // Mark that version data has been set, so we do not attempt to re-initialize again.
    context_->api_info_set_ = true;
  }

  // Depending on response's api key & version, we might need to parse tagged fields element.
  if (responseUsesTaggedFieldsInHeader(context_->api_key_, context_->api_version_)) {
    context_->remaining_response_size_ -= tagged_fields_deserializer_.feed(data);
    if (tagged_fields_deserializer_.ready()) {
      context_->tagged_fields_ = tagged_fields_deserializer_.get();
    } else {
      return ResponseParseResponse::stillWaiting();
    }
  }

  // At this stage, we have fully setup the context - we know the response's api key & version,
  // so we can safely create the payload parser.
  auto next_parser = parser_resolver_.createParser(context_);
  return ResponseParseResponse::nextParser(next_parser);
}

ExpectedResponseSpec ResponseHeaderParser::getResponseSpec(const int32_t correlation_id) {
  const auto it = expected_responses_->find(correlation_id);
  if (it != expected_responses_->end()) {
    const auto spec = it->second;
    expected_responses_->erase(it);
    return spec;
  } else {
    // Response data should always be present in expected responses before response is to be parsed.
    throw EnvoyException(
        absl::StrCat("no response metadata registered for correlation_id ", correlation_id));
  }
};

} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include <vector>

#include "contrib/kafka/filters/network/source/serialization.h"

/**
 * This header file provides serialization support for tagged fields structure added in 2.4.
 * https://github.com/apache/kafka/blob/2.8.1/clients/src/main/java/org/apache/kafka/common/protocol/types/TaggedFields.java
 *
 * Impl note: contrary to other compact data structures, data in tagged field does not have +1 in
 * data length.
 */

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

/**
 * Simple data-holding structure.
 */
struct TaggedField {

  uint32_t tag_;
  std::vector<unsigned char> data_;

  uint32_t computeCompactSize(const EncodingContext& encoder) const {
    uint32_t result{0};
    result += encoder.computeCompactSize(tag_);
    result += encoder.computeCompactSize(static_cast<uint32_t>(data_.size()));
    result += data_.size();
    return result;
  }

  uint32_t encodeCompact(Buffer::Instance& dst, EncodingContext& encoder) const {
    uint32_t written{0};
    written += encoder.encodeCompact(tag_, dst);
    written += encoder.encodeCompact(static_cast<uint32_t>(data_.size()), dst);
    dst.add(data_.data(), data_.size());
    written += data_.size();
    return written;
  }

  bool operator==(const TaggedField& rhs) const { return tag_ == rhs.tag_ && data_ == rhs.data_; }
};

/**
 * Deserializer responsible for extracting a TaggedField from data provided.
 */
class TaggedFieldDeserializer : public Deserializer<TaggedField> {
public:
  TaggedFieldDeserializer() = default;

  uint32_t feed(absl::string_view& data) override {
    uint32_t consumed = 0;
    consumed += tag_deserializer_.feed(data);
    consumed += length_deserializer_.feed(data);

    if (!length_deserializer_.ready()) {
      return consumed;
    }

    if (!length_consumed_) {
      required_ = length_deserializer_.get();
      data_buffer_ = std::vector<unsigned char>(required_);
      length_consumed_ = true;
    }

    const uint32_t data_consumed = std::min<uint32_t>(required_, data.size());
    const uint32_t written = data_buffer_.size() - required_;
    if (data_consumed > 0) {
      memcpy(data_buffer_.data() + written, data.data(), data_consumed); // NOLINT(safe-memcpy)
      required_ -= data_consumed;
      data = {data.data() + data_consumed, data.size() - data_consumed};
    }

    if (required_ == 0) {
      ready_ = true;
    }

    return consumed + data_consumed;
  };

  bool ready() const override { return ready_; };

  TaggedField get() const override { return {tag_deserializer_.get(), data_buffer_}; };

private:
  VarUInt32Deserializer tag_deserializer_;
  VarUInt32Deserializer length_deserializer_;
  bool length_consumed_{false};
  uint32_t required_;
  std::vector<unsigned char> data_buffer_;
  bool ready_{false};
};

/**
 * Aggregate of multiple TaggedField objects.
 */
struct TaggedFields {

  std::vector<TaggedField> fields_;

  uint32_t computeCompactSize(const EncodingContext& encoder) const {
    uint32_t result{0};
    result += encoder.computeCompactSize(static_cast<uint32_t>(fields_.size()));
    for (const TaggedField& tagged_field : fields_) {
      result += tagged_field.computeCompactSize(encoder);
    }
    return result;
  }

  uint32_t encodeCompact(Buffer::Instance& dst, EncodingContext& encoder) const {
    uint32_t written{0};
    written += encoder.encodeCompact(static_cast<uint32_t>(fields_.size()), dst);
    for (const TaggedField& tagged_field : fields_) {
      written += tagged_field.encodeCompact(dst, encoder);
    }
    return written;
  }

  bool operator==(const TaggedFields& rhs) const { return fields_ == rhs.fields_; }
};

/**
 * Deserializer responsible for extracting tagged fields from data provided.
 */
class TaggedFieldsDeserializer : public Deserializer<TaggedFields> {
public:
  uint32_t feed(absl::string_view& data) override {

    const uint32_t count_consumed = count_deserializer_.feed(data);
    if (!count_deserializer_.ready()) {
      return count_consumed;
    }

    if (!children_setup_) {
      const uint32_t field_count = count_deserializer_.get();
      children_ = std::vector<TaggedFieldDeserializer>(field_count);
      children_setup_ = true;
    }

    if (ready_) {
      return count_consumed;
    }

    uint32_t child_consumed{0};
    for (TaggedFieldDeserializer& child : children_) {
      child_consumed += child.feed(data);
    }

    bool children_ready_ = true;
    for (TaggedFieldDeserializer& child : children_) {
      children_ready_ &= child.ready();
    }
    ready_ = children_ready_;

    return count_consumed + child_consumed;
  };

  bool ready() const override { return ready_; };

  TaggedFields get() const override {
    std::vector<TaggedField> fields{};
    fields.reserve(children_.size());
    for (const TaggedFieldDeserializer& child : children_) {
      const TaggedField child_result = child.get();
      fields.push_back(child_result);
    }
    return {fields};
  };

private:
  VarUInt32Deserializer count_deserializer_;
  std::vector<TaggedFieldDeserializer> children_;

  bool children_setup_ = false;
  bool ready_ = false;
};

} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include <map>
#include <memory>

#include "contrib/kafka/filters/network/source/kafka_response.h"
#include "contrib/kafka/filters/network/source/parser.h"
#include "contrib/kafka/filters/network/source/tagged_fields.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

using ResponseParseResponse = ParseResponse<AbstractResponseSharedPtr, ResponseMetadataSharedPtr>;
using ResponseParser = Parser<AbstractResponseSharedPtr, ResponseMetadataSharedPtr>;
using ResponseParserSharedPtr = std::shared_ptr<ResponseParser>;

/**
 * Context that is shared between parsers that are handling the same single message.
 */
struct ResponseContext {

  /**
   * Whether the 'api_key_' & 'api_version_' fields have been initialized.
   */
  bool api_info_set_ = false;

  /**
   * Api key of response that's being parsed.
   */
  int16_t api_key_;

  /**
   * Api version of response that's being parsed.
   */
  int16_t api_version_;

  /**
   * Bytes left to process.
   */
  uint32_t remaining_response_size_;

  /**
   * Response's correlation id.
   */
  int32_t correlation_id_;

  /**
   * Response's tagged fields.
   */
  TaggedFields tagged_fields_;

  /**
   * Bytes left to consume.
   */
  uint32_t& remaining() { return remaining_response_size_; }

  /**
   * Returns data needed for construction of parse failure message.
   */
  const ResponseMetadata asFailureData() const {
    return {api_key_, api_version_, correlation_id_, tagged_fields_};
  }
};

using ResponseContextSharedPtr = std::shared_ptr<ResponseContext>;

// Helper container for response api key & version.
using ExpectedResponseSpec = std::pair<int16_t, int16_t>;
// Response metadata store (maps from correlation id to api key & version).
using ExpectedResponses = std::map<int32_t, ExpectedResponseSpec>;
using ExpectedResponsesSharedPtr = std::shared_ptr<ExpectedResponses>;

/**
 * Response decoder configuration object.
 * Resolves the parser that will be responsible for consuming the response.
 * In other words: provides (api_key, api_version) -> Parser function.
 */
class ResponseParserResolver {
public:
  virtual ~ResponseParserResolver() = default;

  /**
   * Creates a parser that is going to process data specific for given response.
   * @param metadata expected response metadata.
   * @return parser that is capable of processing response.
   */
  virtual ResponseParserSharedPtr createParser(ResponseContextSharedPtr metadata) const;

  /**
   * Return default resolver, that uses response's api key and version to provide a matching parser.
   */
  static const ResponseParserResolver& getDefaultInstance();
};

/**
 * Response parser responsible for consuming response header (payload length and correlation id) and
 * setting up context with this data.
 * @see http://kafka.apache.org/protocol.html#protocol_common
 */
class ResponseHeaderParser : public ResponseParser {
public:
  /**
   * Creates a parser with necessary dependencies (store of expected responses & parser resolver).
   * @param expected_responses store containing mapping from response correlation id to api key &
   * version.
   * @param parser_resolver factory used to create the following payload parser.
   */
  ResponseHeaderParser(ExpectedResponsesSharedPtr expected_responses,
                       const ResponseParserResolver& parser_resolver)
      : expected_responses_{expected_responses},
        parser_resolver_{parser_resolver}, context_{std::make_shared<ResponseContext>()} {};

  /**
   * Consumes 8 bytes (2 x INT32) as response length and correlation id.
   * Uses correlation id to resolve response's api version & key (throws if not possible).
   * Updates the context with data resolved, and then creates the following payload parser using the
   * parser resolver.
   * @return ResponseParser instance to process the response payload.
   */
  ResponseParseResponse parse(absl::string_view& data) override;

  const ResponseContextSharedPtr contextForTest() const { return context_; }

private:
  ExpectedResponseSpec getResponseSpec(int32_t correlation_id);

  const ExpectedResponsesSharedPtr expected_responses_;
  const ResponseParserResolver& parser_resolver_;
  const ResponseContextSharedPtr context_;

  Int32Deserializer length_deserializer_;
  Int32Deserializer correlation_id_deserializer_;
  TaggedFieldsDeserializer tagged_fields_deserializer_;
};

/**
 * Sentinel parser that is responsible for consuming message bytes for messages that had unsupported
 * api_key & api_version. It does not attempt to capture any data, just throws it away until end of
 * message.
 */
class SentinelResponseParser
    : public AbstractSentinelParser<ResponseContextSharedPtr, ResponseParseResponse>,
      public ResponseParser {
public:
  SentinelResponseParser(ResponseContextSharedPtr context) : AbstractSentinelParser{context} {};

  ResponseParseResponse parse(absl::string_view& data) override {
    return AbstractSentinelParser::parse(data);
  }
};

/**
 * Response parser uses a single deserializer to construct a response object.
 * This parser is responsible for consuming response-specific data (e.g. topic names) and always
 * returns a parsed message.
 * @param ResponseType response class.
 * @param DeserializerType deserializer type corresponding to response class (should be subclass of
 * Deserializer<ResponseType>).
 */
template <typename ResponseType, typename DeserializerType>
class ResponseDataParser : public ResponseParser {
public:
  /**
   * Create a parser for given response metadata.
   * @param metadata expected message metadata.
   */
  ResponseDataParser(ResponseContextSharedPtr context) : context_{context} {};

  /**
   * Consume enough data to fill in deserializer and receive the parsed response.
   * Fill in response's header with data stored in context.
   * @param data data to process.
   */
  ResponseParseResponse parse(absl::string_view& data) override {
    context_->remaining_response_size_ -= deserializer_.feed(data);

    if (deserializer_.ready()) {
      if (0 == context_->remaining_response_size_) {
        // After a successful parse, there should be nothing left - we have consumed all the bytes.
        const ResponseMetadata metadata = {context_->api_key_, context_->api_version_,
                                           context_->correlation_id_, context_->tagged_fields_};
        const AbstractResponseSharedPtr response =
            std::make_shared<Response<ResponseType>>(metadata, deserializer_.get());
        return ResponseParseResponse::parsedMessage(response);
      } else {
        // The message makes no sense, the deserializer that matches the schema consumed all
        // necessary data, but there are still bytes in this message.
        return ResponseParseResponse::nextParser(
            std::make_shared<SentinelResponseParser>(context_));
      }
    } else {
      return ResponseParseResponse::stillWaiting();
    }
  }

  const ResponseContextSharedPtr contextForTest() const { return context_; }

private:
  ResponseContextSharedPtr context_;
  DeserializerType deserializer_; // Underlying response-specific deserializer.
};

} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/kafka/filters/network/source/kafka_request_parser.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

const RequestParserResolver& RequestParserResolver::getDefaultInstance() {
  CONSTRUCT_ON_FIRST_USE(RequestParserResolver);
}

RequestParseResponse RequestStartParser::parse(absl::string_view& data) {
  request_length_.feed(data);
  if (request_length_.ready()) {
    context_->remaining_request_size_ = request_length_.get();
    return RequestParseResponse::nextParser(
        std::make_shared<RequestHeaderParser>(parser_resolver_, context_));
  } else {
    return RequestParseResponse::stillWaiting();
  }
}

uint32_t RequestHeaderDeserializer::feed(absl::string_view& data) {
  uint32_t consumed = 0;

  consumed += common_part_deserializer_.feed(data);
  if (common_part_deserializer_.ready()) {
    const auto request_header = common_part_deserializer_.get();
    if (requestUsesTaggedFieldsInHeader(request_header.api_key_, request_header.api_version_)) {
      tagged_fields_present_ = true;
      consumed += tagged_fields_deserializer_.feed(data);
    }
  }

  return consumed;
}

bool RequestHeaderDeserializer::ready() const {
  // Header is only fully parsed after we have processed everything, including tagged fields (if
  // they are present).
  return common_part_deserializer_.ready() &&
         (tagged_fields_present_ ? tagged_fields_deserializer_.ready() : true);
}

RequestHeader RequestHeaderDeserializer::get() const {
  auto result = common_part_deserializer_.get();
  if (tagged_fields_present_) {
    result.tagged_fields_ = tagged_fields_deserializer_.get();
  }
  return result;
}

RequestParseResponse RequestHeaderParser::parse(absl::string_view& data) {
  context_->remaining_request_size_ -= deserializer_->feed(data);
  // One of the two needs must have happened when feeding finishes:
  // - deserializer has consumed all the bytes it needed,
  // - or all the data has been consumed (but deserializer might still need data to be ready).
  ASSERT(deserializer_->ready() || data.empty());
  if (deserializer_->ready()) {
    RequestHeader request_header = deserializer_->get();
    context_->request_header_ = request_header;
    RequestParserSharedPtr next_parser = parser_resolver_.createParser(
        request_header.api_key_, request_header.api_version_, context_);
    return RequestParseResponse::nextParser(next_parser);
  } else {
    return RequestParseResponse::stillWaiting();
  }
}

} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/kafka/filters/network/source/broker/filter_config.h"

#include "source/common/common/assert.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {
namespace Broker {

static std::vector<RewriteRule> extractRewriteRules(const KafkaBrokerProtoConfig& proto_config) {
  if (proto_config.has_id_based_broker_address_rewrite_spec()) {
    std::vector<RewriteRule> result;
    const auto& spec = proto_config.id_based_broker_address_rewrite_spec();
    for (const auto& rule : spec.rules()) {
      result.emplace_back(rule.id(), rule.host(), rule.port());
    }
    return result;
  } else {
    return {};
  }
}

BrokerFilterConfig::BrokerFilterConfig(const KafkaBrokerProtoConfig& proto_config)
    : BrokerFilterConfig{proto_config.stat_prefix(), proto_config.force_response_rewrite(),
                         extractRewriteRules(proto_config)} {}

BrokerFilterConfig::BrokerFilterConfig(const std::string& stat_prefix,
                                       const bool force_response_rewrite,
                                       const std::vector<RewriteRule>& broker_address_rewrite_rules)
    : stat_prefix_{stat_prefix}, force_response_rewrite_{force_response_rewrite},
      broker_address_rewrite_rules_{broker_address_rewrite_rules} {
  ASSERT(!stat_prefix_.empty());
};

bool BrokerFilterConfig::needsResponseRewrite() const {
  return force_response_rewrite_ || !broker_address_rewrite_rules_.empty();
}

absl::optional<HostAndPort>
BrokerFilterConfig::findBrokerAddressOverride(const uint32_t broker_id) const {
  for (const auto& rule : broker_address_rewrite_rules_) {
    if (rule.matches(broker_id)) {
      const HostAndPort hp = {rule.host_, rule.port_};
      return {hp};
    }
  }
  return absl::nullopt;
}

const std::string& BrokerFilterConfig::stat_prefix() const { return stat_prefix_; }

} // namespace Broker
} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include "source/extensions/filters/network/common/factory_base.h"
#include "source/extensions/filters/network/well_known_names.h"

#include "contrib/envoy/extensions/filters/network/kafka_broker/v3/kafka_broker.pb.h"
#include "contrib/envoy/extensions/filters/network/kafka_broker/v3/kafka_broker.pb.validate.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {
namespace Broker {

using KafkaBrokerProtoConfig = envoy::extensions::filters::network::kafka_broker::v3::KafkaBroker;

/**
 * Config registration for the Kafka filter.
 */
class KafkaConfigFactory : public Common::FactoryBase<KafkaBrokerProtoConfig> {
public:
  KafkaConfigFactory() : FactoryBase(NetworkFilterNames::get().KafkaBroker) {}

private:
  // Common::FactoryBase<KafkaBrokerProtoConfig>
  Network::FilterFactoryCb
  createFilterFactoryFromProtoTyped(const KafkaBrokerProtoConfig& proto_config,
                                    Server::Configuration::FactoryContext& context) override;
};

} // namespace Broker
} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include <vector>

#include "envoy/buffer/buffer.h"

#include "source/common/common/logger.h"

#include "contrib/kafka/filters/network/source/broker/filter_config.h"
#include "contrib/kafka/filters/network/source/external/responses.h"
#include "contrib/kafka/filters/network/source/response_codec.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {
namespace Broker {

/**
 * Responsible for modifying any outbound requests.
 */
class ResponseRewriter : public ResponseCallback {
public:
  virtual ~ResponseRewriter() = default;

  /**
   * Performs any desired payload changes.
   * @param buffer buffer with the original data from upstream
   */
  virtual void process(Buffer::Instance& buffer) PURE;
};

using ResponseRewriterSharedPtr = std::shared_ptr<ResponseRewriter>;

/**
 * Uses captured response objects instead of original data.
 * Entry point for any response payload changes.
 */
class ResponseRewriterImpl : public ResponseRewriter, private Logger::Loggable<Logger::Id::kafka> {
public:
  ResponseRewriterImpl(const BrokerFilterConfig& config);

  // ResponseCallback
  void onMessage(AbstractResponseSharedPtr response) override;
  void onFailedParse(ResponseMetadataSharedPtr parse_failure) override;

  // ResponseRewriter
  void process(Buffer::Instance& buffer) override;

  /**
   * Mutates response according to config.
   */
  void updateMetadataBrokerAddresses(MetadataResponse& response) const;

  /**
   * Mutates response according to config.
   */
  void updateFindCoordinatorBrokerAddresses(FindCoordinatorResponse& response) const;

  /**
   * Mutates response according to config.
   */
  void updateDescribeClusterBrokerAddresses(DescribeClusterResponse& response) const;

  size_t getStoredResponseCountForTest() const;

private:
  // Helper function to update various response structures.
  // Pointer-to-member used to handle varying field names across the structs.
  template <typename T> void maybeUpdateHostAndPort(T& arg, const int32_t T::*node_id_field) const {
    const int32_t node_id = arg.*node_id_field;
    const absl::optional<HostAndPort> hostAndPort = config_.findBrokerAddressOverride(node_id);
    if (hostAndPort) {
      ENVOY_LOG(trace, "Changing broker [{}] from {}:{} to {}:{}", node_id, arg.host_, arg.port_,
                hostAndPort->first, hostAndPort->second);
      arg.host_ = hostAndPort->first;
      arg.port_ = hostAndPort->second;
    }
  }

  const BrokerFilterConfig& config_;
  std::vector<AbstractResponseSharedPtr> responses_to_rewrite_;
};

/**
 * Does nothing, letting the data from upstream pass without any changes.
 * It allows us to avoid the unnecessary deserialization-then-serialization steps.
 */
class DoNothingRewriter : public ResponseRewriter {
public:
  // ResponseCallback
  void onMessage(AbstractResponseSharedPtr response) override;
  void onFailedParse(ResponseMetadataSharedPtr parse_failure) override;

  // ResponseRewriter
  void process(Buffer::Instance& buffer) override;
};

/**
 * Factory method that creates a rewriter depending on configuration.
 */
ResponseRewriterSharedPtr createRewriter(const BrokerFilterConfig& config);

} // namespace Broker
} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/kafka/filters/network/source/broker/filter.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {
namespace Broker {

void Forwarder::onMessage(AbstractRequestSharedPtr request) {
  const RequestHeader& header = request->request_header_;
  response_decoder_.expectResponse(header.correlation_id_, header.api_key_, header.api_version_);
}

void Forwarder::onFailedParse(RequestParseFailureSharedPtr parse_failure) {
  const RequestHeader& header = parse_failure->request_header_;
  response_decoder_.expectResponse(header.correlation_id_, header.api_key_, header.api_version_);
}

// Nothing fancy here, proper metrics registration is left to Rich...MetricsImpl constructors.
KafkaMetricsFacadeImpl::KafkaMetricsFacadeImpl(Stats::Scope& scope, TimeSource& time_source,
                                               const std::string& stat_prefix)
    : KafkaMetricsFacadeImpl{time_source,
                             std::make_shared<RichRequestMetricsImpl>(scope, stat_prefix),
                             std::make_shared<RichResponseMetricsImpl>(scope, stat_prefix)} {};

KafkaMetricsFacadeImpl::KafkaMetricsFacadeImpl(TimeSource& time_source,
                                               RichRequestMetricsSharedPtr request_metrics,
                                               RichResponseMetricsSharedPtr response_metrics)
    : time_source_{time_source}, request_metrics_{request_metrics}, response_metrics_{
                                                                        response_metrics} {};

// When request is successfully parsed, increase type count and store its arrival timestamp.
void KafkaMetricsFacadeImpl::onMessage(AbstractRequestSharedPtr request) {
  const RequestHeader& header = request->request_header_;
  request_metrics_->onRequest(header.api_key_);

  const MonotonicTime request_arrival_ts = time_source_.monotonicTime();
  request_arrivals_[header.correlation_id_] = request_arrival_ts;
}

void KafkaMetricsFacadeImpl::onFailedParse(RequestParseFailureSharedPtr) {
  request_metrics_->onUnknownRequest();
}

void KafkaMetricsFacadeImpl::onRequestException() { request_metrics_->onBrokenRequest(); }

// When response is successfully parsed, compute processing time using its correlation id and
// stored request arrival timestamp, then update metrics with the result.
void KafkaMetricsFacadeImpl::onMessage(AbstractResponseSharedPtr response) {
  const ResponseMetadata& metadata = response->metadata_;

  const MonotonicTime response_arrival_ts = time_source_.monotonicTime();
  const MonotonicTime request_arrival_ts = request_arrivals_[metadata.correlation_id_];
  request_arrivals_.erase(metadata.correlation_id_);

  const MonotonicTime::duration time_in_broker = response_arrival_ts - request_arrival_ts;
  const auto ms = std::chrono::duration_cast<std::chrono::milliseconds>(time_in_broker);

  response_metrics_->onResponse(metadata.api_key_, ms.count());
}

void KafkaMetricsFacadeImpl::onFailedParse(ResponseMetadataSharedPtr) {
  response_metrics_->onUnknownResponse();
}

void KafkaMetricsFacadeImpl::onResponseException() { response_metrics_->onBrokenResponse(); }

absl::flat_hash_map<int32_t, MonotonicTime>& KafkaMetricsFacadeImpl::getRequestArrivalsForTest() {
  return request_arrivals_;
}

KafkaBrokerFilter::KafkaBrokerFilter(Stats::Scope& scope, TimeSource& time_source,
                                     const BrokerFilterConfig& filter_config)
    : KafkaBrokerFilter{filter_config, std::make_shared<KafkaMetricsFacadeImpl>(
                                           scope, time_source, filter_config.stat_prefix())} {};

KafkaBrokerFilter::KafkaBrokerFilter(const BrokerFilterConfig& filter_config,
                                     const KafkaMetricsFacadeSharedPtr& metrics)
    : metrics_{metrics}, response_rewriter_{createRewriter(filter_config)},
      response_decoder_{new ResponseDecoder({metrics, response_rewriter_})},
      request_decoder_{
          new RequestDecoder({std::make_shared<Forwarder>(*response_decoder_), metrics})} {};

KafkaBrokerFilter::KafkaBrokerFilter(KafkaMetricsFacadeSharedPtr metrics,
                                     ResponseRewriterSharedPtr response_rewriter,
                                     ResponseDecoderSharedPtr response_decoder,
                                     RequestDecoderSharedPtr request_decoder)
    : metrics_{metrics}, response_rewriter_{response_rewriter}, response_decoder_{response_decoder},
      request_decoder_{request_decoder} {};

Network::FilterStatus KafkaBrokerFilter::onNewConnection() {
  return Network::FilterStatus::Continue;
}

void KafkaBrokerFilter::initializeReadFilterCallbacks(Network::ReadFilterCallbacks&) {}

Network::FilterStatus KafkaBrokerFilter::onData(Buffer::Instance& data, bool) {
  ENVOY_LOG(trace, "data from Kafka client [{} request bytes]", data.length());
  try {
    request_decoder_->onData(data);
    return Network::FilterStatus::Continue;
  } catch (const EnvoyException& e) {
    ENVOY_LOG(debug, "could not process data from Kafka client: {}", e.what());
    metrics_->onRequestException();
    request_decoder_->reset();
    return Network::FilterStatus::StopIteration;
  }
}

Network::FilterStatus KafkaBrokerFilter::onWrite(Buffer::Instance& data, bool) {
  ENVOY_LOG(trace, "data from Kafka broker [{} response bytes]", data.length());
  try {
    response_decoder_->onData(data);
    response_rewriter_->process(data);
    return Network::FilterStatus::Continue;
  } catch (const EnvoyException& e) {
    ENVOY_LOG(debug, "could not process data from Kafka broker: {}", e.what());
    metrics_->onResponseException();
    response_decoder_->reset();
    return Network::FilterStatus::StopIteration;
  }
}

RequestDecoderSharedPtr KafkaBrokerFilter::getRequestDecoderForTest() { return request_decoder_; }

ResponseDecoderSharedPtr KafkaBrokerFilter::getResponseDecoderForTest() {
  return response_decoder_;
}

} // namespace Broker
} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include <utility>

#include "absl/types/optional.h"
#include "contrib/envoy/extensions/filters/network/kafka_broker/v3/kafka_broker.pb.h"
#include "contrib/envoy/extensions/filters/network/kafka_broker/v3/kafka_broker.pb.validate.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {
namespace Broker {

using KafkaBrokerProtoConfig = envoy::extensions::filters::network::kafka_broker::v3::KafkaBroker;

using HostAndPort = std::pair<std::string, uint32_t>;

// Represents a rule matching a broker with given id.
struct RewriteRule {

  uint32_t id_;

  std::string host_;
  uint32_t port_;

  RewriteRule(const uint32_t id, const std::string host, const uint32_t port)
      : id_{id}, host_{host}, port_{port} {};

  bool matches(const uint32_t broker_id) const { return id_ == broker_id; }
};

// Minor helper object that contains broker filter configuration.
class BrokerFilterConfig {
public:
  virtual ~BrokerFilterConfig() = default;

  BrokerFilterConfig(const KafkaBrokerProtoConfig& proto_config);

  // Visible for testing.
  BrokerFilterConfig(const std::string& stat_prefix, const bool force_response_rewrite,
                     const std::vector<RewriteRule>& broker_address_rewrite_rules);

  /**
   * Returns the prefix for stats.
   */
  virtual const std::string& stat_prefix() const;

  /**
   * Whether this configuration means that rewrite should be happening.
   */
  virtual bool needsResponseRewrite() const;

  /**
   * Returns override address for a broker.
   */
  virtual absl::optional<HostAndPort> findBrokerAddressOverride(const uint32_t broker_id) const;

private:
  std::string stat_prefix_;
  bool force_response_rewrite_;
  std::vector<RewriteRule> broker_address_rewrite_rules_;
};

using BrokerFilterConfigSharedPtr = std::shared_ptr<BrokerFilterConfig>;

} // namespace Broker
} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
load(
    "//bazel:envoy_build_system.bzl",
    "envoy_cc_contrib_extension",
    "envoy_cc_library",
    "envoy_contrib_package",
)

licenses(["notice"])  # Apache 2

envoy_contrib_package()

# Kafka-broker network filter.
# Broker filter public docs: https://envoyproxy.io/docs/envoy/latest/configuration/listeners/network_filters/kafka_broker_filter

envoy_cc_contrib_extension(
    name = "config_lib",
    srcs = ["config.cc"],
    hdrs = ["config.h"],
    deps = [
        ":filter_config_lib",
        ":filter_lib",
        "//source/extensions/filters/network:well_known_names",
        "//source/extensions/filters/network/common:factory_base_lib",
        "@envoy_api//contrib/envoy/extensions/filters/network/kafka_broker/v3:pkg_cc_proto",
    ],
)

envoy_cc_library(
    name = "filter_config_lib",
    srcs = [
        "filter_config.cc",
    ],
    hdrs = [
        "filter_config.h",
    ],
    deps = [
        "//source/common/common:assert_lib",
        "@envoy_api//contrib/envoy/extensions/filters/network/kafka_broker/v3:pkg_cc_proto",
    ],
)

envoy_cc_library(
    name = "filter_lib",
    srcs = ["filter.cc"],
    hdrs = [
        "filter.h",
    ],
    deps = [
        ":filter_config_lib",
        ":rewriter_lib",
        "//contrib/kafka/filters/network/source:kafka_metrics_lib",
        "//contrib/kafka/filters/network/source:kafka_request_codec_lib",
        "//contrib/kafka/filters/network/source:kafka_response_codec_lib",
        "//envoy/buffer:buffer_interface",
        "//envoy/network:connection_interface",
        "//envoy/network:filter_interface",
        "//source/common/common:minimal_logger_lib",
    ],
)

envoy_cc_library(
    name = "rewriter_lib",
    srcs = ["rewriter.cc"],
    hdrs = [
        "rewriter.h",
    ],
    deps = [
        ":filter_config_lib",
        "//contrib/kafka/filters/network/source:kafka_response_codec_lib",
        "//envoy/buffer:buffer_interface",
        "//source/common/common:minimal_logger_lib",
    ],
)
#pragma once

#include "envoy/network/filter.h"
#include "envoy/stats/scope.h"

#include "source/common/common/logger.h"

#include "absl/container/flat_hash_map.h"
#include "contrib/kafka/filters/network/source/broker/filter_config.h"
#include "contrib/kafka/filters/network/source/broker/rewriter.h"
#include "contrib/kafka/filters/network/source/external/request_metrics.h"
#include "contrib/kafka/filters/network/source/external/response_metrics.h"
#include "contrib/kafka/filters/network/source/parser.h"
#include "contrib/kafka/filters/network/source/request_codec.h"
#include "contrib/kafka/filters/network/source/response_codec.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {
namespace Broker {

/**
 * Utility class that merges both request & response callbacks.
 */
class KafkaCallback : public RequestCallback, public ResponseCallback {};

using KafkaCallbackSharedPtr = std::shared_ptr<KafkaCallback>;

/**
 * Request callback responsible for updating state of related response decoder.
 * When a request gets successfully parsed, the response decoder registers a new incoming request.
 * When request could not be recognized, we can extract the header, so we can register the
 * expected response (decoder will not be able to capable of decoding the response, but at least we
 * will not break the communication between client and broker).
 */
class Forwarder : public RequestCallback {
public:
  /**
   * Binds forwarder to given response decoder.
   */
  Forwarder(ResponseDecoder& response_decoder) : response_decoder_{response_decoder} {};

  // RequestCallback
  void onMessage(AbstractRequestSharedPtr request) override;
  void onFailedParse(RequestParseFailureSharedPtr parse_failure) override;

private:
  ResponseDecoder& response_decoder_;
};

/**
 * Single access point for all Kafka-related metrics.
 * Implements Kafka message callback, so decoders can refer to it when parse results appear.
 * This interface was extracted to facilitate mock injection in unit tests.
 */
class KafkaMetricsFacade : public KafkaCallback {
public:
  /**
   * To be invoked when exceptions occur while processing a request.
   */
  virtual void onRequestException() PURE;

  /**
   * To be invoked when exceptions occur while processing a response.
   */
  virtual void onResponseException() PURE;
};

using KafkaMetricsFacadeSharedPtr = std::shared_ptr<KafkaMetricsFacade>;

/**
 * Metrics facade implementation that actually uses rich request/response metrics.
 * Keeps requests' arrival timestamps (by correlation id) and uses them calculate response
 * processing time.
 */
class KafkaMetricsFacadeImpl : public KafkaMetricsFacade {
public:
  /**
   * Creates facade that keeps prefixed metrics in given scope, and uses given time source to
   * compute processing durations.
   */
  KafkaMetricsFacadeImpl(Stats::Scope& scope, TimeSource& time_source,
                         const std::string& stat_prefix);

  /**
   * Visible for testing.
   */
  KafkaMetricsFacadeImpl(TimeSource& time_source, RichRequestMetricsSharedPtr request_metrics,
                         RichResponseMetricsSharedPtr response_metrics);

  // RequestCallback
  void onMessage(AbstractRequestSharedPtr request) override;
  void onFailedParse(RequestParseFailureSharedPtr parse_failure) override;

  // ResponseCallback
  void onMessage(AbstractResponseSharedPtr response) override;
  void onFailedParse(ResponseMetadataSharedPtr parse_failure) override;

  // KafkaMetricsFacade
  void onRequestException() override;
  void onResponseException() override;

  absl::flat_hash_map<int32_t, MonotonicTime>& getRequestArrivalsForTest();

private:
  TimeSource& time_source_;
  absl::flat_hash_map<int32_t, MonotonicTime> request_arrivals_;
  RichRequestMetricsSharedPtr request_metrics_;
  RichResponseMetricsSharedPtr response_metrics_;
};

/**
 * Implementation of Kafka broker-level filter.
 * Uses two decoders - request and response ones, that are connected using Forwarder instance.
 * KafkaMetricsFacade is listening for both request/response events to keep metrics.
 * ResponseRewriter is listening for response events to capture and rewrite them if needed.
 *
 *        +---------------------------------------------------+
 *        |                                                   |
 *        |               +--------------+                    |
 *        |   +---------->+RequestDecoder+----------------+   |
 *        |   |           +-------+------+                |   |
 *        |   |                   |                       |   |
 *        |   |                   |                       |   |
 *        |   |                   v                       v   v
 * +------+---+------+       +----+----+        +---------+---+----+
 * |KafkaBrokerFilter|       |Forwarder|        |KafkaMetricsFacade|
 * +------+---+------+       +----+----+        +---------+--------+
 *        |   |                   |                       ^
 *        |   |                   |                       |
 *        |   |                   v                       |
 *        |   |           +-------+-------+               |
 *        |   +---------->+ResponseDecoder+---------------+
 *        |               +-------+-------+
 *        |                       |
 *        |                       v
 *        |               +-------+--------+
 *        +-------------->+ResponseRewriter+
 *                        +----------------+
 */
class KafkaBrokerFilter : public Network::Filter, private Logger::Loggable<Logger::Id::kafka> {
public:
  /**
   * Main constructor.
   * Creates decoders that eventually update prefixed metrics stored in scope, using time source for
   * duration calculation.
   */
  KafkaBrokerFilter(Stats::Scope& scope, TimeSource& time_source,
                    const BrokerFilterConfig& filter_config);

  /**
   * Visible for testing.
   */
  KafkaBrokerFilter(KafkaMetricsFacadeSharedPtr metrics,
                    ResponseRewriterSharedPtr response_rewriter,
                    ResponseDecoderSharedPtr response_decoder,
                    RequestDecoderSharedPtr request_decoder);

  // Network::ReadFilter
  Network::FilterStatus onNewConnection() override;
  void initializeReadFilterCallbacks(Network::ReadFilterCallbacks& callbacks) override;
  Network::FilterStatus onData(Buffer::Instance& data, bool end_stream) override;

  // Network::WriteFilter
  Network::FilterStatus onWrite(Buffer::Instance& data, bool end_stream) override;

  RequestDecoderSharedPtr getRequestDecoderForTest();
  ResponseDecoderSharedPtr getResponseDecoderForTest();

private:
  /**
   * Helper delegate constructor.
   * Passes metrics facade as argument to decoders.
   */
  KafkaBrokerFilter(const BrokerFilterConfig& filter_config,
                    const KafkaMetricsFacadeSharedPtr& metrics);

  const KafkaMetricsFacadeSharedPtr metrics_;
  const ResponseRewriterSharedPtr response_rewriter_;
  const ResponseDecoderSharedPtr response_decoder_;
  const RequestDecoderSharedPtr request_decoder_;
};

} // namespace Broker
} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/kafka/filters/network/source/broker/rewriter.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {
namespace Broker {

// ResponseRewriterImpl.

ResponseRewriterImpl::ResponseRewriterImpl(const BrokerFilterConfig& config) : config_{config} {};

void ResponseRewriterImpl::onMessage(AbstractResponseSharedPtr response) {
  responses_to_rewrite_.push_back(response);
}

void ResponseRewriterImpl::onFailedParse(ResponseMetadataSharedPtr) {}

constexpr int16_t METADATA_API_KEY = 3;
constexpr int16_t FIND_COORDINATOR_API_KEY = 10;
constexpr int16_t DESCRIBE_CLUSTER_API_KEY = 60;

template <typename T> static T& extractResponseData(AbstractResponseSharedPtr& arg) {
  using TSharedPtr = std::shared_ptr<Response<T>>;
  TSharedPtr cast = std::dynamic_pointer_cast<typename TSharedPtr::element_type>(arg);
  if (nullptr == cast) {
    throw new EnvoyException("bug: response class not matching response API key");
  } else {
    return cast->data_;
  }
}

void ResponseRewriterImpl::process(Buffer::Instance& buffer) {
  buffer.drain(buffer.length());
  ResponseEncoder encoder{buffer};
  ENVOY_LOG(trace, "emitting {} stored responses", responses_to_rewrite_.size());
  for (auto response : responses_to_rewrite_) {
    switch (response->apiKey()) {
    case METADATA_API_KEY: {
      auto& mr = extractResponseData<MetadataResponse>(response);
      updateMetadataBrokerAddresses(mr);
      break;
    }
    case FIND_COORDINATOR_API_KEY: {
      auto& fcr = extractResponseData<FindCoordinatorResponse>(response);
      updateFindCoordinatorBrokerAddresses(fcr);
      break;
    }
    case DESCRIBE_CLUSTER_API_KEY: {
      auto& dcr = extractResponseData<DescribeClusterResponse>(response);
      updateDescribeClusterBrokerAddresses(dcr);
      break;
    }
    }
    encoder.encode(*response);
  }
  responses_to_rewrite_.erase(responses_to_rewrite_.begin(), responses_to_rewrite_.end());
}

void ResponseRewriterImpl::updateMetadataBrokerAddresses(MetadataResponse& response) const {
  for (MetadataResponseBroker& broker : response.brokers_) {
    maybeUpdateHostAndPort(broker, &MetadataResponseBroker::node_id_);
  }
}

void ResponseRewriterImpl::updateFindCoordinatorBrokerAddresses(
    FindCoordinatorResponse& response) const {
  maybeUpdateHostAndPort(response, &FindCoordinatorResponse::node_id_);
  for (Coordinator& coordinator : response.coordinators_) {
    maybeUpdateHostAndPort(coordinator, &Coordinator::node_id_);
  }
}

void ResponseRewriterImpl::updateDescribeClusterBrokerAddresses(
    DescribeClusterResponse& response) const {
  for (DescribeClusterBroker& broker : response.brokers_) {
    maybeUpdateHostAndPort(broker, &DescribeClusterBroker::broker_id_);
  }
}

size_t ResponseRewriterImpl::getStoredResponseCountForTest() const {
  return responses_to_rewrite_.size();
}

// DoNothingRewriter.

void DoNothingRewriter::onMessage(AbstractResponseSharedPtr) {}

void DoNothingRewriter::onFailedParse(ResponseMetadataSharedPtr) {}

void DoNothingRewriter::process(Buffer::Instance&) {}

// Factory method.

ResponseRewriterSharedPtr createRewriter(const BrokerFilterConfig& config) {
  if (config.needsResponseRewrite()) {
    return std::make_shared<ResponseRewriterImpl>(config);
  } else {
    return std::make_shared<DoNothingRewriter>();
  }
}

} // namespace Broker
} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/kafka/filters/network/source/broker/config.h"

#include "envoy/registry/registry.h"
#include "envoy/server/filter_config.h"
#include "envoy/stats/scope.h"

#include "contrib/kafka/filters/network/source/broker/filter.h"
#include "contrib/kafka/filters/network/source/broker/filter_config.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {
namespace Broker {

Network::FilterFactoryCb KafkaConfigFactory::createFilterFactoryFromProtoTyped(
    const KafkaBrokerProtoConfig& proto_config, Server::Configuration::FactoryContext& context) {

  const BrokerFilterConfigSharedPtr filter_config =
      std::make_shared<BrokerFilterConfig>(proto_config);
  return [&context, filter_config](Network::FilterManager& filter_manager) -> void {
    Network::FilterSharedPtr filter = std::make_shared<KafkaBrokerFilter>(
        context.scope(), context.serverFactoryContext().timeSource(), *filter_config);
    filter_manager.addFilter(filter);
  };
}

/**
 * Static registration for the Kafka filter. @see RegisterFactory.
 */
REGISTER_FACTORY(KafkaConfigFactory, Server::Configuration::NamedNetworkFilterConfigFactory);

} // namespace Broker
} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/kafka/filters/network/source/serialization.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

constexpr static int16_t NULL_STRING_LENGTH = -1;
constexpr static uint32_t NULL_COMPACT_STRING_LENGTH = 0;
constexpr static int32_t NULL_BYTES_LENGTH = -1;
constexpr static uint32_t NULL_COMPACT_BYTES_LENGTH = 0;

/**
 * Helper method for deserializers that get the length of data, and then copy the given bytes into a
 * local buffer. Templated as there are length and byte type differences.
 * Impl note: This method modifies (sets up) most of Deserializer's fields.
 * @param data bytes to deserialize.
 * @param length_deserializer payload length deserializer.
 * @param length_consumed_marker marker telling whether length has been extracted from
 * length_deserializer, and underlying buffer has been initialized.
 * @param required remaining bytes to consume.
 * @param data_buffer buffer with capacity for 'required' bytes.
 * @param ready marker telling whether this deserialized has finished processing.
 * @param null_value_length value marking null values.
 * @param allow_null_value whether null value if allowed.
 * @return number of bytes consumed.
 */
template <typename DeserializerType, typename LengthType, typename ByteType>
uint32_t feedBytesIntoBuffers(absl::string_view& data, DeserializerType& length_deserializer,
                              bool& length_consumed_marker, LengthType& required,
                              std::vector<ByteType>& data_buffer, bool& ready,
                              const LengthType null_value_length, const bool allow_null_value) {

  const uint32_t length_consumed = length_deserializer.feed(data);
  if (!length_deserializer.ready()) {
    // Break early: we still need to fill in length buffer.
    return length_consumed;
  }

  if (!length_consumed_marker) {
    // Length buffer is ready, but we have not yet processed the result.
    // We need to extract the real data length and initialize buffer for it.
    required = length_deserializer.get();

    if (required >= 0) {
      data_buffer = std::vector<ByteType>(required);
    }

    if (required == null_value_length) {
      if (allow_null_value) {
        // We have received 'null' value in deserializer that allows it (e.g. NullableBytes), no
        // more processing is necessary.
        ready = true;
      } else {
        // Invalid payload: null length for non-null object.
        throw EnvoyException(absl::StrCat("invalid length: ", required));
      }
    }

    if (required < null_value_length) {
      throw EnvoyException(absl::StrCat("invalid length: ", required));
    }

    length_consumed_marker = true;
  }

  if (ready) {
    // Break early: we might not need to consume any bytes for nullable values OR in case of repeat
    // invocation on already-ready buffer.
    return length_consumed;
  }

  const uint32_t data_consumed = std::min<uint32_t>(required, data.size());
  const uint32_t written = data_buffer.size() - required;
  if (data_consumed > 0) {
    memcpy(data_buffer.data() + written, data.data(), data_consumed); // NOLINT(safe-memcpy)
    required -= data_consumed;
    data = {data.data() + data_consumed, data.size() - data_consumed};
  }

  // We have consumed all the bytes, mark the deserializer as ready.
  if (required == 0) {
    ready = true;
  }

  return length_consumed + data_consumed;
}

uint32_t StringDeserializer::feed(absl::string_view& data) {
  return feedBytesIntoBuffers<Int16Deserializer, int16_t, char>(
      data, length_buf_, length_consumed_, required_, data_buf_, ready_, NULL_STRING_LENGTH, false);
}

uint32_t NullableStringDeserializer::feed(absl::string_view& data) {
  return feedBytesIntoBuffers<Int16Deserializer, int16_t, char>(
      data, length_buf_, length_consumed_, required_, data_buf_, ready_, NULL_STRING_LENGTH, true);
}

uint32_t BytesDeserializer::feed(absl::string_view& data) {
  return feedBytesIntoBuffers<Int32Deserializer, int32_t, unsigned char>(
      data, length_buf_, length_consumed_, required_, data_buf_, ready_, NULL_BYTES_LENGTH, false);
}

uint32_t NullableBytesDeserializer::feed(absl::string_view& data) {
  return feedBytesIntoBuffers<Int32Deserializer, int32_t, unsigned char>(
      data, length_buf_, length_consumed_, required_, data_buf_, ready_, NULL_BYTES_LENGTH, true);
}

/**
 * Helper method for "compact" deserializers that get the length of data, and then copy the given
 * bytes into a local buffer. Compared to `feedBytesIntoBuffers` we only use template for data type,
 * as compact data types always use variable-length uint32 for data length.
 * Impl note: This method modifies (sets up) most of Deserializer's fields.
 * @param data bytes to deserialize.
 * @param length_deserializer payload length deserializer.
 * @param length_consumed_marker marker telling whether length has been extracted from
 * length_deserializer, and underlying buffer has been initialized.
 * @param required remaining bytes to consume.
 * @param data_buffer buffer with capacity for 'required' bytes.
 * @param ready marker telling whether this deserialized has finished processing.
 * @param null_value_length value marking null values.
 * @param allow_null_value whether null value if allowed.
 * @return number of bytes consumed.
 */
template <typename ByteType>
uint32_t
feedCompactBytesIntoBuffers(absl::string_view& data, VarUInt32Deserializer& length_deserializer,
                            bool& length_consumed_marker, uint32_t& required,
                            std::vector<ByteType>& data_buffer, bool& ready,
                            const uint32_t null_value_length, const bool allow_null_value) {

  const uint32_t length_consumed = length_deserializer.feed(data);
  if (!length_deserializer.ready()) {
    // Break early: we still need to fill in length buffer.
    return length_consumed;
  }

  if (!length_consumed_marker) {
    // Length buffer is ready, but we have not yet processed the result.
    // We need to extract the real data length and initialize buffer for it.
    required = length_deserializer.get();

    if (null_value_length == required) {
      if (allow_null_value) {
        // We have received 'null' value in deserializer that allows it (e.g. NullableCompactBytes),
        // no more processing is necessary.
        ready = true;
      } else {
        // Invalid payload: null length for non-null object.
        throw EnvoyException(absl::StrCat("invalid length: ", required));
      }
    } else {
      // Compact data types carry data length + 1 (0 is used to mark 'null' in nullable types).
      required--;
      data_buffer = std::vector<ByteType>(required);
    }

    length_consumed_marker = true;
  }

  if (ready) {
    // Break early: we might not need to consume any bytes for nullable values OR in case of repeat
    // invocation on already-ready buffer.
    return length_consumed;
  }

  const uint32_t data_consumed = std::min<uint32_t>(required, data.size());
  const uint32_t written = data_buffer.size() - required;
  if (data_consumed > 0) {
    memcpy(data_buffer.data() + written, data.data(), data_consumed); // NOLINT(safe-memcpy)
    required -= data_consumed;
    data = {data.data() + data_consumed, data.size() - data_consumed};
  }

  // We have consumed all the bytes, mark the deserializer as ready.
  if (required == 0) {
    ready = true;
  }

  return length_consumed + data_consumed;
}

uint32_t CompactStringDeserializer::feed(absl::string_view& data) {
  return feedCompactBytesIntoBuffers<char>(data, length_buf_, length_consumed_, required_,
                                           data_buf_, ready_, NULL_COMPACT_STRING_LENGTH, false);
}

uint32_t NullableCompactStringDeserializer::feed(absl::string_view& data) {
  return feedCompactBytesIntoBuffers<char>(data, length_buf_, length_consumed_, required_,
                                           data_buf_, ready_, NULL_COMPACT_STRING_LENGTH, true);
}

NullableString NullableCompactStringDeserializer::get() const {
  const uint32_t original_data_len = length_buf_.get();
  if (NULL_COMPACT_STRING_LENGTH == original_data_len) {
    return absl::nullopt;
  } else {
    return absl::make_optional(std::string(data_buf_.begin(), data_buf_.end()));
  }
}

uint32_t CompactBytesDeserializer::feed(absl::string_view& data) {
  return feedCompactBytesIntoBuffers<unsigned char>(data, length_buf_, length_consumed_, required_,
                                                    data_buf_, ready_, NULL_COMPACT_BYTES_LENGTH,
                                                    false);
}

uint32_t NullableCompactBytesDeserializer::feed(absl::string_view& data) {
  return feedCompactBytesIntoBuffers<unsigned char>(data, length_buf_, length_consumed_, required_,
                                                    data_buf_, ready_, NULL_COMPACT_BYTES_LENGTH,
                                                    true);
}

NullableBytes NullableCompactBytesDeserializer::get() const {
  const uint32_t original_data_len = length_buf_.get();
  if (NULL_COMPACT_BYTES_LENGTH == original_data_len) {
    return absl::nullopt;
  } else {
    return absl::make_optional(data_buf_);
  }
}

namespace VarlenUtils {

uint32_t writeUnsignedVarint(const uint32_t arg, Bytes& dst) {
  uint32_t value = arg;

  uint32_t elements_with_1 = 0;
  // As long as there are bits set on indexes 8 or higher (counting from 1).
  while ((value & ~(0x7f)) != 0) {
    // Save next 7-bit batch with highest bit set.
    const uint8_t el = (value & 0x7f) | 0x80;
    dst.push_back(el);
    value >>= 7;
    elements_with_1++;
  }

  // After the loop has finished, we are certain that bit 8 = 0, so we can just add final element.
  const uint8_t el = value;
  dst.push_back(el);

  return elements_with_1 + 1;
}

uint32_t writeVarint(const int32_t arg, Bytes& dst) {
  uint32_t zz = (static_cast<uint32_t>(arg) << 1) ^ (arg >> 31); // Zig-zag.
  return writeUnsignedVarint(zz, dst);
}

uint32_t writeVarlong(const int64_t arg, Bytes& dst) {
  uint64_t value = (static_cast<uint64_t>(arg) << 1) ^ (arg >> 63); // Zig-zag.

  uint32_t elements_with_1 = 0;
  // As long as there are bits set on indexes 8 or higher (counting from 1).
  while ((value & ~(0x7f)) != 0) {
    // Save next 7-bit batch with highest bit set.
    const uint8_t el = (value & 0x7f) | 0x80;
    dst.push_back(el);
    value >>= 7;
    elements_with_1++;
  }

  // After the loop has finished, we are certain that bit 8 = 0, so we can just add final element.
  const uint8_t el = value;
  dst.push_back(el);

  return elements_with_1 + 1;
}

} // namespace VarlenUtils

} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include <sstream>

#include "source/common/common/logger.h"

#include "absl/strings/string_view.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

template <typename MessageType, typename FailureDataType> class ParseResponse;

/**
 * Parser is responsible for consuming data relevant to some part of a message, and then returning
 * the decision how the parsing should continue.
 */
template <typename MessageType, typename FailureDataType>
class Parser : public Logger::Loggable<Logger::Id::kafka> {
public:
  virtual ~Parser() = default;

  /**
   * Submit data to be processed by parser, will consume as much data as it is necessary to reach
   * the conclusion what should be the next parse step.
   * @param data bytes to be processed, will be updated by parser if any have been consumed.
   * @return parse status - decision what should be done with current parser (keep/replace).
   */
  virtual ParseResponse<MessageType, FailureDataType> parse(absl::string_view& data) PURE;
};

template <typename MessageType, typename FailureDataType>
using ParserSharedPtr = std::shared_ptr<Parser<MessageType, FailureDataType>>;

/**
 * Three-state holder representing one of:
 * - parser still needs data (`stillWaiting`),
 * - parser is finished, and following parser should be used to process the rest of data
 * (`nextParser`),
 * - parser is finished, and parse result is attached (`parsedMessage` or `parseFailure`).
 */
template <typename MessageType, typename FailureDataType> class ParseResponse {
public:
  using FailureType = FailureDataType;

  /**
   * Constructs a response that states that parser still needs data and should not be replaced.
   */
  static ParseResponse stillWaiting() { return {nullptr, nullptr, nullptr}; }

  /**
   * Constructs a response that states that parser is finished and should be replaced by given
   * parser.
   */
  static ParseResponse nextParser(ParserSharedPtr<MessageType, FailureDataType> next_parser) {
    return {next_parser, nullptr, nullptr};
  };

  /**
   * Constructs a response that states that parser is finished, the message is ready, and parsing
   * can start anew for next message.
   */
  static ParseResponse parsedMessage(MessageType message) { return {nullptr, message, nullptr}; };

  /**
   * Constructs a response that states that parser is finished, the message could not be parsed
   * properly, and parsing can start anew for next message.
   */
  static ParseResponse parseFailure(FailureDataType failure_data) {
    return {nullptr, nullptr, failure_data};
  };

  /**
   * If response contains a next parser or a parse result.
   */
  bool hasData() const {
    return (next_parser_ != nullptr) || (message_ != nullptr) || (failure_data_ != nullptr);
  }

private:
  ParseResponse(ParserSharedPtr<MessageType, FailureDataType> parser, MessageType message,
                FailureDataType failure_data)
      : next_parser_{parser}, message_{message}, failure_data_{failure_data} {};

public:
  ParserSharedPtr<MessageType, FailureDataType> next_parser_;
  MessageType message_;
  FailureDataType failure_data_;
};

template <typename ContextType, typename ResponseType> class AbstractSentinelParser {
public:
  AbstractSentinelParser(ContextType context) : context_{context} {};

  ResponseType parse(absl::string_view& data) {
    const uint32_t min = std::min<uint32_t>(context_->remaining(), data.size());
    data = {data.data() + min, data.size() - min};
    context_->remaining() -= min;
    if (0 == context_->remaining()) {
      using FailureType = typename ResponseType::FailureType::element_type;
      auto failure_data = std::make_shared<FailureType>(context_->asFailureData());
      return ResponseType::parseFailure(failure_data);
    } else {
      return ResponseType::stillWaiting();
    }
  }

  const ContextType contextForTest() const { return context_; }

private:
  ContextType context_;
};

} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/kafka/filters/network/source/response_codec.h"

#include "source/common/buffer/buffer_impl.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

// Default implementation that just creates ResponseHeaderParser with dependencies provided.
class ResponseInitialParserFactoryImpl : public ResponseInitialParserFactory {
  ResponseParserSharedPtr create(ExpectedResponsesSharedPtr expected_responses,
                                 const ResponseParserResolver& parser_resolver) const override {
    return std::make_shared<ResponseHeaderParser>(expected_responses, parser_resolver);
  }
};

const ResponseInitialParserFactory& ResponseInitialParserFactory::getDefaultInstance() {
  CONSTRUCT_ON_FIRST_USE(ResponseInitialParserFactoryImpl);
}

void ResponseDecoder::expectResponse(const int32_t correlation_id, const int16_t api_key,
                                     const int16_t api_version) {
  (*expected_responses_)[correlation_id] = {api_key, api_version};
};

ResponseParserSharedPtr ResponseDecoder::createStartParser() {
  return factory_.create(expected_responses_, response_parser_resolver_);
}

void ResponseEncoder::encode(const AbstractResponse& message) {
  const uint32_t size = htobe32(message.computeSize());
  output_.add(&size, sizeof(size)); // Encode data length.
  message.encode(output_);          // Encode data.
}

} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#!/usr/bin/python

# Main library file containing all the composite deserializer logic.


def generate_main_code(serialization_composite_h_file):
    """
  Main code generator.
  Renders the header file for serialization composites.
  The location of output file is provided as argument.
  """
    generate_code('serialization_composite_h.j2', serialization_composite_h_file)


def generate_test_code(serialization_composite_test_cc_file):
    """
  Test code generator.
  Renders the test file for serialization composites.
  The location of output file is provided as argument.
  """
    generate_code('serialization_composite_test_cc.j2', serialization_composite_test_cc_file)


def generate_code(template_name, output_file):
    """
  Gets definition of structures to render.
  Then renders these structures using template provided into provided output file.
  """
    field_counts = get_field_counts()
    template = RenderingHelper.get_template(template_name)
    contents = template.render(counts=field_counts)
    with open(output_file, 'w') as fd:
        fd.write(contents)


def get_field_counts():
    """
    Generate argument counts that should be processed by composite deserializers.
    """
    return range(1, 13)


class RenderingHelper:
    """
  Helper for jinja templates.
  """

    @staticmethod
    def get_template(template):
        import jinja2
        import os
        import sys
        # Templates are resolved relatively to main start script, due to main & test templates being
        # stored in different directories.
        env = jinja2.Environment(
            loader=jinja2.FileSystemLoader(
                searchpath=os.path.dirname(os.path.abspath(sys.argv[0]))))
        return env.get_template(template)
#!/usr/bin/python

# Launcher for generating composite serializer code.

import contrib.kafka.filters.network.source.serialization.generator as generator
import sys
import os


def main():
    """
  Serialization composite code generator
  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  Generates main source code files for composite deserializers.
  The files are generated, as they are extremely repetitive (composite deserializer for 0..9
  sub-deserializers).

  Usage:
    launcher.py LOCATION_OF_OUTPUT_FILE
  where:
  LOCATION_OF_OUTPUT_FILE : location of 'serialization_composite.h'.

  Creates 'serialization_composite.h' - header with declarations of
  CompositeDeserializerWith???Delegates classes.

  Template used: 'serialization_composite_h.j2'.
  """
    serialization_composite_h_file = os.path.abspath(sys.argv[1])
    generator.generate_main_code(serialization_composite_h_file)


if __name__ == "__main__":
    main()
{#
  Creates 'serialization_composite.h'.

  Template for composite serializers (the CompositeDeserializerWith_N_Delegates classes).
  Covers the corner case of 0 delegates, and then uses templating to create declarations for 1..N
  variants.
#}
#pragma once

#include <algorithm>
#include <memory>
#include <string>
#include <vector>

#include "envoy/buffer/buffer.h"
#include "envoy/common/exception.h"
#include "envoy/common/pure.h"

#include "source/common/common/byte_order.h"
#include "source/common/common/fmt.h"

#include "contrib/kafka/filters/network/source/kafka_types.h"
#include "contrib/kafka/filters/network/source/serialization.h"

#include "absl/strings/string_view.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

/**
 * This header contains only composite deserializers.
 * The basic design is composite deserializer creating delegates DeserializerType1..N.
 * Result of type ResponseType is constructed by getting results of each of delegates.
 * These deserializers can throw, if any of the delegate deserializers can.
 */

/**
 * Composite deserializer that uses 0 deserializer(s) (corner case).
 * Does not consume any bytes, and is always ready to return the result.
 * Creates a result value using the no-arg ResponseType constructor.
 * @param ResponseType type of deserialized data.
 */
template <typename ResponseType>
class CompositeDeserializerWith0Delegates : public Deserializer<ResponseType> {
public:
  CompositeDeserializerWith0Delegates(){};
  uint32_t feed(absl::string_view&) override { return 0; }
  bool ready() const override { return true; }
  ResponseType get() const override { return {}; }
};

{% for field_count in counts %}
/**
 * Composite deserializer that uses {{ field_count }} deserializer(s).
 * Passes data to each of the underlying deserializers (deserializers that are already ready do not
 * consume data, so it's safe).
 * The composite deserializer is ready when the last deserializer is ready (what means that all
 * deserializers before it are ready too).
 * Constructs the result of type ResponseType using { delegate1_.get(), delegate2_.get() ... }.
 *
 * @param ResponseType type of deserialized data{% for field in range(1, field_count + 1) %}.
 * @param DeserializerType{{ field }} deserializer {{ field }}.
{% endfor %} */
template <
  typename ResponseType{% for field in range(1, field_count + 1) %},
  typename DeserializerType{{ field }}{% endfor %}
>
class CompositeDeserializerWith{{ field_count }}Delegates : public Deserializer<ResponseType> {
public:
  CompositeDeserializerWith{{ field_count }}Delegates(){};

  uint32_t feed(absl::string_view& data) override {
    uint32_t consumed = 0;
    {% for field in range(1, field_count + 1) %}
    consumed += delegate{{ field }}_.feed(data);
    {% endfor %}
    return consumed;
  }

  bool ready() const override { return delegate{{ field_count }}_.ready(); }

  ResponseType get() const override {
    return {
      {% for field in range(1, field_count + 1) %}delegate{{ field }}_.get(),
      {% endfor %}};
  }

protected:
  {% for field in range(1, field_count + 1) %}
  DeserializerType{{ field }} delegate{{ field }}_;
  {% endfor %}
};
{% endfor %}

} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include <algorithm>
#include <memory>
#include <string>
#include <vector>

#include "envoy/buffer/buffer.h"
#include "envoy/common/exception.h"
#include "envoy/common/pure.h"

#include "source/common/common/byte_order.h"
#include "source/common/common/fmt.h"
#include "source/common/common/safe_memcpy.h"
#include "source/common/common/utility.h"

#include "absl/strings/str_cat.h"
#include "absl/strings/string_view.h"
#include "contrib/kafka/filters/network/source/kafka_types.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

/**
 * Deserializer is a stateful entity that constructs a result of type T from bytes provided.
 * It can be feed()-ed data until it is ready, filling the internal store.
 * When ready(), it is safe to call get() to transform the internally stored bytes into result.
 * Further feed()-ing should have no effect on a buffer (should return 0 and not move
 * provided pointer).
 * @param T type of deserialized data.
 */
template <typename T> class Deserializer {
public:
  /**
   * The type this deserializer is deserializing.
   */
  using result_type = T;

  virtual ~Deserializer() = default;

  /**
   * Submit data to be processed, will consume as much data as it is necessary.
   * If any bytes are consumed, then the provided string view is updated by stepping over consumed
   * bytes. Invoking this method when deserializer is ready has no effect (consumes 0 bytes).
   * @param data bytes to be processed, will be updated if any have been consumed.
   * @return number of bytes consumed (equal to change in 'data').
   */
  virtual uint32_t feed(absl::string_view& data) PURE;

  /**
   * Whether deserializer has consumed enough data to return result.
   */
  virtual bool ready() const PURE;

  /**
   * Returns the entity that is represented by bytes stored in this deserializer.
   * Should be only called when deserializer is ready.
   */
  virtual T get() const PURE;
};

/**
 * Generic integer deserializer (uses array of sizeof(T) bytes).
 * After all bytes are filled in, the value is converted from network byte-order and returned.
 */
template <typename T> class FixedSizeDeserializer : public Deserializer<T> {
public:
  uint32_t feed(absl::string_view& data) override {
    const uint32_t available = std::min<uint32_t>(sizeof(buf_) - written_, data.size());
    memcpy(buf_ + written_, data.data(), available); // NOLINT(safe-memcpy)
    written_ += available;

    if (written_ == sizeof(buf_)) {
      ready_ = true;
    }

    data = {data.data() + available, data.size() - available};

    return available;
  }

  bool ready() const override { return ready_; }

protected:
  char buf_[sizeof(T) / sizeof(char)];
  uint32_t written_{0};
  bool ready_{false};
};

/**
 * Integer deserializer for int8_t.
 */
class Int8Deserializer : public FixedSizeDeserializer<int8_t> {
public:
  int8_t get() const override {
    int8_t result = buf_[0];
    return result;
  }
};

/**
 * Integer deserializer for int16_t.
 */
class Int16Deserializer : public FixedSizeDeserializer<int16_t> {
public:
  int16_t get() const override {
    int16_t result;
    safeMemcpyUnsafeSrc(&result, buf_);
    return be16toh(result);
  }
};

/**
 * Integer deserializer for uint16_t.
 */
class UInt16Deserializer : public FixedSizeDeserializer<uint16_t> {
public:
  uint16_t get() const override {
    uint16_t result;
    safeMemcpyUnsafeSrc(&result, buf_);
    return be16toh(result);
  }
};

/**
 * Integer deserializer for int32_t.
 */
class Int32Deserializer : public FixedSizeDeserializer<int32_t> {
public:
  int32_t get() const override {
    int32_t result;
    safeMemcpyUnsafeSrc(&result, buf_);
    return be32toh(result);
  }
};

/**
 * Integer deserializer for uint32_t.
 */
class UInt32Deserializer : public FixedSizeDeserializer<uint32_t> {
public:
  uint32_t get() const override {
    uint32_t result;
    safeMemcpyUnsafeSrc(&result, buf_);
    return be32toh(result);
  }
};

/**
 * Integer deserializer for uint64_t.
 */
class Int64Deserializer : public FixedSizeDeserializer<int64_t> {
public:
  int64_t get() const override {
    int64_t result;
    safeMemcpyUnsafeSrc(&result, buf_);
    return be64toh(result);
  }
};

/**
 * Deserializer for Kafka Float64 type.
 * Reference: https://kafka.apache.org/28/protocol.html#protocol_types
 * Represents a double-precision 64-bit format IEEE 754 value. The values are encoded using eight
 * bytes in network byte order (big-endian).
 */
class Float64Deserializer : public FixedSizeDeserializer<double> {

  static_assert(sizeof(double) == sizeof(uint64_t), "sizeof(double) != sizeof(uint64_t)");
  static_assert(std::numeric_limits<double>::is_iec559, "non-IEC559 (IEEE 754) double");

public:
  double get() const override {
    uint64_t in_network_order;
    safeMemcpyUnsafeSrc(&in_network_order, buf_);
    uint64_t in_host_order = be64toh(in_network_order);
    double result;
    safeMemcpy(&result, &in_host_order);
    return result;
  }
};

/**
 * Deserializer for boolean values.
 * Uses a single int8 deserializer, and checks whether the results equals 0.
 * When reading a boolean value, any non-zero value is considered true.
 * Impl note: could have been a subclass of FixedSizeDeserializer<int8_t> with a different get
 * function, but it makes it harder to understand.
 */
class BooleanDeserializer : public Deserializer<bool> {
public:
  BooleanDeserializer() = default;

  uint32_t feed(absl::string_view& data) override { return buffer_.feed(data); }

  bool ready() const override { return buffer_.ready(); }

  bool get() const override { return 0 != buffer_.get(); }

private:
  Int8Deserializer buffer_;
};

/**
 * Integer deserializer for uint32_t that was encoded as variable-length byte array.
 * Encoding documentation:
 * https://cwiki.apache.org/confluence/display/KAFKA/KIP-482%3A+The+Kafka+Protocol+should+Support+Optional+Tagged+Fields#KIP-482:TheKafkaProtocolshouldSupportOptionalTaggedFields-UnsignedVarints
 *
 * Impl note:
 * This implementation is equivalent to the one present in Kafka, what means that for 5-byte
 * inputs, the data at bits 5-7 in 5th byte are *ignored* (as long as 8th bit is unset).
 * Reference:
 * https://github.com/apache/kafka/blob/2.8.1/clients/src/main/java/org/apache/kafka/common/utils/ByteUtils.java#L142
 */
class VarUInt32Deserializer : public Deserializer<uint32_t> {
public:
  VarUInt32Deserializer() = default;

  uint32_t feed(absl::string_view& data) override {
    uint32_t processed = 0;
    while (!ready_ && !data.empty()) {

      // Read next byte from input.
      uint8_t el;
      safeMemcpy(&el, data.data());
      data = {data.data() + 1, data.size() - 1};
      processed++;

      // Put the 7 bits where they should have been.
      // Impl note: the cast is done to avoid undefined behaviour when offset_ >= 28 and some bits
      // at positions 5-7 are set (we would have left shift of signed value that does not fit in
      // data type).
      result_ |= ((static_cast<uint32_t>(el) & 0x7f) << offset_);
      if ((el & 0x80) == 0) {
        // If this was the last byte to process (what is marked by unset highest bit), we are done.
        ready_ = true;
        break;
      } else {
        // Otherwise, we need to read next byte.
        offset_ += 7;
        // Valid input can have at most 5 bytes.
        if (offset_ >= 5 * 7) {
          ExceptionUtil::throwEnvoyException(
              "VarUInt32 is too long (5th byte has highest bit set)");
        }
      }
    }
    return processed;
  }

  bool ready() const override { return ready_; }

  uint32_t get() const override { return result_; }

private:
  uint32_t result_ = 0;
  uint32_t offset_ = 0;
  bool ready_ = false;
};

/**
 * Deserializer for Kafka 'varint' type.
 * Encoding documentation: https://kafka.apache.org/28/protocol.html#protocol_types
 *
 * Impl note:
 * This implementation is equivalent to the one present in Kafka, what means that for 5-byte
 * inputs, the data at bits 5-7 in 5th byte are *ignored* (as long as 8th bit is unset).
 * Reference:
 * https://github.com/apache/kafka/blob/2.8.1/clients/src/main/java/org/apache/kafka/common/utils/ByteUtils.java#L189
 */
class VarInt32Deserializer : public Deserializer<int32_t> {
public:
  VarInt32Deserializer() = default;

  uint32_t feed(absl::string_view& data) override { return varuint32_deserializer_.feed(data); }

  bool ready() const override { return varuint32_deserializer_.ready(); }

  int32_t get() const override {
    const uint32_t res = varuint32_deserializer_.get();
    return (res >> 1) ^ -(res & 1);
  }

private:
  VarUInt32Deserializer varuint32_deserializer_;
};

/**
 * Deserializer for Kafka 'varlong' type.
 * Encoding documentation: https://kafka.apache.org/28/protocol.html#protocol_types
 *
 * Impl note:
 * This implementation is equivalent to the one present in Kafka, what means that for 10-byte
 * inputs, the data at bits 3-7 in 10th byte are *ignored* (as long as 8th bit is unset).
 * Reference:
 * https://github.com/apache/kafka/blob/2.8.1/clients/src/main/java/org/apache/kafka/common/utils/ByteUtils.java#L242
 */
class VarInt64Deserializer : public Deserializer<int64_t> {
public:
  VarInt64Deserializer() = default;

  uint32_t feed(absl::string_view& data) override {
    uint32_t processed = 0;
    while (!ready_ && !data.empty()) {

      // Read next byte from input.
      uint8_t el;
      safeMemcpy(&el, data.data());
      data = {data.data() + 1, data.size() - 1};
      processed++;

      // Put the 7 bits where they should have been.
      // Impl note: the cast is done to avoid undefined behaviour when offset_ >= 63 and some bits
      // at positions 3-7 are set (we would have left shift of signed value that does not fit in
      // data type).
      bytes_ |= ((static_cast<uint64_t>(el) & 0x7f) << offset_);
      if ((el & 0x80) == 0) {
        // If this was the last byte to process (what is marked by unset highest bit), we are done.
        ready_ = true;
        break;
      } else {
        // Otherwise, we need to read next byte.
        offset_ += 7;
        // Valid input can have at most 10 bytes.
        if (offset_ >= 10 * 7) {
          ExceptionUtil::throwEnvoyException(
              "VarInt64 is too long (10th byte has highest bit set)");
        }
      }
    }
    return processed;
  }

  bool ready() const override { return ready_; }

  int64_t get() const override {
    // Do the final conversion, this is a zig-zag encoded signed value.
    return (bytes_ >> 1) ^ -(bytes_ & 1);
  }

private:
  uint64_t bytes_ = 0;
  uint32_t offset_ = 0;
  bool ready_ = false;
};

/**
 * Deserializer of string value.
 * First reads length (INT16) and then allocates the buffer of given length.
 *
 * From Kafka documentation:
 * First the length N is given as an INT16.
 * Then N bytes follow which are the UTF-8 encoding of the character sequence.
 * Length must not be negative.
 */
class StringDeserializer : public Deserializer<std::string> {
public:
  /**
   * Can throw EnvoyException if given string length is not valid.
   */
  uint32_t feed(absl::string_view& data) override;

  bool ready() const override { return ready_; }

  std::string get() const override { return {data_buf_.begin(), data_buf_.end()}; }

private:
  Int16Deserializer length_buf_;
  bool length_consumed_{false};

  int16_t required_;
  std::vector<char> data_buf_;

  bool ready_{false};
};

/**
 * Deserializer of compact string value.
 * First reads length (UNSIGNED_VARINT) and then allocates the buffer of given length.
 *
 * From Kafka documentation:
 * First the length N + 1 is given as an UNSIGNED_VARINT.
 * Then N bytes follow which are the UTF-8 encoding of the character sequence.
 */
class CompactStringDeserializer : public Deserializer<std::string> {
public:
  uint32_t feed(absl::string_view& data) override;

  bool ready() const override { return ready_; }

  std::string get() const override { return {data_buf_.begin(), data_buf_.end()}; }

private:
  VarUInt32Deserializer length_buf_;
  bool length_consumed_{false};

  uint32_t required_;
  std::vector<char> data_buf_;

  bool ready_{false};
};

/**
 * Deserializer of nullable string value.
 * First reads length (INT16) and then allocates the buffer of given length.
 * If length was -1, buffer allocation is omitted and deserializer is immediately ready (returning
 * null value).
 *
 * From Kafka documentation:
 * For non-null strings, first the length N is given as an INT16.
 * Then N bytes follow which are the UTF-8 encoding of the character sequence.
 * A null value is encoded with length of -1 and there are no following bytes.
 */
class NullableStringDeserializer : public Deserializer<NullableString> {
public:
  /**
   * Can throw EnvoyException if given string length is not valid.
   */
  uint32_t feed(absl::string_view& data) override;

  bool ready() const override { return ready_; }

  NullableString get() const override {
    return required_ >= 0 ? absl::make_optional(std::string(data_buf_.begin(), data_buf_.end()))
                          : absl::nullopt;
  }

private:
  Int16Deserializer length_buf_;
  bool length_consumed_{false};

  int16_t required_;
  std::vector<char> data_buf_;

  bool ready_{false};
};

/**
 * Deserializer of nullable compact string value.
 * First reads length (UNSIGNED_VARINT) and then allocates the buffer of given length.
 * If length was 0, buffer allocation is omitted and deserializer is immediately ready (returning
 * null value).
 *
 * From Kafka documentation:
 * First the length N + 1 is given as an UNSIGNED_VARINT.
 * Then N bytes follow which are the UTF-8 encoding of the character sequence.
 * A null string is represented with a length of 0.
 */
class NullableCompactStringDeserializer : public Deserializer<NullableString> {
public:
  uint32_t feed(absl::string_view& data) override;

  bool ready() const override { return ready_; }

  NullableString get() const override;

private:
  VarUInt32Deserializer length_buf_;
  bool length_consumed_{false};

  uint32_t required_;
  std::vector<char> data_buf_;

  bool ready_{false};
};

/**
 * Deserializer of bytes value.
 * First reads length (INT32) and then allocates the buffer of given length.
 *
 * From Kafka documentation:
 * First the length N is given as an INT32. Then N bytes follow.
 */
class BytesDeserializer : public Deserializer<Bytes> {
public:
  /**
   * Can throw EnvoyException if given bytes length is not valid.
   */
  uint32_t feed(absl::string_view& data) override;

  bool ready() const override { return ready_; }

  Bytes get() const override { return data_buf_; }

private:
  Int32Deserializer length_buf_;
  bool length_consumed_{false};
  int32_t required_;

  std::vector<unsigned char> data_buf_;
  bool ready_{false};
};

/**
 * Deserializer of compact bytes value.
 * First reads length (UNSIGNED_VARINT32) and then allocates the buffer of given length.
 *
 * From Kafka documentation:
 * First the length N+1 is given as an UNSIGNED_VARINT32. Then N bytes follow.
 */
class CompactBytesDeserializer : public Deserializer<Bytes> {
public:
  /**
   * Can throw EnvoyException if given bytes length is not valid.
   */
  uint32_t feed(absl::string_view& data) override;

  bool ready() const override { return ready_; }

  Bytes get() const override { return data_buf_; }

private:
  VarUInt32Deserializer length_buf_;
  bool length_consumed_{false};
  uint32_t required_;

  std::vector<unsigned char> data_buf_;
  bool ready_{false};
};

/**
 * Deserializer of nullable bytes value.
 * First reads length (INT32) and then allocates the buffer of given length.
 * If length was -1, buffer allocation is omitted and deserializer is immediately ready (returning
 * null value).
 *
 * From Kafka documentation:
 * For non-null values, first the length N is given as an INT32. Then N bytes follow.
 * A null value is encoded with length of -1 and there are no following bytes.
 */
class NullableBytesDeserializer : public Deserializer<NullableBytes> {
public:
  /**
   * Can throw EnvoyException if given bytes length is not valid.
   */
  uint32_t feed(absl::string_view& data) override;

  bool ready() const override { return ready_; }

  NullableBytes get() const override {
    return required_ >= 0 ? absl::make_optional(data_buf_) : absl::nullopt;
  }

private:
  Int32Deserializer length_buf_;
  bool length_consumed_{false};
  int32_t required_;

  std::vector<unsigned char> data_buf_;
  bool ready_{false};
};

/**
 * Deserializer of nullable compact bytes value.
 * First reads length (UNSIGNED_VARINT32) and then allocates the buffer of given length.
 * If length was 0, buffer allocation is omitted and deserializer is immediately ready (returning
 * null value).
 *
 * From Kafka documentation:
 * First the length N+1 is given as an UNSIGNED_VARINT. Then N bytes follow.
 * A null object is represented with a length of 0.
 */
class NullableCompactBytesDeserializer : public Deserializer<NullableBytes> {
public:
  /**
   * Can throw EnvoyException if given bytes length is not valid.
   */
  uint32_t feed(absl::string_view& data) override;

  bool ready() const override { return ready_; }

  NullableBytes get() const override;

private:
  VarUInt32Deserializer length_buf_;
  bool length_consumed_{false};
  uint32_t required_;

  std::vector<unsigned char> data_buf_;
  bool ready_{false};
};

/**
 * Deserializer for array of objects of the same type.
 *
 * First reads the length of the array, then initializes N underlying deserializers of type
 * DeserializerType. After the last of N deserializers is ready, the results of each of them are
 * gathered and put in a vector.
 * @param DeserializerType underlying deserializer type.
 *
 * From Kafka documentation:
 * Represents a sequence of objects of a given type T. Type T can be either a primitive type (e.g.
 * STRING) or a structure. First, the length N is given as an int32_t. Then N instances of type T
 * follow. A null array is represented with a length of -1.
 */
template <typename DeserializerType>
class ArrayDeserializer : public Deserializer<std::vector<typename DeserializerType::result_type>> {
public:
  using ResponseType = typename DeserializerType::result_type;

  /**
   * Can throw EnvoyException if array length is invalid or if underlying deserializer can throw.
   */
  uint32_t feed(absl::string_view& data) override {

    const uint32_t length_consumed = length_buf_.feed(data);
    if (!length_buf_.ready()) {
      // Break early: we still need to fill in length buffer.
      return length_consumed;
    }

    if (!length_consumed_) {
      required_ = length_buf_.get();
      if (required_ >= 0) {
        children_ = std::vector<DeserializerType>(required_);
      } else {
        ExceptionUtil::throwEnvoyException(absl::StrCat("invalid ARRAY length: ", required_));
      }
      length_consumed_ = true;
    }

    if (ready_) {
      return length_consumed;
    }

    uint32_t child_consumed{0};
    for (DeserializerType& child : children_) {
      child_consumed += child.feed(data);
    }

    bool children_ready_ = true;
    for (DeserializerType& child : children_) {
      children_ready_ &= child.ready();
    }
    ready_ = children_ready_;

    return length_consumed + child_consumed;
  }

  bool ready() const override { return ready_; }

  std::vector<ResponseType> get() const override {
    std::vector<ResponseType> result{};
    result.reserve(children_.size());
    for (const DeserializerType& child : children_) {
      const ResponseType child_result = child.get();
      result.push_back(child_result);
    }
    return result;
  }

private:
  Int32Deserializer length_buf_;
  bool length_consumed_{false};
  int32_t required_;
  std::vector<DeserializerType> children_;
  bool children_setup_{false};
  bool ready_{false};
};

/**
 * Deserializer for compact array of objects of the same type.
 *
 * First reads the length of the array, then initializes N underlying deserializers of type
 * DeserializerType. After the last of N deserializers is ready, the results of each of them are
 * gathered and put in a vector.
 * @param DeserializerType underlying deserializer type.
 *
 * From Kafka documentation:
 * Represents a sequence of objects of a given type T. Type T can be either a primitive type (e.g.
 * STRING) or a structure. First, the length N + 1 is given as an UNSIGNED_VARINT. Then N instances
 * of type T follow. A null array is represented with a length of 0.
 */
template <typename DeserializerType>
class CompactArrayDeserializer
    : public Deserializer<std::vector<typename DeserializerType::result_type>> {
public:
  using ResponseType = typename DeserializerType::result_type;

  /**
   * Can throw EnvoyException if array length is invalid or if underlying deserializer can throw.
   */
  uint32_t feed(absl::string_view& data) override {

    const uint32_t length_consumed = length_buf_.feed(data);
    if (!length_buf_.ready()) {
      // Break early: we still need to fill in length buffer.
      return length_consumed;
    }

    if (!length_consumed_) {
      const uint32_t required = length_buf_.get();
      if (required >= 1) {
        children_ = std::vector<DeserializerType>(required - 1);
      } else {
        ExceptionUtil::throwEnvoyException(
            absl::StrCat("invalid COMPACT_ARRAY length: ", required));
      }
      length_consumed_ = true;
    }

    if (ready_) {
      return length_consumed;
    }

    uint32_t child_consumed{0};
    for (DeserializerType& child : children_) {
      child_consumed += child.feed(data);
    }

    bool children_ready_ = true;
    for (DeserializerType& child : children_) {
      children_ready_ &= child.ready();
    }
    ready_ = children_ready_;

    return length_consumed + child_consumed;
  }

  bool ready() const override { return ready_; }

  std::vector<ResponseType> get() const override {
    std::vector<ResponseType> result{};
    result.reserve(children_.size());
    for (const DeserializerType& child : children_) {
      const ResponseType child_result = child.get();
      result.push_back(child_result);
    }
    return result;
  }

private:
  VarUInt32Deserializer length_buf_;
  bool length_consumed_{false};
  std::vector<DeserializerType> children_;
  bool children_setup_{false};
  bool ready_{false};
};

/**
 * Deserializer for nullable array of objects of the same type.
 *
 * First reads the length of the array, then initializes N underlying deserializers of type
 * DeserializerType. After the last of N deserializers is ready, the results of each of them are
 * gathered and put in a vector.
 * @param DeserializerType underlying deserializer type.
 *
 * From Kafka documentation:
 * Represents a sequence of objects of a given type T. Type T can be either a primitive type (e.g.
 * STRING) or a structure. First, the length N is given as an int32_t. Then N instances of type T
 * follow. A null array is represented with a length of -1.
 */
template <typename DeserializerType>
class NullableArrayDeserializer
    : public Deserializer<NullableArray<typename DeserializerType::result_type>> {
public:
  using ResponseType = typename DeserializerType::result_type;

  /**
   * Can throw EnvoyException if array length is invalid or if underlying deserializer can throw.
   */
  uint32_t feed(absl::string_view& data) override {

    const uint32_t length_consumed = length_buf_.feed(data);
    if (!length_buf_.ready()) {
      // Break early: we still need to fill in length buffer.
      return length_consumed;
    }

    if (!length_consumed_) {
      required_ = length_buf_.get();

      if (required_ >= 0) {
        children_ = std::vector<DeserializerType>(required_);
      }
      if (required_ == NULL_ARRAY_LENGTH) {
        ready_ = true;
      }
      if (required_ < NULL_ARRAY_LENGTH) {
        ExceptionUtil::throwEnvoyException(
            fmt::format("invalid NULLABLE_ARRAY length: {}", required_));
      }

      length_consumed_ = true;
    }

    if (ready_) {
      return length_consumed;
    }

    uint32_t child_consumed{0};
    for (DeserializerType& child : children_) {
      child_consumed += child.feed(data);
    }

    bool children_ready_ = true;
    for (DeserializerType& child : children_) {
      children_ready_ &= child.ready();
    }
    ready_ = children_ready_;

    return length_consumed + child_consumed;
  }

  bool ready() const override { return ready_; }

  NullableArray<ResponseType> get() const override {
    if (NULL_ARRAY_LENGTH != required_) {
      std::vector<ResponseType> result{};
      result.reserve(children_.size());
      for (const DeserializerType& child : children_) {
        const ResponseType child_result = child.get();
        result.push_back(child_result);
      }
      return result;
    } else {
      return absl::nullopt;
    }
  }

private:
  constexpr static int32_t NULL_ARRAY_LENGTH{-1};

  Int32Deserializer length_buf_;
  bool length_consumed_{false};
  int32_t required_;
  std::vector<DeserializerType> children_;
  bool children_setup_{false};
  bool ready_{false};
};

/**
 * Deserializer for compact nullable array of objects of the same type.
 *
 * First reads the length of the array, then initializes N underlying deserializers of type
 * DeserializerType. After the last of N deserializers is ready, the results of each of them are
 * gathered and put in a vector.
 * @param DeserializerType underlying deserializer type.
 *
 * From Kafka documentation:
 * Represents a sequence of objects of a given type T. Type T can be either a primitive type (e.g.
 * STRING) or a structure. First, the length N + 1 is given as an UNSIGNED_VARINT. Then N instances
 * of type T follow. A null array is represented with a length of 0.
 */
template <typename DeserializerType>
class NullableCompactArrayDeserializer
    : public Deserializer<NullableArray<typename DeserializerType::result_type>> {
public:
  using ResponseType = typename DeserializerType::result_type;

  /**
   * Can throw EnvoyException if array length is invalid or if underlying deserializer can throw.
   */
  uint32_t feed(absl::string_view& data) override {

    const uint32_t length_consumed = length_buf_.feed(data);
    if (!length_buf_.ready()) {
      // Break early: we still need to fill in length buffer.
      return length_consumed;
    }

    if (!length_consumed_) {
      const uint32_t required = length_buf_.get();

      // Length is unsigned, so we never throw exceptions.
      if (required >= 1) {
        children_ = std::vector<DeserializerType>(required - 1);
      } else {
        ready_ = true;
      }

      length_consumed_ = true;
    }

    if (ready_) {
      return length_consumed;
    }

    uint32_t child_consumed{0};
    for (DeserializerType& child : children_) {
      child_consumed += child.feed(data);
    }

    bool children_ready_ = true;
    for (DeserializerType& child : children_) {
      children_ready_ &= child.ready();
    }
    ready_ = children_ready_;

    return length_consumed + child_consumed;
  }

  bool ready() const override { return ready_; }

  NullableArray<ResponseType> get() const override {
    if (NULL_ARRAY_LENGTH != length_buf_.get()) {
      std::vector<ResponseType> result{};
      result.reserve(children_.size());
      for (const DeserializerType& child : children_) {
        const ResponseType child_result = child.get();
        result.push_back(child_result);
      }
      return result;
    } else {
      return absl::nullopt;
    }
  }

private:
  constexpr static int32_t NULL_ARRAY_LENGTH{0};

  VarUInt32Deserializer length_buf_;
  bool length_consumed_{false};
  std::vector<DeserializerType> children_;
  bool children_setup_{false};
  bool ready_{false};
};

/**
 * Kafka UUID is basically two longs, so we are going to keep model them the same way.
 * Reference:
 * https://github.com/apache/kafka/blob/2.8.1/clients/src/main/java/org/apache/kafka/common/Uuid.java#L38
 */
class UuidDeserializer : public Deserializer<Uuid> {
public:
  uint32_t feed(absl::string_view& data) override {
    uint32_t consumed = 0;
    consumed += high_bytes_deserializer_.feed(data);
    consumed += low_bytes_deserializer_.feed(data);
    return consumed;
  }

  bool ready() const override { return low_bytes_deserializer_.ready(); }

  Uuid get() const override {
    return {high_bytes_deserializer_.get(), low_bytes_deserializer_.get()};
  }

private:
  Int64Deserializer high_bytes_deserializer_;
  Int64Deserializer low_bytes_deserializer_;
};

// Variable length encoding utilities.
namespace VarlenUtils {

/**
 * Writes given unsigned int in variable-length encoding.
 * Ref: org.apache.kafka.common.utils.ByteUtils.writeUnsignedVarint(int, ByteBuffer)
 */
uint32_t writeUnsignedVarint(const uint32_t arg, Bytes& dst);

/**
 * Writes given signed int in variable-length zig-zag encoding.
 * Ref: org.apache.kafka.common.utils.ByteUtils.writeVarint(int, ByteBuffer)
 */
uint32_t writeVarint(const int32_t arg, Bytes& dst);

/**
 * Writes given long in variable-length zig-zag encoding.
 * Ref: org.apache.kafka.common.utils.ByteUtils.writeVarlong(long, ByteBuffer)
 */
uint32_t writeVarlong(const int64_t arg, Bytes& dst);
} // namespace VarlenUtils

/**
 * Encodes provided argument in Kafka format.
 * In case of primitive types, this is done explicitly as per specification.
 * In case of composite types, this is done by calling 'encode' on provided argument.
 *
 * This object also carries extra information that is used while traversing the request
 * structure-tree during encoding (currently api_version, as different request versions serialize
 * differently).
 */
class EncodingContext {
public:
  EncodingContext(int16_t api_version) : api_version_{api_version} {};

  /**
   * Compute size of given reference, if it were to be encoded.
   * @return serialized size of argument.
   */
  template <typename T> uint32_t computeSize(const T& arg) const;

  /**
   * Compute size of given array, if it were to be encoded.
   * @return serialized size of argument.
   */
  template <typename T> uint32_t computeSize(const std::vector<T>& arg) const;

  /**
   * Compute size of given nullable array, if it were to be encoded.
   * @return serialized size of argument.
   */
  template <typename T> uint32_t computeSize(const NullableArray<T>& arg) const;

  /**
   * Compute size of given reference, if it were to be compactly encoded.
   * @return serialized size of argument.
   */
  template <typename T> uint32_t computeCompactSize(const T& arg) const;

  /**
   * Compute size of given array, if it were to be compactly encoded.
   * @return serialized size of argument.
   */
  template <typename T> uint32_t computeCompactSize(const std::vector<T>& arg) const;

  /**
   * Compute size of given nullable array, if it were to be encoded.
   * @return serialized size of argument.
   */
  template <typename T> uint32_t computeCompactSize(const NullableArray<T>& arg) const;

  /**
   * Encode given reference in a buffer.
   * @return bytes written
   */
  template <typename T> uint32_t encode(const T& arg, Buffer::Instance& dst);

  /**
   * Encode given array in a buffer.
   * @return bytes written
   */
  template <typename T> uint32_t encode(const std::vector<T>& arg, Buffer::Instance& dst);

  /**
   * Encode given nullable array in a buffer.
   * @return bytes written
   */
  template <typename T> uint32_t encode(const NullableArray<T>& arg, Buffer::Instance& dst);

  /**
   * Compactly encode given reference in a buffer.
   * @return bytes written.
   */
  template <typename T> uint32_t encodeCompact(const T& arg, Buffer::Instance& dst);

  /**
   * Compactly encode given array in a buffer.
   * @return bytes written.
   */
  template <typename T> uint32_t encodeCompact(const std::vector<T>& arg, Buffer::Instance& dst);

  /**
   * Compactly encode given nullable array in a buffer.
   * @return bytes written.
   */
  template <typename T> uint32_t encodeCompact(const NullableArray<T>& arg, Buffer::Instance& dst);

  int16_t apiVersion() const { return api_version_; }

private:
  const int16_t api_version_;
};

/**
 * For non-primitive types, call `computeSize` on them, to delegate the work to the entity itself.
 * The entity may use the information in context to decide which fields are included etc.
 */
template <typename T> inline uint32_t EncodingContext::computeSize(const T& arg) const {
  return arg.computeSize(*this);
}

/**
 * For primitive types, Kafka size == sizeof(x).
 */
#define COMPUTE_SIZE_OF_NUMERIC_TYPE(TYPE)                                                         \
  template <> constexpr uint32_t EncodingContext::computeSize(const TYPE&) const {                 \
    return sizeof(TYPE);                                                                           \
  }

COMPUTE_SIZE_OF_NUMERIC_TYPE(bool)
COMPUTE_SIZE_OF_NUMERIC_TYPE(int8_t)
COMPUTE_SIZE_OF_NUMERIC_TYPE(int16_t)
COMPUTE_SIZE_OF_NUMERIC_TYPE(uint16_t)
COMPUTE_SIZE_OF_NUMERIC_TYPE(int32_t)
COMPUTE_SIZE_OF_NUMERIC_TYPE(uint32_t)
COMPUTE_SIZE_OF_NUMERIC_TYPE(int64_t)
COMPUTE_SIZE_OF_NUMERIC_TYPE(double)

/**
 * Template overload for string.
 * Kafka String's size is INT16 for header + N bytes.
 */
template <> inline uint32_t EncodingContext::computeSize(const std::string& arg) const {
  return sizeof(int16_t) + arg.size();
}

/**
 * Template overload for nullable string.
 * Kafka NullableString's size is INT16 for header + N bytes (N >= 0).
 */
template <> inline uint32_t EncodingContext::computeSize(const NullableString& arg) const {
  return sizeof(int16_t) + (arg ? arg->size() : 0);
}

/**
 * Template overload for byte array.
 * Kafka byte array size is INT32 for header + N bytes.
 */
template <> inline uint32_t EncodingContext::computeSize(const Bytes& arg) const {
  return sizeof(int32_t) + arg.size();
}

/**
 * Template overload for nullable byte array.
 * Kafka nullable byte array size is INT32 for header + N bytes (N >= 0).
 */
template <> inline uint32_t EncodingContext::computeSize(const NullableBytes& arg) const {
  return sizeof(int32_t) + (arg ? arg->size() : 0);
}

/**
 * Template overload for Array of T.
 * The size of array is size of header and all of its elements.
 */
template <typename T>
inline uint32_t EncodingContext::computeSize(const std::vector<T>& arg) const {
  uint32_t result = sizeof(int32_t);
  for (const T& el : arg) {
    result += computeSize(el);
  }
  return result;
}

/**
 * Template overload for NullableArray of T.
 * The size of array is size of header and all of its elements.
 */
template <typename T>
inline uint32_t EncodingContext::computeSize(const NullableArray<T>& arg) const {
  return arg ? computeSize(*arg) : sizeof(int32_t);
}

/**
 * Template overload for Uuid.
 */
template <> inline uint32_t EncodingContext::computeSize(const Uuid&) const {
  return 2 * sizeof(uint64_t);
}

/**
 * For non-primitive types, call `computeCompactSize` on them, to delegate the work to the entity
 * itself. The entity may use the information in context to decide which fields are included etc.
 */
template <typename T> inline uint32_t EncodingContext::computeCompactSize(const T& arg) const {
  return arg.computeCompactSize(*this);
}

/**
 * Template overload for int32_t.
 * This data type is not compacted, so we just point to non-compact implementation.
 */
template <> inline uint32_t EncodingContext::computeCompactSize(const int32_t& arg) const {
  return computeSize(arg);
}

/**
 * Template overload for int64_t.
 * This data type is not compacted, so we just point to non-compact implementation.
 */
template <> inline uint32_t EncodingContext::computeCompactSize(const int64_t& arg) const {
  return computeSize(arg);
}

/**
 * Template overload for uint32_t.
 * For this data type, we notice that the result's length depends on whether there are any bits set
 * in groups (1-7, 8-14, 15-21, 22-28, 29-32).
 */
template <> inline uint32_t EncodingContext::computeCompactSize(const uint32_t& arg) const {
  if (arg <= 0x7f) /* 2^7-1 */ {
    return 1;
  } else if (arg <= 0x3fff) /* 2^14-1 */ {
    return 2;
  } else if (arg <= 0x1fffff) /* 2^21-1 */ {
    return 3;
  } else if (arg <= 0xfffffff) /* 2^28-1 */ {
    return 4;
  } else {
    return 5;
  }
}

/**
 * Template overload for compact string.
 * Kafka CompactString's size is var-len encoding of N+1 + N bytes.
 */
template <> inline uint32_t EncodingContext::computeCompactSize(const std::string& arg) const {
  return computeCompactSize(static_cast<uint32_t>(arg.size()) + 1) + arg.size();
}

/**
 * Template overload for compact nullable string.
 * Kafka CompactString's size is var-len encoding of N+1 + N bytes, or 1 otherwise (because we
 * var-length encode the length of 0).
 */
template <> inline uint32_t EncodingContext::computeCompactSize(const NullableString& arg) const {
  return arg ? computeCompactSize(*arg) : 1;
}

/**
 * Template overload for compact byte array.
 * Kafka CompactBytes' size is var-len encoding of N+1 + N bytes.
 */
template <> inline uint32_t EncodingContext::computeCompactSize(const Bytes& arg) const {
  return computeCompactSize(static_cast<uint32_t>(arg.size()) + 1) + arg.size();
}

/**
 * Template overload for nullable compact byte array.
 * Kafka NullableCompactBytes' size is var-len encoding of N+1 + N bytes.
 */
template <> inline uint32_t EncodingContext::computeCompactSize(const NullableBytes& arg) const {
  return arg ? computeCompactSize(*arg) : 1;
}

/**
 * Template overload for CompactArray of T.
 * The size of array is compact size of header and all of its elements.
 */
template <typename T>
uint32_t EncodingContext::computeCompactSize(const std::vector<T>& arg) const {
  uint32_t result = computeCompactSize(static_cast<uint32_t>(arg.size()) + 1);
  for (const T& el : arg) {
    result += computeCompactSize(el);
  }
  return result;
}

/**
 * Template overload for CompactNullableArray of T.
 * The size of array is compact size of header and all of its elements; 1 otherwise (because we
 * var-length encode the length of 0).
 */
template <typename T>
uint32_t EncodingContext::computeCompactSize(const NullableArray<T>& arg) const {
  return arg ? computeCompactSize(*arg) : 1;
}

/**
 * For non-primitive types, call `encode` on them, to delegate the serialization to the entity
 * itself.
 */
template <typename T> inline uint32_t EncodingContext::encode(const T& arg, Buffer::Instance& dst) {
  return arg.encode(dst, *this);
}

/**
 * Template overload for int8_t.
 * Encode a single byte.
 */
template <> inline uint32_t EncodingContext::encode(const int8_t& arg, Buffer::Instance& dst) {
  dst.add(&arg, sizeof(int8_t));
  return sizeof(int8_t);
}

/**
 * Template overload for int16_t, int32_t, uint32_t, int64_t.
 * Encode a N-byte integer, converting to network byte-order.
 */
#define ENCODE_NUMERIC_TYPE(TYPE, CONVERTER)                                                       \
  template <> inline uint32_t EncodingContext::encode(const TYPE& arg, Buffer::Instance& dst) {    \
    const TYPE val = CONVERTER(arg);                                                               \
    dst.add(&val, sizeof(TYPE));                                                                   \
    return sizeof(TYPE);                                                                           \
  }

ENCODE_NUMERIC_TYPE(int16_t, htobe16);
ENCODE_NUMERIC_TYPE(uint16_t, htobe16);
ENCODE_NUMERIC_TYPE(int32_t, htobe32);
ENCODE_NUMERIC_TYPE(uint32_t, htobe32);
ENCODE_NUMERIC_TYPE(int64_t, htobe64);

/**
 * Template overload for double.
 * Encodes 8 bytes.
 */
template <> inline uint32_t EncodingContext::encode(const double& arg, Buffer::Instance& dst) {
  double tmp = arg;
  uint64_t in_host_order;
  safeMemcpy(&in_host_order, &tmp);
  const uint64_t in_network_order = htobe64(in_host_order);
  dst.add(&in_network_order, sizeof(uint64_t));
  return sizeof(uint64_t);
}

/**
 * Template overload for bool.
 * Encode boolean as a single byte.
 */
template <> inline uint32_t EncodingContext::encode(const bool& arg, Buffer::Instance& dst) {
  int8_t val = arg;
  dst.add(&val, sizeof(int8_t));
  return sizeof(int8_t);
}

/**
 * Template overload for std::string.
 * Encode string as INT16 length + N bytes.
 */
template <> inline uint32_t EncodingContext::encode(const std::string& arg, Buffer::Instance& dst) {
  int16_t string_length = arg.length();
  uint32_t header_length = encode(string_length, dst);
  dst.add(arg.c_str(), string_length);
  return header_length + string_length;
}

/**
 * Template overload for NullableString.
 * Encode nullable string as INT16 length + N bytes (length = -1 for null).
 */
template <>
inline uint32_t EncodingContext::encode(const NullableString& arg, Buffer::Instance& dst) {
  if (arg.has_value()) {
    return encode(*arg, dst);
  } else {
    const int16_t len = -1;
    return encode(len, dst);
  }
}

/**
 * Template overload for Bytes.
 * Encode byte array as INT32 length + N bytes.
 */
template <> inline uint32_t EncodingContext::encode(const Bytes& arg, Buffer::Instance& dst) {
  const int32_t data_length = arg.size();
  const uint32_t header_length = encode(data_length, dst);
  dst.add(arg.data(), arg.size());
  return header_length + data_length;
}

/**
 * Template overload for NullableBytes.
 * Encode nullable byte array as INT32 length + N bytes (length = -1 for null value).
 */
template <>
inline uint32_t EncodingContext::encode(const NullableBytes& arg, Buffer::Instance& dst) {
  if (arg.has_value()) {
    return encode(*arg, dst);
  } else {
    const int32_t len = -1;
    return encode(len, dst);
  }
}

/**
 * Encode nullable object array to T as INT32 length + N elements.
 * Each element of type T then serializes itself on its own.
 */
template <typename T>
uint32_t EncodingContext::encode(const std::vector<T>& arg, Buffer::Instance& dst) {
  const NullableArray<T> wrapped = {arg};
  return encode(wrapped, dst);
}

/**
 * Encode nullable object array to T as INT32 length + N elements (length = -1 for null value).
 * Each element of type T then serializes itself on its own.
 */
template <typename T>
uint32_t EncodingContext::encode(const NullableArray<T>& arg, Buffer::Instance& dst) {
  if (arg.has_value()) {
    const int32_t len = arg->size();
    const uint32_t header_length = encode(len, dst);
    uint32_t written{0};
    for (const T& el : *arg) {
      // For each of array elements, resolve the correct method again.
      // Elements could be primitives or complex types, so calling encode() on object won't work.
      written += encode(el, dst);
    }
    return header_length + written;
  } else {
    const int32_t len = -1;
    return encode(len, dst);
  }
}

/**
 * Template overload for Uuid.
 */
template <> inline uint32_t EncodingContext::encode(const Uuid& arg, Buffer::Instance& dst) {
  uint32_t result = 0;
  result += encode(arg.msb_, dst);
  result += encode(arg.lsb_, dst);
  return result;
}

/**
 * For non-primitive types, call `encodeCompact` on them, to delegate the serialization to the
 * entity itself.
 */
template <typename T>
inline uint32_t EncodingContext::encodeCompact(const T& arg, Buffer::Instance& dst) {
  return arg.encodeCompact(dst, *this);
}

/**
 * int32_t is not encoded in compact fashion, so we just delegate to normal implementation.
 */
template <>
inline uint32_t EncodingContext::encodeCompact(const int32_t& arg, Buffer::Instance& dst) {
  return encode(arg, dst);
}

/**
 * int64_t is not encoded in compact fashion, so we just delegate to normal implementation.
 */
template <>
inline uint32_t EncodingContext::encodeCompact(const int64_t& arg, Buffer::Instance& dst) {
  return encode(arg, dst);
}

/**
 * Template overload for variable-length uint32_t (VAR_UINT).
 * Encode the value in 7-bit chunks + marker if field is the last one.
 * Details:
 * https://cwiki.apache.org/confluence/display/KAFKA/KIP-482%3A+The+Kafka+Protocol+should+Support+Optional+Tagged+Fields#KIP-482:TheKafkaProtocolshouldSupportOptionalTaggedFields-UnsignedVarints
 */
template <>
inline uint32_t EncodingContext::encodeCompact(const uint32_t& arg, Buffer::Instance& dst) {
  std::vector<unsigned char> tmp;
  const uint32_t written = VarlenUtils::writeUnsignedVarint(arg, tmp);
  dst.add(tmp.data(), written);
  return written;
}

/**
 * Template overload for std::string.
 * Encode string as VAR_UINT + N bytes.
 */
template <>
inline uint32_t EncodingContext::encodeCompact(const std::string& arg, Buffer::Instance& dst) {
  const uint32_t string_length = arg.length();
  const uint32_t header_length = encodeCompact(string_length + 1, dst);
  dst.add(arg.c_str(), string_length);
  return header_length + string_length;
}

/**
 * Template overload for NullableString.
 * Encode string as VAR_UINT + N bytes, or VAR_UINT 0 for null value.
 */
template <>
inline uint32_t EncodingContext::encodeCompact(const NullableString& arg, Buffer::Instance& dst) {
  if (arg.has_value()) {
    return encodeCompact(*arg, dst);
  } else {
    const uint32_t len = 0;
    return encodeCompact(len, dst);
  }
}

/**
 * Template overload for Bytes.
 * Encode byte array as VAR_UINT + N bytes.
 */
template <>
inline uint32_t EncodingContext::encodeCompact(const Bytes& arg, Buffer::Instance& dst) {
  const uint32_t data_length = arg.size();
  const uint32_t header_length = encodeCompact(data_length + 1, dst);
  dst.add(arg.data(), data_length);
  return header_length + data_length;
}

/**
 * Template overload for NullableBytes.
 * Encode byte array as VAR_UINT + N bytes.
 */
template <>
inline uint32_t EncodingContext::encodeCompact(const NullableBytes& arg, Buffer::Instance& dst) {
  if (arg.has_value()) {
    return encodeCompact(*arg, dst);
  } else {
    const uint32_t len = 0;
    return encodeCompact(len, dst);
  }
}

/**
 * Encode object array of T as VAR_UINT + N elements.
 * Each element of type T then serializes itself on its own.
 */
template <typename T>
uint32_t EncodingContext::encodeCompact(const std::vector<T>& arg, Buffer::Instance& dst) {
  const NullableArray<T> wrapped = {arg};
  return encodeCompact(wrapped, dst);
}

/**
 * Encode nullable object array of T as VAR_UINT + N elements, or VAR_UINT 0 for null value.
 * Each element of type T then serializes itself on its own.
 */
template <typename T>
uint32_t EncodingContext::encodeCompact(const NullableArray<T>& arg, Buffer::Instance& dst) {
  if (arg.has_value()) {
    const uint32_t len = arg->size() + 1;
    const uint32_t header_length = encodeCompact(len, dst);
    uint32_t written{0};
    for (const T& el : *arg) {
      written += encodeCompact(el, dst);
    }
    return header_length + written;
  } else {
    const uint32_t len = 0;
    return encodeCompact(len, dst);
  }
}

} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
{#
  Template for 'response_metrics.h'.

  Generates the response metric names from Kafka message types.
  The metrics structure (KAFKA_RESPONSE_METRICS) is wrapped by RichResponseMetrics instance,
  allowing for easier access to metrics using message's api_key.

  There are two metrics for each of response types (e.g. produce):
  - number of responses received,
  - response processing time in milliseconds (time between receiving a request and receiving a
    response with the same correlation id).
  There is also a metric for counting responses that could not be recognised, and one for responses
  that could caused deserialization errors.
#}

#pragma once

#include <array>
#include <functional>

#include "envoy/stats/scope.h"
#include "envoy/stats/stats_macros.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

/**
 * Generated metrics, we have a counter and a histogram for each request type.
 */
#define KAFKA_RESPONSE_METRICS(COUNTER, HISTOGRAM)                                                 \
{% for message_type in message_types %}                                                            \
  COUNTER({{ message_type.name_in_c_case() }})                                                     \
  HISTOGRAM({{ message_type.name_in_c_case() }}_duration, Milliseconds)                            \
{% endfor %}                                                                                       \
  COUNTER(unknown)                                                                                 \
  COUNTER(failure)

struct KafkaResponseMetrics {
  KAFKA_RESPONSE_METRICS(GENERATE_COUNTER_STRUCT, GENERATE_HISTOGRAM_STRUCT)
};

/**
 * Abstraction layer over response-related metrics.
 * Pure interface so that it can be mocked easily.
 */
class RichResponseMetrics {
public:
  virtual ~RichResponseMetrics() = default;

  /**
   * Invoked when properly-parsed message is received.
   */
  virtual void onResponse(const int16_t api_key, const long long duration) PURE;

  /**
   * Invoked when an unknown message is received.
   */
  virtual void onUnknownResponse() PURE;

  /**
   * Invoked when a deserialization error occurs.
   */
  virtual void onBrokenResponse() PURE;
};

using RichResponseMetricsSharedPtr = std::shared_ptr<RichResponseMetrics>;

/**
 * Metrics implementation that uses Envoy Scope to store metrics.
 */
class RichResponseMetricsImpl: public RichResponseMetrics {
public:
  RichResponseMetricsImpl(Stats::Scope& scope, std::string stat_prefix): metrics_({
    KAFKA_RESPONSE_METRICS(POOL_COUNTER_PREFIX(scope, fmt::format("kafka.{}.response.",
      stat_prefix)), POOL_HISTOGRAM_PREFIX(scope, fmt::format("kafka.{}.response.", stat_prefix)))})
  {};

  void onResponse(const int16_t api_key, const long long duration) override {
    // Both successful message parsing & metrics list depend on protocol-generated code, what means
    // both do support the same api keys.
    switch (api_key) {
    {% for message_type in message_types %}
    case {{ message_type.get_extra('api_key') }} :
      // Increase received message counter and update histogram with duration.
      metrics_.{{ message_type.name_in_c_case() }}_.inc();
      metrics_.{{ message_type.name_in_c_case() }}_duration_.recordValue(duration);
      return;
    {% endfor %}
    }
  }

  void onUnknownResponse() override { metrics_.unknown_.inc(); }

  void onBrokenResponse() override { metrics_.failure_.inc(); }

private:
  KafkaResponseMetrics metrics_;
};

} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
{#
  Template for top-level structure representing a request in Kafka protocol (e.g. ProduceRequest).
  Rendered templates for each request in Kafka protocol will be put into 'requests.h' file.

  This template handles binding the top-level structure deserializer
  (e.g. ProduceRequestV0Deserializer) with RequestDataParser. These parsers are then used by
  RequestParserResolver instance depending on received Kafka api key & api version
  (see 'kafka_request_resolver_cc.j2').
#}

constexpr int16_t {{ complex_type.name | camel_case_to_snake_case | upper }}_API_KEY =
  {{ complex_type.get_extra('api_key') }};

constexpr int16_t {{ complex_type.name | camel_case_to_snake_case | upper }}_MAX_VERSION =
  {{ complex_type.versions[-1] }};

{% for version in complex_type.versions %}class {{ complex_type.name }}V{{ version }}Parser:
  public RequestDataParser<
    {{ complex_type.name }}, {{ complex_type.name }}V{{ version }}Deserializer>
{
public:
  {{ complex_type.name }}V{{ version }}Parser(RequestContextSharedPtr ctx) :
    RequestDataParser{ctx} {};
};

{% endfor %}
{#
  Template for structure representing a composite entity in Kafka protocol (request or response).
  Rendered templates for each structure in Kafka protocol will be put into 'requests.h'
  or 'responses.h'.

  Each structure is capable of holding all versions of given entity (what means its fields are
  actually a superset of union of all versions' fields). Each version has a dedicated deserializer
  (named "${name}V${version}Deserializer" e.g. ProduceRequestV0Deserializer or
  FetchResponseV1Deserializer), which calls the matching constructor.

  To serialize, it is necessary to pass the encoding context (that contains the version that's
  being serialized). Depending on the version, the fields will be written to the buffer.
#}
struct {{ complex_type.name }} {

  {#
     Constructors invoked by deserializers.
     Each constructor has a signature that matches the fields in at least one version (as sometimes
     there are different Kafka versions that are actually composed of precisely the same fields).
  #}
  {% for field in complex_type.fields %}
  {{ field.field_declaration() }}_;{% endfor %}
  {% for constructor in complex_type.compute_constructors() %}
  // constructor used in versions: {{ constructor['versions'] }}
  {{ constructor['full_declaration'] }}{% endfor %}

  {# For every field that's used in version, just compute its size using an encoder. #}
  uint32_t computeSize(const EncodingContext& encoder) const {
    const int16_t api_version = encoder.apiVersion();
    uint32_t written{0};

    {% for spec in complex_type.compute_serialization_specs() %}
    if (api_version >= {{ spec.versions[0] }} && api_version < {{ spec.versions[-1] + 1 }}) {
      written += encoder.{{ spec.compute_size_method_name }}({{ spec.field.name }}_);
    }
    {% endfor %}

    return written;
  }

  uint32_t computeCompactSize(const EncodingContext& encoder) const {
    return computeSize(encoder);
  }

  {# For every field that's used in version, just serialize it. #}
  uint32_t encode(Buffer::Instance& dst, EncodingContext& encoder) const {
    const int16_t api_version = encoder.apiVersion();
    uint32_t written{0};

    {% for spec in complex_type.compute_serialization_specs() %}
    if (api_version >= {{ spec.versions[0] }} && api_version < {{ spec.versions[-1] + 1 }}) {
      written += encoder.{{ spec.encode_method_name }}({{ spec.field.name }}_, dst);
    }
    {% endfor %}

    return written;
  }

  uint32_t encodeCompact(Buffer::Instance& dst, EncodingContext& encoder) const {
    return encode(dst, encoder);
  }

  {% if complex_type.fields|length > 0 %}
  bool operator==(const {{ complex_type.name }}& rhs) const {
  {% else %}
  bool operator==(const {{ complex_type.name }}&) const {
  {% endif %}
    return true{% for field in complex_type.fields %}
    && {{ field.name }}_ == rhs.{{ field.name }}_{% endfor %};
  };

};

{#
  Each structure version has a deserializer that matches the structure's field list.
#}
{% for field_list in complex_type.compute_field_lists() %}
class {{ complex_type.name }}V{{ field_list.version }}Deserializer:
  public CompositeDeserializerWith{{ field_list.field_count() }}Delegates<
    {{ complex_type.name }}
    {% for field in field_list.used_fields() %},
      {{ field.deserializer_name_in_version(field_list.version, field_list.uses_compact_fields) }}
    {% endfor %}>{};
{% endfor %}

{#
  Template for 'kafka_response_resolver.cc'.
  Defines default Kafka response resolver, that uses response parsers in (also generated)
  'responses.h'.
#}
#include "contrib/kafka/filters/network/source/external/responses.h"
#include "contrib/kafka/filters/network/source/kafka_response_parser.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

// Implements declaration from 'kafka_response.h'.
bool responseUsesTaggedFieldsInHeader(const uint16_t api_key, const uint16_t api_version) {
  switch (api_key) {
    {% for message_type in message_types %}
    case {{ message_type.get_extra('api_key') }}:
      switch (api_version) {
        {# ApiVersions responses require special handling. #}
        {% if message_type.get_extra('api_key') != 18 %}
        {% for flexible_version in message_type.flexible_versions %}
        case {{ flexible_version }}:
          return true;
        {% endfor %}
        {% endif %}
        default:
          return false;
      }
    {% endfor %}
    default:
      return false;
  }
}

/**
 * Creates a parser that is going to process data specific for given response.
 * If corresponding parser cannot be found (what means a newer version of Kafka protocol),
 * a sentinel parser is returned.
 * @param context parse context (carries the expected message type information).
 * @return parser that is capable of properly consuming response bytes.
 */
ResponseParserSharedPtr ResponseParserResolver::createParser(
  ResponseContextSharedPtr context) const {

  const int16_t api_key = context->api_key_;
  const int16_t api_version = context->api_version_;

{% for message_type in message_types %}{% for field_list in message_type.compute_field_lists() %}
  if ({{ message_type.get_extra('api_key') }} == api_key
    && {{ field_list.version }} == api_version) {
    return std::make_shared<{{ message_type.name }}V{{ field_list.version }}Parser>(context);
  }{% endfor %}{% endfor %}
  return std::make_shared<SentinelResponseParser>(context);
}

} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
{#
  Main template for 'responses.h' file.
  Gets filled in (by 'contents') with Kafka response structures, deserializers, and parsers.

  For each response we have the following:
  - 1 top-level structure corresponding to the response (e.g. `struct FetchResponse`),
  - N deserializers for top-level structure, one for each response version,
  - N parsers binding each deserializer with parser,
  - 0+ child structures (e.g. `struct FetchableTopicResponse`) that are used by the response's
    top-level structure,
  - deserializers for each child structure.

  So for example, for FetchResponse we have:
  - struct FetchResponse,
  - FetchResponseV0Deserializer, FetchResponseV1Deserializer, FetchResponseV2Deserializer, etc.,
  - FetchResponseV0Parser, FetchResponseV1Parser, FetchResponseV2Parser, etc.,
  - struct FetchableTopicResponse,
  - FetchableTopicResponseV0Deserializer, FetchableTopicResponseV1Deserializer, etc.
    (because topic data is present in every FetchResponse version),
  - struct FetchablePartitionResponse,
  - FetchablePartitionResponseV0Deserializer, FetchablePartitionResponseV1Deserializer, etc.
    (because partition data is present in every FetchableTopicResponse version).
  - AbortedTransaction & its Deserializers (starting with version 4).
#}
#pragma once
#include "contrib/kafka/filters/network/source/kafka_response.h"
#include "contrib/kafka/filters/network/source/kafka_response_parser.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

{{ contents }}

}}}}
{#
  Template for top-level structure representing a response in Kafka protocol
  (e.g. ProduceResponse).
  Rendered templates for each response in Kafka protocol will be put into 'responses.h' file.

  This template handles binding the top-level structure deserializer
  (e.g. ProduceResponseV0Deserializer) with ResponseDataParser.
  These parsers are then used by ResponseParserResolver instance depending on received Kafka
  api key & api version (see 'kafka_response_resolver_cc.j2').
#}

{% for version in complex_type.versions %}class {{ complex_type.name }}V{{ version }}Parser:
  public ResponseDataParser<
    {{ complex_type.name }}, {{ complex_type.name }}V{{ version }}Deserializer>{
public:
  {{ complex_type.name }}V{{ version }}Parser(ResponseContextSharedPtr context):
    ResponseDataParser{context} {};
};

{% endfor %}
{#
  Main template for 'requests.h' file.
  Gets filled in (by 'contents') with Kafka request structures, deserializers, and parsers.

  For each request we have the following:
  - 1 top-level structure corresponding to the request (e.g. `struct FetchRequest`),
  - N deserializers for top-level structure, one for each request version,
  - N parsers binding each deserializer with parser,
  - 0+ child structures (e.g. `struct FetchRequestTopic`, `FetchRequestPartition`) that are used by
    the request's top-level structure,
  - deserializers for each child structure.

  So for example, for FetchRequest we have:
  - struct FetchRequest,
  - FetchRequestV0Deserializer, FetchRequestV1Deserializer, FetchRequestV2Deserializer, etc.,
  - FetchRequestV0Parser, FetchRequestV1Parser, FetchRequestV2Parser, etc.,
  - struct FetchRequestTopic,
  - FetchRequestTopicV0Deserializer, FetchRequestTopicV1Deserializer, etc.
    (because topic data is present in every FetchRequest version),
  - struct FetchRequestPartition,
  - FetchRequestPartitionV0Deserializer, FetchRequestPartitionV1Deserializer, etc.
    (because partition data is present in every FetchRequestTopic version).
#}
#pragma once
#include "contrib/kafka/filters/network/source/kafka_request.h"
#include "contrib/kafka/filters/network/source/kafka_request_parser.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

{{ contents }}

}}}}
{#
  Template for 'request_metrics.h'.

  Generates the request metric names from Kafka message types.
  The metrics structure (KAFKA_REQUEST_METRICS) is wrapped by RichRequestMetrics instance, allowing
  for easier access to metrics using message's api_key.

  There is one metric for each of request types (e.g. produce) - number of responses received.
  There is also a metric for counting requests that could not be recognised, and one for requests
  that could caused deserialization errors.
#}

#pragma once

#include <array>
#include <functional>

#include "envoy/stats/scope.h"
#include "envoy/stats/stats_macros.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

/**
 * Generated metrics, we have a counter for each request type.
 */
#define KAFKA_REQUEST_METRICS(COUNTER)                                                             \
{% for message_type in message_types %}                                                            \
  COUNTER({{ message_type.name_in_c_case() }})                                                     \
{% endfor %}                                                                                       \
  COUNTER(unknown)                                                                                 \
  COUNTER(failure)

struct KafkaRequestMetrics {
  KAFKA_REQUEST_METRICS(GENERATE_COUNTER_STRUCT)
};

/**
 * Abstraction layer over request-related metrics.
 * Pure interface so that it can be mocked easily.
 */
class RichRequestMetrics {
public:
  virtual ~RichRequestMetrics() = default;

  /**
   * Invoked when properly-parsed message is received.
   */
  virtual void onRequest(const int16_t api_key) PURE;

  /**
   * Invoked when an unknown message is received.
   */
  virtual void onUnknownRequest() PURE;

  /**
   * Invoked when a deserialization error occurs.
   */
  virtual void onBrokenRequest() PURE;
};

using RichRequestMetricsSharedPtr = std::shared_ptr<RichRequestMetrics>;

/**
 * Metrics implementation that uses Envoy Scope to store metrics.
 */
class RichRequestMetricsImpl: public RichRequestMetrics {
public:
  RichRequestMetricsImpl(Stats::Scope& scope, std::string stat_prefix): metrics_({
    KAFKA_REQUEST_METRICS(POOL_COUNTER_PREFIX(scope, fmt::format("kafka.{}.request.",
      stat_prefix)))}) {};

  void onRequest(const int16_t api_key) override {
    // Both successful message parsing & metrics list depend on protocol-generated code, what means
    // both do support the same api keys.
    switch (api_key) {
    {% for message_type in message_types %}
    case {{ message_type.get_extra('api_key') }} :
      metrics_.{{ message_type.name_in_c_case() }}_.inc();
      return;
    {% endfor %}
    }
  }

  void onUnknownRequest() override { metrics_.unknown_.inc(); }

  void onBrokenRequest() override { metrics_.failure_.inc(); }

private:
  KafkaRequestMetrics metrics_;
};

} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#!/usr/bin/python

# Main library file containing all the protocol generation logic.


def generate_main_code(type, main_header_file, resolver_cc_file, metrics_header_file, input_files):
    """
  Main code generator.

  Takes input files and processes them into structures representing a Kafka message (request or
  response).

  These responses are then used to create:
  - main_header_file - contains definitions of Kafka structures and their deserializers
  - resolver_cc_file - contains request api key & version mapping to deserializer (from header file)
  - metrics_header_file - contains metrics with names corresponding to messages
  """
    processor = StatefulProcessor(type)
    # Parse provided input files.
    messages = processor.parse_messages(input_files)

    complex_type_template = RenderingHelper.get_template('complex_type_template.j2')
    parsers_template = RenderingHelper.get_template("%s_parser.j2" % type)

    main_header_contents = ''

    for message in messages:
        # For each child structure that is used by request/response, render its matching C++ code.
        dependencies = message.compute_declaration_chain()
        for dependency in dependencies:
            main_header_contents += complex_type_template.render(complex_type=dependency)
        # Each top-level structure (e.g. FetchRequest/FetchResponse) needs corresponding parsers.
        main_header_contents += parsers_template.render(complex_type=message)

    # Full file with headers, namespace declaration etc.
    template = RenderingHelper.get_template("%ss_h.j2" % type)
    contents = template.render(contents=main_header_contents)

    # Generate main header file.
    with open(main_header_file, 'w') as fd:
        fd.write(contents)

    # Generate ...resolver.cc file.
    template = RenderingHelper.get_template("kafka_%s_resolver_cc.j2" % type)
    contents = template.render(message_types=messages)
    with open(resolver_cc_file, 'w') as fd:
        fd.write(contents)

    # Generate ...metrics.h file.
    template = RenderingHelper.get_template("%s_metrics_h.j2" % type)
    contents = template.render(message_types=messages)
    with open(metrics_header_file, 'w') as fd:
        fd.write(contents)


def generate_test_code(
        type, header_test_cc_file, codec_test_cc_file, utilities_cc_file, input_files):
    """
  Test code generator.

  Takes input files and processes them into structures representing a Kafka message (request or
  response).

  These responses are then used to create:
  - header_test_cc_file - tests for basic message serialization deserialization,
  - codec_test_cc_file - tests involving codec and Request/ResponseParserResolver,
  - utilities_cc_file - utilities for creating sample messages.
  """
    processor = StatefulProcessor(type)
    # Parse provided input files.
    messages = processor.parse_messages(input_files)

    # Generate header-test file.
    template = RenderingHelper.get_template("%ss_test_cc.j2" % type)
    contents = template.render(message_types=messages)
    with open(header_test_cc_file, 'w') as fd:
        fd.write(contents)

    # Generate codec-test file.
    template = RenderingHelper.get_template("%s_codec_%s_test_cc.j2" % (type, type))
    contents = template.render(message_types=messages)
    with open(codec_test_cc_file, 'w') as fd:
        fd.write(contents)

    # Generate utilities file.
    template = RenderingHelper.get_template("%s_utilities_cc.j2" % type)
    contents = template.render(message_types=messages)
    with open(utilities_cc_file, 'w') as fd:
        fd.write(contents)


class StatefulProcessor:
    """
  Helper entity that keeps state during the processing.
  Some state needs to be shared across multiple message types, as we need to handle identical
  sub-type names (e.g. both AlterConfigsRequest & IncrementalAlterConfigsRequest have child
  AlterConfigsResource, what would cause a compile-time error if we were to handle it trivially).
  """

    def __init__(self, type):
        self.type = type
        # Complex types that have been encountered during processing.
        self.known_types = set()
        # Name of parent message type that's being processed right now.
        self.currently_processed_message_type = None
        # Common structs declared in this message type.
        self.common_structs = {}

    def parse_messages(self, input_files):
        """
        Parse request/response structures from provided input files.
        """
        import re
        import json

        messages = []
        # Sort the input files, as the processing is stateful, as we want the same order every time.
        input_files.sort()
        # For each specification file, remove comments, and parse the remains.
        for input_file in input_files:
            try:
                with open(input_file, 'r') as fd:
                    raw_contents = fd.read()
                    without_comments = re.sub(r'\s*//.*\n', '\n', raw_contents)
                    without_empty_newlines = re.sub(
                        r'^\s*$', '', without_comments, flags=re.MULTILINE)
                    # Windows support: see PR 10542 for details.
                    amended = re.sub(r'-2147483648', 'INT32_MIN', without_empty_newlines)
                    message_spec = json.loads(amended)
                    api_key = message_spec['apiKey']
                    # (adam.kotwasinski) ConsumerGroupHeartbeat needs some more changes to parse.
                    if api_key not in [68]:
                        message = self.parse_top_level_element(message_spec)
                        messages.append(message)
            except Exception as e:
                print('could not process %s' % input_file)
                raise

        # Sort messages by api_key.
        messages.sort(key=lambda x: x.get_extra('api_key'))
        return messages

    def parse_top_level_element(self, spec):
        """
    Parse a given structure into a request/response.
    Request/response is just a complex type, that has name & version information kept in differently
    named fields, compared to sub-structures in a message.
    """
        self.currently_processed_message_type = spec['name']

        # Figure out all versions of this message type.
        versions = Statics.parse_version_string(spec['validVersions'], 2 << 16 - 1)

        # Figure out the flexible versions.
        flexible_versions_string = spec.get('flexibleVersions', 'none')
        if 'none' != flexible_versions_string:
            flexible_versions = Statics.parse_version_string(flexible_versions_string, versions[-1])
        else:
            flexible_versions = []

        # Sanity check - all flexible versions need to be versioned.
        if [x for x in flexible_versions if x not in versions]:
            raise ValueError('invalid flexible versions')

        try:
            # In 2.4 some types are declared at top level, and only referenced inside.
            # So let's parse them and store them in state.
            common_structs = spec.get('commonStructs')
            if common_structs is not None:
                for common_struct in reversed(common_structs):
                    common_struct_name = common_struct['name']
                    common_struct_versions = Statics.parse_version_string(
                        common_struct['versions'], versions[-1])
                    parsed_complex = self.parse_complex_type(
                        common_struct_name, common_struct, common_struct_versions)
                    self.common_structs[parsed_complex.name] = parsed_complex

            # Parse the type itself.
            complex_type = self.parse_complex_type(
                self.currently_processed_message_type, spec, versions)
            complex_type.register_flexible_versions(flexible_versions)

            # Request / response types need to carry api key version.
            result = complex_type.with_extra('api_key', spec['apiKey'])
            return result

        finally:
            self.common_structs = {}
            self.currently_processed_message_type = None

    def parse_complex_type(self, type_name, field_spec, versions):
        """
    Parse given complex type, returning a structure that holds its name, field specification and
    allowed versions.
    """
        fields_el = field_spec.get('fields')

        if fields_el is not None:
            fields = []
            for child_field in field_spec['fields']:
                child = self.parse_field(child_field, versions[-1])
                if child is not None:
                    fields.append(child)
            # Some structures share the same name, use request/response as prefix.
            if type_name in ['EntityData', 'EntryData', 'PartitionData', 'PartitionSnapshot',
                             'SnapshotId', 'TopicData', 'TopicSnapshot']:
                type_name = self.type.capitalize() + type_name
            # Some of the types repeat multiple times (e.g. AlterableConfig).
            # In such a case, every second or later occurrence of the same name is going to be prefixed
            # with parent type, e.g. we have AlterableConfig (for AlterConfigsRequest) and then
            # IncrementalAlterConfigsRequestAlterableConfig (for IncrementalAlterConfigsRequest).
            # This keeps names unique, while keeping non-duplicate ones short.
            if type_name not in self.known_types:
                self.known_types.add(type_name)
            else:
                type_name = self.currently_processed_message_type + type_name
                self.known_types.add(type_name)

            return Complex(type_name, fields, versions)

        else:
            return self.common_structs[type_name]

    def parse_field(self, field_spec, highest_possible_version):
        """
    Parse given field, returning a structure holding the name, type, and versions when this field is
    actually used (nullable or not). Obviously, field cannot be used in version higher than its
    type's usage.
    """
        if field_spec.get('tag') is not None:
            return None

        version_usage = Statics.parse_version_string(
            field_spec['versions'], highest_possible_version)
        version_usage_as_nullable = Statics.parse_version_string(
            field_spec['nullableVersions'],
            highest_possible_version) if 'nullableVersions' in field_spec else range(-1)
        parsed_type = self.parse_type(field_spec['type'], field_spec, highest_possible_version)
        return FieldSpec(field_spec['name'], parsed_type, version_usage, version_usage_as_nullable)

    def parse_type(self, type_name, field_spec, highest_possible_version):
        """
        Parse a given type element - returns an array type, primitive (e.g. uint32_t) or complex one.
        """
        if (type_name.startswith('[]')):
            # In spec files, array types are defined as `[]underlying_type` instead of having its own
            # element with type inside.
            underlying_type = self.parse_type(type_name[2:], field_spec, highest_possible_version)
            return Array(underlying_type)
        else:
            if (type_name in Primitive.USABLE_PRIMITIVE_TYPE_NAMES):
                return Primitive(type_name, field_spec.get('default'))
            else:
                versions = Statics.parse_version_string(
                    field_spec['versions'], highest_possible_version)
                return self.parse_complex_type(type_name, field_spec, versions)


class Statics:

    @staticmethod
    def parse_version_string(raw_versions, highest_possible_version):
        """
    Return integer range that corresponds to version string in spec file.
    """
        if raw_versions.endswith('+'):
            return range(int(raw_versions[:-1]), highest_possible_version + 1)
        else:
            if '-' in raw_versions:
                tokens = raw_versions.split('-', 1)
                return range(int(tokens[0]), int(tokens[1]) + 1)
            else:
                single_version = int(raw_versions)
                return range(single_version, single_version + 1)


class FieldList:
    """
  List of fields used by given entity (request or child structure) in given message version
  (as fields get added or removed across versions and/or they change compaction level).
  """

    def __init__(self, version, uses_compact_fields, fields):
        self.version = version
        self.uses_compact_fields = uses_compact_fields
        self.fields = fields

    def used_fields(self):
        """
    Return list of fields that are actually used in this version of structure.
    """
        return filter(lambda x: x.used_in_version(self.version), self.fields)

    def constructor_signature(self):
        """
    Return constructor signature.
    Multiple versions of the same structure can have identical signatures (due to version bumps in
    Kafka).
    """
        parameter_spec = map(lambda x: x.parameter_declaration(self.version), self.used_fields())
        return ', '.join(parameter_spec)

    def constructor_init_list(self):
        """
    Renders member initialization list in constructor.
    Takes care of potential optional<T> conversions (as field could be T in V1, but optional<T>
    in V2).
    """
        init_list = []
        for field in self.fields:
            if field.used_in_version(self.version):
                if field.is_nullable():
                    if field.is_nullable_in_version(self.version):
                        # Field is optional<T>, and the parameter is optional<T> in this version.
                        init_list_item = '%s_{%s}' % (field.name, field.name)
                        init_list.append(init_list_item)
                    else:
                        # Field is optional<T>, and the parameter is T in this version.
                        init_list_item = '%s_{absl::make_optional(%s)}' % (field.name, field.name)
                        init_list.append(init_list_item)
                else:
                    # Field is T, so parameter cannot be optional<T>.
                    init_list_item = '%s_{%s}' % (field.name, field.name)
                    init_list.append(init_list_item)
            else:
                # Field is not used in this version, so we need to put in default value.
                init_list_item = '%s_{%s}' % (field.name, field.default_value())
                init_list.append(init_list_item)
            pass
        return ', '.join(init_list)

    def field_count(self):
        return len(list(self.used_fields()))

    def example_value(self):
        return ', '.join(map(lambda x: x.example_value_for_test(self.version), self.used_fields()))


class FieldSpec:
    """
  Represents a field present in a structure (request, or child structure thereof).
  Contains name, type, and versions when it is used (nullable or not).
  """

    def __init__(self, name, type, version_usage, version_usage_as_nullable):
        import re
        separated = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', name)
        self.name = re.sub('([a-z0-9])([A-Z])', r'\1_\2', separated).lower()
        self.type = type
        self.version_usage = version_usage
        self.version_usage_as_nullable = version_usage_as_nullable

    def is_nullable(self):
        return len(self.version_usage_as_nullable) > 0

    def is_nullable_in_version(self, version):
        """
    Whether the field is nullable in given version.
    Fields can be non-nullable in earlier versions.
    See https://github.com/apache/kafka/tree/2.2.0-rc0/clients/src/main/resources/common/message#nullable-fields
    """
        return version in self.version_usage_as_nullable

    def used_in_version(self, version):
        return version in self.version_usage

    def field_declaration(self):
        if self.is_nullable():
            return 'absl::optional<%s> %s' % (self.type.name, self.name)
        else:
            return '%s %s' % (self.type.name, self.name)

    def parameter_declaration(self, version):
        if self.is_nullable_in_version(version):
            return 'absl::optional<%s> %s' % (self.type.name, self.name)
        else:
            return '%s %s' % (self.type.name, self.name)

    def default_value(self):
        if self.is_nullable():
            type_default_value = self.type.default_value()
            # For nullable fields, it's possible to have (Java) null as default value.
            if type_default_value != 'null':
                return '{%s}' % type_default_value
            else:
                return 'absl::nullopt'
        else:
            return str(self.type.default_value())

    def example_value_for_test(self, version):
        if self.is_nullable_in_version(version):
            return 'absl::make_optional<%s>(%s)' % (
                self.type.name, self.type.example_value_for_test(version))
        else:
            return str(self.type.example_value_for_test(version))

    def deserializer_name_in_version(self, version, compact):
        if self.is_nullable_in_version(version):
            return 'Nullable%s' % self.type.deserializer_name_in_version(version, compact)
        else:
            return self.type.deserializer_name_in_version(version, compact)

    def is_printable(self):
        return self.type.is_printable()


class TypeSpecification:

    def compute_declaration_chain(self):
        """
    Computes types that need to be declared before this type can be declared, in C++ sense.
    """
        raise NotImplementedError()

    def deserializer_name_in_version(self, version, compact):
        """
    Renders the deserializer name of given type, in message with given version.
    """
        raise NotImplementedError()

    def default_value(self):
        """
    Returns a default value for given type.
    """
        raise NotImplementedError()

    def has_flexible_handling(self):
        """
    Whether the given type has special encoding when carrying message is using flexible encoding.
    """
        raise NotImplementedError()

    def example_value_for_test(self, version):
        raise NotImplementedError()

    def is_printable(self):
        raise NotImplementedError()


class Array(TypeSpecification):
    """
  Represents array complex type.
  To use instance of this type, it is necessary to declare structures required by self.underlying
  (e.g. to use Array<Foo>, we need to have `struct Foo {...}`).
  """

    def __init__(self, underlying):
        self.underlying = underlying

    @property
    def name(self):
        return 'std::vector<%s>' % self.underlying.name

    def compute_declaration_chain(self):
        # To use an array of type T, we just need to be capable of using type T.
        return self.underlying.compute_declaration_chain()

    def deserializer_name_in_version(self, version, compact):
        # For arrays, deserializer name is (Compact)(Nullable)ArrayDeserializer<ElementDeserializer>.
        element_deserializer_name = self.underlying.deserializer_name_in_version(version, compact)
        return '%sArrayDeserializer<%s>' % ("Compact" if compact else "", element_deserializer_name)

    def default_value(self):
        return 'std::vector<%s>{}' % (self.underlying.name)

    def has_flexible_handling(self):
        return True

    def example_value_for_test(self, version):
        return 'std::vector<%s>{ %s }' % (
            self.underlying.name, self.underlying.example_value_for_test(version))

    def is_printable(self):
        return self.underlying.is_printable()


class Primitive(TypeSpecification):
    """
    Represents a Kafka primitive value.
    """

    USABLE_PRIMITIVE_TYPE_NAMES = [
        'bool', 'int8', 'int16', 'int32', 'int64', 'uint16', 'float64', 'string', 'bytes',
        'records', 'uuid'
    ]

    KAFKA_TYPE_TO_ENVOY_TYPE = {
        'string': 'std::string',
        'bool': 'bool',
        'int8': 'int8_t',
        'int16': 'int16_t',
        'int32': 'int32_t',
        'int64': 'int64_t',
        'uint16': 'uint16_t',
        'float64': 'double',
        'bytes': 'Bytes',
        'records': 'Bytes',
        'uuid': 'Uuid',
        'tagged_fields': 'TaggedFields',
    }

    KAFKA_TYPE_TO_DESERIALIZER = {
        'string': 'StringDeserializer',
        'bool': 'BooleanDeserializer',
        'int8': 'Int8Deserializer',
        'int16': 'Int16Deserializer',
        'int32': 'Int32Deserializer',
        'int64': 'Int64Deserializer',
        'uint16': 'UInt16Deserializer',
        'float64': 'Float64Deserializer',
        'bytes': 'BytesDeserializer',
        'records': 'BytesDeserializer',
        'uuid': 'UuidDeserializer',
        'tagged_fields': 'TaggedFieldsDeserializer',
    }

    KAFKA_TYPE_TO_COMPACT_DESERIALIZER = {
        'string': 'CompactStringDeserializer',
        'bytes': 'CompactBytesDeserializer',
        'records': 'CompactBytesDeserializer'
    }

    # See https://github.com/apache/kafka/tree/trunk/clients/src/main/resources/common/message#deserializing-messages
    KAFKA_TYPE_TO_DEFAULT_VALUE = {
        'string': '""',
        'bool': 'false',
        'int8': '0',
        'int16': '0',
        'int32': '0',
        'int64': '0',
        'bytes': '{}',
        'uuid': 'Uuid{0, 0}',
        'tagged_fields': 'TaggedFields({})',
    }

    # Custom values that make test code more readable.
    KAFKA_TYPE_TO_EXAMPLE_VALUE_FOR_TEST = {
        'string':
            'static_cast<std::string>("string")',
        'bool':
            'false',
        'int8':
            'static_cast<int8_t>(8)',
        'int16':
            'static_cast<int16_t>(16)',
        'uint16':
            'static_cast<uint16_t>(17)',
        'int32':
            'static_cast<int32_t>(32)',
        'int64':
            'static_cast<int64_t>(64)',
        'float64':
            'static_cast<double>(13.125)',
        'bytes':
            'Bytes({0, 1, 2, 3})',
        'records':
            'Bytes({0, 1, 2, 3})',
        'uuid':
            'Uuid{13, 42}',
        'tagged_fields':
            'TaggedFields{std::vector<TaggedField>{{10, Bytes({1, 2, 3})}, {20, Bytes({4, 5, 6})}}}',
    }

    def __init__(self, name, custom_default_value):
        self.original_name = name
        self.name = Primitive.compute(name, Primitive.KAFKA_TYPE_TO_ENVOY_TYPE)
        self.custom_default_value = Primitive.sanitize_value(self.name, custom_default_value)

    @staticmethod
    def compute(name, map):
        if name in map:
            return map[name]
        else:
            raise ValueError(name)

    @staticmethod
    def sanitize_value(type, arg):
        """
        Unfortunately we cannot print Python True/False straight into C++ code, so we lowercase.
        """
        if arg is None:
            return None
        if 'bool' == type:
            return str(arg).lower()
        else:
            return arg

    def compute_declaration_chain(self):
        # Primitives need no declarations.
        return []

    def deserializer_name_in_version(self, version, compact):
        if compact and self.original_name in Primitive.KAFKA_TYPE_TO_COMPACT_DESERIALIZER.keys():
            return Primitive.compute(
                self.original_name, Primitive.KAFKA_TYPE_TO_COMPACT_DESERIALIZER)
        else:
            return Primitive.compute(self.original_name, Primitive.KAFKA_TYPE_TO_DESERIALIZER)

    def default_value(self):
        if self.custom_default_value is not None:
            return self.custom_default_value
        else:
            return Primitive.compute(self.original_name, Primitive.KAFKA_TYPE_TO_DEFAULT_VALUE)

    def has_flexible_handling(self):
        return self.original_name in ['string', 'bytes', 'records', 'tagged_fields']

    def example_value_for_test(self, version):
        return Primitive.compute(self.original_name, Primitive.KAFKA_TYPE_TO_EXAMPLE_VALUE_FOR_TEST)

    def is_printable(self):
        return self.name not in ['Bytes']


class FieldSerializationSpec():

    def __init__(self, field, versions, compute_size_method_name, encode_method_name):
        self.field = field
        self.versions = versions
        self.compute_size_method_name = compute_size_method_name
        self.encode_method_name = encode_method_name


class Complex(TypeSpecification):
    """
  Represents a complex type (multiple types aggregated into one).
  This type gets mapped to a C++ struct.
  """

    def __init__(self, name, fields, versions):
        self.name = name
        self.fields = fields
        self.versions = versions
        self.flexible_versions = None  # Will be set in 'register_flexible_versions'.
        self.attributes = {}

    def register_flexible_versions(self, flexible_versions):
        # If flexible versions are present, so we need to add placeholder 'tagged_fields' field to
        # *every* type that's used in by this message type.
        for type in self.compute_declaration_chain():
            type.flexible_versions = flexible_versions
            if len(flexible_versions) > 0:
                tagged_fields_field = FieldSpec(
                    'tagged_fields', Primitive('tagged_fields', None), flexible_versions, [])
                type.fields.append(tagged_fields_field)

    def compute_declaration_chain(self):
        """
    Computes all dependencies, what means all non-primitive types used by this type.
    They need to be declared before this struct is declared.
    """
        result = []
        for field in self.fields:
            field_dependencies = field.type.compute_declaration_chain()
            for field_dependency in field_dependencies:
                if field_dependency not in result:
                    result.append(field_dependency)
        result.append(self)
        return result

    def with_extra(self, key, value):
        self.attributes[key] = value
        return self

    def get_extra(self, key):
        return self.attributes[key]

    def compute_constructors(self):
        """
    Field lists for different versions may not differ (as Kafka can bump version without any
    changes). But constructors need to be unique, so we need to remove duplicates if the signatures
    match.
    """
        signature_to_constructor = {}
        for field_list in self.compute_field_lists():
            signature = field_list.constructor_signature()
            constructor = signature_to_constructor.get(signature)
            if constructor is None:
                entry = {}
                entry['versions'] = [field_list.version]
                entry['signature'] = signature
                if (len(signature) > 0):
                    entry['full_declaration'] = '%s(%s): %s {};' % (
                        self.name, signature, field_list.constructor_init_list())
                else:
                    entry['full_declaration'] = '%s() {};' % self.name
                signature_to_constructor[signature] = entry
            else:
                constructor['versions'].append(field_list.version)
        return sorted(signature_to_constructor.values(), key=lambda x: x['versions'][0])

    def compute_field_lists(self):
        """
    Return field lists representing each of structure versions.
    """
        field_lists = []
        for version in self.versions:
            field_list = FieldList(version, version in self.flexible_versions, self.fields)
            field_lists.append(field_list)
        return field_lists

    def compute_serialization_specs(self):
        result = []
        for field in self.fields:
            if field.type.has_flexible_handling():
                flexible = [x for x in field.version_usage if x in self.flexible_versions]
                non_flexible = [x for x in field.version_usage if x not in flexible]
                if non_flexible:
                    result.append(
                        FieldSerializationSpec(field, non_flexible, 'computeSize', 'encode'))
                if flexible:
                    result.append(
                        FieldSerializationSpec(
                            field, flexible, 'computeCompactSize', 'encodeCompact'))
            else:
                result.append(
                    FieldSerializationSpec(field, field.version_usage, 'computeSize', 'encode'))
        return result

    def deserializer_name_in_version(self, version, compact):
        return '%sV%dDeserializer' % (self.name, version)

    def name_in_c_case(self):
        import re
        s1 = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', self.name)
        return re.sub('([a-z0-9])([A-Z])', r'\1_\2', s1).lower()

    def default_value(self):
        raise NotImplementedError('unable to create default value of complex type')

    def has_flexible_handling(self):
        return False

    def example_value_for_test(self, version):
        field_list = next(fl for fl in self.compute_field_lists() if fl.version == version)
        example_values = map(lambda x: x.example_value_for_test(version), field_list.used_fields())
        return '%s(%s)' % (self.name, ', '.join(example_values))

    def is_printable(self):
        return True


class RenderingHelper:
    """
    Utility function that allows us to process names in jinja easier.
    """

    @staticmethod
    def camel_case_to_snake_case(str):
        import re
        return re.sub('(?!^)([A-Z]+)', r'_\1', str)

    """
    Helper for jinja templates.
    """

    @staticmethod
    def get_template(template):
        import jinja2
        import os
        import sys
        # Templates are resolved relatively to main start script, due to main & test templates being
        # stored in different directories.
        env = jinja2.Environment(
            loader=jinja2.FileSystemLoader(
                searchpath=os.path.dirname(os.path.abspath(sys.argv[0]))))
        env.filters['camel_case_to_snake_case'] = RenderingHelper.camel_case_to_snake_case
        return env.get_template(template)
{#
  Template for 'kafka_request_resolver.cc'.
  Defines default Kafka request resolver, that uses request parsers in (also generated)
  'requests.h'.
#}
#include "contrib/kafka/filters/network/source/external/requests.h"
#include "contrib/kafka/filters/network/source/kafka_request_parser.h"
#include "contrib/kafka/filters/network/source/parser.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

// Implements declaration from 'kafka_request.h'.
bool requestUsesTaggedFieldsInHeader(const uint16_t api_key, const uint16_t api_version) {
  switch (api_key) {
    {% for message_type in message_types %}
    case {{ message_type.get_extra('api_key') }}:
      switch (api_version) {
        {% for flexible_version in message_type.flexible_versions %}
        case {{ flexible_version }}:
          return true;
        {% endfor %}
        default:
          return false;
      }
    {% endfor %}
    default:
      return false;
  }
}

/**
 * Creates a parser that corresponds to provided key and version.
 * If corresponding parser cannot be found (what means a newer version of Kafka protocol),
 * a sentinel parser is returned.
 * @param api_key Kafka request key
 * @param api_version Kafka request's version
 * @param context parse context
 */
RequestParserSharedPtr RequestParserResolver::createParser(int16_t api_key, int16_t api_version,
                                                           RequestContextSharedPtr context) const {

{% for message_type in message_types %}{% for field_list in message_type.compute_field_lists() %}
  if ({{ message_type.get_extra('api_key') }} == api_key
    && {{ field_list.version }} == api_version) {
    return std::make_shared<{{ message_type.name }}V{{ field_list.version }}Parser>(context);
  }{% endfor %}{% endfor %}
  return std::make_shared<SentinelParser>(context);
}

} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#!/usr/bin/python

# Launcher for generating Kafka protocol code.

import contrib.kafka.filters.network.source.protocol.generator as generator
import sys
import os


def main():
    """
  Kafka code generator script
  ~~~~~~~~~~~~~~~~~~~~~~~~~~~
  Generates C++ code from Kafka protocol specification for Kafka codec.

  Usage:
    launcher.py MESSAGE_TYPE OUTPUT_FILES INPUT_FILES
  where:
  MESSAGE_TYPE : 'request' or 'response'
  OUTPUT_FILES : location of 'requests.h'/'responses.h',
                 'kafka_request_resolver.cc'/'kafka_response_resolver.cc' and
                 'request_metrics.h'/'response_metrics.h'.
  INPUT_FILES: Kafka protocol json files to be processed.

  Kafka spec files are provided in Kafka clients jar file.

  Files created are:
    - ${MESSAGE_TYPE}s.h - definition of all the structures/deserializers/parsers related to Kafka
      requests/responses,
    - kafka_${MESSAGE_TYPE}_resolver.cc - resolver that is responsible for creation of parsers
      defined in ${MESSAGE_TYPE}s.h (it maps request's api key & version to matching parser),
    - ${MESSAGE_TYPE}_metrics.h - rich metrics wrappers for all possible message types.

  Templates used are:
  - to create '${MESSAGE_TYPE}.h': ${MESSAGE_TYPE}_h.j2, complex_type_template.j2,
    request_parser.j2,
  - to create 'kafka_${MESSAGE_TYPE}_resolver.cc': kafka_${MESSAGE_TYPE}_resolver_cc.j2,
  - to create '${MESSAGE_TYPE}_metrics.h': ${MESSAGE_TYPE}_metrics_h.j2.
  """

    type = sys.argv[1]
    main_header_file = os.path.abspath(sys.argv[2])
    resolver_cc_file = os.path.abspath(sys.argv[3])
    metrics_h_file = os.path.abspath(sys.argv[4])
    input_files = sys.argv[5:]
    generator.generate_main_code(
        type, main_header_file, resolver_cc_file, metrics_h_file, input_files)


if __name__ == "__main__":
    main()
#pragma once

#include <memory>
#include <string>
#include <utility>
#include <vector>

#include "absl/types/optional.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

/**
 * Nullable string used by Kafka.
 */
using NullableString = absl::optional<std::string>;

/**
 * Bytes array used by Kafka.
 */
using Bytes = std::vector<unsigned char>;

/**
 * Nullable bytes array used by Kafka.
 */
using NullableBytes = absl::optional<Bytes>;

/**
 * Kafka array of elements of type T.
 */
template <typename T> using NullableArray = absl::optional<std::vector<T>>;

/**
 * Analogous to:
 * https://github.com/apache/kafka/blob/2.8.1/clients/src/main/java/org/apache/kafka/common/Uuid.java#L28
 */
struct Uuid {

  const int64_t msb_;
  const int64_t lsb_;

  Uuid(const int64_t msb, const int64_t lsb) : msb_{msb}, lsb_{lsb} {};

  bool operator==(const Uuid& rhs) const { return msb_ == rhs.msb_ && lsb_ == rhs.lsb_; };
};

/**
 * Kafka topic-partition pair.
 */
using KafkaPartition = std::pair<std::string, int32_t>;

} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include <vector>

#include "envoy/buffer/buffer.h"
#include "envoy/common/pure.h"

#include "absl/container/fixed_array.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

/**
 * Kafka message decoder.
 */
class MessageDecoder {
public:
  virtual ~MessageDecoder() = default;

  /**
   * Processes given buffer attempting to decode messages contained within.
   * @param data buffer instance.
   */
  virtual void onData(Buffer::Instance& data) PURE;
};

template <typename MessageType, typename ParseFailureType> class MessageCallback {
public:
  virtual ~MessageCallback() = default;

  /**
   * Callback method invoked when message is successfully decoded.
   * @param message message that has been decoded.
   */
  virtual void onMessage(MessageType message) PURE;

  /**
   * Callback method invoked when message could not be decoded.
   * Invoked after all message's bytes have been consumed.
   */
  virtual void onFailedParse(ParseFailureType failure_data) PURE;
};

/**
 * Abstract message decoder, that resolves messages from Buffer instances provided.
 * When the message has been parsed, notify the callbacks.
 */
template <typename ParserType, typename CallbackType>
class AbstractMessageDecoder : public MessageDecoder {
public:
  ~AbstractMessageDecoder() override = default;

  /**
   * Creates a decoder that will invoke given callbacks when a message has been parsed.
   * @param callbacks callbacks to be invoked (in order).
   */
  AbstractMessageDecoder(const std::vector<CallbackType> callbacks) : callbacks_{callbacks} {};

  /**
   * Consumes all data present in a buffer.
   * If a message can be successfully parsed, then callbacks get notified with parsed response.
   * Updates decoder state.
   * Can throw if codec's state does not permit usage, or there there were parse failures.
   * Impl note: similar to redis codec, which also keeps state.
   */
  void onData(Buffer::Instance& data) override {
    // Pass slices to `doParse`.
    for (const Buffer::RawSlice& slice : data.getRawSlices()) {
      doParse(slice);
    }
  }

  /**
   * Erases codec state.
   */
  virtual void reset() { current_parser_ = nullptr; }

  ParserType getCurrentParserForTest() const { return current_parser_; }

protected:
  /**
   * Create a start parser for a new message.
   */
  virtual ParserType createStartParser() PURE;

private:
  /**
   * Main parse loop.
   *
   * If there is data to process, and the current parser is not present,
   * create a new one with `createStartParser`.
   * Feed data to a current parser until it returns a parse result.
   * If the parse result is a parsed message, notify callbacks and reset current parser.
   * If the parse result is another parser, update current parser, and keep feeding.
   */
  void doParse(const Buffer::RawSlice& slice) {
    const char* bytes = reinterpret_cast<const char*>(slice.mem_);
    absl::string_view data = {bytes, slice.len_};

    while (!data.empty()) {

      // Re-initialize the parser.
      if (!current_parser_) {
        current_parser_ = createStartParser();
      }

      // Feed the data to the parser.
      auto result = current_parser_->parse(data);
      // This loop guarantees that parsers consuming 0 bytes also get processed in this invocation.
      while (result.hasData()) {
        if (!result.next_parser_) {

          // Next parser is not present, so we have finished parsing a message.
          // Depending on whether the parse was successful, invoke the correct callback.
          if (result.message_) {
            for (auto& callback : callbacks_) {
              callback->onMessage(result.message_);
            }
          } else {
            for (auto& callback : callbacks_) {
              callback->onFailedParse(result.failure_data_);
            }
          }

          // As we finished parsing this response, return to outer loop.
          // If there is more data, the parser will be re-initialized.
          current_parser_ = nullptr;
          break;
        } else {

          // The next parser that's supposed to consume the rest of payload was given.
          current_parser_ = result.next_parser_;
        }

        // Keep parsing the data.
        result = current_parser_->parse(data);
      }
    }
  }

  const std::vector<CallbackType> callbacks_;

  ParserType current_parser_;
};

/**
 * Kafka message encoder.
 * @param MessageType encoded message type (request or response).
 */
template <typename MessageType> class MessageEncoder {
public:
  virtual ~MessageEncoder() = default;

  /**
   * Encodes given message.
   * @param message message to be encoded.
   */
  virtual void encode(const MessageType& message) PURE;
};

} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include "envoy/buffer/buffer.h"
#include "envoy/common/pure.h"

#include "contrib/kafka/filters/network/source/codec.h"
#include "contrib/kafka/filters/network/source/kafka_request.h"
#include "contrib/kafka/filters/network/source/kafka_request_parser.h"
#include "contrib/kafka/filters/network/source/parser.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

using RequestCallback = MessageCallback<AbstractRequestSharedPtr, RequestParseFailureSharedPtr>;

using RequestCallbackSharedPtr = std::shared_ptr<RequestCallback>;

/**
 * Provides initial parser for messages (class extracted to allow injecting test factories).
 */
class InitialParserFactory {
public:
  virtual ~InitialParserFactory() = default;

  /**
   * Creates default instance that returns RequestStartParser instances.
   */
  static const InitialParserFactory& getDefaultInstance();

  /**
   * Creates parser with given context.
   */
  virtual RequestParserSharedPtr create(const RequestParserResolver& parser_resolver) const PURE;
};

/**
 * Decoder that decodes Kafka requests.
 * When a request is decoded, the callbacks are notified, in order.
 *
 * This decoder uses chain of parsers to parse fragments of a request.
 * Each parser along the line returns the fully parsed message or the next parser.
 * Stores parse state (as large message's payload can be provided through multiple `onData` calls).
 */
class RequestDecoder
    : public AbstractMessageDecoder<RequestParserSharedPtr, RequestCallbackSharedPtr> {
public:
  /**
   * Creates a decoder that will notify provided callbacks when a message is successfully parsed.
   * @param callbacks callbacks to be invoked (in order).
   */
  RequestDecoder(const std::vector<RequestCallbackSharedPtr> callbacks)
      : RequestDecoder(InitialParserFactory::getDefaultInstance(),
                       RequestParserResolver::getDefaultInstance(), callbacks){};

  /**
   * Visible for testing.
   * Allows injecting initial parser factory and parser resolver.
   * @param factory parser factory to be used when new message is to be processed.
   * @param parser_resolver supported parser resolver.
   * @param callbacks callbacks to be invoked (in order).
   */
  RequestDecoder(const InitialParserFactory& factory, const RequestParserResolver& parser_resolver,
                 const std::vector<RequestCallbackSharedPtr> callbacks)
      : AbstractMessageDecoder{callbacks}, factory_{factory}, parser_resolver_{parser_resolver} {};

protected:
  RequestParserSharedPtr createStartParser() override;

private:
  const InitialParserFactory& factory_;
  const RequestParserResolver& parser_resolver_;
};

using RequestDecoderSharedPtr = std::shared_ptr<RequestDecoder>;

/**
 * Encodes requests into underlying buffer.
 */
class RequestEncoder : public MessageEncoder<AbstractRequest> {
public:
  /**
   * Wraps buffer with encoder.
   */
  RequestEncoder(Buffer::Instance& output) : output_(output) {}

  /**
   * Encodes request into wrapped buffer.
   */
  void encode(const AbstractRequest& message) override;

private:
  Buffer::Instance& output_;
};

} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include "contrib/kafka/filters/network/source/codec.h"
#include "contrib/kafka/filters/network/source/kafka_response_parser.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

using ResponseCallback = MessageCallback<AbstractResponseSharedPtr, ResponseMetadataSharedPtr>;

using ResponseCallbackSharedPtr = std::shared_ptr<ResponseCallback>;

/**
 * Provides initial parser for responses (class extracted to allow injecting test factories).
 */
class ResponseInitialParserFactory {
public:
  virtual ~ResponseInitialParserFactory() = default;

  /**
   * Creates default instance that returns ResponseHeaderParser instances.
   */
  static const ResponseInitialParserFactory& getDefaultInstance();

  /**
   * Creates first parser in a chain with given dependencies (that will be used by parser further
   * along the parse process).
   */
  virtual ResponseParserSharedPtr create(ExpectedResponsesSharedPtr expected_responses,
                                         const ResponseParserResolver& parser_resolver) const PURE;
};

/**
 * Decoder that decodes Kafka responses.
 * When a response is decoded, the callbacks are notified, in order.
 *
 * This decoder uses chain of parsers to parse fragments of a response.
 * Each parser along the line returns the fully parsed message or the next parser.
 * Stores parse state (as large message's payload can be provided through multiple `onData` calls).
 *
 * As Kafka protocol does not carry response type data, it is necessary to register expected message
 * type beforehand with `expectResponse`.
 */
class ResponseDecoder
    : public AbstractMessageDecoder<ResponseParserSharedPtr, ResponseCallbackSharedPtr>,
      public Logger::Loggable<Logger::Id::kafka> {
public:
  /**
   * Creates a decoder that will notify provided callbacks when a message is successfully parsed.
   * @param callbacks callbacks to be invoked (in order).
   */
  ResponseDecoder(const std::vector<ResponseCallbackSharedPtr> callbacks)
      : ResponseDecoder{ResponseInitialParserFactory::getDefaultInstance(),
                        ResponseParserResolver::getDefaultInstance(), callbacks} {};

  /**
   * Visible for testing.
   * Allows injecting initial parser factory and parser resolver.
   * @param factory parser factory to be used when new message is to be processed.
   * @param parserResolver supported parser resolver.
   * @param callbacks callbacks to be invoked (in order).
   */
  ResponseDecoder(const ResponseInitialParserFactory& factory,
                  const ResponseParserResolver& response_parser_resolver,
                  const std::vector<ResponseCallbackSharedPtr> callbacks)

      : AbstractMessageDecoder{callbacks}, factory_{factory}, response_parser_resolver_{
                                                                  response_parser_resolver} {};

  /**
   * Registers an expected message.
   * The response's api key & version will be used to create corresponding payload parser when
   * message with the same correlation id is received.
   * @param correlation_id id of the response.
   * @param api_key expected api key of response with given correlation id.
   * @param api_version expected api version of response with given correlation id.
   */
  virtual void expectResponse(const int32_t correlation_id, const int16_t api_key,
                              const int16_t api_version);

protected:
  ResponseParserSharedPtr createStartParser() override;

private:
  const ResponseInitialParserFactory& factory_;
  const ResponseParserResolver& response_parser_resolver_;

  // Store containing expected response metadata (api key & version).
  // Response data is stored in order, as per Kafka protocol.
  const ExpectedResponsesSharedPtr expected_responses_ = std::make_shared<ExpectedResponses>();
};

using ResponseDecoderSharedPtr = std::shared_ptr<ResponseDecoder>;

/**
 * Encodes responses into underlying buffer.
 */
class ResponseEncoder : public MessageEncoder<AbstractResponse> {
public:
  /**
   * Wraps buffer with encoder.
   */
  ResponseEncoder(Buffer::Instance& output) : output_(output) {}

  /**
   * Encodes response into wrapped buffer.
   */
  void encode(const AbstractResponse& message) override;

private:
  Buffer::Instance& output_;
};

} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/kafka/filters/network/source/request_codec.h"

#include "source/common/buffer/buffer_impl.h"

#include "absl/strings/string_view.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

class RequestStartParserFactory : public InitialParserFactory {
  RequestParserSharedPtr create(const RequestParserResolver& parser_resolver) const override {
    return std::make_shared<RequestStartParser>(parser_resolver);
  }
};

const InitialParserFactory& InitialParserFactory::getDefaultInstance() {
  CONSTRUCT_ON_FIRST_USE(RequestStartParserFactory);
}

RequestParserSharedPtr RequestDecoder::createStartParser() {
  return factory_.create(parser_resolver_);
}

void RequestEncoder::encode(const AbstractRequest& message) {
  const uint32_t size = htobe32(message.computeSize());
  output_.add(&size, sizeof(size)); // Encode data length.
  message.encode(output_);          // Encode data.
}

} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
load("@base_pip3//:requirements.bzl", "requirement")
load("@rules_python//python:defs.bzl", "py_binary", "py_library")
load(
    "//bazel:envoy_build_system.bzl",
    "envoy_cc_library",
    "envoy_contrib_package",
)

licenses(["notice"])  # Apache 2

envoy_contrib_package()

# Common code for Kafka filters (Kafka type abstractions, protocol, metrics, etc.).

envoy_cc_library(
    name = "abstract_codec_lib",
    srcs = [],
    hdrs = [
        "codec.h",
    ],
    deps = [
        "//source/common/buffer:buffer_lib",
    ],
)

envoy_cc_library(
    name = "kafka_request_codec_lib",
    srcs = ["request_codec.cc"],
    hdrs = [
        "request_codec.h",
    ],
    deps = [
        ":abstract_codec_lib",
        ":kafka_request_parser_lib",
    ],
)

envoy_cc_library(
    name = "kafka_request_parser_lib",
    srcs = [
        "external/kafka_request_resolver.cc",
        "kafka_request_parser.cc",
    ],
    hdrs = [
        "external/requests.h",
        "kafka_request_parser.h",
    ],
    deps = [
        ":kafka_request_lib",
        ":parser_lib",
        ":tagged_fields_lib",
        "//source/common/common:assert_lib",
        "//source/common/common:minimal_logger_lib",
    ],
)

envoy_cc_library(
    name = "kafka_request_lib",
    srcs = [
    ],
    hdrs = [
        "kafka_request.h",
    ],
    deps = [
        ":serialization_lib",
        ":tagged_fields_lib",
    ],
)

genrule(
    name = "kafka_request_generated_source",
    srcs = [
        "@kafka_source//:request_protocol_files",
    ],
    outs = [
        "external/requests.h",
        "external/kafka_request_resolver.cc",
        "external/request_metrics.h",
    ],
    cmd = """
      ./$(location :kafka_protocol_code_generator_bin) request \
        $(location external/requests.h) $(location external/kafka_request_resolver.cc) \
        $(location external/request_metrics.h) $(SRCS)
    """,
    tools = [
        ":kafka_protocol_code_generator_bin",
    ],
)

envoy_cc_library(
    name = "kafka_response_codec_lib",
    srcs = ["response_codec.cc"],
    hdrs = [
        "response_codec.h",
    ],
    deps = [
        ":abstract_codec_lib",
        ":kafka_response_parser_lib",
    ],
)

envoy_cc_library(
    name = "kafka_response_parser_lib",
    srcs = [
        "external/kafka_response_resolver.cc",
        "kafka_response_parser.cc",
    ],
    hdrs = [
        "external/responses.h",
        "kafka_response_parser.h",
    ],
    deps = [
        ":kafka_response_lib",
        ":parser_lib",
        ":tagged_fields_lib",
        "//source/common/common:assert_lib",
        "//source/common/common:minimal_logger_lib",
    ],
)

envoy_cc_library(
    name = "kafka_response_lib",
    srcs = [
    ],
    hdrs = [
        "kafka_response.h",
    ],
    deps = [
        ":serialization_lib",
        ":tagged_fields_lib",
    ],
)

genrule(
    name = "kafka_response_generated_source",
    srcs = [
        "@kafka_source//:response_protocol_files",
    ],
    outs = [
        "external/responses.h",
        "external/kafka_response_resolver.cc",
        "external/response_metrics.h",
    ],
    cmd = """
      ./$(location :kafka_protocol_code_generator_bin) response \
        $(location external/responses.h) $(location external/kafka_response_resolver.cc) \
        $(location external/response_metrics.h) $(SRCS)
    """,
    tools = [
        ":kafka_protocol_code_generator_bin",
    ],
)

py_binary(
    name = "kafka_protocol_code_generator_bin",
    srcs = ["protocol/launcher.py"],
    data = glob(["protocol/*.j2"]),
    main = "protocol/launcher.py",
    deps = [
        ":kafka_protocol_generator_lib",
        requirement("Jinja2"),
        requirement("MarkupSafe"),
    ],
)

py_library(
    name = "kafka_protocol_generator_lib",
    srcs = ["protocol/generator.py"],
)

envoy_cc_library(
    name = "kafka_metrics_lib",
    hdrs = [
        "external/request_metrics.h",
        "external/response_metrics.h",
    ],
    deps = [
    ],
)

envoy_cc_library(
    name = "parser_lib",
    hdrs = ["parser.h"],
    deps = [
        "//source/common/common:minimal_logger_lib",
    ],
)

envoy_cc_library(
    name = "tagged_fields_lib",
    hdrs = ["tagged_fields.h"],
    deps = [":serialization_lib"],
)

envoy_cc_library(
    name = "serialization_lib",
    srcs = [
        "serialization.cc",
    ],
    hdrs = [
        "external/serialization_composite.h",
        "serialization.h",
    ],
    deps = [
        ":kafka_types_lib",
        "//envoy/buffer:buffer_interface",
        "//source/common/common:byte_order_lib",
        "//source/common/common:safe_memcpy_lib",
    ],
)

genrule(
    name = "serialization_composite_generated_source",
    srcs = [],
    outs = [
        "external/serialization_composite.h",
    ],
    cmd = """
      ./$(location :serialization_composite_code_generator_bin) \
      $(location external/serialization_composite.h)
    """,
    tools = [
        ":serialization_composite_code_generator_bin",
    ],
)

py_binary(
    name = "serialization_composite_code_generator_bin",
    srcs = ["serialization/launcher.py"],
    data = glob(["serialization/*.j2"]),
    main = "serialization/launcher.py",
    deps = [
        ":serialization_composite_generator_lib",
        requirement("Jinja2"),
        requirement("MarkupSafe"),
    ],
)

py_library(
    name = "serialization_composite_generator_lib",
    srcs = ["serialization/generator.py"],
)

envoy_cc_library(
    name = "kafka_types_lib",
    hdrs = [
        "kafka_types.h",
    ],
    external_deps = ["abseil_optional"],
    deps = [
        "//source/common/common:macros",
    ],
)
#pragma once

#include <memory>

#include "envoy/common/exception.h"

#include "source/common/common/assert.h"

#include "contrib/kafka/filters/network/source/kafka_request.h"
#include "contrib/kafka/filters/network/source/parser.h"
#include "contrib/kafka/filters/network/source/tagged_fields.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

using RequestParseResponse = ParseResponse<AbstractRequestSharedPtr, RequestParseFailureSharedPtr>;
using RequestParser = Parser<AbstractRequestSharedPtr, RequestParseFailureSharedPtr>;
using RequestParserSharedPtr = std::shared_ptr<RequestParser>;

/**
 * Context that is shared between parsers that are handling the same single message.
 */
struct RequestContext {

  /**
   * Bytes left to consume.
   */
  uint32_t remaining_request_size_{0};

  /**
   * Request header that gets filled in during the parse.
   */
  RequestHeader request_header_{-1, -1, -1, absl::nullopt};

  /**
   * Bytes left to consume.
   */
  uint32_t& remaining() { return remaining_request_size_; }

  /**
   * Returns data needed for construction of parse failure message.
   */
  const RequestHeader asFailureData() const { return request_header_; }
};

using RequestContextSharedPtr = std::shared_ptr<RequestContext>;

/**
 * Request decoder configuration object.
 * Resolves the parser that will be responsible for consuming the request-specific data.
 * In other words: provides (api_key, api_version) -> Parser function.
 */
class RequestParserResolver {
public:
  virtual ~RequestParserResolver() = default;

  /**
   * Creates a parser that is going to process data specific for given api_key & api_version.
   * @param api_key request type.
   * @param api_version request version.
   * @param context context to be used by parser.
   * @return parser that is capable of processing data for given request type & version.
   */
  virtual RequestParserSharedPtr createParser(int16_t api_key, int16_t api_version,
                                              RequestContextSharedPtr context) const;

  /**
   * Return default resolver, that uses request's api key and version to provide a matching parser.
   */
  static const RequestParserResolver& getDefaultInstance();
};

/**
 * Request parser responsible for consuming request length and setting up context with this data.
 * @see http://kafka.apache.org/protocol.html#protocol_common
 */
class RequestStartParser : public RequestParser {
public:
  RequestStartParser(const RequestParserResolver& parser_resolver)
      : parser_resolver_{parser_resolver}, context_{std::make_shared<RequestContext>()} {};

  /**
   * Consumes 4 bytes (INT32) as request length and updates the context with that value.
   * @return RequestHeaderParser instance to process request header.
   */
  RequestParseResponse parse(absl::string_view& data) override;

  const RequestContextSharedPtr contextForTest() const { return context_; }

private:
  const RequestParserResolver& parser_resolver_;
  const RequestContextSharedPtr context_;
  Int32Deserializer request_length_;
};

/**
 * Deserializer that extracts request header (4 fields).
 * Can throw, as one of the fields (client-id) can throw (nullable string with invalid length).
 * @see http://kafka.apache.org/protocol.html#protocol_messages
 */
class RequestHeaderDeserializer : public Deserializer<RequestHeader>,
                                  private Logger::Loggable<Logger::Id::kafka> {

  // Request header, no matter what, has at least 4 fields. They are extracted here.
  using CommonPartDeserializer =
      CompositeDeserializerWith4Delegates<RequestHeader, Int16Deserializer, Int16Deserializer,
                                          Int32Deserializer, NullableStringDeserializer>;

public:
  RequestHeaderDeserializer() = default;

  uint32_t feed(absl::string_view& data) override;
  bool ready() const override;
  RequestHeader get() const override;

private:
  // Deserializer for the first 4 fields, that are present in every request header.
  CommonPartDeserializer common_part_deserializer_;

  // Tagged fields are used only in request header v2.
  // This flag will be set depending on common part's result (api key & version), and will decide
  // whether we want to feed data to tagged fields deserializer.
  bool tagged_fields_present_;
  TaggedFieldsDeserializer tagged_fields_deserializer_;
};

using RequestHeaderDeserializerPtr = std::unique_ptr<RequestHeaderDeserializer>;

/**
 * Parser responsible for extracting the request header and putting it into context.
 * On a successful parse the resolved data (api_key & api_version) is used to determine the next
 * parser.
 * @see http://kafka.apache.org/protocol.html#protocol_messages
 */
class RequestHeaderParser : public RequestParser {
public:
  // Default constructor.
  RequestHeaderParser(const RequestParserResolver& parser_resolver, RequestContextSharedPtr context)
      : RequestHeaderParser{parser_resolver, context,
                            std::make_unique<RequestHeaderDeserializer>()} {};

  // Constructor visible for testing (allows for initial parser injection).
  RequestHeaderParser(const RequestParserResolver& parser_resolver, RequestContextSharedPtr context,
                      RequestHeaderDeserializerPtr deserializer)
      : parser_resolver_{parser_resolver}, context_{context}, deserializer_{
                                                                  std::move(deserializer)} {};

  /**
   * Uses data provided to compute request header.
   * @return Parser instance responsible for processing rest of the message
   */
  RequestParseResponse parse(absl::string_view& data) override;

  const RequestContextSharedPtr contextForTest() const { return context_; }

private:
  const RequestParserResolver& parser_resolver_;
  const RequestContextSharedPtr context_;
  RequestHeaderDeserializerPtr deserializer_;
};

/**
 * Sentinel parser that is responsible for consuming message bytes for messages that had unsupported
 * api_key & api_version. It does not attempt to capture any data, just throws it away until end of
 * message.
 */
class SentinelParser : public AbstractSentinelParser<RequestContextSharedPtr, RequestParseResponse>,
                       public RequestParser {
public:
  SentinelParser(RequestContextSharedPtr context) : AbstractSentinelParser{context} {};

  RequestParseResponse parse(absl::string_view& data) override {
    return AbstractSentinelParser::parse(data);
  }
};

/**
 * Request parser uses a single deserializer to construct a request object.
 * This parser is responsible for consuming request-specific data (e.g. topic names) and always
 * returns a parsed message.
 * @param RequestType request class.
 * @param DeserializerType deserializer type corresponding to request class (should be subclass of
 * Deserializer<RequestType>).
 */
template <typename RequestType, typename DeserializerType>
class RequestDataParser : public RequestParser {
public:
  /**
   * Create a parser with given context.
   * @param context parse context containing request header.
   */
  RequestDataParser(RequestContextSharedPtr context) : context_{context} {};

  /**
   * Consume enough data to fill in deserializer and receive the parsed request.
   * Fill in request's header with data stored in context.
   */
  RequestParseResponse parse(absl::string_view& data) override {
    context_->remaining_request_size_ -= deserializer.feed(data);

    if (deserializer.ready()) {
      if (0 == context_->remaining_request_size_) {
        // After a successful parse, there should be nothing left - we have consumed all the bytes.
        AbstractRequestSharedPtr msg =
            std::make_shared<Request<RequestType>>(context_->request_header_, deserializer.get());
        return RequestParseResponse::parsedMessage(msg);
      } else {
        // The message makes no sense, the deserializer that matches the schema consumed all
        // necessary data, but there are still bytes in this message.
        return RequestParseResponse::nextParser(std::make_shared<SentinelParser>(context_));
      }
    } else {
      return RequestParseResponse::stillWaiting();
    }
  }

  const RequestContextSharedPtr contextForTest() const { return context_; }

protected:
  RequestContextSharedPtr context_;
  DeserializerType deserializer; // underlying request-specific deserializer
};

} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include "envoy/common/exception.h"

#include "contrib/kafka/filters/network/source/external/serialization_composite.h"
#include "contrib/kafka/filters/network/source/serialization.h"
#include "contrib/kafka/filters/network/source/tagged_fields.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

/**
 * Decides if request with given api key & version should have tagged fields in header.
 * This method gets implemented in generated code through 'kafka_request_resolver_cc.j2'.
 * @param api_key Kafka request key.
 * @param api_version Kafka request's version.
 * @return Whether tagged fields should be used for this request.
 */
bool requestUsesTaggedFieldsInHeader(const uint16_t api_key, const uint16_t api_version);

/**
 * Represents fields that are present in every Kafka request message.
 * @see http://kafka.apache.org/protocol.html#protocol_messages
 */
struct RequestHeader {
  int16_t api_key_;
  int16_t api_version_;
  int32_t correlation_id_;
  NullableString client_id_;
  TaggedFields tagged_fields_;

  RequestHeader(const int16_t api_key, const int16_t api_version, const int32_t correlation_id,
                const NullableString& client_id)
      : RequestHeader{api_key, api_version, correlation_id, client_id, TaggedFields{}} {};

  RequestHeader(const int16_t api_key, const int16_t api_version, const int32_t correlation_id,
                const NullableString& client_id, const TaggedFields& tagged_fields)
      : api_key_{api_key}, api_version_{api_version}, correlation_id_{correlation_id},
        client_id_{client_id}, tagged_fields_{tagged_fields} {};

  uint32_t computeSize(const EncodingContext& context) const {
    uint32_t result{0};
    result += context.computeSize(api_key_);
    result += context.computeSize(api_version_);
    result += context.computeSize(correlation_id_);
    result += context.computeSize(client_id_);
    if (requestUsesTaggedFieldsInHeader(api_key_, api_version_)) {
      result += context.computeCompactSize(tagged_fields_);
    }
    return result;
  }

  uint32_t encode(Buffer::Instance& dst, EncodingContext& context) const {
    uint32_t written{0};
    written += context.encode(api_key_, dst);
    written += context.encode(api_version_, dst);
    written += context.encode(correlation_id_, dst);
    written += context.encode(client_id_, dst);
    if (requestUsesTaggedFieldsInHeader(api_key_, api_version_)) {
      written += context.encodeCompact(tagged_fields_, dst);
    }
    return written;
  }

  bool operator==(const RequestHeader& rhs) const {
    return api_key_ == rhs.api_key_ && api_version_ == rhs.api_version_ &&
           correlation_id_ == rhs.correlation_id_ && client_id_ == rhs.client_id_ &&
           tagged_fields_ == rhs.tagged_fields_;
  };
};

/**
 * Carries information that could be extracted during the failed parse.
 */
class RequestParseFailure {
public:
  RequestParseFailure(const RequestHeader& request_header) : request_header_{request_header} {};

  /**
   * Request's header.
   */
  const RequestHeader request_header_;
};

using RequestParseFailureSharedPtr = std::shared_ptr<RequestParseFailure>;

/**
 * Abstract Kafka request.
 * Contains data present in every request (the header with request key, version, etc.).
 * @see http://kafka.apache.org/protocol.html#protocol_messages
 */
class AbstractRequest {
public:
  virtual ~AbstractRequest() = default;

  /**
   * Constructs a request with given header data.
   * @param request_header request's header.
   */
  AbstractRequest(const RequestHeader& request_header) : request_header_{request_header} {};

  /**
   * Computes the size of this request, if it were to be serialized.
   * @return serialized size of request
   */
  virtual uint32_t computeSize() const PURE;

  /**
   * Encode the contents of this request into a given buffer.
   * @param dst buffer instance to keep serialized message
   */
  virtual uint32_t encode(Buffer::Instance& dst) const PURE;

  /**
   * Request's header.
   */
  const RequestHeader request_header_;
};

using AbstractRequestSharedPtr = std::shared_ptr<AbstractRequest>;

/**
 * Concrete request that carries data particular to given request type.
 * @param Data concrete request data type.
 */
template <typename Data> class Request : public AbstractRequest {
public:
  /**
   * Request header fields need to be initialized by user in case of newly created requests.
   */
  Request(const RequestHeader& request_header, const Data& data)
      : AbstractRequest{request_header}, data_{data} {};

  /**
   * Compute the size of request, which includes both the request header and its real data.
   */
  uint32_t computeSize() const override {
    const EncodingContext context{request_header_.api_version_};
    uint32_t result{0};
    // Compute size of header.
    result += context.computeSize(request_header_);
    // Compute size of request data.
    result += context.computeSize(data_);
    return result;
  }

  /**
   * Encodes given request into a buffer, with any extra configuration carried by the context.
   */
  uint32_t encode(Buffer::Instance& dst) const override {
    EncodingContext context{request_header_.api_version_};
    uint32_t written{0};
    // Encode request header.
    written += context.encode(request_header_, dst);
    // Encode request-specific data.
    written += context.encode(data_, dst);
    return written;
  }

  bool operator==(const Request<Data>& rhs) const {
    return request_header_ == rhs.request_header_ && data_ == rhs.data_;
  };

  const Data data_;
};

} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include "contrib/kafka/filters/network/source/external/serialization_composite.h"
#include "contrib/kafka/filters/network/source/serialization.h"
#include "contrib/kafka/filters/network/source/tagged_fields.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace Kafka {

/**
 * Decides if response with given api key & version should have tagged fields in header.
 * Bear in mind, that ApiVersions responses DO NOT contain tagged fields in header (despite having
 * flexible versions) as per
 * https://github.com/apache/kafka/blob/2.8.1/clients/src/main/resources/common/message/ApiVersionsResponse.json#L24
 * This method gets implemented in generated code through 'kafka_response_resolver_cc.j2'.
 *
 * @param api_key Kafka request key.
 * @param api_version Kafka request's version.
 * @return Whether tagged fields should be used for this request.
 */
bool responseUsesTaggedFieldsInHeader(const uint16_t api_key, const uint16_t api_version);

/**
 * Represents Kafka response metadata: expected api key, version and correlation id.
 * @see http://kafka.apache.org/protocol.html#protocol_messages
 */
struct ResponseMetadata {
  ResponseMetadata(const int16_t api_key, const int16_t api_version, const int32_t correlation_id)
      : ResponseMetadata{api_key, api_version, correlation_id, TaggedFields{}} {};

  ResponseMetadata(const int16_t api_key, const int16_t api_version, const int32_t correlation_id,
                   const TaggedFields& tagged_fields)
      : api_key_{api_key}, api_version_{api_version}, correlation_id_{correlation_id},
        tagged_fields_{tagged_fields} {};

  uint32_t computeSize(const EncodingContext& context) const {
    uint32_t result{0};
    result += context.computeSize(correlation_id_);
    if (responseUsesTaggedFieldsInHeader(api_key_, api_version_)) {
      result += context.computeCompactSize(tagged_fields_);
    }
    return result;
  }

  uint32_t encode(Buffer::Instance& dst, EncodingContext& context) const {
    uint32_t written{0};
    // Encode correlation id (api key / version are not present in responses).
    written += context.encode(correlation_id_, dst);
    if (responseUsesTaggedFieldsInHeader(api_key_, api_version_)) {
      written += context.encodeCompact(tagged_fields_, dst);
    }
    return written;
  }

  bool operator==(const ResponseMetadata& rhs) const {
    return api_key_ == rhs.api_key_ && api_version_ == rhs.api_version_ &&
           correlation_id_ == rhs.correlation_id_ && tagged_fields_ == rhs.tagged_fields_;
  };

  const int16_t api_key_;
  const int16_t api_version_;
  const int32_t correlation_id_;
  const TaggedFields tagged_fields_;
};

using ResponseMetadataSharedPtr = std::shared_ptr<ResponseMetadata>;

/**
 * Abstract response object, carrying data related to every response.
 * @see http://kafka.apache.org/protocol.html#protocol_messages
 */
class AbstractResponse {
public:
  virtual ~AbstractResponse() = default;

  /**
   * Constructs a request with given metadata.
   * @param metadata response metadata.
   */
  AbstractResponse(const ResponseMetadata& metadata) : metadata_{metadata} {};

  /**
   * Computes the size of this response, if it were to be serialized.
   * @return serialized size of response.
   */
  virtual uint32_t computeSize() const PURE;

  /**
   * Encode the contents of this response into a given buffer.
   * @param dst buffer instance to keep serialized message.
   */
  virtual uint32_t encode(Buffer::Instance& dst) const PURE;

  /**
   * Convenience method for response's API key.
   */
  int16_t apiKey() const { return metadata_.api_key_; }

  /**
   * Response's metadata.
   */
  const ResponseMetadata metadata_;
};

using AbstractResponseSharedPtr = std::shared_ptr<AbstractResponse>;

/**
 * Concrete response that carries data particular to given response type.
 * @param Data concrete response data type.
 */
template <typename Data> class Response : public AbstractResponse {
public:
  Response(const ResponseMetadata& metadata, const Data& data)
      : AbstractResponse{metadata}, data_{data} {};

  /**
   * Compute the size of response, which includes both the response header (correlation id) and
   * real data.
   */
  uint32_t computeSize() const override {
    const EncodingContext context{metadata_.api_version_};
    uint32_t result{0};
    // Compute size of header.
    result += context.computeSize(metadata_);
    // Compute size of response data.
    result += context.computeSize(data_);
    return result;
  }

  /**
   * Encodes given response into a buffer, with any extra configuration carried by the context.
   */
  uint32_t encode(Buffer::Instance& dst) const override {
    EncodingContext context{metadata_.api_version_};
    uint32_t written{0};
    // Encode response header.
    written += context.encode(metadata_, dst);
    // Encode response-specific data.
    written += context.encode(data_, dst);
    return written;
  }

  bool operator==(const Response<Data>& rhs) const {
    return metadata_ == rhs.metadata_ && data_ == rhs.data_;
  };

  Data data_;
};

} // namespace Kafka
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "envoy/registry/registry.h"

#include "source/common/protobuf/utility.h"
#include "source/extensions/filters/network/well_known_names.h"

#include "test/mocks/server/factory_context.h"

#include "contrib/client_ssl_auth/filters/network/source/config.h"
#include "contrib/envoy/extensions/filters/network/client_ssl_auth/v3/client_ssl_auth.pb.h"
#include "contrib/envoy/extensions/filters/network/client_ssl_auth/v3/client_ssl_auth.pb.validate.h"
#include "gmock/gmock.h"
#include "gtest/gtest.h"

using testing::_;

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace ClientSslAuth {

class IpAllowListConfigTest : public testing::TestWithParam<std::string> {};

const std::string ipv4_cidr_yaml = R"EOF(
- address_prefix: "192.168.3.0"
  prefix_len: 24
)EOF";

const std::string ipv6_cidr_yaml = R"EOF(
- address_prefix: "2001:abcd::"
  prefix_len: 64
)EOF";

INSTANTIATE_TEST_SUITE_P(IpList, IpAllowListConfigTest,
                         ::testing::Values(ipv4_cidr_yaml, ipv6_cidr_yaml));

TEST_P(IpAllowListConfigTest, ClientSslAuthCorrectJson) {
  const std::string yaml = R"EOF(
stat_prefix: my_stat_prefix
auth_api_cluster: fake_cluster
ip_white_list:
)EOF" + GetParam();

  envoy::extensions::filters::network::client_ssl_auth::v3::ClientSSLAuth proto_config;
  TestUtility::loadFromYamlAndValidate(yaml, proto_config);
  NiceMock<Server::Configuration::MockFactoryContext> context;
  context.server_factory_context_.cluster_manager_.initializeClusters({"fake_cluster"}, {});
  context.server_factory_context_.cluster_manager_.initializeThreadLocalClusters({"fake_cluster"});
  ClientSslAuthConfigFactory factory;
  Network::FilterFactoryCb cb = factory.createFilterFactoryFromProto(proto_config, context);
  Network::MockConnection connection;
  EXPECT_CALL(connection, addReadFilter(_));
  cb(connection);
}

TEST_P(IpAllowListConfigTest, ClientSslAuthCorrectProto) {
  const std::string yaml = R"EOF(
stat_prefix: my_stat_prefix
auth_api_cluster: fake_cluster
ip_white_list:
)EOF" + GetParam();

  envoy::extensions::filters::network::client_ssl_auth::v3::ClientSSLAuth proto_config;
  TestUtility::loadFromYamlAndValidate(yaml, proto_config);
  NiceMock<Server::Configuration::MockFactoryContext> context;
  context.server_factory_context_.cluster_manager_.initializeClusters({"fake_cluster"}, {});
  context.server_factory_context_.cluster_manager_.initializeThreadLocalClusters({"fake_cluster"});
  ClientSslAuthConfigFactory factory;
  Network::FilterFactoryCb cb = factory.createFilterFactoryFromProto(proto_config, context);
  Network::MockConnection connection;
  EXPECT_CALL(connection, addReadFilter(_));
  cb(connection);
}

TEST_P(IpAllowListConfigTest, ClientSslAuthEmptyProto) {
  const std::string yaml = R"EOF(
stat_prefix: my_stat_prefix
auth_api_cluster: fake_cluster
ip_white_list:
)EOF" + GetParam();

  NiceMock<Server::Configuration::MockFactoryContext> context;
  context.server_factory_context_.cluster_manager_.initializeClusters({"fake_cluster"}, {});
  context.server_factory_context_.cluster_manager_.initializeThreadLocalClusters({"fake_cluster"});
  ClientSslAuthConfigFactory factory;
  envoy::extensions::filters::network::client_ssl_auth::v3::ClientSSLAuth proto_config =
      *dynamic_cast<envoy::extensions::filters::network::client_ssl_auth::v3::ClientSSLAuth*>(
          factory.createEmptyConfigProto().get());

  TestUtility::loadFromYamlAndValidate(yaml, proto_config);
  Network::FilterFactoryCb cb = factory.createFilterFactoryFromProto(proto_config, context);
  Network::MockConnection connection;
  EXPECT_CALL(connection, addReadFilter(_));
  cb(connection);
}

TEST(ClientSslAuthConfigFactoryTest, ValidateFail) {
  NiceMock<Server::Configuration::MockFactoryContext> context;
  EXPECT_THROW(
      ClientSslAuthConfigFactory().createFilterFactoryFromProto(
          envoy::extensions::filters::network::client_ssl_auth::v3::ClientSSLAuth(), context),
      ProtoValidationException);
}

} // namespace ClientSslAuth
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
{
  "certificates": [
    {
      "device": "chrome-os",
      "email": "vho@lyft.com",
      "fingerprint_sha1": "4c5beecd0b516d9ab53029ae646c4628bc7a1980",
      "fingerprint_sha256": "1b7d42ef0025ad89c1c911d6c10d7e86a4cb7c5863b2980abcbad1895f8b5314",
      "first_name": "Vivian",
      "group": null,
      "pem_encoded": "-----BEGIN CERTIFICATE-----\nMIIFHDCCBASgAwIBAgIRAKOl7/eNakU3mgSOijyzmv0wDQYJKoZIhvcNAQELBQAw\nggFBMQswCQYDVQQGEwJVUzETMBEGA1UECAwKQ2FsaWZvcm5pYTEWMBQGA1UEBwwN\nU2FuIEZyYW5jaXNjbzENMAsGA1UECgwETHlmdDFHMEUGA1UECww+REFOR0VSOiBU\nSElTIFBLSSBIQVMgQSBDVVNUT00gVFJVU1QgUFJPVE9DT0wuIFRIRVJFIElTIE5P\nIENSTC4xRjBEBgNVBAsMPURBTkdFUjogUkVMWUlORyBQQVJUSUVTIE1VU1QgTk9U\nIFRSVVNUIENFUlQgVkFMSURBVElPTiBBTE9ORS4xPjA8BgNVBAMMNUx5ZnQgVlBO\nIEludGVybmFsIENlcnRpZmljYXRlIEF1dGhvcml0eSAoREVWRUxPUE1FTlQpMSUw\nIwYJKoZIhvcNAQkBFhZzZWN1cml0eS10ZWFtQGx5ZnQuY29tMB4XDTE2MDQwNDE3\nNDUwMloXDTE3MDQwNTE3NDUwMlowggEUMRUwEwYDVQQDDAx2aG9AbHlmdC5jb20x\nGzAZBgkqhkiG9w0BCQEWDHZob0BseWZ0LmNvbTELMAkGA1UEBAwCSG8xDzANBgNV\nBCoMBlZpdmlhbjENMAsGA1UECgwETHlmdDELMAkGA1UEBhMCVVMxEzARBgNVBAgM\nCkNhbGlmb3JuaWExRzBFBgNVBAsMPkRBTkdFUjogVEhJUyBQS0kgSEFTIEEgQ1VT\nVE9NIFRSVVNUIFBST1RPQ09MLiBUSEVSRSBJUyBOTyBDUkwuMUYwRAYDVQQLDD1E\nQU5HRVI6IFJFTFlJTkcgUEFSVElFUyBNVVNUIE5PVCBUUlVTVCBDRVJUIFZBTElE\nQVRJT04gQUxPTkUuMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAuSDo\nncWmuzSzSSqQLHOkY0DmThagTzep/KTduHVQyePLMLtNRDDak+/aQaCbXTlQSrYo\n4IOsC3fwGp1ds70l7odFYry9r0yTt8P7sTRnXD59mxLs6XTmzdwqr42R6K5LpHJQ\nfTBFocHJ9Gzk/Ejn11BtzvQe6iX+X3ZPf5IF36sJIdktaHCWFG6Sts2IE5UWBX7K\nOUzAKJ/PlVkiMa4d0nhEBBE2qmZpHBl3g2HGBFHlGoPhmlHqzBeB2IWzn18FN3sL\nYJs3+Ucmr31ZSo6F3r5PzPzOiUxDTXPLDG1DruMEK6Tq5VSGVWkKB/lnObi6REYA\n8YFJYEJuZUoOZNjxywIDAQABozgwNjAMBgNVHRMBAf8EAjAAMA4GA1UdDwEB/wQE\nAwIFoDAWBgNVHSUBAf8EDDAKBggrBgEFBQcDAjANBgkqhkiG9w0BAQsFAAOCAQEA\nOrD/CxKdqN+fCI3mQGVTFz9xgKqx+ka30nMlxBYx0ACD189MmXW1EdjCW6RUIcvP\nxDnt+zV10XnqlzMMh6VIlPp/y9m4758TxkDk4Z8Mni3eCHh4NPYo0V54rxYZL9hJ\nsX8P32Cu6bKcOXb4WIuXcXuKrt/6PVKFACbaYdTYrlvalJz4m0O426o5jcPx8FtI\naqDTXO42ZUwU04C5c1rWh6kh3oqTPVMXPsAKUklwvVQC4jS/QTfAaZE2hdAFIw9l\nu0uMferJP4zHP9gzCmHcv4+ZBzJ0wKz2IVeR45Iyq1QvrMN4pz/bZhQO91VMwHHC\nSPB1iqKP4Ly3rOpmRXWgTg==\n-----END CERTIFICATE-----\n",
      "status": "approved",
      "surname": "Ho"
    }
  ]
}
#include <chrono>
#include <memory>
#include <string>

#include "envoy/runtime/runtime.h"

#include "source/common/http/message_impl.h"
#include "source/common/network/address_impl.h"

#include "test/mocks/network/mocks.h"
#include "test/mocks/runtime/mocks.h"
#include "test/mocks/ssl/mocks.h"
#include "test/mocks/thread_local/mocks.h"
#include "test/mocks/upstream/cluster_manager.h"
#include "test/test_common/environment.h"
#include "test/test_common/printers.h"
#include "test/test_common/utility.h"

#include "contrib/client_ssl_auth/filters/network/source/client_ssl_auth.h"
#include "contrib/envoy/extensions/filters/network/client_ssl_auth/v3/client_ssl_auth.pb.h"
#include "gmock/gmock.h"
#include "gtest/gtest.h"

using testing::_;
using testing::InSequence;
using testing::Invoke;
using testing::Return;
using testing::ReturnRef;

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace ClientSslAuth {

TEST(ClientSslAuthAllowedPrincipalsTest, EmptyString) {
  AllowedPrincipals principals;
  principals.add("");
  EXPECT_EQ(0UL, principals.size());
}

TEST(ClientSslAuthConfigTest, BadClientSslAuthConfig) {
  std::string yaml = R"EOF(
stat_prefix: my_stat_prefix
auth_api_cluster: fake_cluster
ip_white_list:
- address_prefix: 192.168.3.0
  prefix_len: 24
test: a
  )EOF";

  envoy::extensions::filters::network::client_ssl_auth::v3::ClientSSLAuth proto_config{};
  EXPECT_THROW(TestUtility::loadFromYaml(yaml, proto_config), EnvoyException);
}

class ClientSslAuthFilterTest : public testing::Test {
protected:
  ClientSslAuthFilterTest()
      : request_(&cm_.thread_local_cluster_.async_client_),
        interval_timer_(new Event::MockTimer(&dispatcher_)),
        api_(Api::createApiForTest(stats_store_)),
        ssl_(std::make_shared<Ssl::MockConnectionInfo>()) {}
  ~ClientSslAuthFilterTest() override { tls_.shutdownThread(); }

  void setup() {
    std::string yaml = R"EOF(
auth_api_cluster: vpn
stat_prefix: vpn
ip_white_list:
- address_prefix: 1.2.3.4
  prefix_len: 32
- address_prefix: '2001:abcd::'
  prefix_len: 64
    )EOF";

    envoy::extensions::filters::network::client_ssl_auth::v3::ClientSSLAuth proto_config{};
    TestUtility::loadFromYaml(yaml, proto_config);
    cm_.initializeClusters({"vpn"}, {});
    cm_.initializeThreadLocalClusters({"vpn"});
    setupRequest();
    config_ = ClientSslAuthConfig::create(proto_config, tls_, cm_, dispatcher_,
                                          *stats_store_.rootScope(), random_);

    createAuthFilter();
  }

  void createAuthFilter() {
    filter_callbacks_.connection_.callbacks_.clear();
    instance_ = std::make_unique<ClientSslAuthFilter>(config_);
    instance_->initializeReadFilterCallbacks(filter_callbacks_);

    // NOP currently.
    instance_->onAboveWriteBufferHighWatermark();
    instance_->onBelowWriteBufferLowWatermark();
  }

  void setupRequest() {
    EXPECT_CALL(cm_.thread_local_cluster_, httpAsyncClient())
        .WillOnce(ReturnRef(cm_.thread_local_cluster_.async_client_));
    EXPECT_CALL(cm_.thread_local_cluster_.async_client_, send_(_, _, _))
        .WillOnce(
            Invoke([this](Http::RequestMessagePtr&, Http::AsyncClient::Callbacks& callbacks,
                          const Http::AsyncClient::RequestOptions&) -> Http::AsyncClient::Request* {
              callbacks_ = &callbacks;
              return &request_;
            }));
  }

  NiceMock<ThreadLocal::MockInstance> tls_;
  NiceMock<Upstream::MockClusterManager> cm_;
  Event::MockDispatcher dispatcher_;
  Http::MockAsyncClientRequest request_;
  ClientSslAuthConfigSharedPtr config_;
  NiceMock<Network::MockReadFilterCallbacks> filter_callbacks_;
  std::unique_ptr<ClientSslAuthFilter> instance_;
  Event::MockTimer* interval_timer_;
  Http::AsyncClient::Callbacks* callbacks_;
  Stats::TestUtil::TestStore stats_store_;
  NiceMock<Random::MockRandomGenerator> random_;
  Api::ApiPtr api_;
  std::shared_ptr<Ssl::MockConnectionInfo> ssl_;
};

TEST_F(ClientSslAuthFilterTest, NoCluster) {
  std::string yaml = R"EOF(
auth_api_cluster: bad_cluster
stat_prefix: bad_cluster
  )EOF";

  envoy::extensions::filters::network::client_ssl_auth::v3::ClientSSLAuth proto_config{};
  TestUtility::loadFromYaml(yaml, proto_config);
  EXPECT_CALL(cm_, clusters()).WillOnce(Return(Upstream::ClusterManager::ClusterInfoMaps()));
  EXPECT_THROW(ClientSslAuthConfig::create(proto_config, tls_, cm_, dispatcher_,
                                           *stats_store_.rootScope(), random_),
               EnvoyException);
}

TEST_F(ClientSslAuthFilterTest, NoSsl) {
  setup();
  Buffer::OwnedImpl dummy("hello");

  // Check no SSL case, multiple iterations.
  EXPECT_CALL(filter_callbacks_.connection_, ssl()).WillOnce(Return(nullptr));
  EXPECT_EQ(Network::FilterStatus::Continue, instance_->onNewConnection());
  EXPECT_EQ(Network::FilterStatus::Continue, instance_->onData(dummy, false));
  EXPECT_EQ(Network::FilterStatus::Continue, instance_->onData(dummy, false));
  filter_callbacks_.connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);

  EXPECT_EQ(1U, stats_store_.counter("auth.clientssl.vpn.auth_no_ssl").value());

  EXPECT_CALL(request_, cancel());
}

TEST_F(ClientSslAuthFilterTest, Ssl) {
  InSequence s;

  setup();
  Buffer::OwnedImpl dummy("hello");

  // Create a new filter for an SSL connection, with no backing auth data yet.
  createAuthFilter();
  ON_CALL(filter_callbacks_.connection_, ssl()).WillByDefault(Return(ssl_));
  filter_callbacks_.connection_.stream_info_.downstream_connection_info_provider_->setRemoteAddress(
      std::make_shared<Network::Address::Ipv4Instance>("192.168.1.1"));
  std::string expected_sha_1("digest");
  EXPECT_CALL(*ssl_, sha256PeerCertificateDigest()).WillOnce(ReturnRef(expected_sha_1));
  EXPECT_CALL(filter_callbacks_.connection_.stream_info_,
              setResponseFlag(StreamInfo::ResponseFlag::UpstreamProtocolError));
  EXPECT_CALL(filter_callbacks_.connection_.stream_info_,
              setResponseCodeDetails("auth_digest_no_match"));
  EXPECT_CALL(filter_callbacks_.connection_, close(Network::ConnectionCloseType::NoFlush));
  EXPECT_EQ(Network::FilterStatus::StopIteration, instance_->onNewConnection());
  filter_callbacks_.connection_.raiseEvent(Network::ConnectionEvent::Connected);
  filter_callbacks_.connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);

  // Respond.
  EXPECT_CALL(*interval_timer_, enableTimer(_, _));
  Http::ResponseMessagePtr message(new Http::ResponseMessageImpl(
      Http::ResponseHeaderMapPtr{new Http::TestResponseHeaderMapImpl{{":status", "200"}}}));
  message->body().add(
      api_->fileSystem()
          .fileReadToEnd(TestEnvironment::runfilesPath(
              "contrib/client_ssl_auth/filters/network/test/test_data/vpn_response_1.json"))
          .value());
  callbacks_->onSuccess(request_, std::move(message));
  EXPECT_EQ(1U,
            stats_store_
                .gauge("auth.clientssl.vpn.total_principals", Stats::Gauge::ImportMode::NeverImport)
                .value());

  // Create a new filter for an SSL connection with an authorized cert.
  createAuthFilter();
  filter_callbacks_.connection_.stream_info_.downstream_connection_info_provider_->setRemoteAddress(
      std::make_shared<Network::Address::Ipv4Instance>("192.168.1.1"));
  std::string expected_sha_2("1b7d42ef0025ad89c1c911d6c10d7e86a4cb7c5863b2980abcbad1895f8b5314");
  EXPECT_CALL(*ssl_, sha256PeerCertificateDigest()).WillOnce(ReturnRef(expected_sha_2));
  EXPECT_EQ(Network::FilterStatus::StopIteration, instance_->onNewConnection());
  EXPECT_CALL(filter_callbacks_, continueReading());
  filter_callbacks_.connection_.raiseEvent(Network::ConnectionEvent::Connected);
  EXPECT_EQ(Network::FilterStatus::Continue, instance_->onData(dummy, false));
  EXPECT_EQ(Network::FilterStatus::Continue, instance_->onData(dummy, false));
  filter_callbacks_.connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);

  // White list case.
  createAuthFilter();
  filter_callbacks_.connection_.stream_info_.downstream_connection_info_provider_->setRemoteAddress(
      std::make_shared<Network::Address::Ipv4Instance>("1.2.3.4"));
  EXPECT_EQ(Network::FilterStatus::StopIteration, instance_->onNewConnection());
  EXPECT_CALL(filter_callbacks_, continueReading());
  filter_callbacks_.connection_.raiseEvent(Network::ConnectionEvent::Connected);
  EXPECT_EQ(Network::FilterStatus::Continue, instance_->onData(dummy, false));
  EXPECT_EQ(Network::FilterStatus::Continue, instance_->onData(dummy, false));
  filter_callbacks_.connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);

  // IPv6 White list case.
  createAuthFilter();
  filter_callbacks_.connection_.stream_info_.downstream_connection_info_provider_->setRemoteAddress(
      std::make_shared<Network::Address::Ipv6Instance>("2001:abcd::1"));
  EXPECT_EQ(Network::FilterStatus::StopIteration, instance_->onNewConnection());
  EXPECT_CALL(filter_callbacks_, continueReading());
  filter_callbacks_.connection_.raiseEvent(Network::ConnectionEvent::Connected);
  EXPECT_EQ(Network::FilterStatus::Continue, instance_->onData(dummy, false));
  EXPECT_EQ(Network::FilterStatus::Continue, instance_->onData(dummy, false));

  filter_callbacks_.connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);
  EXPECT_EQ(1U, stats_store_.counter("auth.clientssl.vpn.update_success").value());
  EXPECT_EQ(2U, stats_store_.counter("auth.clientssl.vpn.auth_ip_allowlist").value());
  EXPECT_EQ(1U, stats_store_.counter("auth.clientssl.vpn.auth_digest_match").value());
  EXPECT_EQ(1U, stats_store_.counter("auth.clientssl.vpn.auth_digest_no_match").value());

  // Interval timer fires.
  setupRequest();
  interval_timer_->invokeCallback();

  // Error response.
  EXPECT_CALL(*interval_timer_, enableTimer(_, _));
  message = std::make_unique<Http::ResponseMessageImpl>(
      Http::ResponseHeaderMapPtr{new Http::TestResponseHeaderMapImpl{{":status", "503"}}});
  callbacks_->onSuccess(request_, std::move(message));

  // Interval timer fires.
  setupRequest();
  interval_timer_->invokeCallback();

  // Parsing error
  EXPECT_CALL(*interval_timer_, enableTimer(_, _));
  message = std::make_unique<Http::ResponseMessageImpl>(
      Http::ResponseHeaderMapPtr{new Http::TestResponseHeaderMapImpl{{":status", "200"}}});
  message->body().add("bad_json");
  callbacks_->onSuccess(request_, std::move(message));

  // Interval timer fires.
  setupRequest();
  interval_timer_->invokeCallback();

  // No response failure.
  EXPECT_CALL(*interval_timer_, enableTimer(_, _));
  callbacks_->onFailure(request_, Http::AsyncClient::FailureReason::Reset);

  // Interval timer fires, cannot obtain async client.
  EXPECT_CALL(cm_.thread_local_cluster_, httpAsyncClient())
      .WillOnce(ReturnRef(cm_.thread_local_cluster_.async_client_));
  EXPECT_CALL(cm_.thread_local_cluster_.async_client_, send_(_, _, _))
      .WillOnce(
          Invoke([&](Http::RequestMessagePtr&, Http::AsyncClient::Callbacks& callbacks,
                     const Http::AsyncClient::RequestOptions&) -> Http::AsyncClient::Request* {
            callbacks.onSuccess(
                request_,
                Http::ResponseMessagePtr{new Http::ResponseMessageImpl(Http::ResponseHeaderMapPtr{
                    new Http::TestResponseHeaderMapImpl{{":status", "503"}}})});
            // Intentionally return nullptr (instead of request handle) to trigger a particular
            // code path.
            return nullptr;
          }));
  EXPECT_CALL(*interval_timer_, enableTimer(_, _));
  interval_timer_->invokeCallback();

  EXPECT_EQ(4U, stats_store_.counter("auth.clientssl.vpn.update_failure").value());
}

} // namespace ClientSslAuth
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
load(
    "//bazel:envoy_build_system.bzl",
    "envoy_cc_test",
    "envoy_contrib_package",
)

licenses(["notice"])  # Apache 2

envoy_contrib_package()

envoy_cc_test(
    name = "client_ssl_auth_test",
    srcs = ["client_ssl_auth_test.cc"],
    data = glob(["test_data/**"]),
    deps = [
        "//contrib/client_ssl_auth/filters/network/source:client_ssl_auth",
        "//test/mocks/network:network_mocks",
        "//test/mocks/runtime:runtime_mocks",
        "//test/mocks/ssl:ssl_mocks",
        "//test/mocks/thread_local:thread_local_mocks",
        "//test/mocks/upstream:cluster_manager_mocks",
        "//test/test_common:environment_lib",
        "//test/test_common:utility_lib",
        "@envoy_api//contrib/envoy/extensions/filters/network/client_ssl_auth/v3:pkg_cc_proto",
    ],
)

envoy_cc_test(
    name = "config_test",
    srcs = ["config_test.cc"],
    deps = [
        "//contrib/client_ssl_auth/filters/network/source:config",
        "//source/common/protobuf:utility_lib",
        "//test/mocks/server:factory_context_mocks",
        "@envoy_api//contrib/envoy/extensions/filters/network/client_ssl_auth/v3:pkg_cc_proto",
    ],
)
#pragma once

#include <cstdint>
#include <memory>
#include <string>

#include "envoy/common/random_generator.h"
#include "envoy/config/subscription.h"
#include "envoy/network/filter.h"
#include "envoy/stats/scope.h"
#include "envoy/stats/stats_macros.h"
#include "envoy/thread_local/thread_local.h"
#include "envoy/upstream/cluster_manager.h"

#include "source/common/network/cidr_range.h"
#include "source/common/network/utility.h"
#include "source/common/protobuf/utility.h"
#include "source/extensions/config_subscription/rest/rest_api_fetcher.h"

#include "absl/container/node_hash_set.h"
#include "contrib/envoy/extensions/filters/network/client_ssl_auth/v3/client_ssl_auth.pb.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace ClientSslAuth {

/**
 * All client SSL auth stats. @see stats_macros.h
 */
#define ALL_CLIENT_SSL_AUTH_STATS(COUNTER, GAUGE)                                                  \
  COUNTER(auth_digest_match)                                                                       \
  COUNTER(auth_digest_no_match)                                                                    \
  COUNTER(auth_ip_allowlist)                                                                       \
  COUNTER(auth_no_ssl)                                                                             \
  COUNTER(update_failure)                                                                          \
  COUNTER(update_success)                                                                          \
  GAUGE(total_principals, NeverImport)

/**
 * Struct definition for all client SSL auth stats. @see stats_macros.h
 */
struct GlobalStats {
  ALL_CLIENT_SSL_AUTH_STATS(GENERATE_COUNTER_STRUCT, GENERATE_GAUGE_STRUCT)
};

/**
 * Wraps the principals currently allowed to authenticate.
 */
class AllowedPrincipals : public ThreadLocal::ThreadLocalObject {
public:
  void add(const std::string& sha256_digest) {
    if (!sha256_digest.empty()) {
      allowed_sha256_digests_.emplace(sha256_digest);
    }
  }
  bool allowed(const std::string& sha256_digest) const {
    return allowed_sha256_digests_.count(sha256_digest) != 0;
  }
  size_t size() const { return allowed_sha256_digests_.size(); }

private:
  absl::node_hash_set<std::string> allowed_sha256_digests_;
};

using AllowedPrincipalsSharedPtr = std::shared_ptr<AllowedPrincipals>;

class ClientSslAuthConfig;
using ClientSslAuthConfigSharedPtr = std::shared_ptr<ClientSslAuthConfig>;

/**
 * Global configuration for client SSL authentication. The config contacts a JSON API to fetch the
 * list of allowed principals, caches it, then makes auth decisions on it and any associated IP
 * allowlist.
 */
class ClientSslAuthConfig : public Http::RestApiFetcher {
public:
  static ClientSslAuthConfigSharedPtr
  create(const envoy::extensions::filters::network::client_ssl_auth::v3::ClientSSLAuth& config,
         ThreadLocal::SlotAllocator& tls, Upstream::ClusterManager& cm,
         Event::Dispatcher& dispatcher, Stats::Scope& scope, Random::RandomGenerator& random);

  const AllowedPrincipals& allowedPrincipals();
  const Network::Address::IpList& ipAllowlist() { return *ip_allowlist_; }
  GlobalStats& stats() { return stats_; }

private:
  ClientSslAuthConfig(
      const envoy::extensions::filters::network::client_ssl_auth::v3::ClientSSLAuth& config,
      ThreadLocal::SlotAllocator& tls, Upstream::ClusterManager& cm, Event::Dispatcher& dispatcher,
      Stats::Scope& scope, Random::RandomGenerator& random);

  static GlobalStats generateStats(Stats::Scope& scope, const std::string& prefix);

  // Http::RestApiFetcher
  void createRequest(Http::RequestMessage& request) override;
  void parseResponse(const Http::ResponseMessage& response) override;
  void onFetchComplete() override {}
  void onFetchFailure(Config::ConfigUpdateFailureReason reason, const EnvoyException* e) override;

  ThreadLocal::SlotPtr tls_;
  std::unique_ptr<Network::Address::IpList> ip_allowlist_;
  GlobalStats stats_;
};

/**
 * A client SSL auth filter instance. One per connection.
 */
class ClientSslAuthFilter : public Network::ReadFilter, public Network::ConnectionCallbacks {
public:
  ClientSslAuthFilter(ClientSslAuthConfigSharedPtr config) : config_(config) {}

  // Network::ReadFilter
  Network::FilterStatus onData(Buffer::Instance& data, bool end_stream) override;
  Network::FilterStatus onNewConnection() override;
  void initializeReadFilterCallbacks(Network::ReadFilterCallbacks& callbacks) override {
    read_callbacks_ = &callbacks;
    read_callbacks_->connection().addConnectionCallbacks(*this);
  }

  // Network::ConnectionCallbacks
  void onEvent(Network::ConnectionEvent event) override;
  void onAboveWriteBufferHighWatermark() override {}
  void onBelowWriteBufferLowWatermark() override {}

private:
  ClientSslAuthConfigSharedPtr config_;
  Network::ReadFilterCallbacks* read_callbacks_{};
};

} // namespace ClientSslAuth
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include "source/extensions/filters/network/common/factory_base.h"
#include "source/extensions/filters/network/well_known_names.h"

#include "contrib/envoy/extensions/filters/network/client_ssl_auth/v3/client_ssl_auth.pb.h"
#include "contrib/envoy/extensions/filters/network/client_ssl_auth/v3/client_ssl_auth.pb.validate.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace ClientSslAuth {

/**
 * Config registration for the client SSL auth filter. @see NamedNetworkFilterConfigFactory.
 */
class ClientSslAuthConfigFactory
    : public Common::FactoryBase<
          envoy::extensions::filters::network::client_ssl_auth::v3::ClientSSLAuth> {
public:
  ClientSslAuthConfigFactory() : FactoryBase(NetworkFilterNames::get().ClientSslAuth) {}

private:
  Network::FilterFactoryCb createFilterFactoryFromProtoTyped(
      const envoy::extensions::filters::network::client_ssl_auth::v3::ClientSSLAuth& proto_config,
      Server::Configuration::FactoryContext& context) override;
};

} // namespace ClientSslAuth
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/client_ssl_auth/filters/network/source/client_ssl_auth.h"

#include <chrono>
#include <cstdint>
#include <string>

#include "envoy/network/connection.h"
#include "envoy/stats/scope.h"

#include "source/common/common/assert.h"
#include "source/common/common/enum_to_int.h"
#include "source/common/common/fmt.h"
#include "source/common/http/headers.h"
#include "source/common/http/message_impl.h"
#include "source/common/http/utility.h"
#include "source/common/json/json_loader.h"
#include "source/common/network/utility.h"

#include "contrib/envoy/extensions/filters/network/client_ssl_auth/v3/client_ssl_auth.pb.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace ClientSslAuth {

constexpr absl::string_view AuthDigestNoMatch = "auth_digest_no_match";

ClientSslAuthConfig::ClientSslAuthConfig(
    const envoy::extensions::filters::network::client_ssl_auth::v3::ClientSSLAuth& config,
    ThreadLocal::SlotAllocator& tls, Upstream::ClusterManager& cm, Event::Dispatcher& dispatcher,
    Stats::Scope& scope, Random::RandomGenerator& random)
    : RestApiFetcher(
          cm, config.auth_api_cluster(), dispatcher, random,
          std::chrono::milliseconds(PROTOBUF_GET_MS_OR_DEFAULT(config, refresh_delay, 60000)),
          std::chrono::milliseconds(1000)),
      tls_(tls.allocateSlot()), stats_(generateStats(scope, config.stat_prefix())) {
  auto list_or_error = Network::Address::IpList::create(config.ip_white_list());
  THROW_IF_STATUS_NOT_OK(list_or_error, throw);
  ip_allowlist_ = std::move(list_or_error.value());

  if (!cm.clusters().hasCluster(remote_cluster_name_)) {
    throw EnvoyException(
        fmt::format("unknown cluster '{}' in client ssl auth config", remote_cluster_name_));
  }

  AllowedPrincipalsSharedPtr empty(new AllowedPrincipals());
  tls_->set(
      [empty](Event::Dispatcher&) -> ThreadLocal::ThreadLocalObjectSharedPtr { return empty; });
}

ClientSslAuthConfigSharedPtr ClientSslAuthConfig::create(
    const envoy::extensions::filters::network::client_ssl_auth::v3::ClientSSLAuth& config,
    ThreadLocal::SlotAllocator& tls, Upstream::ClusterManager& cm, Event::Dispatcher& dispatcher,
    Stats::Scope& scope, Random::RandomGenerator& random) {
  ClientSslAuthConfigSharedPtr new_config(
      new ClientSslAuthConfig(config, tls, cm, dispatcher, scope, random));
  new_config->initialize();
  return new_config;
}

const AllowedPrincipals& ClientSslAuthConfig::allowedPrincipals() {
  return tls_->getTyped<AllowedPrincipals>();
}

GlobalStats ClientSslAuthConfig::generateStats(Stats::Scope& scope, const std::string& prefix) {
  std::string final_prefix = fmt::format("auth.clientssl.{}.", prefix);
  GlobalStats stats{ALL_CLIENT_SSL_AUTH_STATS(POOL_COUNTER_PREFIX(scope, final_prefix),
                                              POOL_GAUGE_PREFIX(scope, final_prefix))};
  return stats;
}

void ClientSslAuthConfig::parseResponse(const Http::ResponseMessage& message) {
  AllowedPrincipalsSharedPtr new_principals(new AllowedPrincipals());
  Json::ObjectSharedPtr loader = Json::Factory::loadFromString(message.bodyAsString());
  for (const Json::ObjectSharedPtr& certificate : loader->getObjectArray("certificates")) {
    new_principals->add(certificate->getString("fingerprint_sha256"));
  }

  tls_->set([new_principals](Event::Dispatcher&) -> ThreadLocal::ThreadLocalObjectSharedPtr {
    return new_principals;
  });

  stats_.update_success_.inc();
  stats_.total_principals_.set(new_principals->size());
}

void ClientSslAuthConfig::onFetchFailure(Config::ConfigUpdateFailureReason, const EnvoyException*) {
  stats_.update_failure_.inc();
}

static const std::string Path = "/v1/certs/list/approved";

void ClientSslAuthConfig::createRequest(Http::RequestMessage& request) {
  request.headers().setReferenceMethod(Http::Headers::get().MethodValues.Get);
  request.headers().setPath(Path);
}

Network::FilterStatus ClientSslAuthFilter::onData(Buffer::Instance&, bool) {
  return Network::FilterStatus::Continue;
}

Network::FilterStatus ClientSslAuthFilter::onNewConnection() {
  // If this is not an SSL connection, do no further checking. High layers should redirect, etc.
  // if SSL is required.
  if (!read_callbacks_->connection().ssl()) {
    config_->stats().auth_no_ssl_.inc();
    return Network::FilterStatus::Continue;
  } else {
    // Otherwise we need to wait for handshake to be complete before proceeding.
    return Network::FilterStatus::StopIteration;
  }
}

void ClientSslAuthFilter::onEvent(Network::ConnectionEvent event) {
  if (event != Network::ConnectionEvent::Connected) {
    return;
  }

  ASSERT(read_callbacks_->connection().ssl());
  if (config_->ipAllowlist().contains(
          *read_callbacks_->connection().connectionInfoProvider().remoteAddress())) {
    config_->stats().auth_ip_allowlist_.inc();
    read_callbacks_->continueReading();
    return;
  }

  if (!config_->allowedPrincipals().allowed(
          read_callbacks_->connection().ssl()->sha256PeerCertificateDigest())) {
    read_callbacks_->connection().streamInfo().setResponseFlag(
        StreamInfo::ResponseFlag::UpstreamProtocolError);
    read_callbacks_->connection().streamInfo().setResponseCodeDetails(AuthDigestNoMatch);
    config_->stats().auth_digest_no_match_.inc();
    read_callbacks_->connection().close(Network::ConnectionCloseType::NoFlush);
    return;
  }

  config_->stats().auth_digest_match_.inc();
  read_callbacks_->continueReading();
}

} // namespace ClientSslAuth
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
load(
    "//bazel:envoy_build_system.bzl",
    "envoy_cc_extension",
    "envoy_cc_library",
    "envoy_contrib_package",
)

licenses(["notice"])  # Apache 2

# Client SSL authorization L4 network filter
# Public docs: https://envoyproxy.io/docs/envoy/latest/configuration/listeners/network_filters/client_ssl_auth_filter

envoy_contrib_package()

envoy_cc_library(
    name = "client_ssl_auth",
    srcs = ["client_ssl_auth.cc"],
    hdrs = ["client_ssl_auth.h"],
    deps = [
        "//envoy/network:connection_interface",
        "//envoy/network:filter_interface",
        "//envoy/runtime:runtime_interface",
        "//envoy/stats:stats_macros",
        "//envoy/thread_local:thread_local_interface",
        "//envoy/upstream:cluster_manager_interface",
        "//source/common/common:assert_lib",
        "//source/common/common:enum_to_int",
        "//source/common/http:headers_lib",
        "//source/common/http:message_lib",
        "//source/common/http:utility_lib",
        "//source/common/json:json_loader_lib",
        "//source/common/network:cidr_range_lib",
        "//source/common/network:utility_lib",
        "//source/extensions/config_subscription/rest:rest_api_fetcher_lib",
        "@envoy_api//contrib/envoy/extensions/filters/network/client_ssl_auth/v3:pkg_cc_proto",
    ],
)

envoy_cc_extension(
    name = "config",
    srcs = ["config.cc"],
    hdrs = ["config.h"],
    deps = [
        ":client_ssl_auth",
        "//envoy/registry",
        "//source/extensions/filters/network:well_known_names",
        "//source/extensions/filters/network/common:factory_base_lib",
        "@envoy_api//contrib/envoy/extensions/filters/network/client_ssl_auth/v3:pkg_cc_proto",
    ],
)
#include "contrib/client_ssl_auth/filters/network/source/config.h"

#include "envoy/network/connection.h"
#include "envoy/registry/registry.h"

#include "contrib/client_ssl_auth/filters/network/source/client_ssl_auth.h"
#include "contrib/envoy/extensions/filters/network/client_ssl_auth/v3/client_ssl_auth.pb.h"
#include "contrib/envoy/extensions/filters/network/client_ssl_auth/v3/client_ssl_auth.pb.validate.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace ClientSslAuth {

Network::FilterFactoryCb ClientSslAuthConfigFactory::createFilterFactoryFromProtoTyped(
    const envoy::extensions::filters::network::client_ssl_auth::v3::ClientSSLAuth& proto_config,
    Server::Configuration::FactoryContext& context) {
  ASSERT(!proto_config.auth_api_cluster().empty());
  ASSERT(!proto_config.stat_prefix().empty());

  auto& server_context = context.serverFactoryContext();

  ClientSslAuthConfigSharedPtr filter_config(ClientSslAuthConfig::create(
      proto_config, server_context.threadLocal(), server_context.clusterManager(),
      server_context.mainThreadDispatcher(), context.scope(),
      server_context.api().randomGenerator()));
  return [filter_config](Network::FilterManager& filter_manager) -> void {
    filter_manager.addReadFilter(std::make_shared<ClientSslAuthFilter>(filter_config));
  };
}

/**
 * Static registration for the client SSL auth filter. @see RegisterFactory.
 */
LEGACY_REGISTER_FACTORY(ClientSslAuthConfigFactory,
                        Server::Configuration::NamedNetworkFilterConfigFactory,
                        "envoy.client_ssl_auth");

} // namespace ClientSslAuth
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "envoy/network/connection.h"

#include "test/common/stats/stat_test_utility.h"
#include "test/common/upstream/utility.h"
#include "test/mocks/network/connection.h"
#include "test/mocks/network/mocks.h"
#include "test/mocks/server/factory_context.h"
#include "test/mocks/server/instance.h"

#include "contrib/rocketmq_proxy/filters/network/source/config.h"
#include "contrib/rocketmq_proxy/filters/network/source/conn_manager.h"
#include "contrib/rocketmq_proxy/filters/network/source/constant.h"
#include "contrib/rocketmq_proxy/filters/network/test/utility.h"
#include "gmock/gmock.h"
#include "gtest/gtest.h"

using testing::_;
using testing::NiceMock;
using testing::Return;
using testing::ReturnRef;

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

using ConfigRocketmqProxy = envoy::extensions::filters::network::rocketmq_proxy::v3::RocketmqProxy;

class TestConfigImpl : public ConfigImpl {
public:
  TestConfigImpl(RocketmqProxyConfig config, Server::Configuration::MockFactoryContext& context,
                 RocketmqFilterStats& stats)
      : ConfigImpl(config, context), stats_(stats) {}

  RocketmqFilterStats& stats() override { return stats_; }

private:
  RocketmqFilterStats stats_;
};

class RocketmqConnectionManagerTest : public Event::TestUsingSimulatedTime, public testing::Test {
public:
  RocketmqConnectionManagerTest()
      : stats_(RocketmqFilterStats::generateStats("test.", *store_.rootScope())) {}

  ~RocketmqConnectionManagerTest() override {
    filter_callbacks_.connection_.dispatcher_.clearDeferredDeleteList();
  }

  void initializeFilter() { initializeFilter(""); }

  void initializeFilter(const std::string& yaml) {
    if (!yaml.empty()) {
      TestUtility::loadFromYaml(yaml, proto_config_);
      TestUtility::validate(proto_config_);
    }
    config_ = std::make_unique<TestConfigImpl>(proto_config_, factory_context_, stats_);
    conn_manager_ = std::make_unique<ConnectionManager>(
        *config_, factory_context_.server_factory_context_.mainThreadDispatcher().timeSource());
    conn_manager_->initializeReadFilterCallbacks(filter_callbacks_);
    conn_manager_->onNewConnection();
    current_ = factory_context_.server_factory_context_.mainThreadDispatcher()
                   .timeSource()
                   .monotonicTime();
  }

  void initializeCluster() {
    Upstream::HostVector hosts;
    hosts.emplace_back(host_);
    priority_set_.updateHosts(
        1,
        Upstream::HostSetImpl::partitionHosts(std::make_shared<Upstream::HostVector>(hosts),
                                              Upstream::HostsPerLocalityImpl::empty()),
        nullptr, hosts, {}, 100);
    factory_context_.server_factory_context_.cluster_manager_.initializeThreadLocalClusters(
        {"fake_cluster"});
    ON_CALL(factory_context_.server_factory_context_.cluster_manager_.thread_local_cluster_,
            prioritySet())
        .WillByDefault(ReturnRef(priority_set_));
  }

  NiceMock<Server::Configuration::MockFactoryContext> factory_context_;
  Stats::TestUtil::TestStore store_;
  RocketmqFilterStats stats_;
  ConfigRocketmqProxy proto_config_;

  std::unique_ptr<TestConfigImpl> config_;

  Buffer::OwnedImpl buffer_;
  NiceMock<Network::MockReadFilterCallbacks> filter_callbacks_;
  std::unique_ptr<ConnectionManager> conn_manager_;

  Encoder encoder_;
  Decoder decoder_;

  MonotonicTime current_;

  std::shared_ptr<Upstream::MockClusterInfo> cluster_info_{
      new NiceMock<Upstream::MockClusterInfo>()};
  Upstream::HostSharedPtr host_{
      Upstream::makeTestHost(cluster_info_, "tcp://127.0.0.1:80", simTime())};
  Upstream::PrioritySetImpl priority_set_;
};

TEST_F(RocketmqConnectionManagerTest, OnHeartbeat) {
  initializeFilter();

  BufferUtility::fillRequestBuffer(buffer_, RequestCode::HeartBeat);
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(1U, store_.counter("test.heartbeat").value());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnHeartbeatWithDecodeError) {
  initializeFilter();

  std::string json = R"EOF(
  {
    "language": "JAVA",
    "version": 2,
    "opaque": 1,
    "flag": 1,
    "serializeTypeCurrentRPC": "JSON"
  }
  )EOF";

  buffer_.writeBEInt<int32_t>(4 + 4 + json.size());
  buffer_.writeBEInt<int32_t>(json.size());
  buffer_.add(json);
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(1U, store_.counter("test.request_decoding_error").value());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnHeartbeatWithInvalidBodyJson) {
  initializeFilter();

  RemotingCommandPtr cmd = std::make_unique<RemotingCommand>();
  cmd->code(static_cast<int>(RequestCode::HeartBeat));
  std::string heartbeat_data = R"EOF({"clientID": "127})EOF";
  cmd->body().add(heartbeat_data);
  encoder_.encode(cmd, buffer_);

  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(0U, store_.counter("test.request_decoding_error").value());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnHeartbeatWithBodyJsonLackofClientId) {
  initializeFilter();

  RemotingCommandPtr cmd = std::make_unique<RemotingCommand>();
  cmd->code(static_cast<int>(RequestCode::HeartBeat));
  std::string heartbeat_data = R"EOF(
  {
    "consumerDataSet": [{}]
  }
  )EOF";
  cmd->body().add(heartbeat_data);
  encoder_.encode(cmd, buffer_);

  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(0U, store_.counter("test.request_decoding_error").value());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnHeartbeatWithGroupMembersMapExists) {
  initializeFilter();

  auto& group_members_map = conn_manager_->groupMembersForTest();
  std::vector<ConsumerGroupMember> group_members;
  ConsumerGroupMember group_member("127.0.0.1@90330", *conn_manager_);
  group_member.setLastForTest(current_);
  group_members.emplace_back(group_member);
  group_members_map["test_cg"] = group_members;

  BufferUtility::fillRequestBuffer(buffer_, RequestCode::HeartBeat);
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(1U, store_.counter("test.heartbeat").value());
  EXPECT_FALSE(group_member.expired());
  EXPECT_FALSE(group_members_map.at("test_cg").empty());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnHeartbeatWithGroupMembersMapExistsButExpired) {
  initializeFilter();

  auto& group_members_map = conn_manager_->groupMembersForTest();
  std::vector<ConsumerGroupMember> group_members;
  ConsumerGroupMember group_member("127.0.0.2@90330", *conn_manager_);
  group_member.setLastForTest(current_ - std::chrono::seconds(31));
  group_members.emplace_back(group_member);
  group_members_map["test_cg"] = group_members;

  BufferUtility::fillRequestBuffer(buffer_, RequestCode::HeartBeat);
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(1U, store_.counter("test.heartbeat").value());
  EXPECT_TRUE(group_member.expired());
  EXPECT_TRUE(group_members_map.empty());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnHeartbeatWithGroupMembersMapExistsButLackOfClientID) {
  initializeFilter();

  auto& group_members_map = conn_manager_->groupMembersForTest();
  std::vector<ConsumerGroupMember> group_members;
  ConsumerGroupMember group_member("127.0.0.2@90330", *conn_manager_);
  group_member.setLastForTest(current_);
  group_members.emplace_back(group_member);
  group_members_map["test_cg"] = group_members;

  BufferUtility::fillRequestBuffer(buffer_, RequestCode::HeartBeat);
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(1U, store_.counter("test.heartbeat").value());
  EXPECT_FALSE(group_member.expired());
  EXPECT_FALSE(group_members_map.at("test_cg").empty());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnHeartbeatWithDownstreamConnecitonClosed) {
  initializeFilter();

  BufferUtility::fillRequestBuffer(buffer_, RequestCode::HeartBeat);
  NiceMock<Network::MockConnection> connection;
  EXPECT_CALL(connection, state()).WillOnce(Invoke([&]() -> Network::Connection::State {
    return Network::Connection::State::Closed;
  }));
  EXPECT_CALL(filter_callbacks_, connection()).WillRepeatedly(Invoke([&]() -> Network::Connection& {
    return connection;
  }));
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(1U, store_.counter("test.heartbeat").value());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnHeartbeatWithPurgeDirectiveTable) {
  initializeFilter();

  std::string broker_name = "broker_name";
  int32_t broker_id = 0;
  std::chrono::milliseconds delay_0(31 * 1000);
  AckMessageDirective directive_0(broker_name, broker_id,
                                  conn_manager_->timeSource().monotonicTime() - delay_0);
  std::string directive_key_0 = "key_0";
  conn_manager_->insertAckDirective(directive_key_0, directive_0);

  std::chrono::milliseconds delay_1(29 * 1000);
  AckMessageDirective directive_1(broker_name, broker_id,
                                  conn_manager_->timeSource().monotonicTime() - delay_1);
  std::string directive_key_1 = "key_1";
  conn_manager_->insertAckDirective(directive_key_1, directive_1);

  EXPECT_EQ(2, conn_manager_->getAckDirectiveTableForTest().size());

  BufferUtility::fillRequestBuffer(buffer_, RequestCode::HeartBeat);
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(1U, store_.counter("test.heartbeat").value());

  EXPECT_EQ(1, conn_manager_->getAckDirectiveTableForTest().size());
  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnUnregisterClient) {
  initializeFilter();

  auto& group_members_map = conn_manager_->groupMembersForTest();
  BufferUtility::fillRequestBuffer(buffer_, RequestCode::UnregisterClient);
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(1U, store_.counter("test.unregister").value());
  EXPECT_TRUE(group_members_map.empty());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnUnregisterClientWithGroupMembersMapExists) {
  initializeFilter();

  auto& group_members_map = conn_manager_->groupMembersForTest();
  std::vector<ConsumerGroupMember> group_members;
  ConsumerGroupMember group_member("test_client_id", *conn_manager_);
  group_member.setLastForTest(current_);
  group_members.emplace_back(group_member);
  group_members_map["test_cg"] = group_members;

  BufferUtility::fillRequestBuffer(buffer_, RequestCode::UnregisterClient);
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(1U, store_.counter("test.unregister").value());
  EXPECT_FALSE(group_member.expired());
  EXPECT_TRUE(group_members_map.empty());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnUnregisterClientWithGroupMembersMapExistsButExpired) {
  initializeFilter();

  auto& group_members_map = conn_manager_->groupMembersForTest();
  std::vector<ConsumerGroupMember> group_members;
  ConsumerGroupMember group_member("127.0.0.2@90330", *conn_manager_);
  group_member.setLastForTest(current_ - std::chrono::seconds(31));
  group_members.emplace_back(group_member);
  group_members_map["test_cg"] = group_members;

  BufferUtility::fillRequestBuffer(buffer_, RequestCode::UnregisterClient);
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(1U, store_.counter("test.unregister").value());
  EXPECT_TRUE(group_member.expired());
  EXPECT_TRUE(group_members_map.empty());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest,
       OnUnregisterClientWithGroupMembersMapExistsButLackOfClientID) {
  initializeFilter();

  auto& group_members_map = conn_manager_->groupMembersForTest();
  std::vector<ConsumerGroupMember> group_members;
  ConsumerGroupMember group_member("127.0.0.2@90330", *conn_manager_);
  group_member.setLastForTest(current_);
  group_members.emplace_back(group_member);
  group_members_map["test_cg"] = group_members;

  BufferUtility::fillRequestBuffer(buffer_, RequestCode::UnregisterClient);
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(1U, store_.counter("test.unregister").value());
  EXPECT_FALSE(group_member.expired());
  EXPECT_FALSE(group_members_map.empty());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnGetTopicRoute) {
  const std::string yaml = R"EOF(
stat_prefix: test
route_config:
  name: default_route
  routes:
    - match:
        topic:
          exact: test_topic
      route:
        cluster: fake_cluster
)EOF";
  initializeFilter(yaml);

  auto metadata = std::make_shared<envoy::config::core::v3::Metadata>();
  ProtobufWkt::Struct topic_route_data;
  auto* fields = topic_route_data.mutable_fields();
  (*fields)[RocketmqConstants::get().ReadQueueNum] = ValueUtil::numberValue(4);
  (*fields)[RocketmqConstants::get().WriteQueueNum] = ValueUtil::numberValue(4);
  (*fields)[RocketmqConstants::get().ClusterName] = ValueUtil::stringValue("DefaultCluster");
  (*fields)[RocketmqConstants::get().BrokerName] = ValueUtil::stringValue("broker-a");
  (*fields)[RocketmqConstants::get().BrokerId] = ValueUtil::numberValue(0);
  (*fields)[RocketmqConstants::get().Perm] = ValueUtil::numberValue(6);
  metadata->mutable_filter_metadata()->insert(Protobuf::MapPair<std::string, ProtobufWkt::Struct>(
      NetworkFilterNames::get().RocketmqProxy, topic_route_data));
  host_->metadata(metadata);
  initializeCluster();

  BufferUtility::fillRequestBuffer(buffer_, RequestCode::GetRouteInfoByTopic);
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(1U, store_.counter("test.get_topic_route").value());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnGetTopicRouteWithoutRoutes) {
  const std::string yaml = R"EOF(
stat_prefix: test
route_config:
  name: default_route
  routes:
    - match:
        topic:
          exact: test_another_topic
      route:
        cluster: fake_cluster
)EOF";
  initializeFilter(yaml);
  initializeCluster();

  BufferUtility::fillRequestBuffer(buffer_, RequestCode::GetRouteInfoByTopic);
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(1U, store_.counter("test.get_topic_route").value());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnGetTopicRouteWithoutCluster) {
  const std::string yaml = R"EOF(
stat_prefix: test
route_config:
  name: default_route
  routes:
    - match:
        topic:
          exact: test_topic
      route:
        cluster: fake_cluster
)EOF";
  initializeFilter(yaml);

  EXPECT_CALL(factory_context_.server_factory_context_.cluster_manager_, getThreadLocalCluster(_))
      .WillRepeatedly(Return(nullptr));

  BufferUtility::fillRequestBuffer(buffer_, RequestCode::GetRouteInfoByTopic);
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(1U, store_.counter("test.get_topic_route").value());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnGetTopicRouteInDevelopMode) {
  const std::string yaml = R"EOF(
stat_prefix: test
develop_mode: true
route_config:
  name: default_route
  routes:
    - match:
        topic:
          exact: test_topic
      route:
        cluster: fake_cluster
)EOF";
  NiceMock<Server::Configuration::MockServerFactoryContext> server_factory_context;
  NiceMock<LocalInfo::MockLocalInfo> local_info;
  NiceMock<Network::MockIp> ip;
  std::shared_ptr<const Network::MockResolvedAddress> instance =
      std::make_shared<Network::MockResolvedAddress>("logical", "physical");
  EXPECT_CALL(factory_context_, serverFactoryContext())
      .WillRepeatedly(ReturnRef(server_factory_context));
  EXPECT_CALL(server_factory_context, localInfo()).WillRepeatedly(ReturnRef(local_info));
  EXPECT_CALL(local_info, address()).WillRepeatedly(Return(instance));
  EXPECT_CALL(*instance, type()).WillRepeatedly(Return(Network::Address::Type::Ip));
  EXPECT_CALL(*instance, ip()).WillRepeatedly(testing::Return(&ip));
  const std::string address{"1.2.3.4"};
  EXPECT_CALL(ip, addressAsString()).WillRepeatedly(ReturnRef(address));
  EXPECT_CALL(ip, port()).WillRepeatedly(Return(1234));
  initializeFilter(yaml);

  auto metadata = std::make_shared<envoy::config::core::v3::Metadata>();
  ProtobufWkt::Struct topic_route_data;
  auto* fields = topic_route_data.mutable_fields();
  (*fields)[RocketmqConstants::get().ReadQueueNum] = ValueUtil::numberValue(4);
  (*fields)[RocketmqConstants::get().WriteQueueNum] = ValueUtil::numberValue(4);
  (*fields)[RocketmqConstants::get().ClusterName] = ValueUtil::stringValue("DefaultCluster");
  (*fields)[RocketmqConstants::get().BrokerName] = ValueUtil::stringValue("broker-a");
  (*fields)[RocketmqConstants::get().BrokerId] = ValueUtil::numberValue(0);
  (*fields)[RocketmqConstants::get().Perm] = ValueUtil::numberValue(6);
  metadata->mutable_filter_metadata()->insert(Protobuf::MapPair<std::string, ProtobufWkt::Struct>(
      NetworkFilterNames::get().RocketmqProxy, topic_route_data));
  host_->metadata(metadata);
  initializeCluster();

  BufferUtility::fillRequestBuffer(buffer_, RequestCode::GetRouteInfoByTopic);
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(1U, store_.counter("test.get_topic_route").value());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnGetConsumerListByGroup) {
  initializeFilter();

  BufferUtility::fillRequestBuffer(buffer_, RequestCode::GetConsumerListByGroup);
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(1U, store_.counter("test.get_consumer_list").value());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnGetConsumerListByGroupWithGroupMemberMapExists) {
  initializeFilter();

  auto& group_members_map = conn_manager_->groupMembersForTest();
  std::vector<ConsumerGroupMember> group_members;
  ConsumerGroupMember group_member("127.0.0.2@90330", *conn_manager_);
  group_member.setLastForTest(current_ - std::chrono::seconds(31));
  group_members.emplace_back(group_member);
  group_members_map["test_cg"] = group_members;

  BufferUtility::fillRequestBuffer(buffer_, RequestCode::GetConsumerListByGroup);
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(1U, store_.counter("test.get_consumer_list").value());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnPopMessage) {
  const std::string yaml = R"EOF(
stat_prefix: test
route_config:
  name: default_route
  routes:
    - match:
        topic:
          exact: test_topic
      route:
        cluster: fake_cluster
)EOF";
  initializeFilter(yaml);
  initializeCluster();

  BufferUtility::fillRequestBuffer(buffer_, RequestCode::PopMessage);
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(1U, store_.counter("test.pop_message").value());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnAckMessage) {
  const std::string yaml = R"EOF(
stat_prefix: test
route_config:
  name: default_route
  routes:
    - match:
        topic:
          exact: test_topic
      route:
        cluster: fake_cluster
)EOF";
  initializeFilter(yaml);
  initializeCluster();

  BufferUtility::fillRequestBuffer(buffer_, RequestCode::AckMessage);
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(1U, store_.counter("test.ack_message").value());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnData) {
  initializeFilter();

  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(0, buffer_.length());
  EXPECT_EQ(0U, store_.counter("test.request").value());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnDataWithEndStream) {
  initializeFilter();

  Buffer::OwnedImpl buffer;
  BufferUtility::fillRequestBuffer(buffer, RequestCode::SendMessageV2);
  bool underflow, has_error;
  RemotingCommandPtr request = Decoder::decode(buffer, underflow, has_error);
  conn_manager_->createActiveMessage(request);
  EXPECT_EQ(1, conn_manager_->activeMessageList().size());
  conn_manager_->onData(buffer_, true);
  EXPECT_TRUE(conn_manager_->activeMessageList().empty());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnDataWithMinFrameSize) {
  initializeFilter();

  buffer_.add(std::string({'\x00', '\x00', '\x01', '\x8b'}));
  buffer_.add(std::string({'\x00', '\x00', '\x01', '\x76'}));
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(0U, store_.counter("test.request").value());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnDataSendMessage) {
  const std::string yaml = R"EOF(
stat_prefix: test
route_config:
  name: default_route
  routes:
    - match:
        topic:
          exact: test_topic
      route:
        cluster: fake_cluster
)EOF";
  initializeFilter(yaml);
  initializeCluster();

  BufferUtility::fillRequestBuffer(buffer_, RequestCode::SendMessage);
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(1U, store_.counter("test.send_message_v1").value());
  EXPECT_EQ(
      1U,
      store_.gauge("test.send_message_v1_active", Stats::Gauge::ImportMode::Accumulate).value());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnDataSendMessageV2) {
  const std::string yaml = R"EOF(
stat_prefix: test
route_config:
  name: default_route
  routes:
    - match:
        topic:
          exact: test_topic
      route:
        cluster: fake_cluster
)EOF";
  initializeFilter(yaml);
  initializeCluster();

  BufferUtility::fillRequestBuffer(buffer_, RequestCode::SendMessageV2);
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());
  EXPECT_EQ(1U, store_.counter("test.send_message_v2").value());
  EXPECT_EQ(
      1U,
      store_.gauge("test.send_message_v2_active", Stats::Gauge::ImportMode::Accumulate).value());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnDataWithUnsupportedCode) {
  initializeFilter();

  BufferUtility::fillRequestBuffer(buffer_, RequestCode::Unsupported);
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, OnDataInvalidFrameLength) {
  // Test against the invalid input where frame_length <= header_length.
  const std::string yaml = R"EOF(
  stat_prefix: test
  )EOF";
  initializeFilter(yaml);
  buffer_.add(
      std::string({'\x00', '\x00', '\x00', '\x00', '\x00', '\x00', '\x00', '\x00', '\x00'}));
  EXPECT_EQ(conn_manager_->onData(buffer_, false), Network::FilterStatus::StopIteration);
  EXPECT_EQ(1U, store_.counter("test.request").value());

  buffer_.drain(buffer_.length());
}

TEST_F(RocketmqConnectionManagerTest, ConsumerGroupMemberEqual) {
  initializeFilter();

  ConsumerGroupMember m1("abc", *conn_manager_);
  ConsumerGroupMember m2("abc", *conn_manager_);
  EXPECT_TRUE(m1 == m2);
}

TEST_F(RocketmqConnectionManagerTest, ConsumerGroupMemberLessThan) {
  initializeFilter();

  ConsumerGroupMember m1("abc", *conn_manager_);
  ConsumerGroupMember m2("def", *conn_manager_);
  EXPECT_TRUE(m1 < m2);
}

TEST_F(RocketmqConnectionManagerTest, ConsumerGroupMemberExpired) {
  initializeFilter();

  ConsumerGroupMember member("Mock", *conn_manager_);
  EXPECT_FALSE(member.expired());
  EXPECT_STREQ("Mock", member.clientId().data());
}

TEST_F(RocketmqConnectionManagerTest, ConsumerGroupMemberRefresh) {
  initializeFilter();

  ConsumerGroupMember member("Mock", *conn_manager_);
  EXPECT_FALSE(member.expired());
  member.setLastForTest(current_ - std::chrono::seconds(31));
  EXPECT_TRUE(member.expired());
  member.refresh();
  EXPECT_FALSE(member.expired());
}

} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/rocketmq_proxy/filters/network/test/mocks.h"

#include "contrib/rocketmq_proxy/filters/network/source/router/router_impl.h"
#include "gtest/gtest.h"

using testing::_;
using testing::ByMove;
using testing::Return;
using testing::ReturnRef;

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

MockActiveMessage::MockActiveMessage(ConnectionManager& conn_manager, RemotingCommandPtr&& request)
    : ActiveMessage(conn_manager, std::move(request)) {
  route_ = std::make_shared<NiceMock<Router::MockRoute>>();

  ON_CALL(*this, onError(_)).WillByDefault(Invoke([&](absl::string_view error_message) {
    ActiveMessage::onError(error_message);
  }));
  ON_CALL(*this, onReset()).WillByDefault(Return());
  ON_CALL(*this, sendResponseToDownstream()).WillByDefault(Invoke([&]() {
    ActiveMessage::sendResponseToDownstream();
  }));
  ON_CALL(*this, metadata()).WillByDefault(Invoke([&]() { return ActiveMessage::metadata(); }));
  ON_CALL(*this, route()).WillByDefault(Return(route_));
}
MockActiveMessage::~MockActiveMessage() = default;

MockConfig::MockConfig()
    : stats_(RocketmqFilterStats::generateStats("test.", *store_.rootScope())) {
  ON_CALL(*this, stats()).WillByDefault(ReturnRef(stats_));
  ON_CALL(*this, clusterManager()).WillByDefault(ReturnRef(cluster_manager_));
  ON_CALL(*this, createRouter())
      .WillByDefault(Return(ByMove(std::make_unique<Router::RouterImpl>(cluster_manager_))));
  ON_CALL(*this, developMode()).WillByDefault(Return(false));
  ON_CALL(*this, proxyAddress()).WillByDefault(Return(std::string{"1.2.3.4:1234"}));
}

namespace Router {

MockRouteEntry::MockRouteEntry() {
  ON_CALL(*this, clusterName()).WillByDefault(ReturnRef(cluster_name_));
}

MockRouteEntry::~MockRouteEntry() = default;

MockRoute::MockRoute() { ON_CALL(*this, routeEntry()).WillByDefault(Return(&route_entry_)); }
MockRoute::~MockRoute() = default;

} // namespace Router
} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "test/test_common/utility.h"

#include "contrib/envoy/extensions/filters/network/rocketmq_proxy/v3/rocketmq_proxy.pb.h"
#include "contrib/envoy/extensions/filters/network/rocketmq_proxy/v3/rocketmq_proxy.pb.validate.h"
#include "contrib/envoy/extensions/filters/network/rocketmq_proxy/v3/route.pb.h"
#include "contrib/envoy/extensions/filters/network/rocketmq_proxy/v3/route.pb.validate.h"
#include "contrib/rocketmq_proxy/filters/network/source/metadata.h"
#include "contrib/rocketmq_proxy/filters/network/source/router/route_matcher.h"
#include "gmock/gmock.h"
#include "gtest/gtest.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {
namespace Router {

using RouteConfigurationProto =
    envoy::extensions::filters::network::rocketmq_proxy::v3::RouteConfiguration;

RouteConfigurationProto parseRouteConfigurationFromV2Yaml(const std::string& yaml) {
  RouteConfigurationProto route_config;
  TestUtility::loadFromYaml(yaml, route_config);
  TestUtility::validate(route_config);
  return route_config;
}

TEST(RocketmqRouteMatcherTest, RouteWithHeaders) {
  const std::string yaml = R"EOF(
name: default_route
routes:
  - match:
      topic:
        exact: test_topic
      headers:
        - name: code
          string_match:
            exact: '310'
    route:
      cluster: fake_cluster
      metadata_match:
        filter_metadata:
          envoy.lb:
            k1: v1
)EOF";

  RouteConfigurationProto config = parseRouteConfigurationFromV2Yaml(yaml);

  MessageMetadata metadata;
  std::string topic_name = "test_topic";
  metadata.setTopicName(topic_name);
  uint64_t code = 310;
  metadata.headers().addCopy(Http::LowerCaseString("code"), code);
  RouteMatcher matcher(config);
  const Envoy::Router::MetadataMatchCriteria* criteria =
      matcher.route(metadata)->routeEntry()->metadataMatchCriteria();
  const std::vector<Envoy::Router::MetadataMatchCriterionConstSharedPtr>& mmc =
      criteria->metadataMatchCriteria();

  ProtobufWkt::Value v1;
  v1.set_string_value("v1");
  HashedValue hv1(v1);

  EXPECT_EQ(1, mmc.size());
  EXPECT_EQ("k1", mmc[0]->name());
  EXPECT_EQ(hv1, mmc[0]->value());
}

} // namespace Router
} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "test/mocks/local_info/mocks.h"
#include "test/mocks/server/factory_context.h"
#include "test/mocks/server/instance.h"
#include "test/test_common/registry.h"

#include "contrib/envoy/extensions/filters/network/rocketmq_proxy/v3/rocketmq_proxy.pb.h"
#include "contrib/envoy/extensions/filters/network/rocketmq_proxy/v3/rocketmq_proxy.pb.validate.h"
#include "contrib/rocketmq_proxy/filters/network/source/config.h"
#include "gmock/gmock.h"
#include "gtest/gtest.h"

using testing::_;
using testing::Return;
using testing::ReturnRef;

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

using RocketmqProxyProto = envoy::extensions::filters::network::rocketmq_proxy::v3::RocketmqProxy;

RocketmqProxyProto parseRocketmqProxyFromV3Yaml(const std::string& yaml) {
  RocketmqProxyProto rocketmq_proxy;
  TestUtility::loadFromYaml(yaml, rocketmq_proxy);
  return rocketmq_proxy;
}

class RocketmqFilterConfigTestBase {
public:
  void testConfig(RocketmqProxyProto& config) {
    Network::FilterFactoryCb cb;
    EXPECT_NO_THROW({ cb = factory_.createFilterFactoryFromProto(config, context_); });
    Network::MockConnection connection;
    EXPECT_CALL(connection, addReadFilter(_));
    cb(connection);
  }

  NiceMock<Server::Configuration::MockFactoryContext> context_;
  RocketmqProxyFilterConfigFactory factory_;
};

class RocketmqFilterConfigTest : public RocketmqFilterConfigTestBase, public testing::Test {
public:
  ~RocketmqFilterConfigTest() override = default;
};

TEST_F(RocketmqFilterConfigTest, ValidateFail) {
  NiceMock<Server::Configuration::MockFactoryContext> context;
  EXPECT_THROW(
      RocketmqProxyFilterConfigFactory().createFilterFactoryFromProto(
          envoy::extensions::filters::network::rocketmq_proxy::v3::RocketmqProxy(), context),
      ProtoValidationException);
}

TEST_F(RocketmqFilterConfigTest, ValidProtoConfiguration) {
  envoy::extensions::filters::network::rocketmq_proxy::v3::RocketmqProxy config{};
  config.set_stat_prefix("my_stat_prefix");
  NiceMock<Server::Configuration::MockFactoryContext> context;
  RocketmqProxyFilterConfigFactory factory;
  Network::FilterFactoryCb cb = factory.createFilterFactoryFromProto(config, context);
  Network::MockConnection connection;
  EXPECT_CALL(connection, addReadFilter(_));
  cb(connection);
}

TEST_F(RocketmqFilterConfigTest, RocketmqProxyWithEmptyProto) {
  NiceMock<Server::Configuration::MockFactoryContext> context;
  RocketmqProxyFilterConfigFactory factory;
  envoy::extensions::filters::network::rocketmq_proxy::v3::RocketmqProxy config =
      *dynamic_cast<envoy::extensions::filters::network::rocketmq_proxy::v3::RocketmqProxy*>(
          factory.createEmptyConfigProto().get());
  config.set_stat_prefix("my_stat_prefix");
  Network::FilterFactoryCb cb = factory.createFilterFactoryFromProto(config, context);
  Network::MockConnection connection;
  EXPECT_CALL(connection, addReadFilter(_));
  cb(connection);
}

TEST_F(RocketmqFilterConfigTest, RocketmqProxyWithFullConfig) {
  const std::string yaml = R"EOF(
    stat_prefix: rocketmq_incomming_stats
    develop_mode: true
    transient_object_life_span:
      seconds: 30
    )EOF";
  RocketmqProxyProto config = parseRocketmqProxyFromV3Yaml(yaml);
  testConfig(config);
}

TEST_F(RocketmqFilterConfigTest, ProxyAddress) {
  NiceMock<Server::Configuration::MockFactoryContext> context;
  Server::Configuration::MockServerFactoryContext factory_context;
  EXPECT_CALL(context, serverFactoryContext()).WillRepeatedly(ReturnRef(factory_context));

  LocalInfo::MockLocalInfo local_info;
  EXPECT_CALL(factory_context, localInfo()).WillRepeatedly(ReturnRef(local_info));
  std::shared_ptr<const Network::MockResolvedAddress> instance =
      std::make_shared<Network::MockResolvedAddress>("logical", "physical");
  EXPECT_CALL(local_info, address()).WillRepeatedly(Return(instance));
  EXPECT_CALL(*instance, type()).WillRepeatedly(Return(Network::Address::Type::Ip));

  Network::MockIp* ip = new Network::MockIp();
  EXPECT_CALL(*instance, ip()).WillRepeatedly(testing::Return(ip));

  std::string address("1.2.3.4");
  EXPECT_CALL(*ip, addressAsString()).WillRepeatedly(ReturnRef(address));
  EXPECT_CALL(*ip, port()).WillRepeatedly(Return(1234));
  ConfigImpl::RocketmqProxyConfig proxyConfig;
  ConfigImpl configImpl(proxyConfig, context);

  EXPECT_STREQ("1.2.3.4:1234", configImpl.proxyAddress().c_str());
  delete ip;
}

TEST_F(RocketmqFilterConfigTest, ProxyAddressWithDefaultPort) {
  NiceMock<Server::Configuration::MockFactoryContext> context;
  Server::Configuration::MockServerFactoryContext factory_context;
  EXPECT_CALL(context, serverFactoryContext()).WillRepeatedly(ReturnRef(factory_context));

  LocalInfo::MockLocalInfo local_info;
  EXPECT_CALL(factory_context, localInfo()).WillRepeatedly(ReturnRef(local_info));
  std::shared_ptr<const Network::MockResolvedAddress> instance =
      std::make_shared<Network::MockResolvedAddress>("logical", "physical");
  EXPECT_CALL(local_info, address()).WillRepeatedly(Return(instance));
  EXPECT_CALL(*instance, type()).WillRepeatedly(Return(Network::Address::Type::Ip));

  Network::MockIp* ip = new Network::MockIp();
  EXPECT_CALL(*instance, ip()).WillRepeatedly(testing::Return(ip));

  std::string address("1.2.3.4");
  EXPECT_CALL(*ip, addressAsString()).WillRepeatedly(ReturnRef(address));
  EXPECT_CALL(*ip, port()).WillRepeatedly(Return(0));
  ConfigImpl::RocketmqProxyConfig proxyConfig;
  ConfigImpl configImpl(proxyConfig, context);

  EXPECT_STREQ("1.2.3.4:10000", configImpl.proxyAddress().c_str());
  delete ip;
}

TEST_F(RocketmqFilterConfigTest, ProxyAddressWithNonIpType) {
  NiceMock<Server::Configuration::MockFactoryContext> context;
  Server::Configuration::MockServerFactoryContext factory_context;
  EXPECT_CALL(context, serverFactoryContext()).WillRepeatedly(ReturnRef(factory_context));

  LocalInfo::MockLocalInfo local_info;
  EXPECT_CALL(factory_context, localInfo()).WillRepeatedly(ReturnRef(local_info));
  std::shared_ptr<const Network::MockResolvedAddress> instance =
      std::make_shared<Network::MockResolvedAddress>("logical", "physical");
  EXPECT_CALL(local_info, address()).WillRepeatedly(Return(instance));
  EXPECT_CALL(*instance, type()).WillRepeatedly(Return(Network::Address::Type::Pipe));

  Network::MockIp* ip = new Network::MockIp();
  EXPECT_CALL(*instance, ip()).WillRepeatedly(testing::Return(ip));

  std::string address("1.2.3.4");
  EXPECT_CALL(*ip, addressAsString()).WillRepeatedly(ReturnRef(address));
  EXPECT_CALL(*ip, port()).WillRepeatedly(Return(0));
  ConfigImpl::RocketmqProxyConfig proxyConfig;
  ConfigImpl configImpl(proxyConfig, context);

  EXPECT_STREQ("physical", configImpl.proxyAddress().c_str());
  delete ip;
}

} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "source/common/protobuf/utility.h"

#include "absl/container/node_hash_map.h"
#include "contrib/rocketmq_proxy/filters/network/source/topic_route.h"
#include "gtest/gtest.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

TEST(TopicRouteTest, Serialization) {
  QueueData queue_data("broker-a", 8, 8, 6);
  ProtobufWkt::Struct doc;
  queue_data.encode(doc);

  const auto& members = doc.fields();

  ASSERT_STREQ("broker-a", members.at("brokerName").string_value().c_str());
  ASSERT_EQ(queue_data.brokerName(), members.at("brokerName").string_value());
  ASSERT_EQ(queue_data.readQueueNum(), members.at("readQueueNums").number_value());
  ASSERT_EQ(queue_data.writeQueueNum(), members.at("writeQueueNums").number_value());
  ASSERT_EQ(queue_data.perm(), members.at("perm").number_value());
}

TEST(BrokerDataTest, Serialization) {
  absl::node_hash_map<int64_t, std::string> broker_addrs;
  std::string dummy_address("127.0.0.1:10911");
  for (int64_t i = 0; i < 3; i++) {
    broker_addrs[i] = dummy_address;
  }
  std::string cluster("DefaultCluster");
  std::string broker_name("broker-a");
  BrokerData broker_data(cluster, broker_name, std::move(broker_addrs));

  ProtobufWkt::Struct doc;
  broker_data.encode(doc);

  const auto& members = doc.fields();

  ASSERT_STREQ(cluster.c_str(), members.at("cluster").string_value().c_str());
  ASSERT_STREQ(broker_name.c_str(), members.at("brokerName").string_value().c_str());
}

TEST(TopicRouteDataTest, Serialization) {
  TopicRouteData topic_route_data;

  for (int i = 0; i < 16; i++) {
    topic_route_data.queueData().push_back(QueueData("broker-a", 8, 8, 6));
  }

  std::string cluster("DefaultCluster");
  std::string broker_name("broker-a");
  std::string dummy_address("127.0.0.1:10911");

  for (int i = 0; i < 16; i++) {
    absl::node_hash_map<int64_t, std::string> broker_addrs;
    for (int64_t i = 0; i < 3; i++) {
      broker_addrs[i] = dummy_address;
    }
    topic_route_data.brokerData().emplace_back(
        BrokerData(cluster, broker_name, std::move(broker_addrs)));
  }
  ProtobufWkt::Struct doc;
  EXPECT_NO_THROW(topic_route_data.encode(doc));
  MessageUtil::getJsonStringFromMessageOrError(doc);
}

} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/rocketmq_proxy/filters/network/test/utility.h"

#include "gtest/gtest.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

const std::string BufferUtility::topic_name_ = "test_topic";
const std::string BufferUtility::client_id_ = "test_client_id";
const std::string BufferUtility::producer_group_ = "test_pg";
const std::string BufferUtility::consumer_group_ = "test_cg";
const std::string BufferUtility::extra_info_ = "test_extra";
const std::string BufferUtility::msg_body_ = "_Apache_RocketMQ_";
const int BufferUtility::queue_id_ = 1;
int BufferUtility::opaque_ = 0;

void BufferUtility::fillRequestBuffer(Buffer::OwnedImpl& buffer, RequestCode code) {

  RemotingCommandPtr cmd = std::make_unique<RemotingCommand>();
  cmd->code(static_cast<int>(code));
  cmd->opaque(++opaque_);

  switch (code) {
  case RequestCode::SendMessage: {
    std::unique_ptr<SendMessageRequestHeader> header = std::make_unique<SendMessageRequestHeader>();
    header->topic(topic_name_);
    header->version(SendMessageRequestVersion::V1);
    std::string msg_body = msg_body_;
    cmd->body().add(msg_body);
    CommandCustomHeaderPtr ptr(header.release());
    cmd->customHeader(ptr);
  } break;

  case RequestCode::HeartBeat: {
    std::string heartbeat_data = R"EOF(
    {
      "clientID": "127.0.0.1@90330",
      "consumerDataSet": [
        {
          "consumeFromWhere": "CONSUME_FROM_FIRST_OFFSET",
          "consumeType": "CONSUME_PASSIVELY",
          "groupName": "test_cg",
          "messageModel": "CLUSTERING",
          "subscriptionDataSet": [
            {
              "classFilterMode": false,
              "codeSet": [],
              "expressionType": "TAG",
              "subString": "*",
              "subVersion": 1575630587925,
              "tagsSet": [],
              "topic": "test_topic"
            },
            {
              "classFilterMode": false,
              "codeSet": [],
              "expressionType": "TAG",
              "subString": "*",
              "subVersion": 1575630587945,
              "tagsSet": [],
              "topic": "%RETRY%please_rename_unique_group_name_4"
            }
          ],
         "unitMode": false
        }
      ],
      "producerDataSet": [
        {
          "groupName": "CLIENT_INNER_PRODUCER"
        }
      ]
    }
    )EOF";
    cmd->body().add(heartbeat_data);
  } break;

  case RequestCode::UnregisterClient: {
    std::unique_ptr<UnregisterClientRequestHeader> header =
        std::make_unique<UnregisterClientRequestHeader>();
    header->clientId(client_id_);
    header->consumerGroup(consumer_group_);
    CommandCustomHeaderPtr ptr(header.release());
    cmd->customHeader(ptr);
    break;
  }

  case RequestCode::GetRouteInfoByTopic: {
    std::unique_ptr<GetRouteInfoRequestHeader> header =
        std::make_unique<GetRouteInfoRequestHeader>();
    header->topic(topic_name_);
    CommandCustomHeaderPtr ptr(header.release());
    cmd->customHeader(ptr);
    break;
  }

  case RequestCode::GetConsumerListByGroup: {
    std::unique_ptr<GetConsumerListByGroupRequestHeader> header =
        std::make_unique<GetConsumerListByGroupRequestHeader>();
    header->consumerGroup(consumer_group_);
    CommandCustomHeaderPtr ptr(header.release());
    cmd->customHeader(ptr);
    break;
  }

  case RequestCode::SendMessageV2: {
    std::unique_ptr<SendMessageRequestHeader> header = std::make_unique<SendMessageRequestHeader>();
    header->topic(topic_name_);
    header->version(SendMessageRequestVersion::V2);
    header->producerGroup(producer_group_);
    std::string msg_body = msg_body_;
    cmd->body().add(msg_body);
    CommandCustomHeaderPtr ptr(header.release());
    cmd->customHeader(ptr);
    break;
  }

  case RequestCode::PopMessage: {
    std::unique_ptr<PopMessageRequestHeader> header = std::make_unique<PopMessageRequestHeader>();
    header->consumerGroup(consumer_group_);
    header->topic(topic_name_);
    header->queueId(queue_id_);
    header->maxMsgNum(32);
    header->invisibleTime(6000);
    header->pollTime(3000);
    header->bornTime(1000);
    header->initMode(4);

    CommandCustomHeaderPtr ptr(header.release());
    cmd->customHeader(ptr);
    break;
  }

  case RequestCode::AckMessage: {
    std::unique_ptr<AckMessageRequestHeader> header = std::make_unique<AckMessageRequestHeader>();
    header->consumerGroup(consumer_group_);
    header->topic(topic_name_);
    header->queueId(queue_id_);
    header->extraInfo(extra_info_);
    header->offset(1);
    CommandCustomHeaderPtr ptr(header.release());
    cmd->customHeader(ptr);
    break;
  }

  default:
    break;
  }
  Encoder encoder_;
  buffer.drain(buffer.length());
  encoder_.encode(cmd, buffer);
}

void BufferUtility::fillResponseBuffer(Buffer::OwnedImpl& buffer, RequestCode req_code,
                                       ResponseCode resp_code) {
  RemotingCommandPtr cmd = std::make_unique<RemotingCommand>();
  cmd->code(static_cast<int>(resp_code));
  cmd->opaque(opaque_);

  switch (req_code) {
  case RequestCode::SendMessageV2: {
    std::unique_ptr<SendMessageResponseHeader> header =
        std::make_unique<SendMessageResponseHeader>();
    header->msgIdForTest("MSG_ID_01");
    header->queueId(1);
    header->queueOffset(100);
    header->transactionId("TX_01");
    break;
  }
  case RequestCode::PopMessage: {
    std::unique_ptr<PopMessageResponseHeader> header = std::make_unique<PopMessageResponseHeader>();
    header->popTime(1587386521445);
    header->invisibleTime(50000);
    header->reviveQid(5);
    std::string msg_offset_info = "0 6 147";
    header->msgOffsetInfo(msg_offset_info);
    std::string start_offset_info = "0 6 147";
    header->startOffsetInfo(start_offset_info);
    CommandCustomHeaderPtr ptr(header.release());
    cmd->customHeader(ptr);
    cmd->body().add(std::string({'\x00', '\x00', '\x00', '\xD5'}));
    cmd->body().add(std::string({'\xDA', '\xA3', '\x20', '\xA7'}));
    cmd->body().add(std::string({'\x01', '\xE5', '\x9A', '\x3E'}));
    cmd->body().add(std::string({'\x00', '\x00', '\x00', '\x06'}));
    cmd->body().add(std::string({'\x00', '\x00', '\x00', '\x00'}));
    cmd->body().add(std::string({'\x00', '\x00', '\x00', '\x00'}));
    cmd->body().add(std::string({'\x00', '\x00', '\x00', '\x93'}));
    cmd->body().add(std::string({'\x00', '\x00', '\x00', '\x00'}));
    cmd->body().add(std::string({'\x00', '\x4A', '\xE0', '\x46'}));
    cmd->body().add(std::string({'\x00', '\x00', '\x00', '\x00'}));
    cmd->body().add(std::string({'\x00', '\x00', '\x01', '\x71'}));
    cmd->body().add(std::string({'\x97', '\x98', '\x71', '\xB6'}));
    cmd->body().add(std::string({'\x0A', '\x65', '\xC4', '\x91'}));
    cmd->body().add(std::string({'\x00', '\x00', '\x1A', '\xF4'}));
    cmd->body().add(std::string({'\x00', '\x00', '\x01', '\x71'}));
    cmd->body().add(std::string({'\x97', '\x98', '\x71', '\xAF'}));
    cmd->body().add(std::string({'\x0A', '\x65', '\xC1', '\x2D'}));
    cmd->body().add(std::string({'\x00', '\x00', '\x1F', '\x53'}));
    cmd->body().add(std::string({'\x00', '\x00', '\x00', '\x00'}));
    cmd->body().add(std::string({'\x00', '\x00', '\x00', '\x00'}));
    cmd->body().add(std::string({'\x00', '\x00', '\x00', '\x00'}));
    cmd->body().add(std::string({'\x00', '\x00', '\x00', '\x11'}));
    cmd->body().add(std::string("Hello RocketMQ 52"));
    cmd->body().add(std::string({'\x04'}));
    cmd->body().add(std::string("mesh"));
    cmd->body().add(std::string({'\x00', '\x65'}));
    cmd->body().add(std::string("TRACE_ON"));
    cmd->body().add(std::string({'\x01'}));
    cmd->body().add(std::string("true"));
    cmd->body().add(std::string({'\x02'}));
    cmd->body().add(std::string("MSG_REGION"));
    cmd->body().add(std::string({'\x01'}));
    cmd->body().add(std::string("DefaultRegion"));
    cmd->body().add(std::string({'\x02'}));
    cmd->body().add(std::string("UNIQ_KEY"));
    cmd->body().add(std::string({'\x01'}));
    cmd->body().add(std::string("1EE10882893E18B4AAC2664649B60034"));
    cmd->body().add(std::string({'\x02'}));
    cmd->body().add(std::string("WAIT"));
    cmd->body().add(std::string({'\x01'}));
    cmd->body().add(std::string("true"));
    cmd->body().add(std::string({'\x02'}));
    cmd->body().add(std::string("TAGS"));
    cmd->body().add(std::string({'\x01'}));
    cmd->body().add(std::string("TagA"));
    cmd->body().add(std::string({'\x02'}));
    break;
  }
  default:
    break;
  }
  Encoder encoder_;
  buffer.drain(buffer.length());
  encoder_.encode(cmd, buffer);
}
} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "source/common/network/address_impl.h"

#include "test/mocks/network/mocks.h"
#include "test/mocks/server/factory_context.h"

#include "contrib/rocketmq_proxy/filters/network/source/active_message.h"
#include "contrib/rocketmq_proxy/filters/network/source/config.h"
#include "contrib/rocketmq_proxy/filters/network/source/conn_manager.h"
#include "contrib/rocketmq_proxy/filters/network/source/constant.h"
#include "contrib/rocketmq_proxy/filters/network/source/protocol.h"
#include "contrib/rocketmq_proxy/filters/network/test/utility.h"
#include "gmock/gmock.h"
#include "gtest/gtest.h"

using testing::Return;

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

class ActiveMessageTest : public testing::Test {
public:
  ActiveMessageTest()
      : stats_(RocketmqFilterStats::generateStats("test.", *store_.rootScope())),
        config_(rocketmq_proxy_config_, factory_context_),
        connection_manager_(
            config_, factory_context_.serverFactoryContext().mainThreadDispatcher().timeSource()) {
    connection_manager_.initializeReadFilterCallbacks(filter_callbacks_);
  }

  ~ActiveMessageTest() override {
    filter_callbacks_.connection_.dispatcher_.clearDeferredDeleteList();
  }

protected:
  ConfigImpl::RocketmqProxyConfig rocketmq_proxy_config_;
  NiceMock<Network::MockReadFilterCallbacks> filter_callbacks_;
  NiceMock<Server::Configuration::MockFactoryContext> factory_context_;
  Stats::IsolatedStoreImpl store_;
  RocketmqFilterStats stats_;
  ConfigImpl config_;
  ConnectionManager connection_manager_;
};

TEST_F(ActiveMessageTest, ClusterName) {
  std::string json = R"EOF(
  {
    "opaque": 1,
    "code": 35,
    "version": 1,
    "language": "JAVA",
    "serializeTypeCurrentRPC": "JSON",
    "flag": 0,
    "extFields": {
      "clientID": "SampleClient_01",
      "producerGroup": "PG_Example_01",
      "consumerGroup": "CG_001"
    }
  }
  )EOF";

  Buffer::OwnedImpl buffer;
  buffer.writeBEInt<int32_t>(4 + 4 + json.size());
  buffer.writeBEInt<int32_t>(json.size());
  buffer.add(json);

  bool underflow = false;
  bool has_error = false;
  auto cmd = Decoder::decode(buffer, underflow, has_error);
  EXPECT_FALSE(underflow);
  EXPECT_FALSE(has_error);

  ActiveMessage activeMessage(connection_manager_, std::move(cmd));
  EXPECT_FALSE(activeMessage.metadata()->hasTopicName());
}

TEST_F(ActiveMessageTest, FillBrokerData) {

  absl::node_hash_map<int64_t, std::string> address;
  address.emplace(0, "1.2.3.4:10911");
  BrokerData broker_data("DefaultCluster", "broker-a", std::move(address));

  std::vector<BrokerData> list;
  list.push_back(broker_data);

  ActiveMessage::fillBrokerData(list, "DefaultCluster", "broker-a", 1, "localhost:10911");
  ActiveMessage::fillBrokerData(list, "DefaultCluster", "broker-a", 0, "localhost:10911");
  EXPECT_EQ(1, list.size());
  for (auto& it : list) {
    auto& address = it.brokerAddresses();
    EXPECT_EQ(2, address.size());
    EXPECT_STREQ("1.2.3.4:10911", address[0].c_str());
  }
}

TEST_F(ActiveMessageTest, FillAckMessageDirectiveSuccess) {
  RemotingCommandPtr cmd = std::make_unique<RemotingCommand>();
  ActiveMessage active_message(connection_manager_, std::move(cmd));

  Buffer::OwnedImpl buffer;
  // frame length
  buffer.writeBEInt<int32_t>(98);

  // magic code
  buffer.writeBEInt<int32_t>(enumToSignedInt(MessageVersion::V1));

  // body CRC
  buffer.writeBEInt<int32_t>(1);

  // queue Id
  buffer.writeBEInt<int32_t>(2);

  // flag
  buffer.writeBEInt<int32_t>(3);

  // queue offset
  buffer.writeBEInt<int64_t>(4);

  // physical offset
  buffer.writeBEInt<int64_t>(5);

  // system flag
  buffer.writeBEInt<int32_t>(6);

  // born timestamp
  buffer.writeBEInt<int64_t>(7);

  // born host
  buffer.writeBEInt<int32_t>(8);

  // born host port
  buffer.writeBEInt<int32_t>(9);

  // store timestamp
  buffer.writeBEInt<int64_t>(10);

  // store host address ip:port --> long
  Network::Address::Ipv4Instance host_address("127.0.0.1", 10911);
  const sockaddr_in* sock_addr = reinterpret_cast<const sockaddr_in*>(host_address.sockAddr());
  buffer.writeBEInt<int32_t>(sock_addr->sin_addr.s_addr);
  buffer.writeBEInt<int32_t>(sock_addr->sin_port);

  // re-consume times
  buffer.writeBEInt<int32_t>(11);

  // transaction offset
  buffer.writeBEInt<int64_t>(12);

  // body size
  buffer.writeBEInt<int32_t>(0);

  const std::string topic = "TopicTest";

  // topic length
  buffer.writeBEInt<int8_t>(topic.length());

  // topic data
  buffer.add(topic);

  AckMessageDirective directive("broker-a", 0, connection_manager_.timeSource().monotonicTime());
  const std::string group = "Group";
  active_message.fillAckMessageDirective(buffer, group, topic, directive);

  const std::string fake_topic = "FakeTopic";
  active_message.fillAckMessageDirective(buffer, group, fake_topic, directive);

  EXPECT_EQ(connection_manager_.getAckDirectiveTableForTest().size(), 1);
}

TEST_F(ActiveMessageTest, RecordPopRouteInfo) {
  auto host_description = new NiceMock<Upstream::MockHostDescription>();

  auto metadata = std::make_shared<envoy::config::core::v3::Metadata>();
  ProtobufWkt::Struct topic_route_data;
  auto* fields = topic_route_data.mutable_fields();

  std::string broker_name = "broker-a";
  int32_t broker_id = 0;

  (*fields)[RocketmqConstants::get().ReadQueueNum] = ValueUtil::numberValue(4);
  (*fields)[RocketmqConstants::get().WriteQueueNum] = ValueUtil::numberValue(4);
  (*fields)[RocketmqConstants::get().ClusterName] = ValueUtil::stringValue("DefaultCluster");
  (*fields)[RocketmqConstants::get().BrokerName] = ValueUtil::stringValue(broker_name);
  (*fields)[RocketmqConstants::get().BrokerId] = ValueUtil::numberValue(broker_id);
  (*fields)[RocketmqConstants::get().Perm] = ValueUtil::numberValue(6);
  metadata->mutable_filter_metadata()->insert(Protobuf::MapPair<std::string, ProtobufWkt::Struct>(
      NetworkFilterNames::get().RocketmqProxy, topic_route_data));

  EXPECT_CALL(*host_description, metadata()).WillRepeatedly(Return(metadata));

  Upstream::HostDescriptionConstSharedPtr host_description_ptr(host_description);

  Buffer::OwnedImpl buffer;
  BufferUtility::fillRequestBuffer(buffer, RequestCode::PopMessage);

  bool underflow = false;
  bool has_error = false;

  RemotingCommandPtr cmd = Decoder::decode(buffer, underflow, has_error);
  ActiveMessage active_message(connection_manager_, std::move(cmd));
  active_message.recordPopRouteInfo(host_description_ptr);
  auto custom_header = active_message.downstreamRequest()->typedCustomHeader<CommandCustomHeader>();
  EXPECT_EQ(custom_header->targetBrokerName(), broker_name);
  EXPECT_EQ(custom_header->targetBrokerId(), broker_id);
}

} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "source/common/common/empty_string.h"
#include "source/common/common/enum_to_int.h"
#include "source/common/network/address_impl.h"
#include "source/common/protobuf/utility.h"

#include "contrib/rocketmq_proxy/filters/network/source/codec.h"
#include "contrib/rocketmq_proxy/filters/network/test/utility.h"
#include "gmock/gmock.h"
#include "gtest/gtest.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

class RocketmqCodecTest : public testing::Test {
public:
  RocketmqCodecTest() = default;
  ~RocketmqCodecTest() override = default;
};

TEST_F(RocketmqCodecTest, DecodeWithMinFrameSize) {
  Buffer::OwnedImpl buffer;

  buffer.add(std::string({'\x00', '\x00', '\x01', '\x8b'}));
  buffer.add(std::string({'\x00', '\x00', '\x01', '\x76'}));

  bool underflow = false;
  bool has_error = false;

  auto cmd = Decoder::decode(buffer, underflow, has_error);

  EXPECT_TRUE(underflow);
  EXPECT_FALSE(has_error);
  EXPECT_TRUE(nullptr == cmd);
}

TEST_F(RocketmqCodecTest, DecodeWithOverMaxFrameSizeData) {
  Buffer::OwnedImpl buffer;

  buffer.add(std::string({'\x00', '\x40', '\x00', '\x01'}));
  buffer.add(std::string({'\x00', '\x20', '\x00', '\x00', '\x00'}));

  bool underflow = false;
  bool has_error = false;

  auto cmd = Decoder::decode(buffer, underflow, has_error);

  EXPECT_FALSE(underflow);
  EXPECT_TRUE(has_error);
  EXPECT_TRUE(nullptr == cmd);
}

TEST_F(RocketmqCodecTest, DecodeUnsupportHeaderSerialization) {
  Buffer::OwnedImpl buffer;
  std::string header = "random text suffices";

  buffer.writeBEInt<int32_t>(4 + 4 + header.size());
  uint32_t mark = header.size();
  mark |= (1u << 24u);
  buffer.writeBEInt<uint32_t>(mark);
  buffer.add(header);

  bool underflow = false;
  bool has_error = false;

  auto cmd = Decoder::decode(buffer, underflow, has_error);

  EXPECT_FALSE(underflow);
  EXPECT_TRUE(has_error);
  EXPECT_TRUE(nullptr == cmd);
}

TEST_F(RocketmqCodecTest, DecodeInvalidJson) {
  Buffer::OwnedImpl buffer;
  // Invalid json string.
  std::string invalid_json = R"EOF({a: 3)EOF";

  buffer.writeBEInt<int32_t>(4 + 4 + invalid_json.size());
  buffer.writeBEInt<int32_t>(invalid_json.size());
  buffer.add(invalid_json);

  bool underflow = false;
  bool has_error = false;

  auto cmd = Decoder::decode(buffer, underflow, has_error);

  EXPECT_FALSE(underflow);
  EXPECT_TRUE(has_error);
  EXPECT_TRUE(cmd == nullptr);
}

TEST_F(RocketmqCodecTest, DecodeCodeMissing) {
  Buffer::OwnedImpl buffer;
  // Invalid json string.
  std::string invalid_json = R"EOF({"a": 3})EOF";

  buffer.writeBEInt<int32_t>(4 + 4 + invalid_json.size());
  buffer.writeBEInt<int32_t>(invalid_json.size());
  buffer.add(invalid_json);

  bool underflow = false;
  bool has_error = false;

  auto cmd = Decoder::decode(buffer, underflow, has_error);

  EXPECT_FALSE(underflow);
  EXPECT_TRUE(has_error);
  EXPECT_TRUE(cmd == nullptr);
}

TEST_F(RocketmqCodecTest, DecodeVersionMissing) {
  Buffer::OwnedImpl buffer;
  // Invalid json string.
  std::string invalid_json = R"EOF({"code": 3})EOF";

  buffer.writeBEInt<int32_t>(4 + 4 + invalid_json.size());
  buffer.writeBEInt<int32_t>(invalid_json.size());
  buffer.add(invalid_json);

  bool underflow = false;
  bool has_error = false;

  auto cmd = Decoder::decode(buffer, underflow, has_error);

  EXPECT_FALSE(underflow);
  EXPECT_TRUE(has_error);
  EXPECT_TRUE(cmd == nullptr);
}

TEST_F(RocketmqCodecTest, DecodeOpaqueMissing) {
  Buffer::OwnedImpl buffer;
  // Invalid json string.
  std::string invalid_json = R"EOF(
  {
    "code": 3,
    "version": 1
  }
  )EOF";

  buffer.writeBEInt<int32_t>(4 + 4 + invalid_json.size());
  buffer.writeBEInt<int32_t>(invalid_json.size());
  buffer.add(invalid_json);

  bool underflow = false;
  bool has_error = false;

  auto cmd = Decoder::decode(buffer, underflow, has_error);

  EXPECT_FALSE(underflow);
  EXPECT_TRUE(has_error);
  EXPECT_TRUE(cmd == nullptr);
}

TEST_F(RocketmqCodecTest, DecodeFlagMissing) {
  Buffer::OwnedImpl buffer;
  // Invalid json string.
  std::string invalid_json = R"EOF(
  {
    "code": 3,
    "version": 1,
    "opaque": 1
  }
  )EOF";

  buffer.writeBEInt<int32_t>(4 + 4 + invalid_json.size());
  buffer.writeBEInt<int32_t>(invalid_json.size());
  buffer.add(invalid_json);

  bool underflow = false;
  bool has_error = false;

  auto cmd = Decoder::decode(buffer, underflow, has_error);

  EXPECT_FALSE(underflow);
  EXPECT_TRUE(has_error);
  EXPECT_TRUE(cmd == nullptr);
}

TEST_F(RocketmqCodecTest, DecodeRequestSendMessage) {
  Buffer::OwnedImpl buffer;
  BufferUtility::fillRequestBuffer(buffer, RequestCode::SendMessage);

  bool underflow = false;
  bool has_error = false;

  RemotingCommandPtr request = Decoder::decode(buffer, underflow, has_error);

  EXPECT_FALSE(underflow || has_error);
  EXPECT_EQ(request->opaque(), BufferUtility::opaque_);
  Buffer::Instance& body = request->body();
  EXPECT_EQ(body.toString(), BufferUtility::msg_body_);

  auto header = request->typedCustomHeader<SendMessageRequestHeader>();

  EXPECT_EQ(header->topic(), BufferUtility::topic_name_);
  EXPECT_EQ(header->version(), SendMessageRequestVersion::V1);
  EXPECT_EQ(header->queueId(), -1);
}

TEST_F(RocketmqCodecTest, DecodeRequestSendMessageV2) {
  Buffer::OwnedImpl buffer;

  BufferUtility::fillRequestBuffer(buffer, RequestCode::SendMessageV2);

  bool underflow = false;
  bool has_error = false;

  RemotingCommandPtr request = Decoder::decode(buffer, underflow, has_error);

  EXPECT_FALSE(underflow || has_error);
  EXPECT_EQ(request->opaque(), BufferUtility::opaque_);

  Buffer::Instance& body = request->body();

  EXPECT_EQ(body.toString(), BufferUtility::msg_body_);

  auto header = request->typedCustomHeader<SendMessageRequestHeader>();

  EXPECT_EQ(header->topic(), BufferUtility::topic_name_);
  EXPECT_EQ(header->version(), SendMessageRequestVersion::V2);
  EXPECT_EQ(header->queueId(), -1);
}

TEST_F(RocketmqCodecTest, DecodeRequestSendMessageV1) {
  std::string json = R"EOF(
  {
    "code": 10,
    "version": 1,
    "opaque": 1,
    "flag": 0,
    "extFields": {
      "batch": false,
      "bornTimestamp": 1575872212297,
      "defaultTopic": "TBW102",
      "defaultTopicQueueNums": 3,
      "flag": 124,
      "producerGroup": "FooBarGroup",
      "queueId": 1,
      "reconsumeTimes": 0,
      "sysFlag": 0,
      "topic": "FooBar",
      "unitMode": false,
      "properties": "mock_properties",
      "maxReconsumeTimes": 32
      }
  }
  )EOF";
  Buffer::OwnedImpl buffer;

  buffer.writeBEInt<int32_t>(4 + 4 + json.size());
  buffer.writeBEInt<int32_t>(json.size());
  buffer.add(json);

  bool underflow = false;
  bool has_error = false;

  auto cmd = Decoder::decode(buffer, underflow, has_error);

  EXPECT_FALSE(underflow);
  EXPECT_FALSE(has_error);
  EXPECT_TRUE(nullptr != cmd);
  EXPECT_EQ(10, cmd->code());
  EXPECT_EQ(1, cmd->version());
  EXPECT_EQ(1, cmd->opaque());
}

TEST_F(RocketmqCodecTest, DecodeSendMessageResponseWithSystemError) {
  std::string json = R"EOF(
  {
    "code": 1,
    "language": "JAVA",
    "version": 2,
    "opaque": 1,
    "flag": 1,
    "remark": "System error",
    "serializeTypeCurrentRPC": "JSON"
  }
  )EOF";
  Buffer::OwnedImpl buffer;

  buffer.writeBEInt<int32_t>(4 + 4 + json.size());
  buffer.writeBEInt<int32_t>(json.size());
  buffer.add(json);

  bool underflow = false;
  bool has_error = false;

  auto cmd =
      Decoder::decode(buffer, underflow, has_error, static_cast<int>(RequestCode::SendMessage));

  EXPECT_FALSE(has_error);
  EXPECT_FALSE(underflow);
  EXPECT_TRUE(nullptr != cmd);
  EXPECT_STREQ("JAVA", cmd->language().c_str());
  EXPECT_STREQ("JSON", cmd->serializeTypeCurrentRPC().c_str());
  EXPECT_STREQ("System error", cmd->remark().c_str());
  EXPECT_TRUE(nullptr == cmd->customHeader());
}

TEST_F(RocketmqCodecTest, DecodeSendMessageResponseWithSystemBusy) {
  std::string json = R"EOF(
  {
    "code": 2,
    "language": "JAVA",
    "version": 2,
    "opaque": 1,
    "flag": 1,
    "remark": "System busy",
    "serializeTypeCurrentRPC": "JSON"
  }
  )EOF";
  Buffer::OwnedImpl buffer;

  buffer.writeBEInt<int32_t>(4 + 4 + json.size());
  buffer.writeBEInt<int32_t>(json.size());
  buffer.add(json);

  bool underflow = false;
  bool has_error = false;

  auto cmd =
      Decoder::decode(buffer, underflow, has_error, static_cast<int>(RequestCode::SendMessage));

  EXPECT_FALSE(has_error);
  EXPECT_FALSE(underflow);
  EXPECT_TRUE(nullptr != cmd);
  EXPECT_STREQ("JAVA", cmd->language().c_str());
  EXPECT_STREQ("JSON", cmd->serializeTypeCurrentRPC().c_str());
  EXPECT_STREQ("System busy", cmd->remark().c_str());
  EXPECT_TRUE(nullptr == cmd->customHeader());
}

TEST_F(RocketmqCodecTest, DecodeSendMessageResponseWithCodeNotSupported) {
  std::string json = R"EOF(
  {
    "code": 3,
    "language": "JAVA",
    "version": 2,
    "opaque": 1,
    "flag": 1,
    "remark": "Code not supported",
    "serializeTypeCurrentRPC": "JSON"
  }
  )EOF";
  Buffer::OwnedImpl buffer;

  buffer.writeBEInt<int32_t>(4 + 4 + json.size());
  buffer.writeBEInt<int32_t>(json.size());
  buffer.add(json);

  bool underflow = false;
  bool has_error = false;

  auto cmd =
      Decoder::decode(buffer, underflow, has_error, static_cast<int>(RequestCode::SendMessage));

  EXPECT_FALSE(has_error);
  EXPECT_FALSE(underflow);
  EXPECT_TRUE(nullptr != cmd);
  EXPECT_STREQ("JAVA", cmd->language().c_str());
  EXPECT_STREQ("JSON", cmd->serializeTypeCurrentRPC().c_str());
  EXPECT_STREQ("Code not supported", cmd->remark().c_str());
  EXPECT_TRUE(nullptr == cmd->customHeader());
}

TEST_F(RocketmqCodecTest, DecodeSendMessageResponseNormal) {
  std::string json = R"EOF(
  {
    "code": 0,
    "language": "JAVA",
    "version": 2,
    "opaque": 1,
    "flag": 1,
    "remark": "OK",
    "serializeTypeCurrentRPC": "JSON",
    "extFields": {
      "msgId": "A001",
      "queueId": "10",
      "queueOffset": "2",
      "transactionId": ""
    }
  }
  )EOF";
  Buffer::OwnedImpl buffer;

  buffer.writeBEInt<int32_t>(4 + 4 + json.size());
  buffer.writeBEInt<int32_t>(json.size());
  buffer.add(json);

  bool underflow = false;
  bool has_error = false;

  auto cmd =
      Decoder::decode(buffer, underflow, has_error, static_cast<int>(RequestCode::SendMessage));

  EXPECT_FALSE(has_error);
  EXPECT_FALSE(underflow);
  EXPECT_TRUE(nullptr != cmd);
  EXPECT_STREQ("JAVA", cmd->language().c_str());
  EXPECT_STREQ("JSON", cmd->serializeTypeCurrentRPC().c_str());
  EXPECT_STREQ("OK", cmd->remark().c_str());
  EXPECT_TRUE(nullptr != cmd->customHeader());

  auto extHeader = cmd->typedCustomHeader<SendMessageResponseHeader>();

  EXPECT_STREQ("A001", extHeader->msgId().c_str());
  EXPECT_EQ(10, extHeader->queueId());
  EXPECT_EQ(2, extHeader->queueOffset());
}

TEST_F(RocketmqCodecTest, DecodePopMessageResponseNormal) {
  std::string json = R"EOF(
  {
    "code": 0,
    "language": "JAVA",
    "version": 2,
    "opaque": 1,
    "flag": 1,
    "remark": "OK",
    "serializeTypeCurrentRPC": "JSON",
    "extFields": {
      "popTime": "1234",
      "invisibleTime": "10",
      "reviveQid": "2",
      "restNum": "10",
      "startOffsetInfo": "3",
      "msgOffsetInfo": "mock_msg_offset_info",
      "orderCountInfo": "mock_order_count_info"
    }
  }
  )EOF";
  Buffer::OwnedImpl buffer;

  buffer.writeBEInt<int32_t>(4 + 4 + json.size());
  buffer.writeBEInt<int32_t>(json.size());
  buffer.add(json);

  bool underflow = false;
  bool has_error = false;

  auto cmd =
      Decoder::decode(buffer, underflow, has_error, static_cast<int>(RequestCode::PopMessage));

  EXPECT_FALSE(has_error);
  EXPECT_FALSE(underflow);
  EXPECT_TRUE(nullptr != cmd);
  EXPECT_STREQ("JAVA", cmd->language().c_str());
  EXPECT_STREQ("JSON", cmd->serializeTypeCurrentRPC().c_str());
  EXPECT_STREQ("OK", cmd->remark().c_str());
  EXPECT_TRUE(nullptr != cmd->customHeader());

  auto extHeader = cmd->typedCustomHeader<PopMessageResponseHeader>();

  EXPECT_EQ(1234, extHeader->popTimeForTest());
  EXPECT_EQ(10, extHeader->invisibleTime());
  EXPECT_EQ(2, extHeader->reviveQid());
  EXPECT_EQ(10, extHeader->restNum());
  EXPECT_STREQ("3", extHeader->startOffsetInfo().c_str());
  EXPECT_STREQ("mock_msg_offset_info", extHeader->msgOffsetInfo().c_str());
  EXPECT_STREQ("mock_order_count_info", extHeader->orderCountInfo().c_str());
}

TEST_F(RocketmqCodecTest, DecodeRequestSendMessageV2underflow) {
  Buffer::OwnedImpl buffer;

  buffer.add(std::string({'\x00', '\x00', '\x01', '\x8b'}));
  buffer.add(std::string({'\x00', '\x00', '\x01', '\x76'}));

  std::string header_json = R"EOF(
  {
    "code": 310,
    "extFields": {
      "a": "GID_LINGCHU_TEST_0"
  }
  )EOF";

  buffer.add(header_json);
  buffer.add(std::string{"_Apache_RocketMQ_"});

  bool underflow = false;
  bool has_error = false;

  RemotingCommandPtr request = Decoder::decode(buffer, underflow, has_error);

  EXPECT_EQ(underflow, true);
  EXPECT_EQ(has_error, false);
}

TEST_F(RocketmqCodecTest, EncodeResponseSendMessageSuccess) {
  const int version = 285;
  const int opaque = 4;
  const std::string msg_id = "1E05789ABD1F18B4AAC2895B8BE60003";

  RemotingCommandPtr response =
      std::make_unique<RemotingCommand>(static_cast<int>(ResponseCode::Success), version, opaque);

  response->markAsResponse();

  const int queue_id = 0;
  const int queue_offset = 0;

  std::unique_ptr<SendMessageResponseHeader> sendMessageResponseHeader =
      std::make_unique<SendMessageResponseHeader>(msg_id, queue_id, queue_offset, EMPTY_STRING);
  CommandCustomHeaderPtr extHeader(sendMessageResponseHeader.release());
  response->customHeader(extHeader);

  Buffer::OwnedImpl response_buffer;
  Encoder::encode(response, response_buffer);

  uint32_t frame_length = response_buffer.peekBEInt<uint32_t>();
  uint32_t header_length =
      response_buffer.peekBEInt<uint32_t>(Decoder::FRAME_HEADER_LENGTH_FIELD_SIZE);

  EXPECT_EQ(header_length + Decoder::FRAME_HEADER_LENGTH_FIELD_SIZE, frame_length);

  std::unique_ptr<char[]> header_data = std::make_unique<char[]>(header_length);
  const uint32_t frame_header_content_offset =
      Decoder::FRAME_LENGTH_FIELD_SIZE + Decoder::FRAME_HEADER_LENGTH_FIELD_SIZE;
  response_buffer.copyOut(frame_header_content_offset, header_length, header_data.get());
  std::string header_json(header_data.get(), header_length);
  ProtobufWkt::Struct doc;
  MessageUtil::loadFromJson(header_json, doc);
  const auto& members = doc.fields();

  EXPECT_EQ(members.at("code").number_value(), 0);
  EXPECT_EQ(members.at("version").number_value(), version);
  EXPECT_EQ(members.at("opaque").number_value(), opaque);

  const auto& extFields = members.at("extFields").struct_value().fields();

  EXPECT_EQ(extFields.at("msgId").string_value(), msg_id);
  EXPECT_EQ(extFields.at("queueId").number_value(), queue_id);
  EXPECT_EQ(extFields.at("queueOffset").number_value(), queue_offset);
}

TEST_F(RocketmqCodecTest, DecodeQueueIdWithIncompleteBuffer) {
  Buffer::OwnedImpl buffer;
  // incomplete buffer
  buffer.add(std::string({'\x00'}));

  EXPECT_EQ(Decoder::decodeQueueId(buffer, 0), -1);
}

TEST_F(RocketmqCodecTest, DecodeQueueIdSuccess) {
  Buffer::OwnedImpl buffer;
  // frame length
  buffer.writeBEInt(16);

  for (int i = 0; i < 3; i++) {
    buffer.writeBEInt(i);
  }
  EXPECT_EQ(Decoder::decodeQueueId(buffer, 0), 2);
}

TEST_F(RocketmqCodecTest, DecodeQueueIdFailure) {
  Buffer::OwnedImpl buffer;
  buffer.writeBEInt(128);

  // Some random data, but incomplete frame
  buffer.writeBEInt(12);

  EXPECT_EQ(Decoder::decodeQueueId(buffer, 0), -1);
}

TEST_F(RocketmqCodecTest, DecodeQueueOffsetSuccess) {
  Buffer::OwnedImpl buffer;
  // frame length
  buffer.writeBEInt(28);

  // frame data
  for (int i = 0; i < 4; i++) {
    buffer.writeBEInt(i);
  }
  // write queue offset which takes up 8 bytes
  buffer.writeBEInt<int64_t>(4);

  EXPECT_EQ(Decoder::decodeQueueOffset(buffer, 0), 4);
}

TEST_F(RocketmqCodecTest, DecodeQueueOffsetFailure) {
  Buffer::OwnedImpl buffer;

  // Define length of the frame as 128 bytes
  buffer.writeBEInt(128);

  // some random data, just make sure the frame is incomplete
  for (int i = 0; i < 6; i++) {
    buffer.writeBEInt<int32_t>(i);
  }

  EXPECT_EQ(Decoder::decodeQueueOffset(buffer, 0), -1);
}

TEST_F(RocketmqCodecTest, DecodeMsgIdSuccess) {
  Buffer::OwnedImpl buffer;

  // frame length
  buffer.writeBEInt<int32_t>(64);

  // magic code
  buffer.writeBEInt<int32_t>(0);

  // body CRC
  buffer.writeBEInt<int32_t>(1);

  // queue Id
  buffer.writeBEInt<int32_t>(2);

  // flag
  buffer.writeBEInt<int32_t>(3);

  // queue offset
  buffer.writeBEInt<int64_t>(4);

  // physical offset
  buffer.writeBEInt<int64_t>(5);

  // system flag
  buffer.writeBEInt<int32_t>(6);

  // born timestamp
  buffer.writeBEInt<int64_t>(7);

  // born host
  buffer.writeBEInt<int32_t>(8);

  // born host port
  buffer.writeBEInt<int32_t>(9);

  // store timestamp
  buffer.writeBEInt<int64_t>(10);

  // store host address ip:port --> long
  Network::Address::Ipv4Instance host_address("127.0.0.1", 10911);
  const sockaddr_in* sock_addr = reinterpret_cast<const sockaddr_in*>(host_address.sockAddr());
  buffer.writeBEInt<int32_t>(sock_addr->sin_addr.s_addr);
  buffer.writeBEInt<int32_t>(sock_addr->sin_port);
  EXPECT_EQ(Decoder::decodeMsgId(buffer, 0).empty(), false);
}

TEST_F(RocketmqCodecTest, DecodeMsgIdFailure) {
  Buffer::OwnedImpl buffer;

  // frame length
  buffer.writeBEInt<int32_t>(101);

  // magic code
  buffer.writeBEInt<int32_t>(0);
  EXPECT_EQ(Decoder::decodeMsgId(buffer, 0).empty(), true);
}

TEST_F(RocketmqCodecTest, DecodeTopicSuccessV1) {
  Buffer::OwnedImpl buffer;

  // frame length
  buffer.writeBEInt<int32_t>(98);

  // magic code
  buffer.writeBEInt<int32_t>(enumToSignedInt(MessageVersion::V1));

  // body CRC
  buffer.writeBEInt<int32_t>(1);

  // queue Id
  buffer.writeBEInt<int32_t>(2);

  // flag
  buffer.writeBEInt<int32_t>(3);

  // queue offset
  buffer.writeBEInt<int64_t>(4);

  // physical offset
  buffer.writeBEInt<int64_t>(5);

  // system flag
  buffer.writeBEInt<int32_t>(6);

  // born timestamp
  buffer.writeBEInt<int64_t>(7);

  // born host
  buffer.writeBEInt<int32_t>(8);

  // born host port
  buffer.writeBEInt<int32_t>(9);

  // store timestamp
  buffer.writeBEInt<int64_t>(10);

  // store host address ip:port --> long
  Network::Address::Ipv4Instance host_address("127.0.0.1", 10911);
  const sockaddr_in* sock_addr = reinterpret_cast<const sockaddr_in*>(host_address.sockAddr());
  buffer.writeBEInt<int32_t>(sock_addr->sin_addr.s_addr);
  buffer.writeBEInt<int32_t>(sock_addr->sin_port);

  // re-consume times
  buffer.writeBEInt<int32_t>(11);

  // transaction offset
  buffer.writeBEInt<int64_t>(12);

  // body size
  buffer.writeBEInt<int32_t>(0);

  const std::string topic = "TopicTest";

  // topic length
  buffer.writeBEInt<int8_t>(topic.length());

  // topic data
  buffer.add(topic);

  EXPECT_STREQ(Decoder::decodeTopic(buffer, 0).c_str(), topic.c_str());
}

TEST_F(RocketmqCodecTest, DecodeTopicSuccessV2) {
  Buffer::OwnedImpl buffer;

  // frame length
  buffer.writeBEInt<int32_t>(99);

  // magic code
  buffer.writeBEInt<int32_t>(enumToSignedInt(MessageVersion::V2));

  // body CRC
  buffer.writeBEInt<int32_t>(1);

  // queue Id
  buffer.writeBEInt<int32_t>(2);

  // flag
  buffer.writeBEInt<int32_t>(3);

  // queue offset
  buffer.writeBEInt<int64_t>(4);

  // physical offset
  buffer.writeBEInt<int64_t>(5);

  // system flag
  buffer.writeBEInt<int32_t>(6);

  // born timestamp
  buffer.writeBEInt<int64_t>(7);

  // born host
  buffer.writeBEInt<int32_t>(8);

  // born host port
  buffer.writeBEInt<int32_t>(9);

  // store timestamp
  buffer.writeBEInt<int64_t>(10);

  // store host address ip:port --> long
  Network::Address::Ipv4Instance host_address("127.0.0.1", 10911);
  const sockaddr_in* sock_addr = reinterpret_cast<const sockaddr_in*>(host_address.sockAddr());
  buffer.writeBEInt<int32_t>(sock_addr->sin_addr.s_addr);
  buffer.writeBEInt<int32_t>(sock_addr->sin_port);

  // re-consume times
  buffer.writeBEInt<int32_t>(11);

  // transaction offset
  buffer.writeBEInt<int64_t>(12);

  // body size
  buffer.writeBEInt<int32_t>(0);

  const std::string topic = "TopicTest";

  // topic length
  buffer.writeBEInt<int16_t>(topic.length());

  // topic data
  buffer.add(topic);

  EXPECT_STREQ(Decoder::decodeTopic(buffer, 0).c_str(), topic.c_str());
}

TEST_F(RocketmqCodecTest, DecodeTopicFailure) {
  Buffer::OwnedImpl buffer;

  // frame length
  buffer.writeBEInt<int32_t>(64);

  // magic code
  buffer.writeBEInt<int32_t>(0);
  EXPECT_EQ(Decoder::decodeTopic(buffer, 0).empty(), true);
}

} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "test/mocks/server/factory_context.h"

#include "contrib/rocketmq_proxy/filters/network/source/config.h"
#include "contrib/rocketmq_proxy/filters/network/source/conn_manager.h"
#include "contrib/rocketmq_proxy/filters/network/source/constant.h"
#include "contrib/rocketmq_proxy/filters/network/source/router/router.h"
#include "contrib/rocketmq_proxy/filters/network/test/mocks.h"
#include "contrib/rocketmq_proxy/filters/network/test/utility.h"
#include "gtest/gtest.h"

using testing::_;
using testing::ContainsRegex;
using testing::Return;

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {
namespace Router {

class RocketmqRouterTestBase {
public:
  RocketmqRouterTestBase()
      : config_(rocketmq_proxy_config_, context_),
        cluster_info_(std::make_shared<Upstream::MockClusterInfo>()) {
    context_.server_factory_context_.cluster_manager_.initializeThreadLocalClusters(
        {"fake_cluster"});
    conn_manager_ = std::make_unique<ConnectionManager>(
        config_, context_.server_factory_context_.mainThreadDispatcher().timeSource());
    conn_manager_->initializeReadFilterCallbacks(filter_callbacks_);
  }

  ~RocketmqRouterTestBase() { filter_callbacks_.connection_.dispatcher_.clearDeferredDeleteList(); }

  void initializeRouter() {
    router_ = std::make_unique<RouterImpl>(context_.server_factory_context_.clusterManager());
    EXPECT_EQ(nullptr, router_->downstreamConnection());
  }

  void initSendMessageRequest(std::string topic_name = "test_topic", bool is_oneway = false) {
    RemotingCommandPtr request = std::make_unique<RemotingCommand>();
    request->code(static_cast<int>(RequestCode::SendMessageV2));
    if (is_oneway) {
      request->flag(2);
    }
    SendMessageRequestHeader* header = new SendMessageRequestHeader();
    absl::string_view t = topic_name;
    header->topic(t);
    CommandCustomHeaderPtr custom_header(header);
    request->customHeader(custom_header);
    active_message_ =
        std::make_unique<NiceMock<MockActiveMessage>>(*conn_manager_, std::move(request));

    // Not yet implemented:
    EXPECT_EQ(nullptr, router_->metadataMatchCriteria());
  }

  void initPopMessageRequest() {
    Buffer::OwnedImpl buffer;
    BufferUtility::fillRequestBuffer(buffer, RequestCode::PopMessage);

    bool underflow = false;
    bool has_error = false;

    RemotingCommandPtr request = Decoder::decode(buffer, underflow, has_error);

    active_message_ =
        std::make_unique<NiceMock<MockActiveMessage>>(*conn_manager_, std::move(request));
  }

  void initAckMessageRequest() {
    Buffer::OwnedImpl buffer;
    BufferUtility::fillRequestBuffer(buffer, RequestCode::AckMessage);

    bool underflow = false;
    bool has_error = false;

    RemotingCommandPtr request = Decoder::decode(buffer, underflow, has_error);

    active_message_ =
        std::make_unique<NiceMock<MockActiveMessage>>(*conn_manager_, std::move(request));
  }

  void initOneWayAckMessageRequest() {
    RemotingCommandPtr request = std::make_unique<RemotingCommand>();
    request->code(static_cast<int>(RequestCode::AckMessage));
    request->flag(2);
    std::unique_ptr<AckMessageRequestHeader> header = std::make_unique<AckMessageRequestHeader>();
    header->consumerGroup("test_cg");
    header->topic("test_topic");
    header->queueId(0);
    header->extraInfo("test_extra");
    header->offset(1);
    CommandCustomHeaderPtr ptr(header.release());
    request->customHeader(ptr);
    active_message_ =
        std::make_unique<NiceMock<MockActiveMessage>>(*conn_manager_, std::move(request));
  }

  void startRequest() { router_->sendRequestToUpstream(*active_message_); }

  void connectUpstream() {
    context_.server_factory_context_.cluster_manager_.thread_local_cluster_.tcp_conn_pool_
        .poolReady(upstream_connection_);
  }

  void startRequestWithExistingConnection() {
    EXPECT_CALL(
        context_.server_factory_context_.cluster_manager_.thread_local_cluster_.tcp_conn_pool_,
        newConnection(_))
        .WillOnce(
            Invoke([&](Tcp::ConnectionPool::Callbacks& cb) -> Tcp::ConnectionPool::Cancellable* {
              context_.server_factory_context_.cluster_manager_.thread_local_cluster_.tcp_conn_pool_
                  .newConnectionImpl(cb);
              context_.server_factory_context_.cluster_manager_.thread_local_cluster_.tcp_conn_pool_
                  .poolReady(upstream_connection_);
              return nullptr;
            }));
    router_->sendRequestToUpstream(*active_message_);
  }

  void receiveEmptyResponse() {
    Buffer::OwnedImpl buffer;
    router_->onAboveWriteBufferHighWatermark();
    router_->onBelowWriteBufferLowWatermark();
    router_->onUpstreamData(buffer, false);
  }

  void receiveSendMessageResponse(bool end_stream) {
    Buffer::OwnedImpl buffer;
    BufferUtility::fillResponseBuffer(buffer, RequestCode::SendMessageV2, ResponseCode::Success);
    router_->onUpstreamData(buffer, end_stream);
  }

  void receivePopMessageResponse() {
    Buffer::OwnedImpl buffer;
    BufferUtility::fillResponseBuffer(buffer, RequestCode::PopMessage, ResponseCode::Success);
    router_->onUpstreamData(buffer, false);
  }

  void receiveAckMessageResponse() {
    Buffer::OwnedImpl buffer;
    BufferUtility::fillResponseBuffer(buffer, RequestCode::AckMessage, ResponseCode::Success);
    router_->onUpstreamData(buffer, false);
  }

  NiceMock<Network::MockReadFilterCallbacks> filter_callbacks_;
  NiceMock<Server::Configuration::MockFactoryContext> context_;
  ConfigImpl::RocketmqProxyConfig rocketmq_proxy_config_;
  ConfigImpl config_;
  std::unique_ptr<ConnectionManager> conn_manager_;

  std::unique_ptr<Router> router_;

  std::unique_ptr<NiceMock<MockActiveMessage>> active_message_;
  NiceMock<Network::MockClientConnection> upstream_connection_;

  std::shared_ptr<Upstream::MockClusterInfo> cluster_info_;
  NiceMock<Upstream::MockThreadLocalCluster> thread_local_cluster_;
};

class RocketmqRouterTest : public RocketmqRouterTestBase, public testing::Test {};

TEST_F(RocketmqRouterTest, PoolRemoteConnectionFailure) {
  initializeRouter();
  initSendMessageRequest();

  EXPECT_CALL(*active_message_, onError(_))
      .Times(1)
      .WillOnce(Invoke([&](absl::string_view error_message) -> void {
        EXPECT_THAT(error_message, ContainsRegex(".*remote connection failure*."));
      }));

  startRequest();
  context_.server_factory_context_.cluster_manager_.thread_local_cluster_.tcp_conn_pool_
      .poolFailure(Tcp::ConnectionPool::PoolFailureReason::RemoteConnectionFailure);
}

TEST_F(RocketmqRouterTest, PoolTimeout) {
  initializeRouter();
  initSendMessageRequest();

  EXPECT_CALL(*active_message_, onError(_))
      .Times(1)
      .WillOnce(Invoke([&](absl::string_view error_message) -> void {
        EXPECT_THAT(error_message, ContainsRegex(".*timeout*."));
      }));
  EXPECT_CALL(*active_message_, onReset());

  startRequest();
  context_.server_factory_context_.cluster_manager_.thread_local_cluster_.tcp_conn_pool_
      .poolFailure(Tcp::ConnectionPool::PoolFailureReason::Timeout);
}

TEST_F(RocketmqRouterTest, PoolLocalConnectionFailure) {
  initializeRouter();
  initSendMessageRequest();

  EXPECT_CALL(*active_message_, onError(_))
      .Times(1)
      .WillOnce(Invoke([&](absl::string_view error_message) -> void {
        EXPECT_THAT(error_message, ContainsRegex(".*local connection failure*."));
      }));
  EXPECT_CALL(*active_message_, onReset());

  startRequest();
  context_.server_factory_context_.cluster_manager_.thread_local_cluster_.tcp_conn_pool_
      .poolFailure(Tcp::ConnectionPool::PoolFailureReason::LocalConnectionFailure);
}

TEST_F(RocketmqRouterTest, PoolOverflowFailure) {
  initializeRouter();
  initSendMessageRequest();

  EXPECT_CALL(*active_message_, onError(_))
      .Times(1)
      .WillOnce(Invoke([&](absl::string_view error_message) -> void {
        EXPECT_THAT(error_message, ContainsRegex(".*overflow*."));
      }));
  EXPECT_CALL(*active_message_, onReset());

  startRequest();
  context_.server_factory_context_.cluster_manager_.thread_local_cluster_.tcp_conn_pool_
      .poolFailure(Tcp::ConnectionPool::PoolFailureReason::Overflow);
}

TEST_F(RocketmqRouterTest, ClusterMaintenanceMode) {
  initializeRouter();
  initSendMessageRequest();

  EXPECT_CALL(*active_message_, onError(_))
      .Times(1)
      .WillOnce(Invoke([&](absl::string_view error_message) -> void {
        EXPECT_THAT(error_message, ContainsRegex(".*Cluster under maintenance*."));
      }));
  EXPECT_CALL(
      *context_.server_factory_context_.cluster_manager_.thread_local_cluster_.cluster_.info_,
      maintenanceMode())
      .WillOnce(Return(true));
  EXPECT_CALL(*active_message_, onReset());

  startRequest();
}

TEST_F(RocketmqRouterTest, NoHealthyHosts) {
  initializeRouter();
  initSendMessageRequest();

  EXPECT_CALL(*active_message_, onError(_))
      .Times(1)
      .WillOnce(Invoke([&](absl::string_view error_message) -> void {
        EXPECT_THAT(error_message, ContainsRegex(".*No host available*."));
      }));
  EXPECT_CALL(context_.server_factory_context_.cluster_manager_.thread_local_cluster_,
              tcpConnPool(_, _))
      .WillOnce(Return(absl::nullopt));
  EXPECT_CALL(*active_message_, onReset());

  startRequest();
}

TEST_F(RocketmqRouterTest, NoRouteForRequest) {
  initializeRouter();
  initSendMessageRequest();

  EXPECT_CALL(*active_message_, onError(_))
      .Times(1)
      .WillOnce(Invoke([&](absl::string_view error_message) -> void {
        EXPECT_THAT(error_message, ContainsRegex(".*No route for current request*."));
      }));
  EXPECT_CALL(*active_message_, route()).WillRepeatedly(Return(nullptr));
  EXPECT_CALL(*active_message_, onReset());

  startRequest();
}

TEST_F(RocketmqRouterTest, NoCluster) {
  initializeRouter();
  initSendMessageRequest();

  EXPECT_CALL(*active_message_, onReset());
  EXPECT_CALL(context_.server_factory_context_.cluster_manager_, getThreadLocalCluster(_))
      .WillRepeatedly(Return(nullptr));

  startRequest();
}

TEST_F(RocketmqRouterTest, CallWithEmptyResponse) {
  initializeRouter();
  initSendMessageRequest();

  startRequest();
  connectUpstream();

  EXPECT_CALL(*active_message_, sendResponseToDownstream()).Times(0);
  EXPECT_CALL(*active_message_, onReset()).Times(0);

  receiveEmptyResponse();
}

TEST_F(RocketmqRouterTest, OneWayRequest) {
  initializeRouter();
  initSendMessageRequest("test_topic", true);
  startRequest();

  EXPECT_CALL(*active_message_, onReset());

  connectUpstream();

  EXPECT_TRUE(active_message_->metadata()->isOneWay());
}

TEST_F(RocketmqRouterTest, ReceiveSendMessageResponse) {
  initializeRouter();
  initSendMessageRequest();

  startRequest();
  connectUpstream();

  EXPECT_CALL(*active_message_, sendResponseToDownstream());
  EXPECT_CALL(*active_message_, onReset());

  receiveSendMessageResponse(false);
}

TEST_F(RocketmqRouterTest, ReceivePopMessageResponse) {
  initializeRouter();
  initPopMessageRequest();

  startRequest();
  connectUpstream();

  EXPECT_CALL(*active_message_, sendResponseToDownstream());
  EXPECT_CALL(*active_message_, onReset());

  receivePopMessageResponse();
}

TEST_F(RocketmqRouterTest, ReceiveAckMessageResponse) {
  initializeRouter();
  initAckMessageRequest();

  startRequest();
  connectUpstream();

  EXPECT_CALL(*active_message_, sendResponseToDownstream());
  EXPECT_CALL(*active_message_, onReset());

  receiveAckMessageResponse();
}

TEST_F(RocketmqRouterTest, OneWayAckMessage) {
  initializeRouter();
  initOneWayAckMessageRequest();

  startRequest();

  EXPECT_CALL(*active_message_, onReset());

  connectUpstream();
}

TEST_F(RocketmqRouterTest, ReceivedSendMessageResponseWithDecodeError) {
  initializeRouter();
  initSendMessageRequest();

  EXPECT_CALL(*active_message_, onError(_))
      .Times(1)
      .WillOnce(Invoke([&](absl::string_view error_message) -> void {
        EXPECT_THAT(error_message, ContainsRegex(".*Failed to decode response*."));
      }));

  EXPECT_CALL(upstream_connection_, close(Network::ConnectionCloseType::NoFlush));

  startRequest();
  connectUpstream();
  std::string json = R"EOF(
  {
    "language": "JAVA",
    "version": 2,
    "opaque": 1,
    "flag": 1,
    "serializeTypeCurrentRPC": "JSON"
  }
  )EOF";
  Buffer::OwnedImpl buffer;
  buffer.writeBEInt<int32_t>(4 + 4 + json.size());
  buffer.writeBEInt<int32_t>(json.size());
  buffer.add(json);

  EXPECT_CALL(*active_message_, onReset()).WillRepeatedly(Invoke([&]() -> void {
    conn_manager_->deferredDelete(**conn_manager_->activeMessageList().begin());
  }));
  EXPECT_CALL(*active_message_, onReset());

  LinkedList::moveIntoList(std::move(active_message_), conn_manager_->activeMessageList());
  router_->onUpstreamData(buffer, false);
}

TEST_F(RocketmqRouterTest, ReceivedSendMessageResponseWithStreamEnd) {
  initializeRouter();
  initSendMessageRequest();

  EXPECT_CALL(upstream_connection_, close(Network::ConnectionCloseType::NoFlush));

  startRequest();
  connectUpstream();

  EXPECT_CALL(*active_message_, sendResponseToDownstream());
  EXPECT_CALL(*active_message_, onReset());

  receiveSendMessageResponse(true);
}

TEST_F(RocketmqRouterTest, UpstreamRemoteCloseMidResponse) {
  initializeRouter();
  initSendMessageRequest();

  EXPECT_CALL(*active_message_, onError(_))
      .Times(1)
      .WillOnce(Invoke([&](absl::string_view error_message) -> void {
        EXPECT_THAT(error_message, ContainsRegex(".*Connection to upstream is closed*."));
      }));

  startRequest();
  connectUpstream();

  EXPECT_CALL(*active_message_, sendResponseToDownstream()).Times(0);
  EXPECT_CALL(*active_message_, onReset());

  router_->onEvent(Network::ConnectionEvent::RemoteClose);
}

TEST_F(RocketmqRouterTest, UpstreamLocalCloseMidResponse) {
  initializeRouter();
  initSendMessageRequest();

  EXPECT_CALL(*active_message_, onError(_))
      .Times(1)
      .WillOnce(Invoke([&](absl::string_view error_message) -> void {
        EXPECT_THAT(error_message, ContainsRegex(".*Connection to upstream has been closed*."));
      }));

  startRequest();
  connectUpstream();

  EXPECT_CALL(*active_message_, sendResponseToDownstream()).Times(0);
  EXPECT_CALL(*active_message_, onReset());

  router_->onEvent(Network::ConnectionEvent::LocalClose);
}

TEST_F(RocketmqRouterTest, UpstreamConnected) {
  initializeRouter();
  initSendMessageRequest();

  startRequest();
  connectUpstream();

  EXPECT_CALL(*active_message_, sendResponseToDownstream()).Times(0);
  EXPECT_CALL(*active_message_, onReset()).Times(0);

  router_->onEvent(Network::ConnectionEvent::Connected);
}

TEST_F(RocketmqRouterTest, StartRequestWithExistingConnection) {
  initializeRouter();
  initSendMessageRequest();

  EXPECT_CALL(*active_message_, onError(_)).Times(0);
  EXPECT_CALL(*active_message_, onReset()).Times(0);

  startRequestWithExistingConnection();
}

} // namespace Router
} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include "test/mocks/upstream/cluster_manager.h"

#include "contrib/rocketmq_proxy/filters/network/source/active_message.h"
#include "contrib/rocketmq_proxy/filters/network/source/conn_manager.h"
#include "gmock/gmock.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

namespace Router {
class MockRoute;
} // namespace Router

class MockActiveMessage : public ActiveMessage {
public:
  MockActiveMessage(ConnectionManager& conn_manager, RemotingCommandPtr&& request);
  ~MockActiveMessage() override;

  MOCK_METHOD(void, createFilterChain, ());
  MOCK_METHOD(void, sendRequestToUpstream, ());
  MOCK_METHOD(RemotingCommandPtr&, downstreamRequest, ());
  MOCK_METHOD(void, sendResponseToDownstream, ());
  MOCK_METHOD(void, onQueryTopicRoute, ());
  MOCK_METHOD(void, onError, (absl::string_view));
  MOCK_METHOD(ConnectionManager&, connectionManager, ());
  MOCK_METHOD(void, onReset, ());
  MOCK_METHOD(bool, onUpstreamData,
              (Buffer::Instance&, bool, Tcp::ConnectionPool::ConnectionDataPtr&));
  MOCK_METHOD(MessageMetadataSharedPtr, metadata, (), (const));
  MOCK_METHOD(Router::RouteConstSharedPtr, route, ());

  std::shared_ptr<Router::MockRoute> route_;
};

class MockConfig : public Config {
public:
  MockConfig();
  ~MockConfig() override = default;

  MOCK_METHOD(RocketmqFilterStats&, stats, ());
  MOCK_METHOD(Upstream::ClusterManager&, clusterManager, ());
  MOCK_METHOD(Router::RouterPtr, createRouter, ());
  MOCK_METHOD(bool, developMode, (), (const));
  MOCK_METHOD(std::string, proxyAddress, ());
  MOCK_METHOD(Router::Config&, routerConfig, ());

private:
  Stats::IsolatedStoreImpl store_;
  RocketmqFilterStats stats_;
  NiceMock<Upstream::MockClusterManager> cluster_manager_;
  Router::RouterPtr router_;
};

namespace Router {

class MockRouteEntry : public RouteEntry {
public:
  MockRouteEntry();
  ~MockRouteEntry() override;

  // RocketmqProxy::Router::RouteEntry
  MOCK_METHOD(const std::string&, clusterName, (), (const));
  MOCK_METHOD(Envoy::Router::MetadataMatchCriteria*, metadataMatchCriteria, (), (const));

  std::string cluster_name_{"fake_cluster"};
};

class MockRoute : public Route {
public:
  MockRoute();
  ~MockRoute() override;

  // RocketmqProxy::Router::Route
  MOCK_METHOD(const RouteEntry*, routeEntry, (), (const));

  NiceMock<MockRouteEntry> route_entry_;
};
} // namespace Router

} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
load(
    "//bazel:envoy_build_system.bzl",
    "envoy_cc_mock",
    "envoy_cc_test",
    "envoy_cc_test_library",
    "envoy_contrib_package",
)

licenses(["notice"])  # Apache 2

envoy_contrib_package()

envoy_cc_mock(
    name = "mocks_lib",
    srcs = ["mocks.cc"],
    hdrs = ["mocks.h"],
    deps = [
        "//contrib/rocketmq_proxy/filters/network/source:config",
        "//contrib/rocketmq_proxy/filters/network/source/router:router_lib",
        "//test/mocks/upstream:cluster_manager_mocks",
    ],
)

envoy_cc_test_library(
    name = "utility_lib",
    srcs = ["utility.cc"],
    hdrs = ["utility.h"],
    deps = [
        "//contrib/rocketmq_proxy/filters/network/source:config",
    ],
)

envoy_cc_test(
    name = "protocol_test",
    srcs = ["protocol_test.cc"],
    deps = [
        "//contrib/rocketmq_proxy/filters/network/source:config",
        "//test/test_common:utility_lib",
    ],
)

envoy_cc_test(
    name = "router_test",
    srcs = ["router_test.cc"],
    deps = [
        ":mocks_lib",
        ":utility_lib",
        "//contrib/rocketmq_proxy/filters/network/source:config",
        "//test/mocks/server:factory_context_mocks",
        "//test/test_common:utility_lib",
    ],
)

envoy_cc_test(
    name = "topic_route_test",
    srcs = ["topic_route_test.cc"],
    deps = [
        "//contrib/rocketmq_proxy/filters/network/source:config",
        "//source/common/protobuf:utility_lib",
        "//test/test_common:utility_lib",
    ],
)

envoy_cc_test(
    name = "conn_manager_test",
    srcs = ["conn_manager_test.cc"],
    deps = [
        ":utility_lib",
        "//test/common/stats:stat_test_utility_lib",
        "//test/common/upstream:utility_lib",
        "//test/mocks/network:network_mocks",
        "//test/mocks/server:factory_context_mocks",
        "//test/mocks/server:instance_mocks",
        "//test/mocks/stream_info:stream_info_mocks",
        "//test/test_common:utility_lib",
    ],
)

envoy_cc_test(
    name = "active_message_test",
    srcs = ["active_message_test.cc"],
    deps = [
        ":utility_lib",
        "//contrib/rocketmq_proxy/filters/network/source:config",
        "//source/common/network:address_lib",
        "//test/mocks/network:network_mocks",
        "//test/mocks/server:factory_context_mocks",
        "//test/mocks/stream_info:stream_info_mocks",
        "//test/test_common:utility_lib",
    ],
)

envoy_cc_test(
    name = "config_test",
    srcs = ["config_test.cc"],
    deps = [
        "//contrib/rocketmq_proxy/filters/network/source:config",
        "//test/mocks/local_info:local_info_mocks",
        "//test/mocks/server:factory_context_mocks",
        "//test/mocks/server:instance_mocks",
        "//test/test_common:registry_lib",
        "@envoy_api//contrib/envoy/extensions/filters/network/rocketmq_proxy/v3:pkg_cc_proto",
    ],
)

envoy_cc_test(
    name = "codec_test",
    srcs = ["codec_test.cc"],
    deps = [
        ":utility_lib",
        "//source/common/network:address_lib",
        "//source/common/protobuf:utility_lib",
        "//test/mocks/server:server_mocks",
        "//test/test_common:registry_lib",
    ],
)

envoy_cc_test(
    name = "route_matcher_test",
    srcs = ["route_matcher_test.cc"],
    deps = [
        "//contrib/rocketmq_proxy/filters/network/source/router:route_matcher",
        "//test/test_common:utility_lib",
        "@envoy_api//contrib/envoy/extensions/filters/network/rocketmq_proxy/v3:pkg_cc_proto",
    ],
)
#pragma once

#include "contrib/rocketmq_proxy/filters/network/source/config.h"
#include "contrib/rocketmq_proxy/filters/network/source/conn_manager.h"
#include "gtest/gtest.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

class BufferUtility {
public:
  static void fillRequestBuffer(Buffer::OwnedImpl& buffer, RequestCode code);
  static void fillResponseBuffer(Buffer::OwnedImpl& buffer, RequestCode req_code,
                                 ResponseCode resp_code);

  const static std::string topic_name_;
  const static std::string client_id_;
  const static std::string producer_group_;
  const static std::string consumer_group_;
  const static std::string msg_body_;
  const static std::string extra_info_;
  const static int queue_id_;
  static int opaque_;
};
} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "source/common/protobuf/utility.h"

#include "contrib/rocketmq_proxy/filters/network/source/protocol.h"
#include "gtest/gtest.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

class UnregisterClientRequestHeaderTest : public testing::Test {
public:
  std::string client_id_{"SampleClient_01"};
  std::string producer_group_{"PG_Example_01"};
  std::string consumer_group_{"CG_001"};
};

TEST_F(UnregisterClientRequestHeaderTest, Encode) {
  UnregisterClientRequestHeader request_header;
  request_header.clientId(client_id_);
  request_header.producerGroup(producer_group_);
  request_header.consumerGroup(consumer_group_);

  ProtobufWkt::Value doc;
  request_header.encode(doc);

  const auto& members = doc.struct_value().fields();
  EXPECT_STREQ(client_id_.c_str(), members.at("clientID").string_value().c_str());
  EXPECT_STREQ(producer_group_.c_str(), members.at("producerGroup").string_value().c_str());
  EXPECT_STREQ(consumer_group_.c_str(), members.at("consumerGroup").string_value().c_str());
}

TEST_F(UnregisterClientRequestHeaderTest, Decode) {

  std::string json = R"EOF(
  {
    "clientID": "SampleClient_01",
    "producerGroup": "PG_Example_01",
    "consumerGroup": "CG_001"
  }
  )EOF";

  ProtobufWkt::Value doc;
  MessageUtil::loadFromJson(json, *(doc.mutable_struct_value()));
  UnregisterClientRequestHeader unregister_client_request_header;
  unregister_client_request_header.decode(doc);
  EXPECT_STREQ(client_id_.c_str(), unregister_client_request_header.clientId().c_str());
  EXPECT_STREQ(producer_group_.c_str(), unregister_client_request_header.producerGroup().c_str());
  EXPECT_STREQ(consumer_group_.c_str(), unregister_client_request_header.consumerGroup().c_str());
}

TEST(GetConsumerListByGroupResponseBodyTest, Encode) {
  GetConsumerListByGroupResponseBody response_body;
  response_body.add("localhost@1");
  response_body.add("localhost@2");

  ProtobufWkt::Struct doc;
  response_body.encode(doc);

  const auto& members = doc.fields();
  EXPECT_TRUE(members.contains("consumerIdList"));
  EXPECT_EQ(2, members.at("consumerIdList").list_value().values_size());
}

class AckMessageRequestHeaderTest : public testing::Test {
public:
  std::string consumer_group{"CG_Unit_Test"};
  std::string topic{"T_UnitTest"};
  int32_t queue_id{1};
  std::string extra_info{"extra_info_UT"};
  int64_t offset{100};
};

TEST_F(AckMessageRequestHeaderTest, Encode) {
  AckMessageRequestHeader ack_header;
  ack_header.consumerGroup(consumer_group);
  ack_header.topic(topic);
  ack_header.queueId(queue_id);
  ack_header.extraInfo(extra_info);
  ack_header.offset(offset);

  ProtobufWkt::Value doc;
  ack_header.encode(doc);

  const auto& members = doc.struct_value().fields();

  EXPECT_TRUE(members.contains("consumerGroup"));
  EXPECT_STREQ(consumer_group.c_str(), members.at("consumerGroup").string_value().c_str());

  EXPECT_TRUE(members.contains("topic"));
  EXPECT_STREQ(topic.c_str(), members.at("topic").string_value().c_str());

  EXPECT_TRUE(members.contains("queueId"));
  EXPECT_EQ(queue_id, members.at("queueId").number_value());

  EXPECT_TRUE(members.contains("extraInfo"));
  EXPECT_STREQ(extra_info.c_str(), members.at("extraInfo").string_value().c_str());

  EXPECT_TRUE(members.contains("offset"));
  EXPECT_EQ(offset, members.at("offset").number_value());
}

TEST_F(AckMessageRequestHeaderTest, Decode) {
  std::string json = R"EOF(
  {
    "consumerGroup": "CG_Unit_Test",
    "topic": "T_UnitTest",
    "queueId": 1,
    "extraInfo": "extra_info_UT",
    "offset": 100
  }
  )EOF";

  ProtobufWkt::Value doc;
  MessageUtil::loadFromJson(json, *(doc.mutable_struct_value()));

  AckMessageRequestHeader ack_header;
  ack_header.decode(doc);
  ASSERT_STREQ(consumer_group.c_str(), ack_header.consumerGroup().data());
  ASSERT_STREQ(topic.c_str(), ack_header.topic().c_str());
  ASSERT_EQ(queue_id, ack_header.queueId());
  ASSERT_STREQ(extra_info.c_str(), ack_header.extraInfo().data());
  ASSERT_EQ(offset, ack_header.offset());
}

TEST_F(AckMessageRequestHeaderTest, DecodeNumSerializedAsString) {
  std::string json = R"EOF(
  {
    "consumerGroup": "CG_Unit_Test",
    "topic": "T_UnitTest",
    "queueId": "1",
    "extraInfo": "extra_info_UT",
    "offset": "100"
  }
  )EOF";

  ProtobufWkt::Value doc;
  MessageUtil::loadFromJson(json, *(doc.mutable_struct_value()));

  AckMessageRequestHeader ack_header;
  ack_header.decode(doc);
  ASSERT_STREQ(consumer_group.c_str(), ack_header.consumerGroup().data());
  ASSERT_STREQ(topic.c_str(), ack_header.topic().c_str());
  ASSERT_EQ(queue_id, ack_header.queueId());
  ASSERT_STREQ(extra_info.c_str(), ack_header.extraInfo().data());
  ASSERT_EQ(offset, ack_header.offset());
}

class PopMessageRequestHeaderTest : public testing::Test {
public:
  std::string consumer_group{"CG_UT"};
  std::string topic{"T_UT"};
  int32_t queue_id{1};
  int32_t max_msg_nums{2};
  int64_t invisible_time{3};
  int64_t poll_time{4};
  int64_t born_time{5};
  int32_t init_mode{6};

  std::string exp_type{"exp_type_UT"};
  std::string exp{"exp_UT"};
};

TEST_F(PopMessageRequestHeaderTest, Encode) {
  PopMessageRequestHeader pop_request_header;
  pop_request_header.consumerGroup(consumer_group);
  pop_request_header.topic(topic);
  pop_request_header.queueId(queue_id);
  pop_request_header.maxMsgNum(max_msg_nums);
  pop_request_header.invisibleTime(invisible_time);
  pop_request_header.pollTime(poll_time);
  pop_request_header.bornTime(born_time);
  pop_request_header.initMode(init_mode);
  pop_request_header.expType(exp_type);
  pop_request_header.exp(exp);

  ProtobufWkt::Value doc;
  pop_request_header.encode(doc);

  const auto& members = doc.struct_value().fields();

  EXPECT_TRUE(members.contains("consumerGroup"));
  EXPECT_STREQ(consumer_group.c_str(), members.at("consumerGroup").string_value().c_str());

  EXPECT_TRUE(members.contains("topic"));
  EXPECT_STREQ(topic.c_str(), members.at("topic").string_value().c_str());

  EXPECT_TRUE(members.contains("queueId"));
  EXPECT_EQ(queue_id, members.at("queueId").number_value());

  EXPECT_TRUE(members.contains("maxMsgNums"));
  EXPECT_EQ(max_msg_nums, members.at("maxMsgNums").number_value());

  EXPECT_TRUE(members.contains("invisibleTime"));
  EXPECT_EQ(invisible_time, members.at("invisibleTime").number_value());

  EXPECT_TRUE(members.contains("pollTime"));
  EXPECT_EQ(poll_time, members.at("pollTime").number_value());

  EXPECT_TRUE(members.contains("bornTime"));
  EXPECT_EQ(born_time, members.at("bornTime").number_value());

  EXPECT_TRUE(members.contains("initMode"));
  EXPECT_EQ(init_mode, members.at("initMode").number_value());

  EXPECT_TRUE(members.contains("expType"));
  EXPECT_STREQ(exp_type.c_str(), members.at("expType").string_value().c_str());

  EXPECT_TRUE(members.contains("exp"));
  EXPECT_STREQ(exp.c_str(), members.at("exp").string_value().c_str());
}

TEST_F(PopMessageRequestHeaderTest, Decode) {
  std::string json = R"EOF(
  {
    "consumerGroup": "CG_UT",
    "topic": "T_UT",
    "queueId": 1,
    "maxMsgNums": 2,
    "invisibleTime": 3,
    "pollTime": 4,
    "bornTime": 5,
    "initMode": 6,
    "expType": "exp_type_UT",
    "exp": "exp_UT"
  }
  )EOF";

  ProtobufWkt::Value doc;
  MessageUtil::loadFromJson(json, *(doc.mutable_struct_value()));
  PopMessageRequestHeader pop_request_header;
  pop_request_header.decode(doc);

  ASSERT_STREQ(consumer_group.c_str(), pop_request_header.consumerGroup().data());
  ASSERT_STREQ(topic.c_str(), pop_request_header.topic().c_str());
  ASSERT_EQ(queue_id, pop_request_header.queueId());
  ASSERT_EQ(max_msg_nums, pop_request_header.maxMsgNum());
  ASSERT_EQ(invisible_time, pop_request_header.invisibleTime());
  ASSERT_EQ(poll_time, pop_request_header.pollTime());
  ASSERT_EQ(born_time, pop_request_header.bornTime());
  ASSERT_EQ(init_mode, pop_request_header.initMode());
  ASSERT_STREQ(exp_type.c_str(), pop_request_header.expType().c_str());
  ASSERT_STREQ(exp.c_str(), pop_request_header.exp().c_str());
}

TEST_F(PopMessageRequestHeaderTest, DecodeNumSerializedAsString) {
  std::string json = R"EOF(
  {
    "consumerGroup": "CG_UT",
    "topic": "T_UT",
    "queueId": "1",
    "maxMsgNums": "2",
    "invisibleTime": "3",
    "pollTime": "4",
    "bornTime": "5",
    "initMode": "6",
    "expType": "exp_type_UT",
    "exp": "exp_UT"
  }
  )EOF";

  ProtobufWkt::Value doc;
  MessageUtil::loadFromJson(json, *(doc.mutable_struct_value()));
  PopMessageRequestHeader pop_request_header;
  pop_request_header.decode(doc);

  ASSERT_STREQ(consumer_group.c_str(), pop_request_header.consumerGroup().data());
  ASSERT_STREQ(topic.c_str(), pop_request_header.topic().c_str());
  ASSERT_EQ(queue_id, pop_request_header.queueId());
  ASSERT_EQ(max_msg_nums, pop_request_header.maxMsgNum());
  ASSERT_EQ(invisible_time, pop_request_header.invisibleTime());
  ASSERT_EQ(poll_time, pop_request_header.pollTime());
  ASSERT_EQ(born_time, pop_request_header.bornTime());
  ASSERT_EQ(init_mode, pop_request_header.initMode());
  ASSERT_STREQ(exp_type.c_str(), pop_request_header.expType().c_str());
  ASSERT_STREQ(exp.c_str(), pop_request_header.exp().c_str());
}

class PopMessageResponseHeaderTest : public testing::Test {
public:
  int64_t pop_time{1};
  int64_t invisible_time{2};
  int32_t revive_qid{3};
  int64_t rest_num{4};

  std::string start_offset_info{"start"};
  std::string msg_offset_info{"msg"};
  std::string order_count_info{"order"};
};

TEST_F(PopMessageResponseHeaderTest, Encode) {
  PopMessageResponseHeader pop_response_header;
  pop_response_header.popTime(pop_time);
  pop_response_header.invisibleTime(invisible_time);
  pop_response_header.reviveQid(revive_qid);
  pop_response_header.restNum(rest_num);
  pop_response_header.startOffsetInfo(start_offset_info);
  pop_response_header.msgOffsetInfo(msg_offset_info);
  pop_response_header.orderCountInfo(order_count_info);

  ProtobufWkt::Value doc;
  pop_response_header.encode(doc);

  const auto& members = doc.struct_value().fields();

  EXPECT_TRUE(members.contains("popTime"));
  EXPECT_TRUE(members.contains("invisibleTime"));
  EXPECT_TRUE(members.contains("reviveQid"));
  EXPECT_TRUE(members.contains("restNum"));
  EXPECT_TRUE(members.contains("startOffsetInfo"));
  EXPECT_TRUE(members.contains("msgOffsetInfo"));
  EXPECT_TRUE(members.contains("orderCountInfo"));

  EXPECT_EQ(pop_time, members.at("popTime").number_value());
  EXPECT_EQ(invisible_time, members.at("invisibleTime").number_value());
  EXPECT_EQ(revive_qid, members.at("reviveQid").number_value());
  EXPECT_EQ(rest_num, members.at("restNum").number_value());
  EXPECT_STREQ(start_offset_info.c_str(), members.at("startOffsetInfo").string_value().c_str());
  EXPECT_STREQ(msg_offset_info.c_str(), members.at("msgOffsetInfo").string_value().c_str());
  EXPECT_STREQ(order_count_info.c_str(), members.at("orderCountInfo").string_value().c_str());
}

TEST_F(PopMessageResponseHeaderTest, Decode) {
  std::string json = R"EOF(
  {
    "popTime": 1,
    "invisibleTime": 2,
    "reviveQid": 3,
    "restNum": 4,
    "startOffsetInfo": "start",
    "msgOffsetInfo": "msg",
     "orderCountInfo": "order"
  }
  )EOF";

  ProtobufWkt::Value doc;
  MessageUtil::loadFromJson(json, *(doc.mutable_struct_value()));

  PopMessageResponseHeader header;
  header.decode(doc);

  EXPECT_EQ(pop_time, header.popTimeForTest());
  EXPECT_EQ(invisible_time, header.invisibleTime());
  EXPECT_EQ(revive_qid, header.reviveQid());
  EXPECT_EQ(rest_num, header.restNum());

  EXPECT_STREQ(start_offset_info.c_str(), header.startOffsetInfo().data());
  EXPECT_STREQ(msg_offset_info.c_str(), header.msgOffsetInfo().data());
  EXPECT_STREQ(order_count_info.c_str(), header.orderCountInfo().data());
}

TEST_F(PopMessageResponseHeaderTest, DecodeNumSerializedAsString) {
  std::string json = R"EOF(
  {
    "popTime": "1",
    "invisibleTime": "2",
    "reviveQid": "3",
    "restNum": "4",
    "startOffsetInfo": "start",
    "msgOffsetInfo": "msg",
    "orderCountInfo": "order"
  }
  )EOF";

  ProtobufWkt::Value doc;
  MessageUtil::loadFromJson(json, *(doc.mutable_struct_value()));

  PopMessageResponseHeader header;
  header.decode(doc);

  EXPECT_EQ(pop_time, header.popTimeForTest());
  EXPECT_EQ(invisible_time, header.invisibleTime());
  EXPECT_EQ(revive_qid, header.reviveQid());
  EXPECT_EQ(rest_num, header.restNum());

  EXPECT_STREQ(start_offset_info.c_str(), header.startOffsetInfo().data());
  EXPECT_STREQ(msg_offset_info.c_str(), header.msgOffsetInfo().data());
  EXPECT_STREQ(order_count_info.c_str(), header.orderCountInfo().data());
}

class SendMessageResponseHeaderTest : public testing::Test {
public:
  SendMessageResponseHeader response_header_;
};

TEST_F(SendMessageResponseHeaderTest, Encode) {
  response_header_.msgIdForTest("MSG_ID_01");
  response_header_.queueId(1);
  response_header_.queueOffset(100);
  response_header_.transactionId("TX_01");
  ProtobufWkt::Value doc;
  response_header_.encode(doc);

  const auto& members = doc.struct_value().fields();
  EXPECT_TRUE(members.contains("msgId"));
  EXPECT_TRUE(members.contains("queueId"));
  EXPECT_TRUE(members.contains("queueOffset"));
  EXPECT_TRUE(members.contains("transactionId"));

  EXPECT_STREQ("MSG_ID_01", members.at("msgId").string_value().c_str());
  EXPECT_STREQ("TX_01", members.at("transactionId").string_value().c_str());
  EXPECT_EQ(1, members.at("queueId").number_value());
  EXPECT_EQ(100, members.at("queueOffset").number_value());
}

TEST_F(SendMessageResponseHeaderTest, Decode) {
  std::string json = R"EOF(
  {
    "msgId": "abc",
    "queueId": 1,
    "queueOffset": 10,
    "transactionId": "TX_1"
  }
  )EOF";
  ProtobufWkt::Value doc;
  MessageUtil::loadFromJson(json, *(doc.mutable_struct_value()));
  response_header_.decode(doc);
  EXPECT_STREQ("abc", response_header_.msgId().c_str());
  EXPECT_EQ(1, response_header_.queueId());
  EXPECT_EQ(10, response_header_.queueOffset());
  EXPECT_STREQ("TX_1", response_header_.transactionId().c_str());
}

TEST_F(SendMessageResponseHeaderTest, DecodeNumSerializedAsString) {
  std::string json = R"EOF(
  {
    "msgId": "abc",
    "queueId": "1",
    "queueOffset": "10",
    "transactionId": "TX_1"
   }
  )EOF";
  ProtobufWkt::Value doc;
  MessageUtil::loadFromJson(json, *(doc.mutable_struct_value()));
  response_header_.decode(doc);
  EXPECT_STREQ("abc", response_header_.msgId().c_str());
  EXPECT_EQ(1, response_header_.queueId());
  EXPECT_EQ(10, response_header_.queueOffset());
  EXPECT_STREQ("TX_1", response_header_.transactionId().c_str());
}

class SendMessageRequestHeaderTest : public testing::Test {};

TEST_F(SendMessageRequestHeaderTest, EncodeDefault) {
  SendMessageRequestHeader header;
  ProtobufWkt::Value doc;
  header.encode(doc);
  const auto& members = doc.struct_value().fields();
  EXPECT_TRUE(members.contains("producerGroup"));
  EXPECT_TRUE(members.contains("topic"));
  EXPECT_TRUE(members.contains("defaultTopic"));
  EXPECT_TRUE(members.contains("defaultTopicQueueNums"));
  EXPECT_TRUE(members.contains("queueId"));
  EXPECT_TRUE(members.contains("sysFlag"));
  EXPECT_TRUE(members.contains("bornTimestamp"));
  EXPECT_TRUE(members.contains("flag"));
  EXPECT_FALSE(members.contains("properties"));
  EXPECT_FALSE(members.contains("reconsumeTimes"));
  EXPECT_FALSE(members.contains("unitMode"));
  EXPECT_FALSE(members.contains("batch"));
  EXPECT_FALSE(members.contains("maxReconsumeTimes"));
}

TEST_F(SendMessageRequestHeaderTest, EncodeOptional) {
  SendMessageRequestHeader header;
  header.properties("mock");
  header.reconsumeTimes(1);
  header.unitMode(true);
  header.batch(true);
  header.maxReconsumeTimes(32);
  ProtobufWkt::Value doc;
  header.encode(doc);
  const auto& members = doc.struct_value().fields();
  EXPECT_TRUE(members.contains("producerGroup"));
  EXPECT_TRUE(members.contains("topic"));
  EXPECT_TRUE(members.contains("defaultTopic"));
  EXPECT_TRUE(members.contains("defaultTopicQueueNums"));
  EXPECT_TRUE(members.contains("queueId"));
  EXPECT_TRUE(members.contains("sysFlag"));
  EXPECT_TRUE(members.contains("bornTimestamp"));
  EXPECT_TRUE(members.contains("flag"));
  EXPECT_TRUE(members.contains("properties"));
  EXPECT_TRUE(members.contains("reconsumeTimes"));
  EXPECT_TRUE(members.contains("unitMode"));
  EXPECT_TRUE(members.contains("batch"));
  EXPECT_TRUE(members.contains("maxReconsumeTimes"));

  EXPECT_STREQ("mock", members.at("properties").string_value().c_str());
  EXPECT_EQ(1, members.at("reconsumeTimes").number_value());
  EXPECT_TRUE(members.at("unitMode").bool_value());
  EXPECT_TRUE(members.at("batch").bool_value());
  EXPECT_EQ(32, members.at("maxReconsumeTimes").number_value());
}

TEST_F(SendMessageRequestHeaderTest, EncodeDefaultV2) {
  SendMessageRequestHeader header;
  header.version(SendMessageRequestVersion::V2);
  ProtobufWkt::Value doc;
  header.encode(doc);
  const auto& members = doc.struct_value().fields();
  EXPECT_TRUE(members.contains("a"));
  EXPECT_TRUE(members.contains("b"));
  EXPECT_TRUE(members.contains("c"));
  EXPECT_TRUE(members.contains("d"));
  EXPECT_TRUE(members.contains("e"));
  EXPECT_TRUE(members.contains("f"));
  EXPECT_TRUE(members.contains("g"));
  EXPECT_TRUE(members.contains("h"));
  EXPECT_FALSE(members.contains("i"));
  EXPECT_FALSE(members.contains("j"));
  EXPECT_FALSE(members.contains("k"));
  EXPECT_FALSE(members.contains("l"));
  EXPECT_FALSE(members.contains("m"));
}

TEST_F(SendMessageRequestHeaderTest, EncodeOptionalV2) {
  SendMessageRequestHeader header;
  header.properties("mock");
  header.reconsumeTimes(1);
  header.unitMode(true);
  header.batch(true);
  header.maxReconsumeTimes(32);
  header.version(SendMessageRequestVersion::V2);
  ProtobufWkt::Value doc;
  header.encode(doc);

  const auto& members = doc.struct_value().fields();
  EXPECT_TRUE(members.contains("a"));
  EXPECT_TRUE(members.contains("b"));
  EXPECT_TRUE(members.contains("c"));
  EXPECT_TRUE(members.contains("d"));
  EXPECT_TRUE(members.contains("e"));
  EXPECT_TRUE(members.contains("f"));
  EXPECT_TRUE(members.contains("g"));
  EXPECT_TRUE(members.contains("h"));
  EXPECT_TRUE(members.contains("i"));
  EXPECT_TRUE(members.contains("j"));
  EXPECT_TRUE(members.contains("k"));
  EXPECT_TRUE(members.contains("l"));
  EXPECT_TRUE(members.contains("m"));

  EXPECT_STREQ("mock", members.at("i").string_value().c_str());
  EXPECT_EQ(1, members.at("j").number_value());
  EXPECT_TRUE(members.at("k").bool_value());
  EXPECT_TRUE(members.at("m").bool_value());
  EXPECT_EQ(32, members.at("l").number_value());
}

TEST_F(SendMessageRequestHeaderTest, EncodeV3) {
  SendMessageRequestHeader header;
  header.version(SendMessageRequestVersion::V3);
  ProtobufWkt::Value doc;
  header.encode(doc);
}

TEST_F(SendMessageRequestHeaderTest, DecodeV1) {
  std::string json = R"EOF(
  {
    "batch": false,
    "bornTimestamp": 1575872212297,
    "defaultTopic": "TBW102",
    "defaultTopicQueueNums": 3,
    "flag": 124,
    "producerGroup": "FooBarGroup",
    "queueId": 1,
    "reconsumeTimes": 0,
    "sysFlag": 0,
    "topic": "FooBar",
    "unitMode": false
  }
  )EOF";

  SendMessageRequestHeader header;
  ProtobufWkt::Value doc;
  MessageUtil::loadFromJson(json, *(doc.mutable_struct_value()));
  header.decode(doc);
  EXPECT_STREQ("FooBar", header.topic().c_str());
  EXPECT_EQ(1, header.queueId());
  EXPECT_STREQ("FooBarGroup", header.producerGroup().c_str());
  EXPECT_STREQ("TBW102", header.defaultTopic().c_str());
  EXPECT_EQ(3, header.defaultTopicQueueNumber());
  EXPECT_EQ(0, header.sysFlag());
  EXPECT_EQ(1575872212297, header.bornTimestamp());
  EXPECT_EQ(124, header.flag());
  EXPECT_STREQ("", header.properties().c_str());
  EXPECT_EQ(0, header.reconsumeTimes());
  EXPECT_FALSE(header.unitMode());
  EXPECT_FALSE(header.batch());
  EXPECT_EQ(0, header.maxReconsumeTimes());
}

TEST_F(SendMessageRequestHeaderTest, DecodeV1Optional) {
  std::string json = R"EOF(
  {
    "batch": false,
    "bornTimestamp": 1575872212297,
    "defaultTopic": "TBW102",
    "defaultTopicQueueNums": 3,
    "flag": 124,
    "producerGroup": "FooBarGroup",
    "queueId": 1,
    "reconsumeTimes": 0,
    "sysFlag": 0,
    "topic": "FooBar",
    "unitMode": false,
    "properties": "mock_properties",
    "maxReconsumeTimes": 32
  }
  )EOF";

  SendMessageRequestHeader header;
  ProtobufWkt::Value doc;
  MessageUtil::loadFromJson(json, *(doc.mutable_struct_value()));
  header.decode(doc);
  EXPECT_STREQ("FooBar", header.topic().c_str());
  EXPECT_EQ(1, header.queueId());
  EXPECT_STREQ("FooBarGroup", header.producerGroup().c_str());
  EXPECT_STREQ("TBW102", header.defaultTopic().c_str());
  EXPECT_EQ(3, header.defaultTopicQueueNumber());
  EXPECT_EQ(0, header.sysFlag());
  EXPECT_EQ(1575872212297, header.bornTimestamp());
  EXPECT_EQ(124, header.flag());
  EXPECT_STREQ("mock_properties", header.properties().c_str());
  EXPECT_EQ(0, header.reconsumeTimes());
  EXPECT_FALSE(header.unitMode());
  EXPECT_FALSE(header.batch());
  EXPECT_EQ(32, header.maxReconsumeTimes());
}

TEST_F(SendMessageRequestHeaderTest, DecodeV1OptionalNumSerializedAsString) {
  std::string json = R"EOF(
  {
    "batch": "false",
    "bornTimestamp": "1575872212297",
    "defaultTopic": "TBW102",
    "defaultTopicQueueNums": "3",
    "flag": "124",
    "producerGroup": "FooBarGroup",
    "queueId": "1",
    "reconsumeTimes": "0",
    "sysFlag": "0",
    "topic": "FooBar",
    "unitMode": "false",
    "properties": "mock_properties",
    "maxReconsumeTimes": "32"
  }
  )EOF";

  SendMessageRequestHeader header;
  ProtobufWkt::Value doc;
  MessageUtil::loadFromJson(json, *(doc.mutable_struct_value()));
  header.decode(doc);
  EXPECT_STREQ("FooBar", header.topic().c_str());
  EXPECT_EQ(1, header.queueId());
  EXPECT_STREQ("FooBarGroup", header.producerGroup().c_str());
  EXPECT_STREQ("TBW102", header.defaultTopic().c_str());
  EXPECT_EQ(3, header.defaultTopicQueueNumber());
  EXPECT_EQ(0, header.sysFlag());
  EXPECT_EQ(1575872212297, header.bornTimestamp());
  EXPECT_EQ(124, header.flag());
  EXPECT_STREQ("mock_properties", header.properties().c_str());
  EXPECT_EQ(0, header.reconsumeTimes());
  EXPECT_FALSE(header.unitMode());
  EXPECT_FALSE(header.batch());
  EXPECT_EQ(32, header.maxReconsumeTimes());
}

TEST_F(SendMessageRequestHeaderTest, DecodeV2) {
  std::string json = R"EOF(
  {
    "a": "FooBarGroup",
    "b": "FooBar",
    "c": "TBW102",
    "d": 3,
    "e": 1,
    "f": 0,
    "g": 1575872563203,
    "h": 124,
    "j": 0,
    "k": false,
    "m": false
  }
  )EOF";

  SendMessageRequestHeader header;
  header.version(SendMessageRequestVersion::V2);
  ProtobufWkt::Value doc;
  MessageUtil::loadFromJson(json, *(doc.mutable_struct_value()));
  header.decode(doc);
  EXPECT_STREQ("FooBar", header.topic().c_str());
  EXPECT_EQ(1, header.queueId());
  EXPECT_STREQ("FooBarGroup", header.producerGroup().c_str());
  EXPECT_STREQ("TBW102", header.defaultTopic().c_str());
  EXPECT_EQ(3, header.defaultTopicQueueNumber());
  EXPECT_EQ(0, header.sysFlag());
  EXPECT_EQ(1575872563203, header.bornTimestamp());
  EXPECT_EQ(124, header.flag());
  EXPECT_STREQ("", header.properties().c_str());
  EXPECT_EQ(0, header.reconsumeTimes());
  EXPECT_FALSE(header.unitMode());
  EXPECT_FALSE(header.batch());
  EXPECT_EQ(0, header.maxReconsumeTimes());
}

TEST_F(SendMessageRequestHeaderTest, DecodeV2Optional) {
  std::string json = R"EOF(
  {
    "a": "FooBarGroup",
    "b": "FooBar",
    "c": "TBW102",
    "d": 3,
    "e": 1,
    "f": 0,
    "g": 1575872563203,
    "h": 124,
    "i": "mock_properties",
    "j": 0,
    "k": false,
    "l": 1,
    "m": false
  }
  )EOF";

  SendMessageRequestHeader header;
  header.version(SendMessageRequestVersion::V2);
  ProtobufWkt::Value doc;
  MessageUtil::loadFromJson(json, *(doc.mutable_struct_value()));
  header.decode(doc);
  EXPECT_STREQ("FooBar", header.topic().c_str());
  EXPECT_EQ(1, header.queueId());
  EXPECT_STREQ("FooBarGroup", header.producerGroup().c_str());
  EXPECT_STREQ("TBW102", header.defaultTopic().c_str());
  EXPECT_EQ(3, header.defaultTopicQueueNumber());
  EXPECT_EQ(0, header.sysFlag());
  EXPECT_EQ(1575872563203, header.bornTimestamp());
  EXPECT_EQ(124, header.flag());
  EXPECT_STREQ("mock_properties", header.properties().c_str());
  EXPECT_EQ(0, header.reconsumeTimes());
  EXPECT_FALSE(header.unitMode());
  EXPECT_FALSE(header.batch());
  EXPECT_EQ(1, header.maxReconsumeTimes());
}

TEST_F(SendMessageRequestHeaderTest, DecodeV2OptionalNumSerializedAsString) {
  std::string json = R"EOF(
  {
    "a": "FooBarGroup",
    "b": "FooBar",
    "c": "TBW102",
    "d": "3",
    "e": "1",
    "f": "0",
    "g": "1575872563203",
    "h": "124",
    "i": "mock_properties",
    "j": "0",
    "k": "false",
    "l": "1",
    "m": "false"
  }
  )EOF";

  SendMessageRequestHeader header;
  header.version(SendMessageRequestVersion::V2);
  ProtobufWkt::Value doc;
  MessageUtil::loadFromJson(json, *(doc.mutable_struct_value()));
  header.decode(doc);
  EXPECT_STREQ("FooBar", header.topic().c_str());
  EXPECT_EQ(1, header.queueId());
  EXPECT_STREQ("FooBarGroup", header.producerGroup().c_str());
  EXPECT_STREQ("TBW102", header.defaultTopic().c_str());
  EXPECT_EQ(3, header.defaultTopicQueueNumber());
  EXPECT_EQ(0, header.sysFlag());
  EXPECT_EQ(1575872563203, header.bornTimestamp());
  EXPECT_EQ(124, header.flag());
  EXPECT_STREQ("mock_properties", header.properties().c_str());
  EXPECT_EQ(0, header.reconsumeTimes());
  EXPECT_FALSE(header.unitMode());
  EXPECT_FALSE(header.batch());
  EXPECT_EQ(1, header.maxReconsumeTimes());
}

TEST_F(SendMessageRequestHeaderTest, DecodeV3) {
  std::string json = R"EOF(
  {
    "batch": false,
    "bornTimestamp": 1575872212297,
    "defaultTopic": "TBW102",
    "defaultTopicQueueNums": 3,
    "flag": 124,
    "producerGroup": "FooBarGroup",
    "queueId": 1,
    "reconsumeTimes": 0,
    "sysFlag": 0,
    "topic": "FooBar",
    "unitMode": false
  }
  )EOF";

  SendMessageRequestHeader header;
  ProtobufWkt::Value doc;
  MessageUtil::loadFromJson(json, *(doc.mutable_struct_value()));
  header.version(SendMessageRequestVersion::V3);
  header.decode(doc);
}

class HeartbeatDataTest : public testing::Test {
public:
  HeartbeatData data_;
};

TEST_F(HeartbeatDataTest, Decoding) {
  std::string json = R"EOF(
  {
    "clientID": "127.0.0.1@23606",
    "consumerDataSet": [
      {
        "consumeFromWhere": "CONSUME_FROM_LAST_OFFSET",
        "consumeType": "CONSUME_ACTIVELY",
        "groupName": "please_rename_unique_group_name_4",
        "messageModel": "CLUSTERING",
        "subscriptionDataSet": [
          {
            "classFilterMode": false,
            "codeSet": [],
            "expressionType": "TAG",
            "subString": "*",
            "subVersion": 0,
            "tagsSet": [],
            "topic": "test_topic"
          }
        ],
        "unitMode": false
      }
    ],
    "producerDataSet": [
      {
        "groupName": "CLIENT_INNER_PRODUCER"
      }
    ]
  }
  )EOF";

  const char* clientId = "127.0.0.1@23606";
  const char* consumerGroup = "please_rename_unique_group_name_4";

  HeartbeatData heart_beat_data;
  ProtobufWkt::Struct doc;
  MessageUtil::loadFromJson(json, doc);

  heart_beat_data.decode(doc);
  EXPECT_STREQ(clientId, heart_beat_data.clientId().c_str());
  EXPECT_EQ(1, heart_beat_data.consumerGroups().size());
  EXPECT_STREQ(consumerGroup, heart_beat_data.consumerGroups()[0].c_str());
}

TEST_F(HeartbeatDataTest, DecodeClientIdMissing) {
  std::string json = R"EOF(
  {
    "consumerDataSet": [
      {
        "consumeFromWhere": "CONSUME_FROM_LAST_OFFSET",
        "consumeType": "CONSUME_ACTIVELY",
        "groupName": "please_rename_unique_group_name_4",
        "messageModel": "CLUSTERING",
        "subscriptionDataSet": [
          {
            "classFilterMode": false,
            "codeSet": [],
            "expressionType": "TAG",
            "subString": "*",
            "subVersion": 0,
            "tagsSet": [],
            "topic": "test_topic"
          }
        ],
        "unitMode": false
      }
    ],
    "producerDataSet": [
      {
        "groupName": "CLIENT_INNER_PRODUCER"
      }
    ]
  }
  )EOF";

  ProtobufWkt::Struct doc;
  MessageUtil::loadFromJson(json, doc);
  EXPECT_FALSE(data_.decode(doc));
}

TEST_F(HeartbeatDataTest, Encode) {
  data_.clientId("CID_01");
  ProtobufWkt::Struct doc;
  data_.encode(doc);
  const auto& members = doc.fields();
  EXPECT_TRUE(members.contains("clientID"));
  EXPECT_STREQ("CID_01", members.at("clientID").string_value().c_str());
}

class RemotingCommandTest : public testing::Test {
public:
  RemotingCommand cmd_;
};

TEST_F(RemotingCommandTest, FlagResponse) {
  cmd_.markAsResponse();
  EXPECT_EQ(1, cmd_.flag());
}

TEST_F(RemotingCommandTest, FlagOneway) {
  cmd_.markAsOneway();
  EXPECT_EQ(2, cmd_.flag());
}

TEST_F(RemotingCommandTest, Remark) {
  const char* remark = "OK";
  cmd_.remark(remark);
  EXPECT_STREQ(remark, cmd_.remark().c_str());
}

} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/rocketmq_proxy/filters/network/source/codec.h"

#include <string>

#include "source/common/common/assert.h"
#include "source/common/common/empty_string.h"
#include "source/common/common/enum_to_int.h"
#include "source/common/common/logger.h"

#include "contrib/rocketmq_proxy/filters/network/source/protocol.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

RemotingCommandPtr Decoder::decode(Buffer::Instance& buffer, bool& underflow, bool& has_error,
                                   int request_code) {
  // Verify there is at least some bits, which stores frame length and header length
  if (buffer.length() <= MIN_FRAME_SIZE) {
    underflow = true;
    return nullptr;
  }

  auto frame_length = buffer.peekBEInt<uint32_t>();

  if (frame_length > MAX_FRAME_SIZE) {
    has_error = true;
    return nullptr;
  }

  if (buffer.length() < frame_length) {
    underflow = true;
    return nullptr;
  }
  buffer.drain(FRAME_LENGTH_FIELD_SIZE);

  auto mark = buffer.peekBEInt<uint32_t>();
  uint32_t header_length = adjustHeaderLength(mark);
  if (frame_length < header_length + FRAME_HEADER_LENGTH_FIELD_SIZE) {
    // There is an error in frame_length.
    // Make sure body_length is non-negative.
    has_error = true;
    return nullptr;
  }
  buffer.drain(FRAME_HEADER_LENGTH_FIELD_SIZE);

  uint32_t body_length = frame_length - FRAME_HEADER_LENGTH_FIELD_SIZE - header_length;

  ENVOY_LOG(debug,
            "Request/Response Frame Meta: Frame Length = {}, Header Length = {}, Body Length = {}",
            frame_length, header_length, body_length);

  Buffer::OwnedImpl header_buffer;
  header_buffer.move(buffer, header_length);
  std::string header_json = header_buffer.toString();
  ENVOY_LOG(trace, "Request/Response Header JSON: {}", header_json);

  int32_t code, version, opaque;
  uint32_t flag;
  if (isJsonHeader(mark)) {
    ProtobufWkt::Struct header_struct;

    // Parse header JSON text
    try {
      MessageUtil::loadFromJson(header_json, header_struct);
    } catch (std::exception& e) {
      has_error = true;
      ENVOY_LOG(error, "Failed to parse header JSON: {}. Error message: {}", header_json, e.what());
      return nullptr;
    }

    const auto& filed_value_pair = header_struct.fields();
    if (!filed_value_pair.contains("code")) {
      ENVOY_LOG(error, "Malformed frame: 'code' field is missing. Header JSON: {}", header_json);
      has_error = true;
      return nullptr;
    }
    code = filed_value_pair.at("code").number_value();
    if (!filed_value_pair.contains("version")) {
      ENVOY_LOG(error, "Malformed frame: 'version' field is missing. Header JSON: {}", header_json);
      has_error = true;
      return nullptr;
    }
    version = filed_value_pair.at("version").number_value();
    if (!filed_value_pair.contains("opaque")) {
      ENVOY_LOG(error, "Malformed frame: 'opaque' field is missing. Header JSON: {}", header_json);
      has_error = true;
      return nullptr;
    }
    opaque = filed_value_pair.at("opaque").number_value();
    if (!filed_value_pair.contains("flag")) {
      ENVOY_LOG(error, "Malformed frame: 'flag' field is missing. Header JSON: {}", header_json);
      has_error = true;
      return nullptr;
    }
    flag = filed_value_pair.at("flag").number_value();
    RemotingCommandPtr cmd = std::make_unique<RemotingCommand>(code, version, opaque);
    cmd->flag(flag);
    if (filed_value_pair.contains("language")) {
      cmd->language(filed_value_pair.at("language").string_value());
    }

    if (filed_value_pair.contains("serializeTypeCurrentRPC")) {
      cmd->serializeTypeCurrentRPC(filed_value_pair.at("serializeTypeCurrentRPC").string_value());
    }

    cmd->body_.move(buffer, body_length);

    if (RemotingCommand::isResponse(flag)) {
      if (filed_value_pair.contains("remark")) {
        cmd->remark(filed_value_pair.at("remark").string_value());
      }
      cmd->custom_header_ = decodeResponseExtHeader(static_cast<ResponseCode>(code), header_struct,
                                                    static_cast<RequestCode>(request_code));
    } else {
      cmd->custom_header_ = decodeExtHeader(static_cast<RequestCode>(code), header_struct);
    }
    return cmd;
  } else {
    ENVOY_LOG(warn, "Unsupported header serialization type");
    has_error = true;
    return nullptr;
  }
}

bool Decoder::isComplete(Buffer::Instance& buffer, int32_t cursor) {
  if (buffer.length() - cursor < 4) {
    // buffer is definitely incomplete.
    return false;
  }

  auto total_size = buffer.peekBEInt<int32_t>(cursor);
  return buffer.length() - cursor >= static_cast<uint32_t>(total_size);
}

std::string Decoder::decodeTopic(Buffer::Instance& buffer, int32_t cursor) {
  if (!isComplete(buffer, cursor)) {
    return EMPTY_STRING;
  }

  auto magic_code = buffer.peekBEInt<int32_t>(cursor + 4);

  MessageVersion message_version = V1;
  if (enumToSignedInt(MessageVersion::V1) == magic_code) {
    message_version = V1;
  } else if (enumToSignedInt(MessageVersion::V2) == magic_code) {
    message_version = V2;
  }

  int32_t offset = 4   /* total size */
                   + 4 /* magic code */
                   + 4 /* body CRC */
                   + 4 /* queue Id */
                   + 4 /* flag */
                   + 8 /* queue offset */
                   + 8 /* physical offset */
                   + 4 /* sys flag */
                   + 8 /* born timestamp */
                   + 4 /* born host */
                   + 4 /* born host port */
                   + 8 /* store timestamp */
                   + 4 /* store host */
                   + 4 /* store host port */
                   + 4 /* re-consume times */
                   + 8 /* transaction offset */
      ;
  auto body_size = buffer.peekBEInt<int32_t>(cursor + offset);
  offset += 4 /* body size */
            + body_size /* body */;
  int32_t topic_length;
  std::string topic;
  switch (message_version) {
  case V1: {
    topic_length = buffer.peekBEInt<int8_t>(cursor + offset);
    topic.reserve(topic_length);
    topic.resize(topic_length);
    buffer.copyOut(cursor + offset + sizeof(int8_t), topic_length, &topic[0]);
    break;
  }
  case V2: {
    topic_length = buffer.peekBEInt<int16_t>(cursor + offset);
    topic.reserve(topic_length);
    topic.resize(topic_length);
    buffer.copyOut(cursor + offset + sizeof(int16_t), topic_length, &topic[0]);
    break;
  }
  }
  return topic;
}

int32_t Decoder::decodeQueueId(Buffer::Instance& buffer, int32_t cursor) {
  if (!isComplete(buffer, cursor)) {
    return -1;
  }

  int32_t offset = 4   /* total size */
                   + 4 /* magic code */
                   + 4 /* body CRC */;

  return buffer.peekBEInt<int32_t>(cursor + offset);
}

int64_t Decoder::decodeQueueOffset(Buffer::Instance& buffer, int32_t cursor) {
  if (!isComplete(buffer, cursor)) {
    return -1;
  }

  int32_t offset = 4   /* total size */
                   + 4 /* magic code */
                   + 4 /* body CRC */
                   + 4 /* queue Id */
                   + 4 /* flag */;
  return buffer.peekBEInt<int64_t>(cursor + offset);
}

std::string Decoder::decodeMsgId(Buffer::Instance& buffer, int32_t cursor) {
  if (!isComplete(buffer, cursor)) {
    return EMPTY_STRING;
  }

  int32_t offset = 4   /* total size */
                   + 4 /* magic code */
                   + 4 /* body CRC */
                   + 4 /* queue Id */
                   + 4 /* flag */
                   + 8 /* queue offset */;
  auto physical_offset = buffer.peekBEInt<int64_t>(cursor + offset);
  offset += 8   /* physical offset */
            + 4 /* sys flag */
            + 8 /* born timestamp */
            + 4 /* born host */
            + 4 /* born host port */
            + 8 /* store timestamp */
      ;

  Buffer::OwnedImpl msg_id_buffer;
  msg_id_buffer.writeBEInt<int64_t>(buffer.peekBEInt<int64_t>(cursor + offset));
  msg_id_buffer.writeBEInt<int64_t>(physical_offset);
  std::string msg_id;
  msg_id.reserve(32);
  for (uint64_t i = 0; i < msg_id_buffer.length(); i++) {
    auto c = msg_id_buffer.peekBEInt<uint8_t>();
    msg_id.append(1, static_cast<char>(c >> 4U));
    msg_id.append(1, static_cast<char>(c & 0xFU));
  }
  return msg_id;
}

CommandCustomHeaderPtr Decoder::decodeExtHeader(RequestCode code,
                                                ProtobufWkt::Struct& header_struct) {
  const auto& filed_value_pair = header_struct.fields();
  switch (code) {
  case RequestCode::SendMessage: {
    ASSERT(filed_value_pair.contains("extFields"));
    const auto& ext_fields = filed_value_pair.at("extFields");
    auto send_msg_ext_header = new SendMessageRequestHeader();
    send_msg_ext_header->version_ = SendMessageRequestVersion::V1;
    send_msg_ext_header->decode(ext_fields);
    return send_msg_ext_header;
  }
  case RequestCode::SendMessageV2: {
    ASSERT(filed_value_pair.contains("extFields"));
    const auto& ext_fields = filed_value_pair.at("extFields");
    auto send_msg_ext_header = new SendMessageRequestHeader();
    send_msg_ext_header->version_ = SendMessageRequestVersion::V2;
    send_msg_ext_header->decode(ext_fields);
    return send_msg_ext_header;
  }

  case RequestCode::GetRouteInfoByTopic: {
    ASSERT(filed_value_pair.contains("extFields"));
    const auto& ext_fields = filed_value_pair.at("extFields");
    auto get_route_info_request_header = new GetRouteInfoRequestHeader();
    get_route_info_request_header->decode(ext_fields);
    return get_route_info_request_header;
  }

  case RequestCode::UnregisterClient: {
    ASSERT(filed_value_pair.contains("extFields"));
    const auto& ext_fields = filed_value_pair.at("extFields");
    auto unregister_client_request_header = new UnregisterClientRequestHeader();
    unregister_client_request_header->decode(ext_fields);
    return unregister_client_request_header;
  }

  case RequestCode::GetConsumerListByGroup: {
    ASSERT(filed_value_pair.contains("extFields"));
    const auto& ext_fields = filed_value_pair.at("extFields");
    auto get_consumer_list_by_group_request_header = new GetConsumerListByGroupRequestHeader();
    get_consumer_list_by_group_request_header->decode(ext_fields);
    return get_consumer_list_by_group_request_header;
  }

  case RequestCode::PopMessage: {
    ASSERT(filed_value_pair.contains("extFields"));
    const auto& ext_fields = filed_value_pair.at("extFields");
    auto pop_message_request_header = new PopMessageRequestHeader();
    pop_message_request_header->decode(ext_fields);
    return pop_message_request_header;
  }

  case RequestCode::AckMessage: {
    ASSERT(filed_value_pair.contains("extFields"));
    const auto& ext_fields = filed_value_pair.at("extFields");
    auto ack_message_request_header = new AckMessageRequestHeader();
    ack_message_request_header->decode(ext_fields);
    return ack_message_request_header;
  }

  case RequestCode::HeartBeat: {
    // Heartbeat does not have an extended header.
    return nullptr;
  }

  default:
    ENVOY_LOG(warn, "Unsupported request code: {}", static_cast<int>(code));
    return nullptr;
  }
}

CommandCustomHeaderPtr Decoder::decodeResponseExtHeader(ResponseCode response_code,
                                                        ProtobufWkt::Struct& header_struct,
                                                        RequestCode request_code) {
  // No need to decode a failed response.
  if (response_code != ResponseCode::Success &&
      response_code != ResponseCode::ReplicaNotAvailable) {
    return nullptr;
  }
  const auto& filed_value_pair = header_struct.fields();
  switch (request_code) {
  case RequestCode::SendMessage:
  case RequestCode::SendMessageV2: {
    auto send_message_response_header = new SendMessageResponseHeader();
    ASSERT(filed_value_pair.contains("extFields"));
    auto& ext_fields = filed_value_pair.at("extFields");
    send_message_response_header->decode(ext_fields);
    return send_message_response_header;
  }

  case RequestCode::PopMessage: {
    auto pop_message_response_header = new PopMessageResponseHeader();
    ASSERT(filed_value_pair.contains("extFields"));
    const auto& ext_fields = filed_value_pair.at("extFields");
    pop_message_response_header->decode(ext_fields);
    return pop_message_response_header;
  }
  default:
    return nullptr;
  }
}

void Encoder::encode(const RemotingCommandPtr& command, Buffer::Instance& data) {

  ProtobufWkt::Struct command_struct;
  auto* fields = command_struct.mutable_fields();

  ProtobufWkt::Value code_v;
  code_v.set_number_value(command->code_);
  (*fields)["code"] = code_v;

  ProtobufWkt::Value language_v;
  language_v.set_string_value(command->language());
  (*fields)["language"] = language_v;

  ProtobufWkt::Value version_v;
  version_v.set_number_value(command->version_);
  (*fields)["version"] = version_v;

  ProtobufWkt::Value opaque_v;
  opaque_v.set_number_value(command->opaque_);
  (*fields)["opaque"] = opaque_v;

  ProtobufWkt::Value flag_v;
  flag_v.set_number_value(command->flag_);
  (*fields)["flag"] = flag_v;

  if (!command->remark_.empty()) {
    ProtobufWkt::Value remark_v;
    remark_v.set_string_value(command->remark_);
    (*fields)["remark"] = remark_v;
  }

  ProtobufWkt::Value serialization_type_v;
  serialization_type_v.set_string_value(command->serializeTypeCurrentRPC());
  (*fields)["serializeTypeCurrentRPC"] = serialization_type_v;

  if (command->custom_header_) {
    ProtobufWkt::Value ext_fields_v;
    command->custom_header_->encode(ext_fields_v);
    (*fields)["extFields"] = ext_fields_v;
  }

  std::string json = MessageUtil::getJsonStringFromMessageOrError(command_struct);

  int32_t frame_length = 4;
  int32_t header_length = json.size();
  frame_length += header_length;
  frame_length += command->bodyLength();

  data.writeBEInt<int32_t>(frame_length);
  data.writeBEInt<int32_t>(header_length);
  data.add(json);

  // add body
  if (command->bodyLength() > 0) {
    data.add(command->body());
  }
}

} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include <map>
#include <utility>

#include "envoy/common/pure.h"
#include "envoy/common/time.h"

#include "source/common/buffer/buffer_impl.h"
#include "source/common/common/logger.h"
#include "source/common/protobuf/protobuf.h"

#include "absl/strings/string_view.h"
#include "contrib/rocketmq_proxy/filters/network/source/metadata.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

/**
 * Retry topic prefix
 */
constexpr absl::string_view RetryTopicPrefix = "%RETRY%";

/**
 * RocketMQ supports two versions of sending message protocol. These two versions are identical in
 * terms of functionality. But they do differ in encoding scheme. See SendMessageRequestHeader
 * encode/decode functions for specific differences.
 */
enum class SendMessageRequestVersion : uint32_t {
  V1 = 0,
  V2 = 1,
  // Only for test purpose
  V3 = 2,
};

/**
 * Command custom header are used in combination with RemotingCommand::code, to provide further
 * instructions and data for the operation defined by the protocol.
 * In addition to the shared encode/decode functions, this class also defines target-broker-name and
 * target-broker-id fields, which are helpful if the associated remoting command should be delivered
 * to specific host according to the semantics of the previous command.
 */
class CommandCustomHeader {
public:
  CommandCustomHeader() = default;

  virtual ~CommandCustomHeader() = default;

  virtual void encode(ProtobufWkt::Value& root) PURE;

  virtual void decode(const ProtobufWkt::Value& ext_fields) PURE;

  const std::string& targetBrokerName() const { return target_broker_name_; }

  void targetBrokerName(absl::string_view broker_name) {
    target_broker_name_ = std::string(broker_name.data(), broker_name.length());
  }

  int32_t targetBrokerId() const { return target_broker_id_; }

  void targetBrokerId(int32_t broker_id) { target_broker_id_ = broker_id; }

protected:
  /**
   * If this field is not empty, RDS will employ this field and target-broker-id to direct the
   * associated request to a subset of the chosen cluster.
   */
  std::string target_broker_name_;

  /**
   * Used along with target-broker-name field.
   */
  int32_t target_broker_id_;
};

using CommandCustomHeaderPtr = CommandCustomHeader*;

/**
 * This class extends from CommandCustomHeader, adding a commonly used field by various custom
 * command headers which participate the process of request routing.
 */
class RoutingCommandCustomHeader : public CommandCustomHeader {
public:
  virtual const std::string& topic() const { return topic_; }

  virtual void topic(absl::string_view t) { topic_ = std::string(t.data(), t.size()); }

protected:
  std::string topic_;
};

/**
 * This class defines basic request/response forms used by RocketMQ among all its components.
 */
class RemotingCommand {
public:
  RemotingCommand() : RemotingCommand(0, 0, 0) {}

  RemotingCommand(int code, int version, int opaque)
      : code_(code), version_(version), opaque_(opaque), flag_(0) {}

  ~RemotingCommand() { delete custom_header_; }

  int32_t code() const { return code_; }

  void code(int code) { code_ = code; }

  const std::string& language() const { return language_; }

  void language(absl::string_view lang) { language_ = std::string(lang.data(), lang.size()); }

  int32_t version() const { return version_; }

  void opaque(int opaque) { opaque_ = opaque; }

  int32_t opaque() const { return opaque_; }

  uint32_t flag() const { return flag_; }

  void flag(uint32_t f) { flag_ = f; }

  void customHeader(CommandCustomHeaderPtr custom_header) { custom_header_ = custom_header; }

  CommandCustomHeaderPtr customHeader() const { return custom_header_; }

  template <typename T> T* typedCustomHeader() {
    if (!custom_header_) {
      return nullptr;
    }

    return dynamic_cast<T*>(custom_header_);
  }

  uint32_t bodyLength() const { return body_.length(); }

  Buffer::Instance& body() { return body_; }

  const std::string& remark() const { return remark_; }

  void remark(absl::string_view remark) { remark_ = std::string(remark.data(), remark.length()); }

  const std::string& serializeTypeCurrentRPC() const { return serialize_type_current_rpc_; }

  void serializeTypeCurrentRPC(absl::string_view serialization_type) {
    serialize_type_current_rpc_ = std::string(serialization_type.data(), serialization_type.size());
  }

  bool isOneWay() const {
    uint32_t marker = 1u << SHIFT_ONEWAY;
    return (flag_ & marker) == marker;
  }

  void markAsResponse() { flag_ |= (1u << SHIFT_RPC); }

  void markAsOneway() { flag_ |= (1u << SHIFT_ONEWAY); }

  static bool isResponse(uint32_t flag) { return (flag & (1u << SHIFT_RPC)) == (1u << SHIFT_RPC); }

private:
  /**
   * Action code of this command. Possible values are defined in RequestCode enumeration.
   */
  int32_t code_;

  /**
   * Language used by the client.
   */
  std::string language_{"CPP"};

  /**
   * Version of the client SDK.
   */
  int32_t version_;

  /**
   * Request ID. If the RPC is request-response form, this field is used to establish the
   * association.
   */
  int32_t opaque_;

  /**
   * Bit-wise flag indicating RPC type, including whether it is one-way or request-response;
   * a request or response command.
   */
  uint32_t flag_;

  /**
   * Remark is used to deliver text message in addition to code. Urgent scenarios may use this field
   * to transfer diagnostic message to the counterparts when a full-fledged response is impossible.
   */
  std::string remark_;

  /**
   * Indicate how the custom command header is serialized.
   */
  std::string serialize_type_current_rpc_{"JSON"};

  /**
   * The custom command header works with command code to provide additional protocol
   * implementation.
   * Generally speaking, each code has pair of request/response custom command header.
   */
  CommandCustomHeaderPtr custom_header_{nullptr};

  /**
   * The command body, in form of binary.
   */
  Buffer::OwnedImpl body_;

  static constexpr uint32_t SHIFT_RPC = 0;

  static constexpr uint32_t SHIFT_ONEWAY = 1;

  friend class Encoder;
  friend class Decoder;
};

using RemotingCommandPtr = std::unique_ptr<RemotingCommand>;

/**
 * Command codes used when sending requests. Meaning of each field is self-explanatory.
 */
enum class RequestCode : uint32_t {
  SendMessage = 10,
  HeartBeat = 34,
  UnregisterClient = 35,
  GetConsumerListByGroup = 38,
  PopMessage = 50,
  AckMessage = 51,
  GetRouteInfoByTopic = 105,
  SendMessageV2 = 310,
  // Only for test purpose
  Unsupported = 999,
};

/**
 * Command code used when sending responses. Meaning of each enum is self-explanatory.
 */
enum class ResponseCode : uint32_t {
  Success = 0,
  SystemError = 1,
  SystemBusy = 2,
  RequestCodeNotSupported = 3,
  ReplicaNotAvailable = 11,
};

/**
 * Custom command header for sending messages.
 */
class SendMessageRequestHeader : public RoutingCommandCustomHeader,
                                 Logger::Loggable<Logger::Id::rocketmq> {
public:
  ~SendMessageRequestHeader() override = default;

  int32_t queueId() const { return queue_id_; }

  /**
   * TODO(lizhanhui): Remove this write API after adding queue-id-aware route logic
   * @param queue_id target queue Id.
   */
  void queueId(int32_t queue_id) { queue_id_ = queue_id; }

  void producerGroup(std::string producer_group) { producer_group_ = std::move(producer_group); }

  void encode(ProtobufWkt::Value& root) override;

  void decode(const ProtobufWkt::Value& ext_fields) override;

  const std::string& producerGroup() const { return producer_group_; }

  const std::string& defaultTopic() const { return default_topic_; }

  int32_t defaultTopicQueueNumber() const { return default_topic_queue_number_; }

  int32_t sysFlag() const { return sys_flag_; }

  int32_t flag() const { return flag_; }

  int64_t bornTimestamp() const { return born_timestamp_; }

  const std::string& properties() const { return properties_; }

  int32_t reconsumeTimes() const { return reconsume_time_; }

  bool unitMode() const { return unit_mode_; }

  bool batch() const { return batch_; }

  int32_t maxReconsumeTimes() const { return max_reconsume_time_; }

  void properties(absl::string_view props) {
    properties_ = std::string(props.data(), props.size());
  }

  void reconsumeTimes(int32_t reconsume_times) { reconsume_time_ = reconsume_times; }

  void unitMode(bool unit_mode) { unit_mode_ = unit_mode; }

  void batch(bool batch) { batch_ = batch; }

  void maxReconsumeTimes(int32_t max_reconsume_times) { max_reconsume_time_ = max_reconsume_times; }

  void version(SendMessageRequestVersion version) { version_ = version; }

  SendMessageRequestVersion version() const { return version_; }

private:
  std::string producer_group_;
  std::string default_topic_;
  int32_t default_topic_queue_number_{0};
  int32_t queue_id_{-1};
  int32_t sys_flag_{0};
  int64_t born_timestamp_{0};
  int32_t flag_{0};
  std::string properties_;
  int32_t reconsume_time_{0};
  bool unit_mode_{false};
  bool batch_{false};
  int32_t max_reconsume_time_{0};
  SendMessageRequestVersion version_{SendMessageRequestVersion::V1};

  friend class Decoder;
};

/**
 * Custom command header to respond to a send-message-request.
 */
class SendMessageResponseHeader : public CommandCustomHeader {
public:
  SendMessageResponseHeader() = default;

  SendMessageResponseHeader(std::string msg_id, int32_t queue_id, int64_t queue_offset,
                            std::string transaction_id)
      : msg_id_(std::move(msg_id)), queue_id_(queue_id), queue_offset_(queue_offset),
        transaction_id_(std::move(transaction_id)) {}

  void encode(ProtobufWkt::Value& root) override;

  void decode(const ProtobufWkt::Value& ext_fields) override;

  const std::string& msgId() const { return msg_id_; }

  int32_t queueId() const { return queue_id_; }

  int64_t queueOffset() const { return queue_offset_; }

  const std::string& transactionId() const { return transaction_id_; }

  // This function is for testing only.
  void msgIdForTest(absl::string_view msg_id) {
    msg_id_ = std::string(msg_id.data(), msg_id.size());
  }

  void queueId(int32_t queue_id) { queue_id_ = queue_id; }

  void queueOffset(int64_t queue_offset) { queue_offset_ = queue_offset; }

  void transactionId(absl::string_view transaction_id) {
    transaction_id_ = std::string(transaction_id.data(), transaction_id.size());
  }

private:
  std::string msg_id_;
  int32_t queue_id_{0};
  int64_t queue_offset_{0};
  std::string transaction_id_;
};

/**
 * Classic RocketMQ needs to known addresses of each broker to work with. To resolve the addresses,
 * client SDK uses this command header to query name servers.
 *
 * This header is kept for compatible purpose only.
 */
class GetRouteInfoRequestHeader : public RoutingCommandCustomHeader {
public:
  void encode(ProtobufWkt::Value& root) override;

  void decode(const ProtobufWkt::Value& ext_fields) override;
};

/**
 * When a client wishes to consume messages stored in brokers, it sends a pop command to brokers.
 * Brokers would send a batch of messages to the client. At the same time, the broker keeps the
 * batch invisible for a configured period of time, waiting for acknowledgments from the client.
 *
 * If the client manages to consume the messages within promised time interval and sends ack command
 * back to the broker, the broker will mark the acknowledged ones as consumed. Otherwise, the
 * previously sent messages are visible again and would be consumable for other client instances.
 *
 * Through this approach, we achieves stateless message-pulling, comparing to classic offset-based
 * consuming progress management. This models brings about some extra workload to broker side, but
 * it fits Envoy well.
 */
class PopMessageRequestHeader : public RoutingCommandCustomHeader {
public:
  friend class Decoder;

  void encode(ProtobufWkt::Value& root) override;

  void decode(const ProtobufWkt::Value& ext_fields) override;

  const std::string& consumerGroup() const { return consumer_group_; }

  void consumerGroup(absl::string_view consumer_group) {
    consumer_group_ = std::string(consumer_group.data(), consumer_group.size());
  }

  int32_t queueId() const { return queue_id_; }

  void queueId(int32_t queue_id) { queue_id_ = queue_id; }

  int32_t maxMsgNum() const { return max_msg_nums_; }

  void maxMsgNum(int32_t max_msg_num) { max_msg_nums_ = max_msg_num; }

  int64_t invisibleTime() const { return invisible_time_; }

  void invisibleTime(int64_t invisible_time) { invisible_time_ = invisible_time; }

  int64_t pollTime() const { return poll_time_; }

  void pollTime(int64_t poll_time) { poll_time_ = poll_time; }

  int64_t bornTime() const { return born_time_; }

  void bornTime(int64_t born_time) { born_time_ = born_time; }

  int32_t initMode() const { return init_mode_; }

  void initMode(int32_t init_mode) { init_mode_ = init_mode; }

  const std::string& expType() const { return exp_type_; }

  void expType(absl::string_view exp_type) {
    exp_type_ = std::string(exp_type.data(), exp_type.size());
  }

  const std::string& exp() const { return exp_; }

  void exp(absl::string_view exp) { exp_ = std::string(exp.data(), exp.size()); }

private:
  std::string consumer_group_;
  int32_t queue_id_{-1};
  int32_t max_msg_nums_{32};
  int64_t invisible_time_{0};
  int64_t poll_time_{0};
  int64_t born_time_{0};
  int32_t init_mode_{0};
  std::string exp_type_;
  std::string exp_;
  bool order_{false};
};

/**
 * The pop response command header. See pop request header for how-things-work explanation.
 */
class PopMessageResponseHeader : public CommandCustomHeader {
public:
  void decode(const ProtobufWkt::Value& ext_fields) override;

  void encode(ProtobufWkt::Value& root) override;

  // This function is for testing only.
  int64_t popTimeForTest() const { return pop_time_; }

  void popTime(int64_t pop_time) { pop_time_ = pop_time; }

  int64_t invisibleTime() const { return invisible_time_; }

  void invisibleTime(int64_t invisible_time) { invisible_time_ = invisible_time; }

  int32_t reviveQid() const { return revive_qid_; }

  void reviveQid(int32_t revive_qid) { revive_qid_ = revive_qid; }

  int64_t restNum() const { return rest_num_; }

  void restNum(int64_t rest_num) { rest_num_ = rest_num; }

  const std::string& startOffsetInfo() const { return start_offset_info_; }

  void startOffsetInfo(absl::string_view start_offset_info) {
    start_offset_info_ = std::string(start_offset_info.data(), start_offset_info.size());
  }

  const std::string& msgOffsetInfo() const { return msg_off_set_info_; }

  void msgOffsetInfo(absl::string_view msg_offset_info) {
    msg_off_set_info_ = std::string(msg_offset_info.data(), msg_offset_info.size());
  }

  const std::string& orderCountInfo() const { return order_count_info_; }

  void orderCountInfo(absl::string_view order_count_info) {
    order_count_info_ = std::string(order_count_info.data(), order_count_info.size());
  }

private:
  int64_t pop_time_{0};
  int64_t invisible_time_{0};
  int32_t revive_qid_{0};
  int64_t rest_num_{0};
  std::string start_offset_info_;
  std::string msg_off_set_info_;
  std::string order_count_info_;
};

/**
 * This command is used by the client to acknowledge message(s) that has been successfully consumed.
 * Once the broker received this request, the associated message will formally marked as consumed.
 *
 * Note: the ack request has to be sent the exactly same broker where messages are popped from.
 */
class AckMessageRequestHeader : public RoutingCommandCustomHeader {
public:
  void decode(const ProtobufWkt::Value& ext_fields) override;

  void encode(ProtobufWkt::Value& root) override;

  absl::string_view consumerGroup() const { return consumer_group_; }

  int64_t offset() const { return offset_; }

  void consumerGroup(absl::string_view consumer_group) {
    consumer_group_ = std::string(consumer_group.data(), consumer_group.size());
  }

  int32_t queueId() const { return queue_id_; }
  void queueId(int32_t queue_id) { queue_id_ = queue_id; }

  absl::string_view extraInfo() const { return extra_info_; }
  void extraInfo(absl::string_view extra_info) {
    extra_info_ = std::string(extra_info.data(), extra_info.size());
  }

  void offset(int64_t offset) { offset_ = offset; }

  const std::string& directiveKey() {
    if (key_.empty()) {
      key_ = fmt::format("{}-{}-{}-{}", consumer_group_, topic_, queue_id_, offset_);
    }
    return key_;
  }

private:
  std::string consumer_group_;
  int32_t queue_id_{0};
  std::string extra_info_;
  int64_t offset_{0};
  std::string key_;
};

/**
 * When a client shuts down gracefully, it notifies broker(now envoy) this event.
 */
class UnregisterClientRequestHeader : public CommandCustomHeader {
public:
  void encode(ProtobufWkt::Value& root) override;

  void decode(const ProtobufWkt::Value& ext_fields) override;

  void clientId(absl::string_view client_id) {
    client_id_ = std::string(client_id.data(), client_id.length());
  }

  const std::string& clientId() const { return client_id_; }

  void producerGroup(absl::string_view producer_group) {
    producer_group_ = std::string(producer_group.data(), producer_group.length());
  }

  const std::string& producerGroup() const { return producer_group_; }

  void consumerGroup(absl::string_view consumer_group) {
    consumer_group_ = std::string(consumer_group.data(), consumer_group.length());
  }

  const std::string& consumerGroup() const { return consumer_group_; }

private:
  std::string client_id_;
  std::string producer_group_;
  std::string consumer_group_;
};

/**
 * Classic SDK clients use client-side load balancing. This header is kept for compatibility.
 */
class GetConsumerListByGroupRequestHeader : public CommandCustomHeader {
public:
  void encode(ProtobufWkt::Value& root) override;

  void decode(const ProtobufWkt::Value& ext_fields) override;

  void consumerGroup(absl::string_view consumer_group) {
    consumer_group_ = std::string(consumer_group.data(), consumer_group.length());
  }

  const std::string& consumerGroup() const { return consumer_group_; }

private:
  std::string consumer_group_;
};

/**
 * The response body.
 */
class GetConsumerListByGroupResponseBody {
public:
  void encode(ProtobufWkt::Struct& root);

  void add(absl::string_view consumer_id) {
    consumer_id_list_.emplace_back(consumer_id.data(), consumer_id.length());
  }

private:
  std::vector<std::string> consumer_id_list_;
};

/**
 * Client periodically sends heartbeat to servers to maintain alive status.
 */
class HeartbeatData : public Logger::Loggable<Logger::Id::rocketmq> {
public:
  bool decode(ProtobufWkt::Struct& doc);

  const std::string& clientId() const { return client_id_; }

  const std::vector<std::string>& consumerGroups() const { return consumer_groups_; }

  void encode(ProtobufWkt::Struct& root);

  void clientId(absl::string_view client_id) {
    client_id_ = std::string(client_id.data(), client_id.size());
  }

private:
  std::string client_id_;
  std::vector<std::string> consumer_groups_;
};

class MetadataHelper {
public:
  MetadataHelper() = delete;

  static void parseRequest(RemotingCommandPtr& request, MessageMetadataSharedPtr metadata);
};

/**
 * Directive to ensure entailing ack requests are routed to the same broker host where pop
 * requests are made.
 */
struct AckMessageDirective {

  AckMessageDirective(absl::string_view broker_name, int32_t broker_id, MonotonicTime create_time)
      : broker_name_(broker_name), broker_id_(broker_id), creation_time_(create_time) {}

  std::string broker_name_;
  int32_t broker_id_;
  MonotonicTime creation_time_;
};

} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include <memory>
#include <string>

#include "source/extensions/filters/network/common/factory_base.h"
#include "source/extensions/filters/network/well_known_names.h"

#include "contrib/envoy/extensions/filters/network/rocketmq_proxy/v3/rocketmq_proxy.pb.h"
#include "contrib/envoy/extensions/filters/network/rocketmq_proxy/v3/rocketmq_proxy.pb.validate.h"
#include "contrib/rocketmq_proxy/filters/network/source/conn_manager.h"
#include "contrib/rocketmq_proxy/filters/network/source/router/route_matcher.h"
#include "contrib/rocketmq_proxy/filters/network/source/router/router_impl.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

class RocketmqProxyFilterConfigFactory
    : public Common::FactoryBase<
          envoy::extensions::filters::network::rocketmq_proxy::v3::RocketmqProxy> {
public:
  RocketmqProxyFilterConfigFactory() : FactoryBase(NetworkFilterNames::get().RocketmqProxy, true) {}

private:
  Network::FilterFactoryCb createFilterFactoryFromProtoTyped(
      const envoy::extensions::filters::network::rocketmq_proxy::v3::RocketmqProxy& proto_config,
      Server::Configuration::FactoryContext& context) override;
};

class ConfigImpl : public Config, public Router::Config, Logger::Loggable<Logger::Id::config> {
public:
  using RocketmqProxyConfig =
      envoy::extensions::filters::network::rocketmq_proxy::v3::RocketmqProxy;

  ConfigImpl(const RocketmqProxyConfig& config, Server::Configuration::FactoryContext& context);
  ~ConfigImpl() override = default;

  // Config
  RocketmqFilterStats& stats() override { return stats_; }
  Upstream::ClusterManager& clusterManager() override {
    return context_.serverFactoryContext().clusterManager();
  }
  Router::RouterPtr createRouter() override {
    return std::make_unique<Router::RouterImpl>(context_.serverFactoryContext().clusterManager());
  }
  bool developMode() const override { return develop_mode_; }

  std::chrono::milliseconds transientObjectLifeSpan() const override {
    return transient_object_life_span_;
  }

  std::string proxyAddress() override;
  Router::Config& routerConfig() override { return *this; }

  // Router::Config
  Router::RouteConstSharedPtr route(const MessageMetadata& metadata) const override;

private:
  Server::Configuration::FactoryContext& context_;
  const std::string stats_prefix_;
  RocketmqFilterStats stats_;
  Router::RouteMatcherPtr route_matcher_;
  const bool develop_mode_;
  std::chrono::milliseconds transient_object_life_span_;

  static constexpr uint64_t TransientObjectLifeSpan = 30 * 1000;
};

} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include <string>

#include "source/common/singleton/const_singleton.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

struct RocketmqValues {
  /**
   * All the values below are the properties of single broker in filter_metadata.
   */
  const std::string ReadQueueNum = "read_queue_num";
  const std::string WriteQueueNum = "write_queue_num";
  const std::string ClusterName = "cluster_name";
  const std::string BrokerName = "broker_name";
  const std::string BrokerId = "broker_id";
  const std::string Perm = "perm";
};

using RocketmqConstants = ConstSingleton<RocketmqValues>;

} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include <list>

#include "envoy/common/time.h"
#include "envoy/network/connection.h"
#include "envoy/network/filter.h"
#include "envoy/stats/scope.h"
#include "envoy/stats/stats.h"
#include "envoy/stats/stats_macros.h"
#include "envoy/stats/timespan.h"
#include "envoy/upstream/thread_local_cluster.h"

#include "source/common/buffer/buffer_impl.h"
#include "source/common/common/logger.h"

#include "absl/container/flat_hash_map.h"
#include "absl/strings/string_view.h"
#include "contrib/envoy/extensions/filters/network/rocketmq_proxy/v3/rocketmq_proxy.pb.h"
#include "contrib/envoy/extensions/filters/network/rocketmq_proxy/v3/rocketmq_proxy.pb.validate.h"
#include "contrib/rocketmq_proxy/filters/network/source/active_message.h"
#include "contrib/rocketmq_proxy/filters/network/source/codec.h"
#include "contrib/rocketmq_proxy/filters/network/source/stats.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

class Config {
public:
  virtual ~Config() = default;

  virtual RocketmqFilterStats& stats() PURE;

  virtual Upstream::ClusterManager& clusterManager() PURE;

  virtual Router::RouterPtr createRouter() PURE;

  /**
   * Indicate whether this proxy is running in development mode. If true, this proxy plugin may
   * work without dedicated traffic intercepting facility without considering backward
   * compatibility.
   * @return true when in development mode; false otherwise.
   */
  virtual bool developMode() const PURE;

  virtual std::string proxyAddress() PURE;

  virtual Router::Config& routerConfig() PURE;

  virtual std::chrono::milliseconds transientObjectLifeSpan() const PURE;
};

class ConnectionManager;

/**
 * This class is to ensure legacy RocketMQ SDK works. Heartbeat between client SDK and envoy is not
 * necessary any more and should be removed once the lite SDK is in-place.
 */
class ConsumerGroupMember {
public:
  ConsumerGroupMember(absl::string_view client_id, ConnectionManager& conn_manager);

  bool operator==(const ConsumerGroupMember& other) const { return client_id_ == other.client_id_; }

  bool operator<(const ConsumerGroupMember& other) const { return client_id_ < other.client_id_; }

  void refresh();

  bool expired() const;

  absl::string_view clientId() const { return client_id_; }

  void setLastForTest(MonotonicTime tp) { last_ = tp; }

private:
  std::string client_id_;
  ConnectionManager* connection_manager_;
  MonotonicTime last_;
};

class ConnectionManager : public Network::ReadFilter, Logger::Loggable<Logger::Id::filter> {
public:
  ConnectionManager(Config& config, TimeSource& time_source);

  ~ConnectionManager() override = default;

  /**
   * Called when data is read on the connection.
   * @param data supplies the read data which may be modified.
   * @param end_stream supplies whether this is the last byte on the connection. This will only
   *        be set if the connection has half-close semantics enabled.
   * @return status used by the filter manager to manage further filter iteration.
   */
  Network::FilterStatus onData(Buffer::Instance& data, bool end_stream) override;

  /**
   * Called when a connection is first established. Filters should do one time long term processing
   * that needs to be done when a connection is established. Filter chain iteration can be stopped
   * if needed.
   * @return status used by the filter manager to manage further filter iteration.
   */
  Network::FilterStatus onNewConnection() override;

  /**
   * Initializes the read filter callbacks used to interact with the filter manager. It will be
   * called by the filter manager a single time when the filter is first registered. Thus, any
   * construction that requires the backing connection should take place in the context of this
   * function.
   *
   * IMPORTANT: No outbound networking or complex processing should be done in this function.
   *            That should be done in the context of onNewConnection() if needed.
   *
   * @param callbacks supplies the callbacks.
   */
  void initializeReadFilterCallbacks(Network::ReadFilterCallbacks&) override;

  /**
   * Send response to downstream either when envoy proxy has received result from upstream hosts or
   * the proxy itself may serve the request.
   * @param response Response to write to downstream with identical opaque number.
   */
  void sendResponseToDownstream(RemotingCommandPtr& response);

  void onGetTopicRoute(RemotingCommandPtr request);

  /**
   * Called when downstream sends heartbeat requests.
   * @param request heartbeat request from downstream
   */
  void onHeartbeat(RemotingCommandPtr request);

  void addOrUpdateGroupMember(absl::string_view group, absl::string_view client_id);

  void onUnregisterClient(RemotingCommandPtr request);

  void onError(RemotingCommandPtr& request, absl::string_view error_msg);

  void onSendMessage(RemotingCommandPtr request);

  void onGetConsumerListByGroup(RemotingCommandPtr request);

  void onPopMessage(RemotingCommandPtr request);

  void onAckMessage(RemotingCommandPtr request);

  ActiveMessage& createActiveMessage(RemotingCommandPtr& request);

  void deferredDelete(ActiveMessage& active_message);

  void resetAllActiveMessages(absl::string_view error_msg);

  Config& config() { return config_; }

  RocketmqFilterStats& stats() { return stats_; }

  absl::flat_hash_map<std::string, std::vector<ConsumerGroupMember>>& groupMembersForTest() {
    return group_members_;
  }

  std::list<ActiveMessagePtr>& activeMessageList() { return active_message_list_; }

  void insertAckDirective(const std::string& key, const AckMessageDirective& directive) {
    ack_directive_table_.insert(std::make_pair(key, directive));
  }

  void eraseAckDirective(const std::string& key) {
    auto it = ack_directive_table_.find(key);
    if (it != ack_directive_table_.end()) {
      ack_directive_table_.erase(it);
    }
  }

  TimeSource& timeSource() const { return time_source_; }

  const absl::flat_hash_map<std::string, AckMessageDirective>& getAckDirectiveTableForTest() const {
    return ack_directive_table_;
  }

  friend class ConsumerGroupMember;

private:
  /**
   * Dispatch incoming requests from downstream to run through filter chains.
   */
  void dispatch();

  /**
   * Invoked by heartbeat to purge deprecated ack_directive entries.
   */
  void purgeDirectiveTable();

  Network::ReadFilterCallbacks* read_callbacks_{};
  Buffer::OwnedImpl request_buffer_;

  Config& config_;
  TimeSource& time_source_;
  RocketmqFilterStats& stats_;

  std::list<ActiveMessagePtr> active_message_list_;

  absl::flat_hash_map<std::string, std::vector<ConsumerGroupMember>> group_members_;

  /**
   * Message unique key to message acknowledge directive mapping.
   * Acknowledge requests first consult this table to determine which host in the cluster to go.
   */
  absl::flat_hash_map<std::string, AckMessageDirective> ack_directive_table_;
};
} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include <string>

#include "source/common/http/header_map_impl.h"

#include "absl/types/optional.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

class MessageMetadata {
public:
  MessageMetadata() = default;

  void setOneWay(bool oneway) { is_oneway_ = oneway; }
  bool isOneWay() const { return is_oneway_; }

  bool hasTopicName() const { return topic_name_.has_value(); }
  const std::string& topicName() const { return topic_name_.value(); }
  void setTopicName(const std::string& topic_name) { topic_name_ = topic_name; }

  /**
   * @return HeaderMap of current headers
   */
  const Http::HeaderMap& headers() const { return *headers_; }
  Http::HeaderMap& headers() { return *headers_; }

private:
  bool is_oneway_{false};
  absl::optional<std::string> topic_name_{};

  Http::HeaderMapPtr headers_{Http::RequestHeaderMapImpl::create()};
};

using MessageMetadataSharedPtr = std::shared_ptr<MessageMetadata>;

} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include "envoy/event/deferred_deletable.h"
#include "envoy/network/connection.h"
#include "envoy/network/filter.h"
#include "envoy/stats/timespan.h"

#include "source/common/buffer/buffer_impl.h"
#include "source/common/common/linked_object.h"
#include "source/common/common/logger.h"

#include "absl/types/optional.h"
#include "contrib/rocketmq_proxy/filters/network/source/codec.h"
#include "contrib/rocketmq_proxy/filters/network/source/protocol.h"
#include "contrib/rocketmq_proxy/filters/network/source/router/router.h"
#include "contrib/rocketmq_proxy/filters/network/source/topic_route.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

class ConnectionManager;

/**
 * ActiveMessage represents an in-flight request from downstream that has not yet received response
 * from upstream.
 */
class ActiveMessage : public LinkedObject<ActiveMessage>,
                      public Event::DeferredDeletable,
                      Logger::Loggable<Logger::Id::rocketmq> {
public:
  ActiveMessage(ConnectionManager& conn_manager, RemotingCommandPtr&& request);

  ~ActiveMessage() override;

  /**
   * Set up filter-chain according to configuration from bootstrap config file and dynamic
   * configuration items from Pilot.
   */
  void createFilterChain();

  /**
   * Relay requests from downstream to upstream cluster. If the target cluster is absent at the
   * moment, it triggers cluster discovery service request and mark awaitCluster as true.
   * ClusterUpdateCallback will process requests marked await-cluster once the target cluster is
   * in place.
   */
  void sendRequestToUpstream();

  const RemotingCommandPtr& downstreamRequest() const;

  /**
   * Parse pop response and insert ack route directive such that ack requests will be forwarded to
   * the same broker host from which messages are popped.
   * @param buffer Pop response body.
   * @param group Consumer group name.
   * @param topic Topic from which messages are popped
   * @param directive ack route directive
   */
  virtual void fillAckMessageDirective(Buffer::Instance& buffer, const std::string& group,
                                       const std::string& topic,
                                       const AckMessageDirective& directive);

  virtual void sendResponseToDownstream();

  void onQueryTopicRoute();

  virtual void onError(absl::string_view error_message);

  ConnectionManager& connectionManager() { return connection_manager_; }

  virtual void onReset();

  bool onUpstreamData(Buffer::Instance& data, bool end_stream,
                      Tcp::ConnectionPool::ConnectionDataPtr& conn_data);

  virtual MessageMetadataSharedPtr metadata() const { return metadata_; }

  virtual Router::RouteConstSharedPtr route();

  void recordPopRouteInfo(Upstream::HostDescriptionConstSharedPtr host_description);

  static void fillBrokerData(std::vector<BrokerData>& list, const std::string& cluster,
                             const std::string& broker_name, int64_t broker_id,
                             const std::string& address);

private:
  ConnectionManager& connection_manager_;
  RemotingCommandPtr request_;
  RemotingCommandPtr response_;
  MessageMetadataSharedPtr metadata_;
  Router::RouterPtr router_;
  absl::optional<Router::RouteConstSharedPtr> cached_route_;

  void updateActiveRequestStats(bool is_inc = true);
};

using ActiveMessagePtr = std::unique_ptr<ActiveMessage>;

} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/rocketmq_proxy/filters/network/source/protocol.h"

#include "source/common/common/assert.h"
#include "source/common/common/enum_to_int.h"

#include "contrib/rocketmq_proxy/filters/network/source/constant.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

void SendMessageRequestHeader::encode(ProtobufWkt::Value& root) {
  auto& members = *(root.mutable_struct_value()->mutable_fields());

  switch (version_) {
  case SendMessageRequestVersion::V1: {
    ProtobufWkt::Value producer_group_v;
    producer_group_v.set_string_value(producer_group_);
    members["producerGroup"] = producer_group_v;

    ProtobufWkt::Value topic_v;
    topic_v.set_string_value(topic_.c_str(), topic_.length());
    members["topic"] = topic_v;

    ProtobufWkt::Value default_topic_v;
    default_topic_v.set_string_value(default_topic_);
    members["defaultTopic"] = default_topic_v;

    ProtobufWkt::Value default_topic_queue_number_v;
    default_topic_queue_number_v.set_number_value(default_topic_queue_number_);
    members["defaultTopicQueueNums"] = default_topic_queue_number_v;

    ProtobufWkt::Value queue_id_v;
    queue_id_v.set_number_value(queue_id_);
    members["queueId"] = queue_id_v;

    ProtobufWkt::Value sys_flag_v;
    sys_flag_v.set_number_value(sys_flag_);
    members["sysFlag"] = sys_flag_v;

    ProtobufWkt::Value born_timestamp_v;
    born_timestamp_v.set_number_value(born_timestamp_);
    members["bornTimestamp"] = born_timestamp_v;

    ProtobufWkt::Value flag_v;
    flag_v.set_number_value(flag_);
    members["flag"] = flag_v;

    if (!properties_.empty()) {
      ProtobufWkt::Value properties_v;
      properties_v.set_string_value(properties_.c_str(), properties_.length());
      members["properties"] = properties_v;
    }

    if (reconsume_time_ > 0) {
      ProtobufWkt::Value reconsume_times_v;
      reconsume_times_v.set_number_value(reconsume_time_);
      members["reconsumeTimes"] = reconsume_times_v;
    }

    if (unit_mode_) {
      ProtobufWkt::Value unit_mode_v;
      unit_mode_v.set_bool_value(unit_mode_);
      members["unitMode"] = unit_mode_v;
    }

    if (batch_) {
      ProtobufWkt::Value batch_v;
      batch_v.set_bool_value(batch_);
      members["batch"] = batch_v;
    }

    if (max_reconsume_time_ > 0) {
      ProtobufWkt::Value max_reconsume_time_v;
      max_reconsume_time_v.set_number_value(max_reconsume_time_);
      members["maxReconsumeTimes"] = max_reconsume_time_v;
    }
    break;
  }
  case SendMessageRequestVersion::V2: {
    ProtobufWkt::Value producer_group_v;
    producer_group_v.set_string_value(producer_group_.c_str(), producer_group_.length());
    members["a"] = producer_group_v;

    ProtobufWkt::Value topic_v;
    topic_v.set_string_value(topic_.c_str(), topic_.length());
    members["b"] = topic_v;

    ProtobufWkt::Value default_topic_v;
    default_topic_v.set_string_value(default_topic_.c_str(), default_topic_.length());
    members["c"] = default_topic_v;

    ProtobufWkt::Value default_topic_queue_number_v;
    default_topic_queue_number_v.set_number_value(default_topic_queue_number_);
    members["d"] = default_topic_queue_number_v;

    ProtobufWkt::Value queue_id_v;
    queue_id_v.set_number_value(queue_id_);
    members["e"] = queue_id_v;

    ProtobufWkt::Value sys_flag_v;
    sys_flag_v.set_number_value(sys_flag_);
    members["f"] = sys_flag_v;

    ProtobufWkt::Value born_timestamp_v;
    born_timestamp_v.set_number_value(born_timestamp_);
    members["g"] = born_timestamp_v;

    ProtobufWkt::Value flag_v;
    flag_v.set_number_value(flag_);
    members["h"] = flag_v;

    if (!properties_.empty()) {
      ProtobufWkt::Value properties_v;
      properties_v.set_string_value(properties_.c_str(), properties_.length());
      members["i"] = properties_v;
    }

    if (reconsume_time_ > 0) {
      ProtobufWkt::Value reconsume_times_v;
      reconsume_times_v.set_number_value(reconsume_time_);
      members["j"] = reconsume_times_v;
    }

    if (unit_mode_) {
      ProtobufWkt::Value unit_mode_v;
      unit_mode_v.set_bool_value(unit_mode_);
      members["k"] = unit_mode_v;
    }

    if (batch_) {
      ProtobufWkt::Value batch_v;
      batch_v.set_bool_value(batch_);
      members["m"] = batch_v;
    }

    if (max_reconsume_time_ > 0) {
      ProtobufWkt::Value max_reconsume_time_v;
      max_reconsume_time_v.set_number_value(max_reconsume_time_);
      members["l"] = max_reconsume_time_v;
    }
    break;
  }
  default:
    break;
  }
}

void SendMessageRequestHeader::decode(const ProtobufWkt::Value& ext_fields) {
  const auto& members = ext_fields.struct_value().fields();
  switch (version_) {
  case SendMessageRequestVersion::V1: {
    ASSERT(members.contains("producerGroup"));
    ASSERT(members.contains("topic"));
    ASSERT(members.contains("defaultTopic"));
    ASSERT(members.contains("defaultTopicQueueNums"));
    ASSERT(members.contains("queueId"));
    ASSERT(members.contains("sysFlag"));
    ASSERT(members.contains("bornTimestamp"));
    ASSERT(members.contains("flag"));

    producer_group_ = members.at("producerGroup").string_value();
    topic_ = members.at("topic").string_value();
    default_topic_ = members.at("defaultTopic").string_value();

    if (members.at("defaultTopicQueueNums").kind_case() == ProtobufWkt::Value::kNumberValue) {
      default_topic_queue_number_ = members.at("defaultTopicQueueNums").number_value();
    } else {
      default_topic_queue_number_ = std::stoi(members.at("defaultTopicQueueNums").string_value());
    }

    if (members.at("queueId").kind_case() == ProtobufWkt::Value::kNumberValue) {
      queue_id_ = members.at("queueId").number_value();
    } else {
      queue_id_ = std::stoi(members.at("queueId").string_value());
    }

    if (members.at("sysFlag").kind_case() == ProtobufWkt::Value::kNumberValue) {
      sys_flag_ = static_cast<int32_t>(members.at("sysFlag").number_value());
    } else {
      sys_flag_ = std::stoi(members.at("sysFlag").string_value());
    }

    if (members.at("bornTimestamp").kind_case() == ProtobufWkt::Value::kNumberValue) {
      born_timestamp_ = static_cast<int64_t>(members.at("bornTimestamp").number_value());
    } else {
      born_timestamp_ = std::stoll(members.at("bornTimestamp").string_value());
    }

    if (members.at("flag").kind_case() == ProtobufWkt::Value::kNumberValue) {
      flag_ = static_cast<int32_t>(members.at("flag").number_value());
    } else {
      flag_ = std::stoi(members.at("flag").string_value());
    }

    if (members.contains("properties")) {
      properties_ = members.at("properties").string_value();
    }

    if (members.contains("reconsumeTimes")) {
      if (members.at("reconsumeTimes").kind_case() == ProtobufWkt::Value::kNumberValue) {
        reconsume_time_ = members.at("reconsumeTimes").number_value();
      } else {
        reconsume_time_ = std::stoi(members.at("reconsumeTimes").string_value());
      }
    }

    if (members.contains("unitMode")) {
      if (members.at("unitMode").kind_case() == ProtobufWkt::Value::kBoolValue) {
        unit_mode_ = members.at("unitMode").bool_value();
      } else {
        unit_mode_ = (members.at("unitMode").string_value() == std::string("true"));
      }
    }

    if (members.contains("batch")) {
      if (members.at("batch").kind_case() == ProtobufWkt::Value::kBoolValue) {
        batch_ = members.at("batch").bool_value();
      } else {
        batch_ = (members.at("batch").string_value() == std::string("true"));
      }
    }

    if (members.contains("maxReconsumeTimes")) {
      if (members.at("maxReconsumeTimes").kind_case() == ProtobufWkt::Value::kNumberValue) {
        max_reconsume_time_ = static_cast<int32_t>(members.at("maxReconsumeTimes").number_value());
      } else {
        max_reconsume_time_ = std::stoi(members.at("maxReconsumeTimes").string_value());
      }
    }
    break;
  }

  case SendMessageRequestVersion::V2: {
    ASSERT(members.contains("a"));
    ASSERT(members.contains("b"));
    ASSERT(members.contains("c"));
    ASSERT(members.contains("d"));
    ASSERT(members.contains("e"));
    ASSERT(members.contains("f"));
    ASSERT(members.contains("g"));
    ASSERT(members.contains("h"));

    producer_group_ = members.at("a").string_value();
    topic_ = members.at("b").string_value();
    default_topic_ = members.at("c").string_value();

    if (members.at("d").kind_case() == ProtobufWkt::Value::kNumberValue) {
      default_topic_queue_number_ = members.at("d").number_value();
    } else {
      default_topic_queue_number_ = std::stoi(members.at("d").string_value());
    }

    if (members.at("e").kind_case() == ProtobufWkt::Value::kNumberValue) {
      queue_id_ = members.at("e").number_value();
    } else {
      queue_id_ = std::stoi(members.at("e").string_value());
    }

    if (members.at("f").kind_case() == ProtobufWkt::Value::kNumberValue) {
      sys_flag_ = static_cast<int32_t>(members.at("f").number_value());
    } else {
      sys_flag_ = std::stoi(members.at("f").string_value());
    }

    if (members.at("g").kind_case() == ProtobufWkt::Value::kNumberValue) {
      born_timestamp_ = static_cast<int64_t>(members.at("g").number_value());
    } else {
      born_timestamp_ = std::stoll(members.at("g").string_value());
    }

    if (members.at("h").kind_case() == ProtobufWkt::Value::kNumberValue) {
      flag_ = static_cast<int32_t>(members.at("h").number_value());
    } else {
      flag_ = std::stoi(members.at("h").string_value());
    }

    if (members.contains("i")) {
      properties_ = members.at("i").string_value();
    }

    if (members.contains("j")) {
      if (members.at("j").kind_case() == ProtobufWkt::Value::kNumberValue) {
        reconsume_time_ = members.at("j").number_value();
      } else {
        reconsume_time_ = std::stoi(members.at("j").string_value());
      }
    }

    if (members.contains("k")) {
      if (members.at("k").kind_case() == ProtobufWkt::Value::kBoolValue) {
        unit_mode_ = members.at("k").bool_value();
      } else {
        unit_mode_ = (members.at("k").string_value() == std::string("true"));
      }
    }

    if (members.contains("m")) {
      if (members.at("m").kind_case() == ProtobufWkt::Value::kBoolValue) {
        batch_ = members.at("m").bool_value();
      } else {
        batch_ = (members.at("m").string_value() == std::string("true"));
      }
    }

    if (members.contains("l")) {
      if (members.at("l").kind_case() == ProtobufWkt::Value::kNumberValue) {
        max_reconsume_time_ = members.at("l").number_value();
      } else {
        max_reconsume_time_ = std::stoi(members.at("l").string_value());
      }
    }
    break;
  }
  default:
    ENVOY_LOG(error, "Unknown SendMessageRequestVersion: {}", static_cast<int>(version_));
    break;
  }
}

void SendMessageResponseHeader::encode(ProtobufWkt::Value& root) {
  auto& members = *(root.mutable_struct_value()->mutable_fields());

  ASSERT(!msg_id_.empty());
  ProtobufWkt::Value msg_id_v;
  msg_id_v.set_string_value(msg_id_.c_str(), msg_id_.length());
  members["msgId"] = msg_id_v;

  ASSERT(queue_id_ >= 0);
  ProtobufWkt::Value queue_id_v;
  queue_id_v.set_number_value(queue_id_);
  members["queueId"] = queue_id_v;

  ASSERT(queue_offset_ >= 0);
  ProtobufWkt::Value queue_offset_v;
  queue_offset_v.set_number_value(queue_offset_);
  members["queueOffset"] = queue_offset_v;

  if (!transaction_id_.empty()) {
    ProtobufWkt::Value transaction_id_v;
    transaction_id_v.set_string_value(transaction_id_.c_str(), transaction_id_.length());
    members["transactionId"] = transaction_id_v;
  }
}

void SendMessageResponseHeader::decode(const ProtobufWkt::Value& ext_fields) {
  const auto& members = ext_fields.struct_value().fields();
  ASSERT(members.contains("msgId"));
  ASSERT(members.contains("queueId"));
  ASSERT(members.contains("queueOffset"));

  msg_id_ = members.at("msgId").string_value();

  if (members.at("queueId").kind_case() == ProtobufWkt::Value::kNumberValue) {
    queue_id_ = members.at("queueId").number_value();
  } else {
    queue_id_ = std::stoi(members.at("queueId").string_value());
  }

  if (members.at("queueOffset").kind_case() == ProtobufWkt::Value::kNumberValue) {
    queue_offset_ = members.at("queueOffset").number_value();
  } else {
    queue_offset_ = std::stoll(members.at("queueOffset").string_value());
  }

  if (members.contains("transactionId")) {
    transaction_id_ = members.at("transactionId").string_value();
  }
}

void GetRouteInfoRequestHeader::encode(ProtobufWkt::Value& root) {
  auto& members = *(root.mutable_struct_value()->mutable_fields());

  ProtobufWkt::Value topic_v;
  topic_v.set_string_value(topic_.c_str(), topic_.length());
  members["topic"] = topic_v;
}

void GetRouteInfoRequestHeader::decode(const ProtobufWkt::Value& ext_fields) {
  const auto& members = ext_fields.struct_value().fields();
  ASSERT(members.contains("topic"));
  topic_ = members.at("topic").string_value();
}

void PopMessageRequestHeader::encode(ProtobufWkt::Value& root) {
  auto& members = *(root.mutable_struct_value()->mutable_fields());

  ASSERT(!consumer_group_.empty());
  ProtobufWkt::Value consumer_group_v;
  consumer_group_v.set_string_value(consumer_group_.c_str(), consumer_group_.size());
  members["consumerGroup"] = consumer_group_v;

  ASSERT(!topic_.empty());
  ProtobufWkt::Value topicNode;
  topicNode.set_string_value(topic_.c_str(), topic_.length());
  members["topic"] = topicNode;

  ProtobufWkt::Value queue_id_v;
  queue_id_v.set_number_value(queue_id_);
  members["queueId"] = queue_id_v;

  ProtobufWkt::Value max_msg_nums_v;
  max_msg_nums_v.set_number_value(max_msg_nums_);
  members["maxMsgNums"] = max_msg_nums_v;

  ProtobufWkt::Value invisible_time_v;
  invisible_time_v.set_number_value(invisible_time_);
  members["invisibleTime"] = invisible_time_v;

  ProtobufWkt::Value poll_time_v;
  poll_time_v.set_number_value(poll_time_);
  members["pollTime"] = poll_time_v;

  ProtobufWkt::Value born_time_v;
  born_time_v.set_number_value(born_time_);
  members["bornTime"] = born_time_v;

  ProtobufWkt::Value init_mode_v;
  init_mode_v.set_number_value(init_mode_);
  members["initMode"] = init_mode_v;

  if (!exp_type_.empty()) {
    ProtobufWkt::Value exp_type_v;
    exp_type_v.set_string_value(exp_type_.c_str(), exp_type_.size());
    members["expType"] = exp_type_v;
  }

  if (!exp_.empty()) {
    ProtobufWkt::Value exp_v;
    exp_v.set_string_value(exp_.c_str(), exp_.size());
    members["exp"] = exp_v;
  }
}

void PopMessageRequestHeader::decode(const ProtobufWkt::Value& ext_fields) {
  const auto& members = ext_fields.struct_value().fields();
  ASSERT(members.contains("consumerGroup"));
  ASSERT(members.contains("topic"));
  ASSERT(members.contains("queueId"));
  ASSERT(members.contains("maxMsgNums"));
  ASSERT(members.contains("invisibleTime"));
  ASSERT(members.contains("pollTime"));
  ASSERT(members.contains("bornTime"));
  ASSERT(members.contains("initMode"));

  consumer_group_ = members.at("consumerGroup").string_value();
  topic_ = members.at("topic").string_value();

  if (members.at("queueId").kind_case() == ProtobufWkt::Value::kNumberValue) {
    queue_id_ = members.at("queueId").number_value();
  } else {
    queue_id_ = std::stoi(members.at("queueId").string_value());
  }

  if (members.at("maxMsgNums").kind_case() == ProtobufWkt::Value::kNumberValue) {
    max_msg_nums_ = members.at("maxMsgNums").number_value();
  } else {
    max_msg_nums_ = std::stoi(members.at("maxMsgNums").string_value());
  }

  if (members.at("invisibleTime").kind_case() == ProtobufWkt::Value::kNumberValue) {
    invisible_time_ = members.at("invisibleTime").number_value();
  } else {
    invisible_time_ = std::stoll(members.at("invisibleTime").string_value());
  }

  if (members.at("pollTime").kind_case() == ProtobufWkt::Value::kNumberValue) {
    poll_time_ = members.at("pollTime").number_value();
  } else {
    poll_time_ = std::stoll(members.at("pollTime").string_value());
  }

  if (members.at("bornTime").kind_case() == ProtobufWkt::Value::kNumberValue) {
    born_time_ = members.at("bornTime").number_value();
  } else {
    born_time_ = std::stoll(members.at("bornTime").string_value());
  }

  if (members.at("initMode").kind_case() == ProtobufWkt::Value::kNumberValue) {
    init_mode_ = members.at("initMode").number_value();
  } else {
    init_mode_ = std::stol(members.at("initMode").string_value());
  }

  if (members.contains("expType")) {
    exp_type_ = members.at("expType").string_value();
  }

  if (members.contains("exp")) {
    exp_ = members.at("exp").string_value();
  }
}

void PopMessageResponseHeader::encode(ProtobufWkt::Value& root) {
  auto& members = *(root.mutable_struct_value()->mutable_fields());

  ProtobufWkt::Value pop_time_v;
  pop_time_v.set_number_value(pop_time_);
  members["popTime"] = pop_time_v;

  ProtobufWkt::Value invisible_time_v;
  invisible_time_v.set_number_value(invisible_time_);
  members["invisibleTime"] = invisible_time_v;

  ProtobufWkt::Value revive_qid_v;
  revive_qid_v.set_number_value(revive_qid_);
  members["reviveQid"] = revive_qid_v;

  ProtobufWkt::Value rest_num_v;
  rest_num_v.set_number_value(rest_num_);
  members["restNum"] = rest_num_v;

  if (!start_offset_info_.empty()) {
    ProtobufWkt::Value start_offset_info_v;
    start_offset_info_v.set_string_value(start_offset_info_.c_str(), start_offset_info_.size());
    members["startOffsetInfo"] = start_offset_info_v;
  }

  if (!msg_off_set_info_.empty()) {
    ProtobufWkt::Value msg_offset_info_v;
    msg_offset_info_v.set_string_value(msg_off_set_info_.c_str(), msg_off_set_info_.size());
    members["msgOffsetInfo"] = msg_offset_info_v;
  }

  if (!order_count_info_.empty()) {
    ProtobufWkt::Value order_count_info_v;
    order_count_info_v.set_string_value(order_count_info_.c_str(), order_count_info_.size());
    members["orderCountInfo"] = order_count_info_v;
  }
}

void PopMessageResponseHeader::decode(const ProtobufWkt::Value& ext_fields) {
  const auto& members = ext_fields.struct_value().fields();
  ASSERT(members.contains("popTime"));
  ASSERT(members.contains("invisibleTime"));
  ASSERT(members.contains("reviveQid"));
  ASSERT(members.contains("restNum"));

  if (members.at("popTime").kind_case() == ProtobufWkt::Value::kNumberValue) {
    pop_time_ = members.at("popTime").number_value();
  } else {
    pop_time_ = std::stoull(members.at("popTime").string_value());
  }

  if (members.at("invisibleTime").kind_case() == ProtobufWkt::Value::kNumberValue) {
    invisible_time_ = members.at("invisibleTime").number_value();
  } else {
    invisible_time_ = std::stoull(members.at("invisibleTime").string_value());
  }

  if (members.at("reviveQid").kind_case() == ProtobufWkt::Value::kNumberValue) {
    revive_qid_ = members.at("reviveQid").number_value();
  } else {
    revive_qid_ = std::stoul(members.at("reviveQid").string_value());
  }

  if (members.at("restNum").kind_case() == ProtobufWkt::Value::kNumberValue) {
    rest_num_ = members.at("restNum").number_value();
  } else {
    rest_num_ = std::stoull(members.at("restNum").string_value());
  }

  if (members.contains("startOffsetInfo")) {
    start_offset_info_ = members.at("startOffsetInfo").string_value();
  }

  if (members.contains("msgOffsetInfo")) {
    msg_off_set_info_ = members.at("msgOffsetInfo").string_value();
  }

  if (members.contains("orderCountInfo")) {
    order_count_info_ = members.at("orderCountInfo").string_value();
  }
}

void AckMessageRequestHeader::encode(ProtobufWkt::Value& root) {
  auto& members = *(root.mutable_struct_value()->mutable_fields());

  ASSERT(!consumer_group_.empty());
  ProtobufWkt::Value consumer_group_v;
  consumer_group_v.set_string_value(consumer_group_.c_str(), consumer_group_.size());
  members["consumerGroup"] = consumer_group_v;

  ASSERT(!topic_.empty());
  ProtobufWkt::Value topic_v;
  topic_v.set_string_value(topic_.c_str(), topic_.size());
  members["topic"] = topic_v;

  ASSERT(queue_id_ >= 0);
  ProtobufWkt::Value queue_id_v;
  queue_id_v.set_number_value(queue_id_);
  members["queueId"] = queue_id_v;

  ASSERT(!extra_info_.empty());
  ProtobufWkt::Value extra_info_v;
  extra_info_v.set_string_value(extra_info_.c_str(), extra_info_.size());
  members["extraInfo"] = extra_info_v;

  ASSERT(offset_ >= 0);
  ProtobufWkt::Value offset_v;
  offset_v.set_number_value(offset_);
  members["offset"] = offset_v;
}

void AckMessageRequestHeader::decode(const ProtobufWkt::Value& ext_fields) {
  const auto& members = ext_fields.struct_value().fields();
  ASSERT(members.contains("consumerGroup"));
  ASSERT(members.contains("topic"));
  ASSERT(members.contains("queueId"));
  ASSERT(members.contains("extraInfo"));
  ASSERT(members.contains("offset"));

  consumer_group_ = members.at("consumerGroup").string_value();

  topic_ = members.at("topic").string_value();

  if (members.at("queueId").kind_case() == ProtobufWkt::Value::kNumberValue) {
    queue_id_ = members.at("queueId").number_value();
  } else {
    queue_id_ = std::stoi(members.at("queueId").string_value());
  }

  extra_info_ = members.at("extraInfo").string_value();

  if (members.at("offset").kind_case() == ProtobufWkt::Value::kNumberValue) {
    offset_ = members.at("offset").number_value();
  } else {
    offset_ = std::stoll(members.at("offset").string_value());
  }
}

void UnregisterClientRequestHeader::encode(ProtobufWkt::Value& root) {
  auto& members = *(root.mutable_struct_value()->mutable_fields());

  ASSERT(!client_id_.empty());
  ProtobufWkt::Value client_id_v;
  client_id_v.set_string_value(client_id_.c_str(), client_id_.size());
  members["clientID"] = client_id_v;

  ASSERT(!producer_group_.empty() || !consumer_group_.empty());
  if (!producer_group_.empty()) {
    ProtobufWkt::Value producer_group_v;
    producer_group_v.set_string_value(producer_group_.c_str(), producer_group_.size());
    members["producerGroup"] = producer_group_v;
  }

  if (!consumer_group_.empty()) {
    ProtobufWkt::Value consumer_group_v;
    consumer_group_v.set_string_value(consumer_group_.c_str(), consumer_group_.size());
    members["consumerGroup"] = consumer_group_v;
  }
}

void UnregisterClientRequestHeader::decode(const ProtobufWkt::Value& ext_fields) {
  const auto& members = ext_fields.struct_value().fields();
  ASSERT(members.contains("clientID"));
  ASSERT(members.contains("producerGroup") || members.contains("consumerGroup"));

  client_id_ = members.at("clientID").string_value();

  if (members.contains("consumerGroup")) {
    consumer_group_ = members.at("consumerGroup").string_value();
  }

  if (members.contains("producerGroup")) {
    producer_group_ = members.at("producerGroup").string_value();
  }
}

void GetConsumerListByGroupResponseBody::encode(ProtobufWkt::Struct& root) {
  auto& members = *(root.mutable_fields());

  ProtobufWkt::Value consumer_id_list_v;
  auto member_list = consumer_id_list_v.mutable_list_value();
  for (const auto& consumerId : consumer_id_list_) {
    auto consumer_id_v = new ProtobufWkt::Value;
    consumer_id_v->set_string_value(consumerId.c_str(), consumerId.size());
    member_list->mutable_values()->AddAllocated(consumer_id_v);
  }
  members["consumerIdList"] = consumer_id_list_v;
}

bool HeartbeatData::decode(ProtobufWkt::Struct& doc) {
  const auto& members = doc.fields();
  if (!members.contains("clientID")) {
    return false;
  }

  client_id_ = members.at("clientID").string_value();

  if (members.contains("consumerDataSet")) {
    auto& consumer_data_list = members.at("consumerDataSet").list_value().values();
    for (const auto& it : consumer_data_list) {
      if (it.struct_value().fields().contains("groupName")) {
        consumer_groups_.push_back(it.struct_value().fields().at("groupName").string_value());
      }
    }
  }
  return true;
}

void HeartbeatData::encode(ProtobufWkt::Struct& root) {
  auto& members = *(root.mutable_fields());

  ProtobufWkt::Value client_id_v;
  client_id_v.set_string_value(client_id_.c_str(), client_id_.size());
  members["clientID"] = client_id_v;
}

void GetConsumerListByGroupRequestHeader::encode(ProtobufWkt::Value& root) {
  auto& members = *(root.mutable_struct_value()->mutable_fields());

  ProtobufWkt::Value consumer_group_v;
  consumer_group_v.set_string_value(consumer_group_.c_str(), consumer_group_.size());
  members["consumerGroup"] = consumer_group_v;
}

void GetConsumerListByGroupRequestHeader::decode(const ProtobufWkt::Value& ext_fields) {
  const auto& members = ext_fields.struct_value().fields();
  ASSERT(members.contains("consumerGroup"));

  consumer_group_ = members.at("consumerGroup").string_value();
}

void MetadataHelper::parseRequest(RemotingCommandPtr& request, MessageMetadataSharedPtr metadata) {
  metadata->setOneWay(request->isOneWay());
  CommandCustomHeader* custom_header = request->customHeader();

  auto route_command_custom_header = request->typedCustomHeader<RoutingCommandCustomHeader>();
  if (route_command_custom_header != nullptr) {
    metadata->setTopicName(route_command_custom_header->topic());
  }

  const uint64_t code = request->code();
  metadata->headers().addCopy(Http::LowerCaseString("code"), code);

  if (enumToInt(RequestCode::AckMessage) == code) {
    metadata->headers().addCopy(Http::LowerCaseString(RocketmqConstants::get().BrokerName),
                                custom_header->targetBrokerName());
    metadata->headers().addCopy(Http::LowerCaseString(RocketmqConstants::get().BrokerId),
                                custom_header->targetBrokerId());
  }
}

} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include <map>
#include <memory>
#include <string>

#include "envoy/common/platform.h"
#include "envoy/network/filter.h"

#include "source/common/buffer/buffer_impl.h"
#include "source/common/common/logger.h"
#include "source/common/protobuf/utility.h"

#include "contrib/rocketmq_proxy/filters/network/source/protocol.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

enum MessageVersion : uint32_t {
  V1 = (0xAABBCCDDU ^ 1880681586U) + 8U,
  V2 = (0xAABBCCDDU ^ 1880681586U) + 4U
};

class Decoder : Logger::Loggable<Logger::Id::rocketmq> {
public:
  Decoder() = default;

  ~Decoder() = default;

  /**
   * @param buffer Data buffer to decode.
   * @param underflow Indicate if buffer contains enough data in terms of protocol frame.
   * @param has_error Indicate if the decoding is successful or not.
   * @param request_code Corresponding request code if applies.
   * @return Decoded remote command.
   */
  static RemotingCommandPtr decode(Buffer::Instance& buffer, bool& underflow, bool& has_error,
                                   int request_code = 0);

  static std::string decodeTopic(Buffer::Instance& buffer, int32_t cursor);

  static int32_t decodeQueueId(Buffer::Instance& buffer, int32_t cursor);

  static int64_t decodeQueueOffset(Buffer::Instance& buffer, int32_t cursor);

  static std::string decodeMsgId(Buffer::Instance& buffer, int32_t cursor);

  static constexpr uint32_t MIN_FRAME_SIZE = 8;

  static constexpr uint32_t MAX_FRAME_SIZE = 4 * 1024 * 1024;

  static constexpr uint32_t FRAME_LENGTH_FIELD_SIZE = 4;

  static constexpr uint32_t FRAME_HEADER_LENGTH_FIELD_SIZE = 4;

private:
  static uint32_t adjustHeaderLength(uint32_t len) { return len & 0xFFFFFFu; }

  static bool isJsonHeader(uint32_t len) { return (len >> 24u) == 0; }

  static CommandCustomHeaderPtr decodeExtHeader(RequestCode code,
                                                ProtobufWkt::Struct& header_struct);

  static CommandCustomHeaderPtr decodeResponseExtHeader(ResponseCode response_code,
                                                        ProtobufWkt::Struct& header_struct,
                                                        RequestCode request_code);

  static bool isComplete(Buffer::Instance& buffer, int32_t cursor);
};

class Encoder {
public:
  static void encode(const RemotingCommandPtr& command, Buffer::Instance& buffer);
};

} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/rocketmq_proxy/filters/network/source/active_message.h"

#include "envoy/upstream/cluster_manager.h"

#include "source/common/common/empty_string.h"
#include "source/common/common/enum_to_int.h"
#include "source/common/protobuf/utility.h"
#include "source/extensions/filters/network/well_known_names.h"

#include "absl/strings/match.h"
#include "contrib/rocketmq_proxy/filters/network/source/conn_manager.h"
#include "contrib/rocketmq_proxy/filters/network/source/constant.h"
#include "contrib/rocketmq_proxy/filters/network/source/topic_route.h"

using Envoy::Tcp::ConnectionPool::ConnectionDataPtr;

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

ActiveMessage::ActiveMessage(ConnectionManager& conn_manager, RemotingCommandPtr&& request)
    : connection_manager_(conn_manager), request_(std::move(request)) {
  metadata_ = std::make_shared<MessageMetadata>();
  MetadataHelper::parseRequest(request_, metadata_);
  updateActiveRequestStats();
}

ActiveMessage::~ActiveMessage() { updateActiveRequestStats(false); }

void ActiveMessage::createFilterChain() { router_ = connection_manager_.config().createRouter(); }

void ActiveMessage::sendRequestToUpstream() {
  if (!router_) {
    createFilterChain();
  }
  router_->sendRequestToUpstream(*this);
}

Router::RouteConstSharedPtr ActiveMessage::route() {
  if (cached_route_) {
    return cached_route_.value();
  }
  const std::string& topic_name = metadata_->topicName();
  ENVOY_LOG(trace, "fetch route for topic: {}", topic_name);
  Router::RouteConstSharedPtr route = connection_manager_.config().routerConfig().route(*metadata_);
  cached_route_ = route;
  return cached_route_.value();
}

void ActiveMessage::onError(absl::string_view error_message) {
  connection_manager_.onError(request_, error_message);
}

const RemotingCommandPtr& ActiveMessage::downstreamRequest() const { return request_; }

void ActiveMessage::fillAckMessageDirective(Buffer::Instance& buffer, const std::string& group,
                                            const std::string& topic,
                                            const AckMessageDirective& directive) {
  int32_t cursor = 0;
  const int32_t buffer_length = buffer.length();
  while (cursor < buffer_length) {
    auto frame_length = buffer.peekBEInt<int32_t>(cursor);
    std::string decoded_topic = Decoder::decodeTopic(buffer, cursor);
    ENVOY_LOG(trace, "Process a message: consumer group: {}, topic: {}, messageId: {}",
              decoded_topic, group, Decoder::decodeMsgId(buffer, cursor));
    if (!absl::StartsWith(decoded_topic, RetryTopicPrefix) && decoded_topic != topic) {
      ENVOY_LOG(warn,
                "Decoded topic from pop-response does not equal to request. Decoded topic: "
                "{}, request topic: {}, message ID: {}",
                decoded_topic, topic, Decoder::decodeMsgId(buffer, cursor));
    }

    /*
     * Sometimes, client SDK may used -1 for queue-id in the pop request so that broker servers
     * are allowed to lookup all queues it serves. So we need to use the actual queue Id from
     * response body.
     */
    int32_t queue_id = Decoder::decodeQueueId(buffer, cursor);
    int64_t queue_offset = Decoder::decodeQueueOffset(buffer, cursor);

    std::string key = fmt::format("{}-{}-{}-{}", group, decoded_topic, queue_id, queue_offset);
    connection_manager_.insertAckDirective(key, directive);
    ENVOY_LOG(
        debug,
        "Insert an ack directive. Consumer group: {}, topic: {}, queue Id: {}, queue offset: {}",
        group, topic, queue_id, queue_offset);
    cursor += frame_length;
  }
}

void ActiveMessage::sendResponseToDownstream() {
  if (request_->code() == enumToSignedInt(RequestCode::PopMessage)) {
    // Fill ack message directive
    auto pop_header = request_->typedCustomHeader<PopMessageRequestHeader>();
    AckMessageDirective directive(pop_header->targetBrokerName(), pop_header->targetBrokerId(),
                                  connection_manager_.timeSource().monotonicTime());
    ENVOY_LOG(trace, "Receive pop response from broker name: {}, broker ID: {}",
              pop_header->targetBrokerName(), pop_header->targetBrokerId());
    fillAckMessageDirective(response_->body(), pop_header->consumerGroup(), pop_header->topic(),
                            directive);
  }

  // If acknowledgment of the message is successful, we need to erase the ack directive from
  // manager.
  if (request_->code() == enumToSignedInt(RequestCode::AckMessage) &&
      response_->code() == enumToSignedInt(ResponseCode::Success)) {
    auto ack_header = request_->typedCustomHeader<AckMessageRequestHeader>();
    connection_manager_.eraseAckDirective(ack_header->directiveKey());
  }

  if (response_) {
    response_->opaque(request_->opaque());
    connection_manager_.sendResponseToDownstream(response_);
  }
}

void ActiveMessage::fillBrokerData(std::vector<BrokerData>& list, const std::string& cluster,
                                   const std::string& broker_name, int64_t broker_id,
                                   const std::string& address) {
  bool found = false;
  for (auto& entry : list) {
    if (entry.cluster() == cluster && entry.brokerName() == broker_name) {
      found = true;
      if (entry.brokerAddresses().find(broker_id) != entry.brokerAddresses().end()) {
        ENVOY_LOG(warn, "Duplicate broker_id found. Broker ID: {}, address: {}", broker_id,
                  address);
        continue;
      } else {
        entry.brokerAddresses()[broker_id] = address;
      }
    }
  }

  if (!found) {
    absl::node_hash_map<int64_t, std::string> addresses;
    addresses.emplace(broker_id, address);

    list.emplace_back(BrokerData(cluster, broker_name, std::move(addresses)));
  }
}

void ActiveMessage::onQueryTopicRoute() {
  std::string cluster_name;
  ASSERT(metadata_->hasTopicName());
  const std::string& topic_name = metadata_->topicName();
  Upstream::ThreadLocalCluster* cluster = nullptr;
  Router::RouteConstSharedPtr route = this->route();
  if (route) {
    cluster_name = route->routeEntry()->clusterName();
    Upstream::ClusterManager& cluster_manager = connection_manager_.config().clusterManager();
    cluster = cluster_manager.getThreadLocalCluster(cluster_name);
  }
  if (cluster) {
    ENVOY_LOG(trace, "Envoy has an operating cluster {} for topic {}", cluster_name, topic_name);
    std::vector<QueueData> queue_data_list;
    std::vector<BrokerData> broker_data_list;
    for (auto& host_set : cluster->prioritySet().hostSetsPerPriority()) {
      if (host_set->hosts().empty()) {
        continue;
      }
      for (const auto& host : host_set->hosts()) {
        std::string broker_address = host->address()->asString();
        auto& filter_metadata = host->metadata()->filter_metadata();
        const auto filter_it = filter_metadata.find(NetworkFilterNames::get().RocketmqProxy);
        ASSERT(filter_it != filter_metadata.end());
        const auto& metadata_fields = filter_it->second.fields();
        ASSERT(metadata_fields.contains(RocketmqConstants::get().BrokerName));
        std::string broker_name =
            metadata_fields.at(RocketmqConstants::get().BrokerName).string_value();
        ASSERT(metadata_fields.contains(RocketmqConstants::get().ClusterName));
        std::string broker_cluster_name =
            metadata_fields.at(RocketmqConstants::get().ClusterName).string_value();
        // Proto3 will ignore the field if the value is zero.
        int32_t read_queue_num = 0;
        if (metadata_fields.contains(RocketmqConstants::get().ReadQueueNum)) {
          read_queue_num = static_cast<int32_t>(
              metadata_fields.at(RocketmqConstants::get().ReadQueueNum).number_value());
        }
        int32_t write_queue_num = 0;
        if (metadata_fields.contains(RocketmqConstants::get().WriteQueueNum)) {
          write_queue_num = static_cast<int32_t>(
              metadata_fields.at(RocketmqConstants::get().WriteQueueNum).number_value());
        }
        int32_t perm = 0;
        if (metadata_fields.contains(RocketmqConstants::get().Perm)) {
          perm = static_cast<int32_t>(
              metadata_fields.at(RocketmqConstants::get().Perm).number_value());
        }
        int32_t broker_id = 0;
        if (metadata_fields.contains(RocketmqConstants::get().BrokerId)) {
          broker_id = static_cast<int32_t>(
              metadata_fields.at(RocketmqConstants::get().BrokerId).number_value());
        }
        queue_data_list.emplace_back(QueueData(broker_name, read_queue_num, write_queue_num, perm));
        if (connection_manager_.config().developMode()) {
          ENVOY_LOG(trace, "Develop mode, return proxy address to replace all broker addresses so "
                           "that L4 network rewrite is not required");
          fillBrokerData(broker_data_list, broker_cluster_name, broker_name, broker_id,
                         connection_manager_.config().proxyAddress());
        } else {
          fillBrokerData(broker_data_list, broker_cluster_name, broker_name, broker_id,
                         broker_address);
        }
      }
    }
    ENVOY_LOG(trace, "Prepare TopicRouteData for {} OK", topic_name);
    TopicRouteData topic_route_data(std::move(queue_data_list), std::move(broker_data_list));
    ProtobufWkt::Struct data_struct;
    topic_route_data.encode(data_struct);
    std::string json = MessageUtil::getJsonStringFromMessageOrError(data_struct);
    ENVOY_LOG(trace, "Serialize TopicRouteData for {} OK:\n{}", cluster_name, json);
    RemotingCommandPtr response = std::make_unique<RemotingCommand>(
        static_cast<int>(ResponseCode::Success), downstreamRequest()->version(),
        downstreamRequest()->opaque());
    response->markAsResponse();
    response->body().add(json);
    connection_manager_.sendResponseToDownstream(response);
  } else {
    onError("Cluster is not available");
    ENVOY_LOG(warn, "Cluster for topic {} is not available", topic_name);
  }
  onReset();
}

void ActiveMessage::onReset() { connection_manager_.deferredDelete(*this); }

bool ActiveMessage::onUpstreamData(Envoy::Buffer::Instance& data, bool end_stream,
                                   ConnectionDataPtr& conn_data) {
  bool underflow = false;
  bool has_error = false;
  response_ = Decoder::decode(data, underflow, has_error, downstreamRequest()->code());
  if (underflow && !end_stream) {
    ENVOY_LOG(trace, "Wait for more data from upstream");
    return false;
  }

  if (enumToSignedInt(RequestCode::PopMessage) == request_->code() && router_ != nullptr) {
    recordPopRouteInfo(router_->upstreamHost());
  }

  connection_manager_.stats().response_.inc();
  if (!has_error) {
    connection_manager_.stats().response_decoding_success_.inc();
    // Relay response to downstream
    sendResponseToDownstream();
  } else {
    ENVOY_LOG(error, "Failed to decode response for opaque: {}, close immediately.",
              downstreamRequest()->opaque());
    onError("Failed to decode response from upstream");
    connection_manager_.stats().response_decoding_error_.inc();
    conn_data->connection().close(Network::ConnectionCloseType::NoFlush);
  }

  if (end_stream) {
    conn_data->connection().close(Network::ConnectionCloseType::NoFlush);
  }
  return true;
}

void ActiveMessage::recordPopRouteInfo(Upstream::HostDescriptionConstSharedPtr host_description) {
  if (host_description) {
    auto host_metadata = host_description->metadata();
    auto filter_metadata = host_metadata->filter_metadata();
    const auto filter_it = filter_metadata.find(NetworkFilterNames::get().RocketmqProxy);
    ASSERT(filter_it != filter_metadata.end());
    const auto& metadata_fields = filter_it->second.fields();
    ASSERT(metadata_fields.contains(RocketmqConstants::get().BrokerName));
    std::string broker_name =
        metadata_fields.at(RocketmqConstants::get().BrokerName).string_value();
    // Proto3 will ignore the field if the value is zero.
    int32_t broker_id = 0;
    if (metadata_fields.contains(RocketmqConstants::get().BrokerId)) {
      broker_id = static_cast<int32_t>(
          metadata_fields.at(RocketmqConstants::get().BrokerId).number_value());
    }
    // Tag the request with upstream host metadata: broker-name, broker-id
    auto custom_header = request_->typedCustomHeader<CommandCustomHeader>();
    custom_header->targetBrokerName(broker_name);
    custom_header->targetBrokerId(broker_id);
  }
}

void ActiveMessage::updateActiveRequestStats(bool is_inc) {
  if (is_inc) {
    connection_manager_.stats().request_active_.inc();
  } else {
    connection_manager_.stats().request_active_.dec();
  }
  auto code = static_cast<RequestCode>(request_->code());
  switch (code) {
  case RequestCode::PopMessage: {
    if (is_inc) {
      connection_manager_.stats().pop_message_active_.inc();
    } else {
      connection_manager_.stats().pop_message_active_.dec();
    }
    break;
  }
  case RequestCode::SendMessage: {
    if (is_inc) {
      connection_manager_.stats().send_message_v1_active_.inc();
    } else {
      connection_manager_.stats().send_message_v1_active_.dec();
    }
    break;
  }
  case RequestCode::SendMessageV2: {
    if (is_inc) {
      connection_manager_.stats().send_message_v2_active_.inc();
    } else {
      connection_manager_.stats().send_message_v2_active_.dec();
    }
    break;
  }
  case RequestCode::GetRouteInfoByTopic: {
    if (is_inc) {
      connection_manager_.stats().get_topic_route_active_.inc();
    } else {
      connection_manager_.stats().get_topic_route_active_.dec();
    }
    break;
  }
  default:
    break;
  }
}

} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
load(
    "//bazel:envoy_build_system.bzl",
    "envoy_cc_contrib_extension",
    "envoy_cc_library",
    "envoy_contrib_package",
)

licenses(["notice"])  # Apache 2

envoy_contrib_package()

envoy_cc_library(
    name = "constant",
    hdrs = ["constant.h"],
    deps = ["//source/common/singleton:const_singleton"],
)

envoy_cc_library(
    name = "stats_interface",
    hdrs = ["stats.h"],
    deps = [
        "//envoy/stats:stats_interface",
        "//envoy/stats:stats_macros",
    ],
)

envoy_cc_library(
    name = "rocketmq_interface",
    hdrs = [
        "topic_route.h",
    ],
    deps = [
        "//source/common/protobuf:utility_lib",
    ],
)

envoy_cc_library(
    name = "rocketmq_lib",
    srcs = [
        "topic_route.cc",
    ],
    deps = [
        ":rocketmq_interface",
    ],
)

envoy_cc_library(
    name = "protocol_interface",
    hdrs = ["protocol.h"],
    deps = [
        ":metadata_lib",
        "//source/common/buffer:buffer_lib",
        "//source/common/protobuf:utility_lib",
    ],
)

envoy_cc_library(
    name = "protocol_lib",
    srcs = ["protocol.cc"],
    deps = [
        ":constant",
        ":protocol_interface",
        "//source/common/common:enum_to_int",
    ],
)

envoy_cc_library(
    name = "codec_lib",
    srcs = [
        "codec.cc",
    ],
    hdrs = [
        "codec.h",
    ],
    deps = [
        ":protocol_lib",
        "//envoy/network:filter_interface",
        "//source/common/protobuf:utility_lib",
    ],
)

envoy_cc_library(
    name = "conn_manager_lib",
    srcs = [
        "active_message.cc",
        "conn_manager.cc",
    ],
    hdrs = [
        "active_message.h",
        "conn_manager.h",
    ],
    deps = [
        ":codec_lib",
        ":constant",
        ":protocol_lib",
        ":rocketmq_lib",
        ":stats_interface",
        "//contrib/rocketmq_proxy/filters/network/source/router:router_interface",
        "//envoy/buffer:buffer_interface",
        "//envoy/event:dispatcher_interface",
        "//envoy/network:connection_interface",
        "//envoy/tcp:conn_pool_interface",
        "//envoy/upstream:cluster_manager_interface",
        "//source/common/buffer:buffer_lib",
        "//source/common/common:assert_lib",
        "//source/common/common:empty_string",
        "//source/common/common:enum_to_int",
        "//source/common/common:linked_object",
        "//source/common/protobuf:utility_lib",
        "//source/common/stats:timespan_lib",
        "//source/common/upstream:load_balancer_lib",
        "//source/extensions/filters/network:well_known_names",
        "@envoy_api//contrib/envoy/extensions/filters/network/rocketmq_proxy/v3:pkg_cc_proto",
    ],
)

envoy_cc_contrib_extension(
    name = "config",
    srcs = [
        "config.cc",
    ],
    hdrs = [
        "config.h",
    ],
    deps = [
        ":conn_manager_lib",
        "//contrib/rocketmq_proxy/filters/network/source/router:route_matcher",
        "//contrib/rocketmq_proxy/filters/network/source/router:router_lib",
        "//envoy/registry",
        "//envoy/server:filter_config_interface",
        "//source/common/common:logger_lib",
        "//source/common/common:minimal_logger_lib",
        "//source/common/config:utility_lib",
        "//source/extensions/filters/network/common:factory_base_lib",
        "@envoy_api//contrib/envoy/extensions/filters/network/rocketmq_proxy/v3:pkg_cc_proto",
    ],
)

envoy_cc_library(
    name = "metadata_lib",
    hdrs = ["metadata.h"],
    external_deps = ["abseil_optional"],
    deps = [
        "//source/common/http:header_map_lib",
    ],
)
#include "contrib/rocketmq_proxy/filters/network/source/topic_route.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

void QueueData::encode(ProtobufWkt::Struct& data_struct) {
  auto* fields = data_struct.mutable_fields();

  ProtobufWkt::Value broker_name_v;
  broker_name_v.set_string_value(broker_name_);
  (*fields)["brokerName"] = broker_name_v;

  ProtobufWkt::Value read_queue_num_v;
  read_queue_num_v.set_number_value(read_queue_nums_);
  (*fields)["readQueueNums"] = read_queue_num_v;

  ProtobufWkt::Value write_queue_num_v;
  write_queue_num_v.set_number_value(write_queue_nums_);
  (*fields)["writeQueueNums"] = write_queue_num_v;

  ProtobufWkt::Value perm_v;
  perm_v.set_number_value(perm_);
  (*fields)["perm"] = perm_v;
}

void BrokerData::encode(ProtobufWkt::Struct& data_struct) {
  auto& members = *(data_struct.mutable_fields());

  ProtobufWkt::Value cluster_v;
  cluster_v.set_string_value(cluster_);
  members["cluster"] = cluster_v;

  ProtobufWkt::Value broker_name_v;
  broker_name_v.set_string_value(broker_name_);
  members["brokerName"] = broker_name_v;

  if (!broker_addrs_.empty()) {
    ProtobufWkt::Value brokerAddrsNode;
    auto& brokerAddrsMembers = *(brokerAddrsNode.mutable_struct_value()->mutable_fields());
    for (auto& entry : broker_addrs_) {
      ProtobufWkt::Value address_v;
      address_v.set_string_value(entry.second);
      brokerAddrsMembers[std::to_string(entry.first)] = address_v;
    }
    members["brokerAddrs"] = brokerAddrsNode;
  }
}

void TopicRouteData::encode(ProtobufWkt::Struct& data_struct) {
  auto* fields = data_struct.mutable_fields();

  if (!queue_data_.empty()) {
    ProtobufWkt::ListValue queue_data_list_v;
    for (auto& queueData : queue_data_) {
      queueData.encode(data_struct);
      queue_data_list_v.add_values()->mutable_struct_value()->CopyFrom(data_struct);
    }
    (*fields)["queueDatas"].mutable_list_value()->CopyFrom(queue_data_list_v);
  }

  if (!broker_data_.empty()) {
    ProtobufWkt::ListValue broker_data_list_v;
    for (auto& brokerData : broker_data_) {
      brokerData.encode(data_struct);
      broker_data_list_v.add_values()->mutable_struct_value()->CopyFrom(data_struct);
    }
    (*fields)["brokerDatas"].mutable_list_value()->CopyFrom(broker_data_list_v);
  }
}

} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include <string>
#include <vector>

#include "source/common/protobuf/utility.h"

#include "absl/container/node_hash_map.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {
class QueueData {
public:
  QueueData(const std::string& broker_name, int32_t read_queue_num, int32_t write_queue_num,
            int32_t perm)
      : broker_name_(broker_name), read_queue_nums_(read_queue_num),
        write_queue_nums_(write_queue_num), perm_(perm) {}

  void encode(ProtobufWkt::Struct& data_struct);

  const std::string& brokerName() const { return broker_name_; }

  int32_t readQueueNum() const { return read_queue_nums_; }

  int32_t writeQueueNum() const { return write_queue_nums_; }

  int32_t perm() const { return perm_; }

private:
  std::string broker_name_;
  int32_t read_queue_nums_;
  int32_t write_queue_nums_;
  int32_t perm_;
};

class BrokerData {
public:
  BrokerData(const std::string& cluster, const std::string& broker_name,
             absl::node_hash_map<int64_t, std::string>&& broker_addrs)
      : cluster_(cluster), broker_name_(broker_name), broker_addrs_(broker_addrs) {}

  void encode(ProtobufWkt::Struct& data_struct);

  const std::string& cluster() const { return cluster_; }

  const std::string& brokerName() const { return broker_name_; }

  absl::node_hash_map<int64_t, std::string>& brokerAddresses() { return broker_addrs_; }

private:
  std::string cluster_;
  std::string broker_name_;
  absl::node_hash_map<int64_t, std::string> broker_addrs_;
};

class TopicRouteData {
public:
  void encode(ProtobufWkt::Struct& data_struct);

  TopicRouteData() = default;

  TopicRouteData(std::vector<QueueData>&& queue_data, std::vector<BrokerData>&& broker_data)
      : queue_data_(queue_data), broker_data_(broker_data) {}

  std::vector<QueueData>& queueData() { return queue_data_; }

  std::vector<BrokerData>& brokerData() { return broker_data_; }

private:
  std::vector<QueueData> queue_data_;
  std::vector<BrokerData> broker_data_;
};

} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include <string>

#include "envoy/stats/scope.h"
#include "envoy/stats/stats_macros.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

/**
 * All rocketmq filter stats. @see stats_macros.h
 */
#define ALL_ROCKETMQ_FILTER_STATS(COUNTER, GAUGE, HISTOGRAM)                                       \
  COUNTER(request)                                                                                 \
  COUNTER(request_decoding_error)                                                                  \
  COUNTER(request_decoding_success)                                                                \
  COUNTER(response)                                                                                \
  COUNTER(response_decoding_error)                                                                 \
  COUNTER(response_decoding_success)                                                               \
  COUNTER(response_error)                                                                          \
  COUNTER(response_success)                                                                        \
  COUNTER(heartbeat)                                                                               \
  COUNTER(unregister)                                                                              \
  COUNTER(get_topic_route)                                                                         \
  COUNTER(send_message_v1)                                                                         \
  COUNTER(send_message_v2)                                                                         \
  COUNTER(pop_message)                                                                             \
  COUNTER(ack_message)                                                                             \
  COUNTER(get_consumer_list)                                                                       \
  COUNTER(maintenance_failure)                                                                     \
  GAUGE(request_active, Accumulate)                                                                \
  GAUGE(send_message_v1_active, Accumulate)                                                        \
  GAUGE(send_message_v2_active, Accumulate)                                                        \
  GAUGE(pop_message_active, Accumulate)                                                            \
  GAUGE(get_topic_route_active, Accumulate)                                                        \
  GAUGE(send_message_pending, Accumulate)                                                          \
  GAUGE(pop_message_pending, Accumulate)                                                           \
  GAUGE(get_topic_route_pending, Accumulate)                                                       \
  GAUGE(total_pending, Accumulate)                                                                 \
  HISTOGRAM(request_time_ms, Milliseconds)

/**
 * Struct definition for all rocketmq proxy stats. @see stats_macros.h
 */
struct RocketmqFilterStats {
  ALL_ROCKETMQ_FILTER_STATS(GENERATE_COUNTER_STRUCT, GENERATE_GAUGE_STRUCT,
                            GENERATE_HISTOGRAM_STRUCT)

  static RocketmqFilterStats generateStats(const std::string& prefix, Stats::Scope& scope) {
    return RocketmqFilterStats{ALL_ROCKETMQ_FILTER_STATS(POOL_COUNTER_PREFIX(scope, prefix),
                                                         POOL_GAUGE_PREFIX(scope, prefix),
                                                         POOL_HISTOGRAM_PREFIX(scope, prefix))};
  }
};

} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/rocketmq_proxy/filters/network/source/conn_manager.h"

#include "envoy/buffer/buffer.h"
#include "envoy/network/connection.h"

#include "source/common/common/enum_to_int.h"
#include "source/common/protobuf/utility.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

ConsumerGroupMember::ConsumerGroupMember(absl::string_view client_id,
                                         ConnectionManager& conn_manager)
    : client_id_(client_id.data(), client_id.size()), connection_manager_(&conn_manager),
      last_(connection_manager_->time_source_.monotonicTime()) {}

void ConsumerGroupMember::refresh() { last_ = connection_manager_->time_source_.monotonicTime(); }

bool ConsumerGroupMember::expired() const {
  auto duration = connection_manager_->time_source_.monotonicTime() - last_;
  return std::chrono::duration_cast<std::chrono::milliseconds>(duration).count() >
         connection_manager_->config().transientObjectLifeSpan().count();
}

ConnectionManager::ConnectionManager(Config& config, TimeSource& time_source)
    : config_(config), time_source_(time_source), stats_(config.stats()) {}

Envoy::Network::FilterStatus ConnectionManager::onData(Envoy::Buffer::Instance& data,
                                                       bool end_stream) {
  ENVOY_CONN_LOG(trace, "rocketmq_proxy: received {} bytes.", read_callbacks_->connection(),
                 data.length());
  request_buffer_.move(data);
  dispatch();
  if (end_stream) {
    resetAllActiveMessages("Connection to downstream is closed");
    read_callbacks_->connection().close(Envoy::Network::ConnectionCloseType::FlushWrite);
  }
  return Network::FilterStatus::StopIteration;
}

void ConnectionManager::dispatch() {
  if (request_buffer_.length() < Decoder::MIN_FRAME_SIZE) {
    ENVOY_CONN_LOG(warn, "rocketmq_proxy: request buffer length is less than min frame size: {}",
                   read_callbacks_->connection(), request_buffer_.length());
    return;
  }

  bool underflow = false;
  bool has_decode_error = false;
  while (!underflow) {
    RemotingCommandPtr request = Decoder::decode(request_buffer_, underflow, has_decode_error);
    if (underflow) {
      // Wait for more data
      break;
    }
    stats_.request_.inc();

    // Decode error, we need to close connection immediately.
    if (has_decode_error) {
      ENVOY_CONN_LOG(error, "Failed to decode request, close connection immediately",
                     read_callbacks_->connection());
      stats_.request_decoding_error_.inc();
      resetAllActiveMessages("Failed to decode data from downstream. Close connection immediately");
      read_callbacks_->connection().close(Envoy::Network::ConnectionCloseType::FlushWrite);
      return;
    } else {
      stats_.request_decoding_success_.inc();
    }

    switch (static_cast<RequestCode>(request->code())) {
    case RequestCode::GetRouteInfoByTopic: {
      ENVOY_CONN_LOG(trace, "GetTopicRoute request, code: {}, opaque: {}",
                     read_callbacks_->connection(), request->code(), request->opaque());
      onGetTopicRoute(std::move(request));
    } break;

    case RequestCode::UnregisterClient: {
      ENVOY_CONN_LOG(trace, "process unregister client request, code: {}, opaque: {}",
                     read_callbacks_->connection(), request->code(), request->opaque());
      onUnregisterClient(std::move(request));
    } break;

    case RequestCode::SendMessage: {
      ENVOY_CONN_LOG(trace, "SendMessage request, code: {}, opaque: {}",
                     read_callbacks_->connection(), request->code(), request->opaque());
      onSendMessage(std::move(request));
      stats_.send_message_v1_.inc();
    } break;

    case RequestCode::SendMessageV2: {
      ENVOY_CONN_LOG(trace, "SendMessage request, code: {}, opaque: {}",
                     read_callbacks_->connection(), request->code(), request->opaque());
      onSendMessage(std::move(request));
      stats_.send_message_v2_.inc();
    } break;

    case RequestCode::GetConsumerListByGroup: {
      ENVOY_CONN_LOG(trace, "GetConsumerListByGroup request, code: {}, opaque: {}",
                     read_callbacks_->connection(), request->code(), request->opaque());
      onGetConsumerListByGroup(std::move(request));
    } break;

    case RequestCode::PopMessage: {
      ENVOY_CONN_LOG(trace, "PopMessage request, code: {}, opaque: {}",
                     read_callbacks_->connection(), request->code(), request->opaque());
      onPopMessage(std::move(request));
      stats_.pop_message_.inc();
    } break;

    case RequestCode::AckMessage: {
      ENVOY_CONN_LOG(trace, "AckMessage request, code: {}, opaque: {}",
                     read_callbacks_->connection(), request->code(), request->opaque());
      onAckMessage(std::move(request));
      stats_.ack_message_.inc();
    } break;

    case RequestCode::HeartBeat: {
      ENVOY_CONN_LOG(trace, "Heartbeat request, opaque: {}", read_callbacks_->connection(),
                     request->opaque());
      onHeartbeat(std::move(request));
    } break;

    default: {
      ENVOY_CONN_LOG(warn, "Request code {} not supported yet", read_callbacks_->connection(),
                     request->code());
      std::string error_msg("Request not supported");
      onError(request, error_msg);
    } break;
    }
  }
}

void ConnectionManager::purgeDirectiveTable() {
  auto current = time_source_.monotonicTime();
  for (auto it = ack_directive_table_.begin(); it != ack_directive_table_.end();) {
    auto duration = current - it->second.creation_time_;
    if (std::chrono::duration_cast<std::chrono::milliseconds>(duration).count() >
        config_.transientObjectLifeSpan().count()) {
      ack_directive_table_.erase(it++);
    } else {
      it++;
    }
  }
}

void ConnectionManager::sendResponseToDownstream(RemotingCommandPtr& response) {
  Buffer::OwnedImpl buffer;
  Encoder::encode(response, buffer);
  if (read_callbacks_->connection().state() == Network::Connection::State::Open) {
    ENVOY_CONN_LOG(trace, "Write response to downstream. Opaque: {}", read_callbacks_->connection(),
                   response->opaque());
    read_callbacks_->connection().write(buffer, false);
  } else {
    ENVOY_CONN_LOG(error, "Send response to downstream failed as connection is no longer open",
                   read_callbacks_->connection());
  }
}

void ConnectionManager::onGetTopicRoute(RemotingCommandPtr request) {
  createActiveMessage(request).onQueryTopicRoute();
  stats_.get_topic_route_.inc();
}

void ConnectionManager::onHeartbeat(RemotingCommandPtr request) {
  const std::string& body = request->body().toString();

  purgeDirectiveTable();

  ProtobufWkt::Struct body_struct;
  try {
    MessageUtil::loadFromJson(body, body_struct);
  } catch (std::exception& e) {
    ENVOY_LOG(warn, "Failed to decode heartbeat body. Error message: {}", e.what());
    return;
  }

  HeartbeatData heartbeatData;
  if (!heartbeatData.decode(body_struct)) {
    ENVOY_LOG(warn, "Failed to decode heartbeat data");
    return;
  }

  for (const auto& group : heartbeatData.consumerGroups()) {
    addOrUpdateGroupMember(group, heartbeatData.clientId());
  }

  RemotingCommandPtr response = std::make_unique<RemotingCommand>();
  response->code(enumToSignedInt(ResponseCode::Success));
  response->opaque(request->opaque());
  response->remark("Heartbeat OK");
  response->markAsResponse();
  sendResponseToDownstream(response);
  stats_.heartbeat_.inc();
}

void ConnectionManager::addOrUpdateGroupMember(absl::string_view group,
                                               absl::string_view client_id) {
  ENVOY_LOG(trace, "#addOrUpdateGroupMember. Group: {}, client ID: {}", group, client_id);
  auto search = group_members_.find(group);
  if (search == group_members_.end()) {
    std::vector<ConsumerGroupMember> members;
    members.emplace_back(ConsumerGroupMember(client_id, *this));
    group_members_.emplace(std::string(group.data(), group.size()), members);
  } else {
    std::vector<ConsumerGroupMember>& members = search->second;
    for (auto it = members.begin(); it != members.end();) {
      if (it->clientId() == client_id) {
        it->refresh();
        ++it;
      } else if (it->expired()) {
        it = members.erase(it);
      } else {
        ++it;
      }
    }
    if (members.empty()) {
      group_members_.erase(search);
    }
  }
}

void ConnectionManager::onUnregisterClient(RemotingCommandPtr request) {
  auto header = request->typedCustomHeader<UnregisterClientRequestHeader>();
  ASSERT(header != nullptr);
  ASSERT(!header->clientId().empty());
  ENVOY_LOG(trace, "Unregister client ID: {}, producer group: {}, consumer group: {}",
            header->clientId(), header->producerGroup(), header->consumerGroup());

  if (!header->consumerGroup().empty()) {
    auto search = group_members_.find(header->consumerGroup());
    if (search != group_members_.end()) {
      std::vector<ConsumerGroupMember>& members = search->second;
      for (auto it = members.begin(); it != members.end();) {
        if (it->clientId() == header->clientId()) {
          it = members.erase(it);
        } else if (it->expired()) {
          it = members.erase(it);
        } else {
          ++it;
        }
      }
      if (members.empty()) {
        group_members_.erase(search);
      }
    }
  }

  RemotingCommandPtr response = std::make_unique<RemotingCommand>(
      enumToSignedInt(ResponseCode::Success), request->version(), request->opaque());
  response->markAsResponse();
  response->remark("Envoy unregister client OK.");
  sendResponseToDownstream(response);
  stats_.unregister_.inc();
}

void ConnectionManager::onError(RemotingCommandPtr& request, absl::string_view error_msg) {
  Buffer::OwnedImpl buffer;
  RemotingCommandPtr response = std::make_unique<RemotingCommand>();
  response->markAsResponse();
  response->opaque(request->opaque());
  response->code(enumToSignedInt(ResponseCode::SystemError));
  response->remark(error_msg);
  sendResponseToDownstream(response);
}

void ConnectionManager::onSendMessage(RemotingCommandPtr request) {
  ENVOY_CONN_LOG(trace, "#onSendMessage, opaque: {}", read_callbacks_->connection(),
                 request->opaque());
  auto header = request->typedCustomHeader<SendMessageRequestHeader>();
  header->queueId(-1);
  createActiveMessage(request).sendRequestToUpstream();
}

void ConnectionManager::onGetConsumerListByGroup(RemotingCommandPtr request) {
  auto requestExtHeader = request->typedCustomHeader<GetConsumerListByGroupRequestHeader>();

  ASSERT(requestExtHeader != nullptr);
  ASSERT(!requestExtHeader->consumerGroup().empty());

  ENVOY_LOG(trace, "#onGetConsumerListByGroup, consumer group: {}",
            requestExtHeader->consumerGroup());

  auto search = group_members_.find(requestExtHeader->consumerGroup());
  GetConsumerListByGroupResponseBody getConsumerListByGroupResponseBody;
  if (search != group_members_.end()) {
    std::vector<ConsumerGroupMember>& members = search->second;
    std::sort(members.begin(), members.end());
    for (const auto& member : members) {
      getConsumerListByGroupResponseBody.add(member.clientId());
    }
  } else {
    ENVOY_LOG(warn, "There is no consumer belongs to consumer_group: {}",
              requestExtHeader->consumerGroup());
  }
  ProtobufWkt::Struct body_struct;

  getConsumerListByGroupResponseBody.encode(body_struct);

  RemotingCommandPtr response = std::make_unique<RemotingCommand>(
      enumToSignedInt(ResponseCode::Success), request->version(), request->opaque());
  response->markAsResponse();
  std::string json = MessageUtil::getJsonStringFromMessageOrError(body_struct);
  response->body().add(json);
  ENVOY_LOG(trace, "GetConsumerListByGroup respond with body: {}", json);

  sendResponseToDownstream(response);
  stats_.get_consumer_list_.inc();
}

void ConnectionManager::onPopMessage(RemotingCommandPtr request) {
  auto header = request->typedCustomHeader<PopMessageRequestHeader>();
  ASSERT(header != nullptr);
  ENVOY_LOG(trace, "#onPopMessage. Consumer group: {}, topic: {}", header->consumerGroup(),
            header->topic());
  createActiveMessage(request).sendRequestToUpstream();
}

void ConnectionManager::onAckMessage(RemotingCommandPtr request) {
  auto header = request->typedCustomHeader<AckMessageRequestHeader>();
  ASSERT(header != nullptr);
  ENVOY_LOG(
      trace,
      "#onAckMessage. Consumer group: {}, topic: {}, queue Id: {}, offset: {}, extra-info: {}",
      header->consumerGroup(), header->topic(), header->queueId(), header->offset(),
      header->extraInfo());

  // Fill the target broker_name and broker_id routing directive
  auto it = ack_directive_table_.find(header->directiveKey());
  if (it == ack_directive_table_.end()) {
    ENVOY_LOG(warn, "There was no previous ack directive available, which is unexpected");
    onError(request, "No ack directive is found");
    return;
  }
  header->targetBrokerName(it->second.broker_name_);
  header->targetBrokerId(it->second.broker_id_);

  createActiveMessage(request).sendRequestToUpstream();
}

ActiveMessage& ConnectionManager::createActiveMessage(RemotingCommandPtr& request) {
  ENVOY_CONN_LOG(trace, "ConnectionManager#createActiveMessage. Code: {}, opaque: {}",
                 read_callbacks_->connection(), request->code(), request->opaque());
  ActiveMessagePtr active_message = std::make_unique<ActiveMessage>(*this, std::move(request));
  LinkedList::moveIntoList(std::move(active_message), active_message_list_);
  return **active_message_list_.begin();
}

void ConnectionManager::deferredDelete(ActiveMessage& active_message) {
  read_callbacks_->connection().dispatcher().deferredDelete(
      active_message.removeFromList(active_message_list_));
}

void ConnectionManager::resetAllActiveMessages(absl::string_view error_msg) {
  while (!active_message_list_.empty()) {
    ENVOY_CONN_LOG(warn, "Reset pending request {} due to error: {}", read_callbacks_->connection(),
                   active_message_list_.front()->downstreamRequest()->opaque(), error_msg);
    active_message_list_.front()->onReset();
    stats_.response_error_.inc();
  }
}

Envoy::Network::FilterStatus ConnectionManager::onNewConnection() {
  return Network::FilterStatus::Continue;
}

void ConnectionManager::initializeReadFilterCallbacks(
    Envoy::Network::ReadFilterCallbacks& callbacks) {
  read_callbacks_ = &callbacks;
}

} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/rocketmq_proxy/filters/network/source/config.h"

#include <cstdlib>

#include "envoy/registry/registry.h"
#include "envoy/server/filter_config.h"

#include "source/extensions/filters/network/well_known_names.h"

#include "contrib/envoy/extensions/filters/network/rocketmq_proxy/v3/rocketmq_proxy.pb.h"
#include "contrib/rocketmq_proxy/filters/network/source/conn_manager.h"
#include "contrib/rocketmq_proxy/filters/network/source/stats.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

namespace rocketmq_config = envoy::extensions::filters::network::rocketmq_proxy::v3;

Network::FilterFactoryCb RocketmqProxyFilterConfigFactory::createFilterFactoryFromProtoTyped(
    const rocketmq_config::RocketmqProxy& proto_config,
    Server::Configuration::FactoryContext& context) {
  std::shared_ptr<ConfigImpl> filter_config = std::make_shared<ConfigImpl>(proto_config, context);
  return [filter_config, &context](Network::FilterManager& filter_manager) -> void {
    filter_manager.addReadFilter(std::make_shared<ConnectionManager>(
        *filter_config, context.serverFactoryContext().mainThreadDispatcher().timeSource()));
  };
}

REGISTER_FACTORY(RocketmqProxyFilterConfigFactory,
                 Server::Configuration::NamedNetworkFilterConfigFactory);

ConfigImpl::ConfigImpl(const RocketmqProxyConfig& config,
                       Server::Configuration::FactoryContext& context)
    : context_(context), stats_prefix_(fmt::format("rocketmq.{}.", config.stat_prefix())),
      stats_(RocketmqFilterStats::generateStats(stats_prefix_, context_.scope())),
      route_matcher_(new Router::RouteMatcher(config.route_config())),
      develop_mode_(config.develop_mode()),
      transient_object_life_span_(PROTOBUF_GET_MS_OR_DEFAULT(config, transient_object_life_span,
                                                             TransientObjectLifeSpan)) {}

std::string ConfigImpl::proxyAddress() {
  const LocalInfo::LocalInfo& localInfo = context_.serverFactoryContext().localInfo();
  Network::Address::InstanceConstSharedPtr address = localInfo.address();
  if (address->type() == Network::Address::Type::Ip) {
    const std::string& ip = address->ip()->addressAsString();
    std::string proxyAddr{ip};
    if (address->ip()->port()) {
      return proxyAddr.append(":").append(std::to_string(address->ip()->port()));
    } else {
      ENVOY_LOG(trace, "Local info does not have port specified, defaulting to 10000");
      return proxyAddr.append(":10000");
    }
  }
  return address->asString();
}

Router::RouteConstSharedPtr ConfigImpl::route(const MessageMetadata& metadata) const {
  return route_matcher_->route(metadata);
}

} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/rocketmq_proxy/filters/network/source/router/router_impl.h"

#include "source/common/common/enum_to_int.h"
#include "source/extensions/filters/network/well_known_names.h"

#include "contrib/rocketmq_proxy/filters/network/source/active_message.h"
#include "contrib/rocketmq_proxy/filters/network/source/codec.h"
#include "contrib/rocketmq_proxy/filters/network/source/conn_manager.h"
#include "contrib/rocketmq_proxy/filters/network/source/constant.h"
#include "contrib/rocketmq_proxy/filters/network/source/protocol.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {
namespace Router {

RouterImpl::RouterImpl(Envoy::Upstream::ClusterManager& cluster_manager)
    : cluster_manager_(cluster_manager) {}

RouterImpl::~RouterImpl() {
  if (handle_) {
    handle_->cancel(Tcp::ConnectionPool::CancelPolicy::Default);
  }
}

Upstream::HostDescriptionConstSharedPtr RouterImpl::upstreamHost() { return upstream_host_; }

void RouterImpl::onAboveWriteBufferHighWatermark() {
  ENVOY_LOG(trace, "Above write buffer high watermark");
}

void RouterImpl::onBelowWriteBufferLowWatermark() {
  ENVOY_LOG(trace, "Below write buffer low watermark");
}

void RouterImpl::onEvent(Network::ConnectionEvent event) {
  switch (event)
  case Network::ConnectionEvent::RemoteClose: {
    ENVOY_LOG(error, "Connection to upstream: {} is closed by remote peer",
              upstream_host_->address()->asString());
    // Send local reply to downstream
    active_message_->onError("Connection to upstream is closed by remote peer");
    break;
  case Network::ConnectionEvent::LocalClose:
    ENVOY_LOG(error, "Connection to upstream: {} has been closed",
              upstream_host_->address()->asString());
    // Send local reply to downstream
    active_message_->onError("Connection to upstream has been closed");
    break;
  default:
    // Ignore other events for now
    ENVOY_LOG(trace, "Ignore event type");
    return;
  }
    active_message_->onReset();
}

const Envoy::Router::MetadataMatchCriteria* RouterImpl::metadataMatchCriteria() {
  if (route_entry_) {
    return route_entry_->metadataMatchCriteria();
  }
  return nullptr;
}

void RouterImpl::onUpstreamData(Buffer::Instance& data, bool end_stream) {
  ENVOY_LOG(trace, "Received some data from upstream: {} bytes, end_stream: {}", data.length(),
            end_stream);
  if (active_message_->onUpstreamData(data, end_stream, connection_data_)) {
    reset();
  }
}

void RouterImpl::sendRequestToUpstream(ActiveMessage& active_message) {
  active_message_ = &active_message;
  int opaque = active_message_->downstreamRequest()->opaque();
  ASSERT(active_message_->metadata()->hasTopicName());
  std::string topic_name = active_message_->metadata()->topicName();

  RouteConstSharedPtr route = active_message.route();
  if (!route) {
    active_message.onError("No route for current request.");
    ENVOY_LOG(warn, "Can not find route for topic {}", topic_name);
    reset();
    return;
  }

  route_entry_ = route->routeEntry();
  const std::string cluster_name = route_entry_->clusterName();
  Upstream::ThreadLocalCluster* cluster = cluster_manager_.getThreadLocalCluster(cluster_name);
  if (!cluster) {
    active_message.onError("Cluster does not exist.");
    ENVOY_LOG(warn, "Cluster for {} is not available", cluster_name);
    reset();
    return;
  }

  cluster_info_ = cluster->info();
  if (cluster_info_->maintenanceMode()) {
    ENVOY_LOG(warn, "Cluster {} is under maintenance. Opaque: {}", cluster_name, opaque);
    active_message.onError("Cluster under maintenance.");
    active_message.connectionManager().stats().maintenance_failure_.inc();
    reset();
    return;
  }

  auto data = cluster->tcpConnPool(Upstream::ResourcePriority::Default, this);
  if (!data) {
    ENVOY_LOG(warn, "No host available for cluster {}. Opaque: {}", cluster_name, opaque);
    active_message.onError("No host available");
    reset();
    return;
  }

  upstream_request_ = std::make_unique<UpstreamRequest>(*this);
  Tcp::ConnectionPool::Cancellable* cancellable = data.value().newConnection(*upstream_request_);
  if (cancellable) {
    handle_ = cancellable;
    ENVOY_LOG(trace, "No connection is available for now. Create a cancellable handle. Opaque: {}",
              opaque);
  } else {
    /*
     * UpstreamRequest#onPoolReady or #onPoolFailure should have been invoked.
     */
    ENVOY_LOG(trace,
              "One connection is picked up from connection pool, callback should have been "
              "executed. Opaque: {}",
              opaque);
  }
}

RouterImpl::UpstreamRequest::UpstreamRequest(RouterImpl& router) : router_(router) {}

void RouterImpl::UpstreamRequest::onPoolReady(Tcp::ConnectionPool::ConnectionDataPtr&& conn,
                                              Upstream::HostDescriptionConstSharedPtr host) {
  router_.connection_data_ = std::move(conn);
  router_.upstream_host_ = host;
  router_.connection_data_->addUpstreamCallbacks(router_);
  if (router_.handle_) {
    ENVOY_LOG(trace, "#onPoolReady, reset cancellable handle to nullptr");
    router_.handle_ = nullptr;
  }
  ENVOY_LOG(debug, "Current chosen host address: {}", host->address()->asString());
  // TODO(lizhanhui): we may optimize out encoding in case we there is no protocol translation.
  Buffer::OwnedImpl buffer;
  Encoder::encode(router_.active_message_->downstreamRequest(), buffer);
  router_.connection_data_->connection().write(buffer, false);
  ENVOY_LOG(trace, "Write data to upstream OK. Opaque: {}",
            router_.active_message_->downstreamRequest()->opaque());

  if (router_.active_message_->metadata()->isOneWay()) {
    ENVOY_LOG(trace,
              "Reset ActiveMessage since data is written and the downstream request is one-way. "
              "Opaque: {}",
              router_.active_message_->downstreamRequest()->opaque());

    // For one-way ack-message requests, we need erase previously stored ack-directive.
    if (enumToSignedInt(RequestCode::AckMessage) ==
        router_.active_message_->downstreamRequest()->code()) {
      auto ack_header = router_.active_message_->downstreamRequest()
                            ->typedCustomHeader<AckMessageRequestHeader>();
      router_.active_message_->connectionManager().eraseAckDirective(ack_header->directiveKey());
    }

    router_.reset();
  }
}

void RouterImpl::UpstreamRequest::onPoolFailure(Tcp::ConnectionPool::PoolFailureReason reason,
                                                absl::string_view,
                                                Upstream::HostDescriptionConstSharedPtr host) {
  if (router_.handle_) {
    ENVOY_LOG(trace, "#onPoolFailure, reset cancellable handle to nullptr");
    router_.handle_ = nullptr;
  }
  switch (reason) {
  case Tcp::ConnectionPool::PoolFailureReason::Overflow: {
    ENVOY_LOG(error, "Unable to acquire a connection to send request to upstream");
    router_.active_message_->onError("overflow");
  } break;

  case Tcp::ConnectionPool::PoolFailureReason::RemoteConnectionFailure: {
    ENVOY_LOG(error, "Failed to make request to upstream due to remote connection error. Host {}",
              host->address()->asString());
    router_.active_message_->onError("remote connection failure");
  } break;

  case Tcp::ConnectionPool::PoolFailureReason::LocalConnectionFailure: {
    ENVOY_LOG(error, "Failed to make request to upstream due to local connection error. Host: {}",
              host->address()->asString());
    router_.active_message_->onError("local connection failure");
  } break;

  case Tcp::ConnectionPool::PoolFailureReason::Timeout: {
    ENVOY_LOG(error, "Failed to make request to upstream due to timeout. Host: {}",
              host->address()->asString());
    router_.active_message_->onError("timeout");
  } break;
  }

  // Release resources allocated to this request.
  router_.reset();
}

void RouterImpl::reset() {
  active_message_->onReset();
  if (connection_data_) {
    connection_data_.reset(nullptr);
  }
}

} // namespace Router
} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/rocketmq_proxy/filters/network/source/router/route_matcher.h"

#include "source/common/router/metadatamatchcriteria_impl.h"
#include "source/extensions/filters/network/well_known_names.h"

#include "contrib/rocketmq_proxy/filters/network/source/metadata.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {
namespace Router {

RouteEntryImpl::RouteEntryImpl(
    const envoy::extensions::filters::network::rocketmq_proxy::v3::Route& route)
    : topic_name_(route.match().topic()), cluster_name_(route.route().cluster()),
      config_headers_(Http::HeaderUtility::buildHeaderDataVector(route.match().headers())) {

  if (route.route().has_metadata_match()) {
    const auto filter_it = route.route().metadata_match().filter_metadata().find(
        Envoy::Config::MetadataFilters::get().ENVOY_LB);
    if (filter_it != route.route().metadata_match().filter_metadata().end()) {
      metadata_match_criteria_ =
          std::make_unique<Envoy::Router::MetadataMatchCriteriaImpl>(filter_it->second);
    }
  }
}

const std::string& RouteEntryImpl::clusterName() const { return cluster_name_; }

const RouteEntry* RouteEntryImpl::routeEntry() const { return this; }

RouteConstSharedPtr RouteEntryImpl::matches(const MessageMetadata& metadata) const {
  if (headersMatch(metadata.headers())) {
    const std::string& topic_name = metadata.topicName();
    if (topic_name_.match(topic_name)) {
      return shared_from_this();
    }
  }
  return nullptr;
}

bool RouteEntryImpl::headersMatch(const Http::HeaderMap& headers) const {
  ENVOY_LOG(debug, "rocketmq route matcher: headers size {}, metadata headers size {}",
            config_headers_.size(), headers.size());
  return Http::HeaderUtility::matchHeaders(headers, config_headers_);
}

RouteMatcher::RouteMatcher(const RouteConfig& config) {
  for (const auto& route : config.routes()) {
    routes_.emplace_back(std::make_shared<RouteEntryImpl>(route));
  }
  ENVOY_LOG(debug, "rocketmq route matcher: routes list size {}", routes_.size());
}

RouteConstSharedPtr RouteMatcher::route(const MessageMetadata& metadata) const {
  const std::string& topic_name = metadata.topicName();
  for (const auto& route : routes_) {
    RouteConstSharedPtr route_entry = route->matches(metadata);
    if (nullptr != route_entry) {
      ENVOY_LOG(debug, "rocketmq route matcher: find cluster success for topic: {}", topic_name);
      return route_entry;
    }
  }
  ENVOY_LOG(debug, "rocketmq route matcher: find cluster failed for topic: {}", topic_name);
  return nullptr;
}

} // namespace Router
} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include <string>

#include "envoy/config/typed_config.h"
#include "envoy/server/filter_config.h"

#include "source/common/common/logger.h"
#include "source/common/common/matchers.h"
#include "source/common/http/header_utility.h"

#include "contrib/envoy/extensions/filters/network/rocketmq_proxy/v3/route.pb.h"
#include "contrib/rocketmq_proxy/filters/network/source/router/router.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

class MessageMetadata;

namespace Router {

class RouteEntryImpl : public RouteEntry,
                       public Route,
                       public std::enable_shared_from_this<RouteEntryImpl>,
                       public Logger::Loggable<Logger::Id::rocketmq> {
public:
  RouteEntryImpl(const envoy::extensions::filters::network::rocketmq_proxy::v3::Route& route);
  ~RouteEntryImpl() override = default;

  // Router::RouteEntry
  const std::string& clusterName() const override;
  const Envoy::Router::MetadataMatchCriteria* metadataMatchCriteria() const override {
    return metadata_match_criteria_.get();
  }

  // Router::Route
  const RouteEntry* routeEntry() const override;

  RouteConstSharedPtr matches(const MessageMetadata& metadata) const;

private:
  bool headersMatch(const Http::HeaderMap& headers) const;

  const Matchers::StringMatcherImpl<envoy::type::matcher::v3::StringMatcher> topic_name_;
  const std::string cluster_name_;
  const std::vector<Http::HeaderUtility::HeaderDataPtr> config_headers_;
  Envoy::Router::MetadataMatchCriteriaConstPtr metadata_match_criteria_;
};

using RouteEntryImplConstSharedPtr = std::shared_ptr<const RouteEntryImpl>;

class RouteMatcher : public Logger::Loggable<Logger::Id::rocketmq> {
public:
  using RouteConfig = envoy::extensions::filters::network::rocketmq_proxy::v3::RouteConfiguration;
  RouteMatcher(const RouteConfig& config);

  RouteConstSharedPtr route(const MessageMetadata& metadata) const;

private:
  std::vector<RouteEntryImplConstSharedPtr> routes_;
};

using RouteMatcherPtr = std::unique_ptr<RouteMatcher>;

} // namespace Router
} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
load(
    "//bazel:envoy_build_system.bzl",
    "envoy_cc_library",
    "envoy_contrib_package",
)

licenses(["notice"])  # Apache 2

envoy_contrib_package()

envoy_cc_library(
    name = "router_interface",
    hdrs = ["router.h"],
    deps = [
        "//envoy/tcp:conn_pool_interface",
        "//envoy/upstream:load_balancer_interface",
        "//source/common/upstream:load_balancer_lib",
    ],
)

envoy_cc_library(
    name = "router_lib",
    srcs = ["router_impl.cc"],
    hdrs = ["router_impl.h"],
    deps = [
        ":router_interface",
        "//contrib/rocketmq_proxy/filters/network/source:conn_manager_lib",
        "//envoy/upstream:cluster_manager_interface",
        "//envoy/upstream:thread_local_cluster_interface",
        "//source/extensions/filters/network:well_known_names",
    ],
)

envoy_cc_library(
    name = "route_matcher",
    srcs = ["route_matcher.cc"],
    hdrs = ["route_matcher.h"],
    deps = [
        ":router_interface",
        "//contrib/rocketmq_proxy/filters/network/source:metadata_lib",
        "//envoy/config:typed_config_interface",
        "//envoy/server:filter_config_interface",
        "//source/common/common:logger_lib",
        "//source/common/common:matchers_lib",
        "//source/common/http:header_utility_lib",
        "//source/common/router:metadatamatchcriteria_lib",
        "//source/extensions/filters/network:well_known_names",
        "@envoy_api//contrib/envoy/extensions/filters/network/rocketmq_proxy/v3:pkg_cc_proto",
    ],
)
#pragma once

#include "envoy/tcp/conn_pool.h"
#include "envoy/upstream/cluster_manager.h"
#include "envoy/upstream/thread_local_cluster.h"

#include "source/common/common/logger.h"
#include "source/common/upstream/load_balancer_impl.h"

#include "contrib/rocketmq_proxy/filters/network/source/router/router.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {
namespace Router {

class RouterImpl : public Router, public Logger::Loggable<Logger::Id::rocketmq> {
public:
  explicit RouterImpl(Upstream::ClusterManager& cluster_manager);

  ~RouterImpl() override;

  // Tcp::ConnectionPool::UpstreamCallbacks
  void onUpstreamData(Buffer::Instance& data, bool end_stream) override;
  void onAboveWriteBufferHighWatermark() override;
  void onBelowWriteBufferLowWatermark() override;
  void onEvent(Network::ConnectionEvent event) override;

  // Upstream::LoadBalancerContextBase
  const Envoy::Router::MetadataMatchCriteria* metadataMatchCriteria() override;

  void sendRequestToUpstream(ActiveMessage& active_message) override;

  void reset() override;

  Upstream::HostDescriptionConstSharedPtr upstreamHost() override;

private:
  class UpstreamRequest : public Tcp::ConnectionPool::Callbacks {
  public:
    UpstreamRequest(RouterImpl& router);

    void onPoolFailure(Tcp::ConnectionPool::PoolFailureReason reason,
                       absl::string_view transport_failure_reason,
                       Upstream::HostDescriptionConstSharedPtr host) override;

    void onPoolReady(Tcp::ConnectionPool::ConnectionDataPtr&& conn,
                     Upstream::HostDescriptionConstSharedPtr host) override;

  private:
    RouterImpl& router_;
  };
  using UpstreamRequestPtr = std::unique_ptr<UpstreamRequest>;

  Upstream::ClusterManager& cluster_manager_;
  Tcp::ConnectionPool::ConnectionDataPtr connection_data_;

  /**
   * On requesting connection from upstream connection pool, this handle may be assigned when no
   * connection is readily available at the moment. We may cancel the request through this handle.
   *
   * If there are connections which can be returned immediately, this handle is assigned as nullptr.
   */
  Tcp::ConnectionPool::Cancellable* handle_{nullptr};
  Upstream::HostDescriptionConstSharedPtr upstream_host_;
  ActiveMessage* active_message_{nullptr};
  Upstream::ClusterInfoConstSharedPtr cluster_info_;
  UpstreamRequestPtr upstream_request_;
  const RouteEntry* route_entry_{};
};
} // namespace Router
} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include "envoy/tcp/conn_pool.h"

#include "source/common/upstream/load_balancer_impl.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace RocketmqProxy {

class ActiveMessage;
class MessageMetadata;

namespace Router {

/**
 * RouteEntry is an individual resolved route entry.
 */
class RouteEntry {
public:
  virtual ~RouteEntry() = default;

  /**
   * @return const std::string& the upstream cluster that owns the route.
   */
  virtual const std::string& clusterName() const PURE;

  /**
   * @return MetadataMatchCriteria* the metadata that a subset load balancer should match when
   * selecting an upstream host
   */
  virtual const Envoy::Router::MetadataMatchCriteria* metadataMatchCriteria() const PURE;
};

/**
 * Route holds the RouteEntry for a request.
 */
class Route {
public:
  virtual ~Route() = default;

  /**
   * @return the route entry or nullptr if there is no matching route for the request.
   */
  virtual const RouteEntry* routeEntry() const PURE;
};

using RouteConstSharedPtr = std::shared_ptr<const Route>;
using RouteSharedPtr = std::shared_ptr<Route>;

/**
 * The router configuration.
 */
class Config {
public:
  virtual ~Config() = default;

  virtual RouteConstSharedPtr route(const MessageMetadata& metadata) const PURE;
};

class Router : public Tcp::ConnectionPool::UpstreamCallbacks,
               public Upstream::LoadBalancerContextBase {

public:
  virtual void sendRequestToUpstream(ActiveMessage& active_message) PURE;

  /**
   * Release resources associated with this router.
   */
  virtual void reset() PURE;

  /**
   * Return host description that is eventually connected.
   * @return upstream host if a connection has been established; nullptr otherwise.
   */
  virtual Upstream::HostDescriptionConstSharedPtr upstreamHost() PURE;
};

using RouterPtr = std::unique_ptr<Router>;
} // namespace Router
} // namespace RocketmqProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "envoy/config/core/v3/extension.pb.h"

#include "source/common/protobuf/utility.h"

#include "test/mocks/server/factory_context.h"
#include "test/test_common/environment.h"
#include "test/test_common/status_utility.h"

#include "contrib/dlb/source/connection_balancer_impl.h"
#include "contrib/envoy/extensions/network/connection_balance/dlb/v3alpha/dlb.pb.h"
#include "gtest/gtest.h"

namespace Envoy {
namespace Extensions {
namespace Dlb {

class DlbConnectionBalanceFactoryTest : public testing::Test {
protected:
  // Create a default DLB connection balance typed config.
  static void makeDlbConnectionBalanceConfig(
      envoy::config::core::v3::TypedExtensionConfig& typed_config,
      envoy::extensions::network::connection_balance::dlb::v3alpha::Dlb& dlb) {
    typed_config.mutable_typed_config()->PackFrom(dlb);
    typed_config.set_name("envoy.network.connection_balance.dlb");
  }

  // Verify typed config is dlb, and unpack to dlb object.
  static void verifyDlbConnectionBalanceConfigAndUnpack(
      envoy::config::core::v3::TypedExtensionConfig& typed_config,
      envoy::extensions::network::connection_balance::dlb::v3alpha::Dlb& dlb) {
    EXPECT_EQ(typed_config.name(), "envoy.network.connection_balance.dlb");
    EXPECT_EQ(typed_config.typed_config().type_url(),
              "type.googleapis.com/"
              "envoy.extensions.network.connection_balance.dlb.v3alpha.Dlb");
    ASSERT_OK(MessageUtil::unpackToNoThrow(typed_config.typed_config(), dlb));
  }
};

TEST_F(DlbConnectionBalanceFactoryTest, MakeDefaultConfig) {
  envoy::config::core::v3::TypedExtensionConfig typed_config;
  envoy::extensions::network::connection_balance::dlb::v3alpha::Dlb dlb;
  makeDlbConnectionBalanceConfig(typed_config, dlb);
  verifyDlbConnectionBalanceConfigAndUnpack(typed_config, dlb);
  EXPECT_EQ(0, dlb.id());
  EXPECT_EQ(0, dlb.max_retries());
  EXPECT_EQ(envoy::extensions::network::connection_balance::dlb::v3alpha::Dlb::None,
            dlb.fallback_policy());
}

TEST_F(DlbConnectionBalanceFactoryTest, MakeCustomConfig) {
  envoy::config::core::v3::TypedExtensionConfig typed_config;

  envoy::extensions::network::connection_balance::dlb::v3alpha::Dlb dlb;
  dlb.set_id(10);
  dlb.set_max_retries(12);
  dlb.set_fallback_policy(
      envoy::extensions::network::connection_balance::dlb::v3alpha::Dlb::ExactConnectionBalance);

  makeDlbConnectionBalanceConfig(typed_config, dlb);
  verifyDlbConnectionBalanceConfigAndUnpack(typed_config, dlb);
  EXPECT_EQ(10, dlb.id());
  EXPECT_EQ(12, dlb.max_retries());
  EXPECT_EQ(
      envoy::extensions::network::connection_balance::dlb::v3alpha::Dlb::ExactConnectionBalance,
      dlb.fallback_policy());
}

TEST_F(DlbConnectionBalanceFactoryTest, EmptyProto) {
  DlbConnectionBalanceFactory factory;
  EXPECT_NE(nullptr,
            dynamic_cast<envoy::extensions::network::connection_balance::dlb::v3alpha::Dlb*>(
                factory.createEmptyConfigProto().get()));
}

TEST_F(DlbConnectionBalanceFactoryTest, MockDetectDlbDevice) {
  envoy::extensions::network::connection_balance::dlb::v3alpha::Dlb dlb;
  dlb.set_id(1);

  const std::string& dlb_path = TestEnvironment::temporaryDirectory();
  TestEnvironment::createPath(dlb_path);
  const std::ofstream file(dlb_path + "/" + "dlb6");

  const auto& result = detectDlbDevice(dlb.id(), dlb_path);
  EXPECT_EQ(true, result.has_value());
  EXPECT_EQ(6, result.value());
  TestEnvironment::removePath(dlb_path);
}

#ifndef DLB_DISABLED

using testing::HasSubstr;

TEST_F(DlbConnectionBalanceFactoryTest, MakeFromDefaultProto) {
  envoy::config::core::v3::TypedExtensionConfig typed_config;
  DlbConnectionBalanceFactory factory;
  NiceMock<Server::Configuration::MockFactoryContext> context;

  envoy::extensions::network::connection_balance::dlb::v3alpha::Dlb dlb;
  makeDlbConnectionBalanceConfig(typed_config, dlb);

  EXPECT_THAT_THROWS_MESSAGE(factory.createConnectionBalancerFromProto(typed_config, context),
                             EnvoyException, HasSubstr("no available dlb hardware"));
}

TEST_F(DlbConnectionBalanceFactoryTest, MakeFromNopFallbackProto) {
  envoy::config::core::v3::TypedExtensionConfig typed_config;
  DlbConnectionBalanceFactory factory;
  NiceMock<Server::Configuration::MockFactoryContext> context;

  envoy::extensions::network::connection_balance::dlb::v3alpha::Dlb dlb;
  dlb.set_fallback_policy(
      envoy::extensions::network::connection_balance::dlb::v3alpha::Dlb::NopConnectionBalance);
  makeDlbConnectionBalanceConfig(typed_config, dlb);

  EXPECT_LOG_CONTAINS("warn", "fallback to Nop Connection Balance",
                      factory.createConnectionBalancerFromProto(typed_config, context));
  EXPECT_TRUE(dynamic_cast<Network::NopConnectionBalancerImpl*>(
      factory.createConnectionBalancerFromProto(typed_config, context).get()));
}

TEST_F(DlbConnectionBalanceFactoryTest, MakeFromExactFallbackProto) {
  envoy::config::core::v3::TypedExtensionConfig typed_config;
  DlbConnectionBalanceFactory factory;
  NiceMock<Server::Configuration::MockFactoryContext> context;

  envoy::extensions::network::connection_balance::dlb::v3alpha::Dlb dlb;
  dlb.set_fallback_policy(
      envoy::extensions::network::connection_balance::dlb::v3alpha::Dlb::ExactConnectionBalance);
  makeDlbConnectionBalanceConfig(typed_config, dlb);

  EXPECT_LOG_CONTAINS("warn", "fallback to Exact Connection Balance",
                      factory.createConnectionBalancerFromProto(typed_config, context));
  EXPECT_TRUE(dynamic_cast<Network::ExactConnectionBalancerImpl*>(
      factory.createConnectionBalancerFromProto(typed_config, context).get()));
}

TEST_F(DlbConnectionBalanceFactoryTest, TooManyThreads) {
  envoy::config::core::v3::TypedExtensionConfig typed_config;
  DlbConnectionBalanceFactory factory;
  NiceMock<Server::Configuration::MockFactoryContext> context;
  context.server_factory_context_.options_.concurrency_ = 33;

  envoy::extensions::network::connection_balance::dlb::v3alpha::Dlb dlb;
  makeDlbConnectionBalanceConfig(typed_config, dlb);
  EXPECT_THAT_THROWS_MESSAGE(
      factory.createConnectionBalancerFromProto(typed_config, context), EnvoyException,
      HasSubstr("Dlb connection balanncer only supports up to 32 worker threads"));
}
#endif

} // namespace Dlb
} // namespace Extensions
} // namespace Envoy
load(
    "//bazel:envoy_build_system.bzl",
    "envoy_cc_test",
    "envoy_contrib_package",
)

licenses(["notice"])  # Apache 2

envoy_contrib_package()

envoy_cc_test(
    name = "config_test",
    srcs = select({
        "//bazel:linux_x86_64": ["config_test.cc"],
        "//conditions:default": [],
    }),
    deps = [
        "//contrib/dlb/source:connection_balancer",
        "//source/common/protobuf:utility_lib",
        "//test/mocks/server:factory_context_mocks",
        "//test/test_common:environment_lib",
        "//test/test_common:status_utility_lib",
        "@envoy_api//contrib/envoy/extensions/network/connection_balance/dlb/v3alpha:pkg_cc_proto",
        "@envoy_api//envoy/config/core/v3:pkg_cc_proto",
    ],
)
#pragma once

#include <memory>
#include <string>

#include "envoy/event/dispatcher.h"
#include "envoy/registry/registry.h"
#include "envoy/server/filter_config.h"

#include "source/common/api/os_sys_calls_impl.h"
#include "source/common/listener_manager/active_tcp_listener.h"
#include "source/common/network/connection_balancer_impl.h"
#include "source/common/protobuf/protobuf.h"

#include "contrib/envoy/extensions/network/connection_balance/dlb/v3alpha/dlb.pb.h"
#include "contrib/envoy/extensions/network/connection_balance/dlb/v3alpha/dlb.pb.validate.h"

#ifndef DLB_DISABLED
#include "dlb.h"
#endif

namespace Envoy {
namespace Extensions {
namespace Dlb {

class DlbBalancedConnectionHandlerImpl : public Envoy::Network::BalancedConnectionHandler,
                                         public Logger::Loggable<Logger::Id::connection> {
public:
  DlbBalancedConnectionHandlerImpl(Envoy::Network::BalancedConnectionHandler& handler, int index,
                                   std::string name)
      : handler_(handler), index_(index), name_(name) {}
  // Post socket to Dlb hardware.
  void post(Network::ConnectionSocketPtr&& socket) override;

  void onAcceptWorker(Network::ConnectionSocketPtr&&, bool, bool) override {}

  // Create Dlb event and callback.
  void setDlbEvent();

  // Get socket from Dlb hardware and re-use listener onAcceptWorker().
  void onDlbEvents(uint32_t flags);

  // Only for override, those are never used.
  uint64_t numConnections() const override { return 0; }
  void incNumConnections() override {}

private:
  Envoy::Network::BalancedConnectionHandler& handler_;
  int index_;
  std::string name_;
  Envoy::Event::FileEventPtr dlb_event_;
};

// The dir should always be "/dev" in production.
// For test it is a temporary directory.
// Return Dlb device id, absl::nullopt means error.
static absl::optional<uint> detectDlbDevice(const uint config_id, const std::string& dir) {
  uint device_id = config_id;
  Api::OsSysCalls& os_sys_calls = Api::OsSysCallsSingleton::get();
  struct stat buffer;

  std::string device_path = fmt::format("{}/dlb{}", dir, device_id);
  if (os_sys_calls.stat(device_path.c_str(), &buffer).return_value_ != 0) {
    int i = 0;
    // auto detect available dlb devices, now the max number of dlb device id is 63.
    const int max_id = 64;
    for (; i < max_id; i++) {
      device_path = fmt::format("{}/dlb{}", dir, i);
      if (os_sys_calls.stat(device_path.c_str(), &buffer).return_value_ == 0) {
        device_id = i;
        break;
      }
    }
    if (i == 64) {
      return absl::nullopt;
    }
  }
  return absl::optional<uint>{device_id};
}

class DlbConnectionBalanceFactory : public Envoy::Network::ConnectionBalanceFactory,
                                    public Logger::Loggable<Logger::Id::config> {
public:
  ~DlbConnectionBalanceFactory() override;
  ProtobufTypes::MessagePtr createEmptyConfigProto() override {
    return std::make_unique<envoy::extensions::network::connection_balance::dlb::v3alpha::Dlb>();
  }

  Envoy::Network::ConnectionBalancerSharedPtr
  createConnectionBalancerFromProto(const Protobuf::Message& config,
                                    Server::Configuration::FactoryContext&) override;

  std::string name() const override { return "envoy.network.connection_balance.dlb"; }

  // Log error info in warn level and fallback based on fallback policy.
  Envoy::Network::ConnectionBalancerSharedPtr fallback(const std::string& message);

  // Init those only when Envoy start.
  int domain_id, ldb_pool_id, dir_pool_id, tx_queue_id;
  // The default value is None.
  envoy::extensions::network::connection_balance::dlb::v3alpha::Dlb::FallbackPolicy
      fallback_policy{};
#ifndef DLB_DISABLED
  dlb_domain_hdl_t domain;
  dlb_hdl_t dlb{};
  dlb_dev_cap_t cap;

  // Share those cross worker threads.
  std::vector<dlb_port_hdl_t> tx_ports, rx_ports;
  uint max_retries;
#endif
  std::vector<int> efds;
  std::vector<std::shared_ptr<DlbBalancedConnectionHandlerImpl>> dlb_handlers;
  std::vector<Envoy::Event::FileEventPtr> file_events;
#ifndef DLB_DISABLED
  const static int cq_depth = 8;
  static int createLdbPort(dlb_domain_hdl_t domain, dlb_dev_cap_t cap, int ldb_pool, int dir_pool) {
    dlb_create_port_t args;

    if (!cap.combined_credits) {
      args.ldb_credit_pool_id = ldb_pool;
      args.dir_credit_pool_id = dir_pool;
    } else {
      args.credit_pool_id = ldb_pool;
    }
    args.cq_depth = cq_depth;
    args.num_ldb_event_state_entries = cq_depth * 2;
    args.cos_id = DLB_PORT_COS_ID_ANY;

    return dlb_create_ldb_port(domain, &args);
  }

  static int createSchedDomain(dlb_hdl_t dlb, dlb_resources_t rsrcs, dlb_dev_cap_t cap,
                               uint32_t num_ldb_ports) {
    int p_rsrsc = 100;
    dlb_create_sched_domain_t args;

    args.num_ldb_queues = 1;
    args.num_ldb_ports = num_ldb_ports;
    args.num_dir_ports = 0;
    args.num_ldb_event_state_entries = 2 * args.num_ldb_ports * cq_depth;
    if (!cap.combined_credits) {
      args.num_ldb_credits = rsrcs.max_contiguous_ldb_credits * p_rsrsc / 100;
      args.num_dir_credits = rsrcs.max_contiguous_dir_credits * p_rsrsc / 100;

      args.num_ldb_credit_pools = 1;
      args.num_dir_credit_pools = 1;
    } else {
      args.num_credits = rsrcs.num_credits * p_rsrsc / 100;
      args.num_credit_pools = 1;
    }

    args.num_sn_slots[0] = rsrcs.num_sn_slots[0] * p_rsrsc / 100;
    args.num_sn_slots[1] = rsrcs.num_sn_slots[1] * p_rsrsc / 100;

    return dlb_create_sched_domain(dlb, &args);
  }

  static int createLdbQueue(dlb_domain_hdl_t domain) {
    dlb_create_ldb_queue_t args = {0, 0};

    return dlb_create_ldb_queue(domain, &args);
  }
#endif
};

using DlbConnectionBalanceFactorySingleton = InjectableSingleton<DlbConnectionBalanceFactory>;

/**
 * Implementation of connection balancer that does balancing with the help of Dlb hardware.
 */
class DlbConnectionBalancerImpl : public Envoy::Network::ConnectionBalancer,
                                  public Logger::Loggable<Logger::Id::connection> {
public:
  /** registerHandler() does following things:
   * - get listener
   * - create DlbBalancedConnectionHandlerImpl
   * - create Dlb event of DlbBalancedConnectionHandlerImpl
   */
  void registerHandler(Envoy::Network::BalancedConnectionHandler&) override;

  // Remove DlbBalancedConnectionHandlerImpl by listener.
  void unregisterHandler(Envoy::Network::BalancedConnectionHandler&) override;

  // Return DlbBalancedConnectionHandlerImpl to handle Dlb send/recv.
  Envoy::Network::BalancedConnectionHandler&
  pickTargetHandler(Envoy::Network::BalancedConnectionHandler& current_handler) override;
};

} // namespace Dlb
} // namespace Extensions
} // namespace Envoy
#include "contrib/dlb/source/connection_balancer_impl.h"

#include <sys/eventfd.h>
#include <unistd.h>

#include <algorithm>
#include <cstdlib>
#include <memory>

#include "contrib/envoy/extensions/network/connection_balance/dlb/v3alpha/dlb.pb.h"

#ifndef DLB_DISABLED
#include "dlb.h"
#endif

namespace Envoy {
namespace Extensions {
namespace Dlb {

Envoy::Network::ConnectionBalancerSharedPtr
DlbConnectionBalanceFactory::fallback(const std::string& message) {
  switch (fallback_policy) {
  case envoy::extensions::network::connection_balance::dlb::v3alpha::Dlb::ExactConnectionBalance: {
    ENVOY_LOG(warn, fmt::format("error: {}, fallback to Exact Connection Balance", message));
    return std::make_shared<Network::ExactConnectionBalancerImpl>();
  }
  case envoy::extensions::network::connection_balance::dlb::v3alpha::Dlb::NopConnectionBalance: {
    ENVOY_LOG(warn, fmt::format("error: {}, fallback to Nop Connection Balance", message));
    return std::make_shared<Network::NopConnectionBalancerImpl>();
  }
  case envoy::extensions::network::connection_balance::dlb::v3alpha::Dlb::None:
  default:
    ExceptionUtil::throwEnvoyException(message);
  }
}

Envoy::Network::ConnectionBalancerSharedPtr
DlbConnectionBalanceFactory::createConnectionBalancerFromProto(
    const Protobuf::Message& config, Server::Configuration::FactoryContext& context) {
  const auto& typed_config =
      dynamic_cast<const envoy::config::core::v3::TypedExtensionConfig&>(config);
  envoy::extensions::network::connection_balance::dlb::v3alpha::Dlb dlb_config;
  auto status = Envoy::MessageUtil::unpackToNoThrow(typed_config.typed_config(), dlb_config);
  if (!status.ok()) {
    return fallback(fmt::format("unexpected dlb config: {}", typed_config.DebugString()));
  }

  fallback_policy = dlb_config.fallback_policy();

  const uint32_t worker_num = context.serverFactoryContext().options().concurrency();

  if (worker_num > 32) {
    return fallback("Dlb connection balanncer only supports up to 32 worker threads, "
                    "please decrease the number of threads by `--concurrency`");
  }

  const uint& config_id = dlb_config.id();
  const auto& result = detectDlbDevice(config_id, "/dev");
  if (!result.has_value()) {
    return fallback("no available dlb hardware");
  }

  const uint& device_id = result.value();
  if (device_id != config_id) {
    ENVOY_LOG(warn, "dlb device {} is not found, use dlb device {} instead", config_id, device_id);
  }

#ifdef DLB_DISABLED
  throw EnvoyException("X86_64 architecture is required for Dlb.");
#else

  max_retries = dlb_config.max_retries();

  dlb_resources_t rsrcs;
  if (dlb_open(device_id, &dlb) == -1) {
    return fallback(fmt::format("dlb_open {}", errorDetails(errno)));
  }
  if (dlb_get_dev_capabilities(dlb, &cap)) {
    return fallback(fmt::format("dlb_get_dev_capabilities {}", errorDetails(errno)));
  }

  if (dlb_get_num_resources(dlb, &rsrcs)) {
    return fallback(fmt::format("dlb_get_num_resources {}", errorDetails(errno)));
  }

  ENVOY_LOG(debug,
            "dlb available resources: domains: {}, LDB queues: {}, LDB ports: {}, "
            "ES entries: {}, Contig ES entries: {}, LDB credits: {}, Config LDB credits: {}, LDB "
            "credit pools: {}",
            rsrcs.num_sched_domains, rsrcs.num_ldb_queues, rsrcs.num_ldb_ports,
            rsrcs.num_ldb_event_state_entries, rsrcs.max_contiguous_ldb_event_state_entries,
            rsrcs.num_ldb_credits, rsrcs.max_contiguous_ldb_credits, rsrcs.num_ldb_credit_pools);

  if (rsrcs.num_ldb_ports < 2 * worker_num) {
    return fallback(fmt::format("no available dlb port resources, request: {}, available: {}",
                                2 * worker_num, rsrcs.num_ldb_ports));
  }

  domain_id = createSchedDomain(dlb, rsrcs, cap, 2 * worker_num);
  if (domain_id == -1) {
    return fallback(fmt::format("dlb_create_sched_domain_ {}", errorDetails(errno)));
  }

  domain = dlb_attach_sched_domain(dlb, domain_id);
  if (domain == nullptr) {
    return fallback(fmt::format("dlb_attach_sched_domain {}", errorDetails(errno)));
  }

  const int partial_resources = 100;
  if (!cap.combined_credits) {
    int max_ldb_credits = rsrcs.num_ldb_credits * partial_resources / 100;
    int max_dir_credits = rsrcs.num_dir_credits * partial_resources / 100;

    ldb_pool_id = dlb_create_ldb_credit_pool(domain, max_ldb_credits);

    if (ldb_pool_id == -1) {
      return fallback(fmt::format("dlb_create_ldb_credit_pool {}", errorDetails(errno)));
    }

    dir_pool_id = dlb_create_dir_credit_pool(domain, max_dir_credits);

    if (dir_pool_id == -1) {
      return fallback(fmt::format("dlb_create_dir_credit_pool {}", errorDetails(errno)));
    }
  } else {
    int max_credits = rsrcs.num_credits * partial_resources / 100;

    ldb_pool_id = dlb_create_credit_pool(domain, max_credits);

    if (ldb_pool_id == -1) {
      return fallback(fmt::format("dlb_create_credit_pool {}", errorDetails(errno)));
    }
  }

  tx_queue_id = createLdbQueue(domain);
  if (tx_queue_id == -1) {
    return fallback(fmt::format("tx create_ldb_queue {}", errorDetails(errno)));
  }

  for (uint i = 0; i < worker_num; i++) {
    int tx_port_id = createLdbPort(domain, cap, ldb_pool_id, dir_pool_id);
    if (tx_port_id == -1) {
      return fallback(fmt::format("tx dlb_create_ldb_port {}", errorDetails(errno)));
    }

    dlb_port_hdl_t tx_port = dlb_attach_ldb_port(domain, tx_port_id);
    if (tx_port == nullptr) {
      return fallback(fmt::format("tx dlb_attach_ldb_port {}", errorDetails(errno)));
    }
    tx_ports.push_back(tx_port);

    int rx_port_id = createLdbPort(domain, cap, ldb_pool_id, dir_pool_id);
    if (rx_port_id == -1) {
      return fallback(fmt::format("rx dlb_create_ldb_port {}", errorDetails(errno)));
    }

    dlb_port_hdl_t rx_port = dlb_attach_ldb_port(domain, rx_port_id);
    if (rx_port == nullptr) {
      return fallback(fmt::format("rx dlb_attach_ldb_port {}", errorDetails(errno)));
    }
    rx_ports.push_back(rx_port);

    if (dlb_link_queue(rx_port, tx_queue_id, 0) == -1) {
      return fallback(fmt::format("dlb_link_queue {}", errorDetails(errno)));
    }

    int efd = eventfd(0, EFD_NONBLOCK);
    if (efd < 0) {
      return fallback(fmt::format("dlb eventfd {}", errorDetails(errno)));
    }
    if (dlb_enable_cq_epoll(rx_port, true, efd)) {
      return fallback(fmt::format("dlb_enable_cq_epoll {}", errorDetails(errno)));
    }
    efds.push_back(efd);
  }

  if (dlb_launch_domain_alert_thread(domain, nullptr, nullptr)) {
    return fallback(fmt::format("dlb_launch_domain_alert_thread {}", errorDetails(errno)));
  }

  if (dlb_start_sched_domain(domain)) {
    return fallback(fmt::format("dlb_start_sched_domain {}", errorDetails(errno)));
  }
#endif
  DlbConnectionBalanceFactorySingleton::initialize(this);

  return std::make_shared<DlbConnectionBalancerImpl>();
}

DlbConnectionBalanceFactory::~DlbConnectionBalanceFactory() {
#ifndef DLB_DISABLED
  if (dlb != nullptr) {
    for (dlb_port_hdl_t port : rx_ports) {
      if (dlb_disable_port(port)) {
        ENVOY_LOG(error, "dlb_disable_port {}", errorDetails(errno));
      }
      if (dlb_detach_port(port) == -1) {
        ENVOY_LOG(error, "dlb_detach_port {}", errorDetails(errno));
      }
    }
    for (dlb_port_hdl_t port : tx_ports) {
      if (dlb_disable_port(port)) {
        ENVOY_LOG(error, "dlb_disable_port {}", errorDetails(errno));
      }
      if (dlb_detach_port(port) == -1) {
        ENVOY_LOG(error, "dlb_detach_port {}", errorDetails(errno));
      }
    }
    if (dlb_detach_sched_domain(domain) == -1) {
      ENVOY_LOG(error, "dlb_detach_sched_domain {}", errorDetails(errno));
    }

    if (dlb_reset_sched_domain(dlb, domain_id) == -1) {
      ENVOY_LOG(error, "dlb_reset_sched_domain {}", errorDetails(errno));
    }

    if (dlb_close(dlb) == -1) {
      ENVOY_LOG(error, "dlb_close {}", errorDetails(errno));
    }
  }

#endif
  for (int fd : efds) {
    if (close(fd) == -1) {
      ENVOY_LOG(error, "dlb close fd {}", errorDetails(errno));
    }
  }
}

REGISTER_FACTORY(DlbConnectionBalanceFactory, Envoy::Network::ConnectionBalanceFactory);

void DlbBalancedConnectionHandlerImpl::setDlbEvent() {
  auto listener = dynamic_cast<Envoy::Server::ActiveTcpListener*>(&handler_);

  dlb_event_ = listener->dispatcher().createFileEvent(
      DlbConnectionBalanceFactorySingleton::get().efds[index_],
      [this](uint32_t events) -> void { onDlbEvents(events); }, Event::FileTriggerType::Level,
      Event::FileReadyType::Read);
  dlb_event_->setEnabled(Event::FileReadyType::Read);
}

void DlbBalancedConnectionHandlerImpl::post(
    [[maybe_unused]] Network::ConnectionSocketPtr&& socket) {
#ifdef DLB_DISABLED
  throw EnvoyException("X86_64 architecture is required for Dlb.");
#else
  // The pointer will be casted to unique_ptr in onDlbEvents(), no need to consider free.
  auto s = socket.release();
  dlb_event_t events[1];
  events[0].send.queue_id = DlbConnectionBalanceFactorySingleton::get().tx_queue_id;
  events[0].send.sched_type = SCHED_UNORDERED;
  events[0].adv_send.udata64 = reinterpret_cast<std::uintptr_t>(s);
  int ret = dlb_send(DlbConnectionBalanceFactorySingleton::get().tx_ports[index_], 1, &events[0]);
  if (ret != 1) {
    if (DlbConnectionBalanceFactorySingleton::get().max_retries > 0) {
      uint i = 0;
      while (i < DlbConnectionBalanceFactorySingleton::get().max_retries) {
        ENVOY_LOG(debug, "{} dlb_send fail, start retry, errono: {}", name_, errno);
        ret = dlb_send(DlbConnectionBalanceFactorySingleton::get().tx_ports[index_], 1, &events[0]);
        if (ret == 1) {
          ENVOY_LOG(warn, "{} dlb_send retry {} times and succeed", name_, i + 1);
          break;
        }
        i++;
      }

      if (ret != 1) {
        ENVOY_LOG(error,
                  "{} dlb_send fail with {} times retry, errono: {}, message: {}, increase "
                  "max_retries may help",
                  name_, DlbConnectionBalanceFactorySingleton::get().max_retries, errno,
                  errorDetails(errno));
      }
    } else {
      ENVOY_LOG(error,
                "{} dlb_send fail without retry, errono: {}, message: {}, set "
                "max_retries may help",
                name_, DlbConnectionBalanceFactorySingleton::get().max_retries, errno,
                errorDetails(errno));
    }

  } else {
    ENVOY_LOG(debug, "{} dlb send fd {}", name_, s->ioHandle().fdDoNotUse());
  }
#endif
}

void DlbBalancedConnectionHandlerImpl::onDlbEvents(uint32_t flags) {
  ASSERT(flags & (Event::FileReadyType::Read));
#ifdef DLB_DISABLED
  throw EnvoyException("X86_64 architecture is required for Dlb.");
#else
  dlb_event_t dlb_events[32];
  int num_rx = dlb_recv(DlbConnectionBalanceFactorySingleton::get().rx_ports.at(index_), 32, false,
                        dlb_events);
  if (num_rx == 0) {
    ENVOY_LOG(debug, "{} dlb receive none, skip", name_);
    return;
  } else {
    ENVOY_LOG(debug, "{} get dlb event {}", name_, num_rx);
  }

  int ret = dlb_release(DlbConnectionBalanceFactorySingleton::get().rx_ports.at(index_), num_rx);
  if (ret != num_rx) {
    ENVOY_LOG(debug, "{} dlb release {}", name_, errorDetails(errno));
  }
  for (int i = 0; i < num_rx; i++) {
    if (dlb_events[i].recv.error) {
      ENVOY_LOG(error, "{} dlb receive {}", name_, errorDetails(errno));
      continue;
    }

    if (dlb_events[i].recv.udata64) {
      const uint64_t data = dlb_events[i].recv.udata64;
      auto socket = reinterpret_cast<Network::ConnectionSocket*>(data);

      ENVOY_LOG(debug, "{} dlb recv {}", name_, socket->ioHandle().fdDoNotUse());
      auto listener = dynamic_cast<Envoy::Server::ActiveTcpListener*>(&handler_);
      auto active_socket = std::make_unique<Envoy::Server::ActiveTcpSocket>(
          *listener, std::unique_ptr<Network::ConnectionSocket>(socket),
          listener->config_->handOffRestoredDestinationConnections());
      listener->onSocketAccepted(std::move(active_socket));
      listener->incNumConnections();
    }
  }
#endif
}

void DlbConnectionBalancerImpl::registerHandler(
    Envoy::Network::BalancedConnectionHandler& handler) {

  auto listener = dynamic_cast<Envoy::Server::ActiveTcpListener*>(&handler);

  const std::string worker_name = listener->dispatcher().name();
  const int index =
      std::stoi(worker_name.substr(worker_name.find_first_of('_') + 1, worker_name.size()));

  auto dlb_handler =
      std::make_shared<DlbBalancedConnectionHandlerImpl>(handler, index, worker_name);
  dlb_handler->setDlbEvent();

  DlbConnectionBalanceFactorySingleton::get().dlb_handlers.push_back(dlb_handler);
}

void DlbConnectionBalancerImpl::unregisterHandler(
    Envoy::Network::BalancedConnectionHandler& handler) {
  auto listener = dynamic_cast<Envoy::Server::ActiveTcpListener*>(&handler);
  auto worker_name = listener->dispatcher().name();
  int index = std::stoi(worker_name.substr(worker_name.find_first_of('_') + 1, worker_name.size()));

  // Now Dlb does not support change config when running, clean Dlb related config in
  // DlbBalancedConnectionHandlerImpl
  auto dlb_handlers = DlbConnectionBalanceFactorySingleton::get().dlb_handlers;
  dlb_handlers.erase(dlb_handlers.begin() + index);
}

Envoy::Network::BalancedConnectionHandler& DlbConnectionBalancerImpl::pickTargetHandler(
    Envoy::Network::BalancedConnectionHandler& current_handler) {
  auto listener = dynamic_cast<Envoy::Server::ActiveTcpListener*>(&current_handler);
  auto worker_name = listener->dispatcher().name();
  const int index =
      std::stoi(worker_name.substr(worker_name.find_first_of('_') + 1, worker_name.size()));
  return *DlbConnectionBalanceFactorySingleton::get().dlb_handlers[index];
}

} // namespace Dlb
} // namespace Extensions
} // namespace Envoy
load("@rules_foreign_cc//foreign_cc:defs.bzl", "make")
load(
    "//bazel:envoy_build_system.bzl",
    "envoy_cc_contrib_extension",
    "envoy_contrib_package",
)
load(
    "//contrib:all_contrib_extensions.bzl",
    "envoy_contrib_linux_x86_64_constraints",
)

licenses(["notice"])  # Apache 2

envoy_contrib_package()

make(
    name = "dlb",
    includes = [],
    lib_source = "@intel_dlb//:libdlb",
    out_static_libs = ["libdlb.a"],
    postfix_script = "mv libdlb.a $INSTALLDIR/lib && rm -rf $INSTALLDIR/include && mkdir -p $INSTALLDIR/include && cp -L *.h $INSTALLDIR/include",
    tags = ["skip_on_windows"],
    target_compatible_with = envoy_contrib_linux_x86_64_constraints(),
    targets = ["libdlb.a"],
)

envoy_cc_contrib_extension(
    name = "connection_balancer",
    srcs = select({
        "//bazel:linux_x86_64": ["connection_balancer_impl.cc"],
        "//conditions:default": [],
    }),
    hdrs = ["connection_balancer_impl.h"],
    defines = select({
        "//bazel:linux_x86_64": [],
        "//conditions:default": [
            "DLB_DISABLED=1",
        ],
    }),
    deps = [
        "//envoy/api:api_interface",
        "//envoy/registry",
        "//envoy/server:factory_context_interface",
        "//envoy/server:filter_config_interface",
        "//source/common/common:logger_lib",
        "//source/common/listener_manager:active_tcp_listener",
        "//source/common/network:connection_balancer_lib",
        "//source/common/protobuf:utility_lib",
        "@envoy_api//contrib/envoy/extensions/network/connection_balance/dlb/v3alpha:pkg_cc_proto",
    ] + select({
        "//bazel:linux_x86_64": [
            ":dlb",
        ],
        "//conditions:default": [
        ],
    }),
)
#pragma once

#include "source/common/buffer/buffer_impl.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace PostgresProxy {

void createPostgresMsg(Buffer::Instance& data, std::string type, std::string payload = "");
void createInitialPostgresRequest(Buffer::Instance& data);

} // namespace PostgresProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
admin:
  access_log:
  - name: envoy.access_loggers.file
    typed_config:
      "@type": type.googleapis.com/envoy.extensions.access_loggers.file.v3.FileAccessLog
      path: "{}"
  address:
    socket_address:
      address: "{}"
      port_value: 0
static_resources:
  clusters:
    name: cluster_0
    type: STATIC
    load_assignment:
      cluster_name: cluster_0
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: "{}"
                port_value: 0
    #downstream startTLS transport socket:
    {}
  listeners:
    name: listener_0
    address:
      socket_address:
        address: "{}"
        port_value: 0
    filter_chains:
    - filters:
      - name: postgres
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.postgres_proxy.v3alpha.PostgresProxy
          stat_prefix: postgres_stats
          # downstream SSL option:
          {}
          # upstream SSL option:
          {}
      # additional filters
      {}
      - name: tcp
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.tcp_proxy.v3.TcpProxy
          stat_prefix: tcp_stats
          cluster: cluster_0
      # upstream startTLS transport socket
      {}
#include <gmock/gmock.h>
#include <gtest/gtest.h>

#include "source/common/buffer/buffer_impl.h"

#include "contrib/postgres_proxy/filters/network/source/postgres_message.h"
#include "fmt/printf.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace PostgresProxy {

// Tests for individual types used in Postgres messages.
//
// Integer types.

// Fixture class for testing Integer types.
template <typename T> class IntTest : public testing::Test {
public:
  T field_;
  Buffer::OwnedImpl data_;
};

using IntTypes = ::testing::Types<Int32, Int16, Int8>;
TYPED_TEST_SUITE(IntTest, IntTypes);

TYPED_TEST(IntTest, BasicRead) {
  this->data_.template writeBEInt<decltype(std::declval<TypeParam>().get())>(12);
  uint64_t pos = 0;
  uint64_t left;
  // Simulate that message is too short.
  left = sizeof(TypeParam) - 1;
  ASSERT_THAT(Message::ValidationFailed, this->field_.validate(this->data_, 0, pos, left));
  // Single 4-byte int. Message length is correct.
  left = sizeof(TypeParam);
  ASSERT_THAT(Message::ValidationOK, this->field_.validate(this->data_, 0, pos, left));

  // Read the value after successful validation.
  pos = 0;
  left = sizeof(TypeParam);
  ASSERT_TRUE(this->field_.read(this->data_, pos, left));

  ASSERT_THAT(this->field_.toString(), "[12]");
  // pos should be moved forward by the number of bytes read.
  ASSERT_THAT(pos, sizeof(TypeParam));
  ASSERT_THAT(12, this->field_.get());

  // Make sure that all bytes have been read from the buffer.
  ASSERT_THAT(left, 0);
}

TYPED_TEST(IntTest, ReadWithLeftovers) {
  this->data_.template writeBEInt<decltype(std::declval<TypeParam>().get())>(12);
  // Write 1 byte more.
  this->data_.template writeBEInt<uint8_t>(11);
  uint64_t pos = 0;
  uint64_t left = this->data_.length();
  ASSERT_THAT(Message::ValidationOK, this->field_.validate(this->data_, 0, pos, left));

  pos = 0;
  left = this->data_.length();
  ASSERT_TRUE(this->field_.read(this->data_, pos, left));
  ASSERT_THAT(this->field_.toString(), "[12]");
  // pos should be moved forward by the number of bytes read.
  ASSERT_THAT(pos, sizeof(TypeParam));

  // Make sure that all bytes have been read from the buffer.
  ASSERT_THAT(left, 1);
}

TYPED_TEST(IntTest, ReadAtOffset) {
  // write 1 byte before the actual value.
  this->data_.template writeBEInt<uint8_t>(11);
  this->data_.template writeBEInt<decltype(std::declval<TypeParam>().get())>(12);

  uint64_t pos = 1;
  uint64_t left = this->data_.length() - 1;
  ASSERT_THAT(Message::ValidationOK, this->field_.validate(this->data_, 1, pos, left));

  pos = 1;
  left = this->data_.length() - 1;
  ASSERT_TRUE(this->field_.read(this->data_, pos, left));
  ASSERT_THAT(this->field_.toString(), "[12]");
  // pos should be moved forward by the number of bytes read.
  ASSERT_THAT(pos, 1 + sizeof(TypeParam));
  // Nothing should be left to read.
  ASSERT_THAT(left, 0);
}

TYPED_TEST(IntTest, NotEnoughData) {
  this->data_.template writeBEInt<decltype(std::declval<TypeParam>().get())>(12);
  // Start from offset 1. There is not enough data in the buffer for the required type.
  uint64_t pos = 1;
  uint64_t left = this->data_.length();

  ASSERT_THAT(this->field_.validate(this->data_, 0, pos, left), Message::ValidationNeedMoreData);
}

// Byte1 should format content as char.
TEST(Byte1, Formatting) {
  Byte1 field;

  Buffer::OwnedImpl data;
  data.add("I");

  uint64_t pos = 0;
  uint64_t left = 1;
  ASSERT_THAT(Message::ValidationOK, field.validate(data, 0, pos, left));
  ASSERT_THAT(pos, 1);
  ASSERT_THAT(left, 0);

  pos = 0;
  left = 1;
  ASSERT_TRUE(field.read(data, pos, left));
  ASSERT_THAT(pos, 1);
  ASSERT_THAT(left, 0);

  ASSERT_THAT(field.toString(), "[I]");
}

// Tests for String type.
TEST(StringType, SingleString) {
  String field;

  Buffer::OwnedImpl data;
  data.add("test");
  // Passed length 3 is too short.
  uint64_t pos = 0;
  uint64_t left = 3;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationFailed);
  // Correct length, but terminating zero is missing.
  left = 5;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationNeedMoreData);
  // Add terminating zero.
  data.writeBEInt<uint8_t>(0);
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationOK);
  ASSERT_THAT(pos, 5);
  ASSERT_THAT(left, 0);

  pos = 0;
  left = 5;
  ASSERT_TRUE(field.read(data, pos, left));
  ASSERT_THAT(pos, 5);
  ASSERT_THAT(left, 0);

  auto out = field.toString();
  ASSERT_THAT(out, "[test]");
}

TEST(StringType, NoTerminatingByte) {
  String field;

  Buffer::OwnedImpl data;
  data.add("test");
  uint64_t pos = 0;
  uint64_t left = 4;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationFailed);
  left = 5;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationNeedMoreData);
}

// ByteN type is always placed at the end of Postgres message.
// There is no explicit message length. Length must be deduced from
// "length" field on Postgres message.
TEST(ByteN, BasicTest) {
  ByteN field;

  Buffer::OwnedImpl data;
  // Write 11 bytes. We will read only 10 to make sure
  // that len is used, not buffer's length.
  for (auto i = 0; i < 11; i++) {
    data.writeBEInt<uint8_t>(i);
  }
  uint64_t pos = 0;
  uint64_t left;

  // Since ByteN structure does not contain length field, any
  // value less than number of bytes in the buffer should
  // pass validation.
  pos = 0;
  left = 0;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationOK);
  ASSERT_THAT(pos, 0);
  ASSERT_THAT(left, 0);
  pos = 0;
  left = 1;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationOK);
  ASSERT_THAT(pos, 1);
  ASSERT_THAT(left, 0);
  pos = 0;
  left = 4;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationOK);
  ASSERT_THAT(pos, 4);
  ASSERT_THAT(left, 0);

  pos = 0;
  left = 10;
  ASSERT_TRUE(field.read(data, pos, left));
  ASSERT_THAT(pos, 10);
  ASSERT_THAT(left, 0);

  auto out = field.toString();
  ASSERT_THAT(out, "[0 1 2 3 4 5 6 7 8 9]");
}

TEST(ByteN, NotEnoughData) {
  ByteN field;

  Buffer::OwnedImpl data;
  // Write 10 bytes, but set message length to be 11.
  for (auto i = 0; i < 10; i++) {
    data.writeBEInt<uint8_t>(i);
  }
  uint64_t pos = 0;
  uint64_t left = 11;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationNeedMoreData);
}

TEST(ByteN, Empty) {
  ByteN field;

  Buffer::OwnedImpl data;
  // Write nothing to data buffer.
  uint64_t pos = 0;
  uint64_t left = 0;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationOK);
  ASSERT_TRUE(field.read(data, pos, left));

  auto out = field.toString();
  ASSERT_THAT(out, "[]");
}

// VarByteN type. It contains 4 bytes length field with value which follows.
TEST(VarByteN, BasicTest) {
  VarByteN field;
  Buffer::OwnedImpl data;

  uint64_t pos = 0;
  uint64_t left = 0;
  // Simulate that message ended and VarByteN's length fields  sticks past the
  // message boundary.
  data.writeBEInt<int32_t>(5);
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationFailed);

  // Write VarByteN with length equal to zero. No value follows.
  // Set structure length to be -1 (means no payload).
  left = 4;
  data.drain(data.length());
  data.writeBEInt<int32_t>(-1);
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationOK);
  // The same for structure length 0.
  pos = 0;
  left = 4;
  data.drain(data.length());
  data.writeBEInt<int32_t>(0);
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationOK);

  // Simulate that VarByteN would extend past message boundary.
  data.drain(data.length());
  data.writeBEInt<int32_t>(30);
  pos = 0;
  left = 4;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationFailed);

  // Simulate that VarByteN length is 6, there are 6 bytes left to the
  // message boundary, but buffer contains only 4 bytes.
  data.drain(data.length());
  data.writeBEInt<int32_t>(6);
  data.writeBEInt<uint32_t>(16);
  pos = 0;
  left = 6;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationNeedMoreData);

  data.drain(data.length());
  // Write first value.
  data.writeBEInt<int32_t>(0);

  // Write 2nd value with 5 bytes.
  data.writeBEInt<uint32_t>(5);
  for (auto i = 0; i < 5; i++) {
    data.writeBEInt<uint8_t>(10 + i);
  }

  // Write special case value with length -1. No value follows.
  data.writeBEInt<int32_t>(-1);

  pos = 0;
  left = 4 + 4 + 5 + 4;
  uint64_t expected_left = left;
  uint64_t orig_pos = pos;
  uint64_t orig_left = left;
  // Read the first value.
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationOK);
  pos = orig_pos;
  left = orig_left;
  ASSERT_TRUE(field.read(data, pos, left));
  ASSERT_THAT(pos, 4);
  expected_left -= 4;
  ASSERT_THAT(left, expected_left);
  auto out = field.toString();
  ASSERT_TRUE(out.find("0 bytes") != std::string::npos);

  // Read the second value.
  orig_pos = pos;
  orig_left = left;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationOK);
  pos = orig_pos;
  left = orig_left;
  ASSERT_TRUE(field.read(data, pos, left));
  ASSERT_THAT(pos, 4 + 4 + 5);
  expected_left -= (4 + 5);
  ASSERT_THAT(left, expected_left);
  out = field.toString();
  ASSERT_TRUE(out.find("5 bytes") != std::string::npos);
  ASSERT_TRUE(out.find("10 11 12 13 14") != std::string::npos);

  // Read the third value.
  orig_pos = pos;
  orig_left = left;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationOK);
  pos = orig_pos;
  left = orig_left;
  ASSERT_TRUE(field.read(data, pos, left));
  ASSERT_THAT(pos, 4 + 4 + 5 + 4);
  expected_left -= 4;
  ASSERT_THAT(left, expected_left);
  out = field.toString();
  ASSERT_TRUE(out.find("-1 bytes") != std::string::npos);
}

// Array composite type tests.
TEST(Array, SingleInt) {
  Array<Int32> field;

  Buffer::OwnedImpl data;
  // Simulate that message ends before the array.
  uint64_t pos = 0;
  uint64_t left = 1;
  data.writeBEInt<int8_t>(1);
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationFailed);

  // Write the value of the element into the array.
  data.drain(data.length());
  data.writeBEInt<int16_t>(1);
  data.writeBEInt<uint32_t>(123);
  // Simulate that message length end before end of array.
  left = 5;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationFailed);

  left = 6;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationOK);
  ASSERT_THAT(pos, 6);
  ASSERT_THAT(left, 0);
  pos = 0;
  left = 6;
  ASSERT_TRUE(field.read(data, pos, left));
  ASSERT_THAT(pos, 6);
  ASSERT_THAT(left, 0);

  auto out = field.toString();
  ASSERT_TRUE(out.find("Array of 1") != std::string::npos);
  ASSERT_TRUE(out.find("123") != std::string::npos);
}

TEST(Array, MultipleInts) {
  Array<Int8> field;

  Buffer::OwnedImpl data;
  // Write 3 as size of array, but add only 2 elements into array.
  data.writeBEInt<uint16_t>(3);
  data.writeBEInt<uint8_t>(211);
  data.writeBEInt<uint8_t>(212);

  uint64_t pos = 0;
  uint64_t left = 2 + 3 * 1;

  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationNeedMoreData);

  // Add the third element.
  data.writeBEInt<uint8_t>(213);

  // Simulate that message ends before end of the array.
  left = 2 + 3 * 1 - 1;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationFailed);

  left = 2 + 3 * 1;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationOK);
  ASSERT_THAT(pos, 5);
  ASSERT_THAT(left, 0);
  pos = 0;
  left = 2 + 3 * 1;
  ASSERT_TRUE(field.read(data, pos, left));
  ASSERT_THAT(pos, 5);
  ASSERT_THAT(left, 0);

  auto out = field.toString();
  ASSERT_TRUE(out.find("Array of 3") != std::string::npos);
  ASSERT_TRUE(out.find("211") != std::string::npos);
  ASSERT_TRUE(out.find("212") != std::string::npos);
  ASSERT_TRUE(out.find("213") != std::string::npos);
}

TEST(Array, Empty) {
  Array<Int16> field;

  Buffer::OwnedImpl data;
  // Write 0 elements into array.
  data.writeBEInt<uint16_t>(0);

  uint64_t pos = 0;
  uint64_t left = 2;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationOK);
  ASSERT_THAT(pos, 2);
  ASSERT_THAT(left, 0);
  pos = 0;
  left = 2;
  ASSERT_TRUE(field.read(data, pos, left));
  ASSERT_THAT(pos, 2);
  ASSERT_THAT(left, 0);

  auto out = field.toString();
  ASSERT_TRUE(out.find("Array of 0") != std::string::npos);
}

// Test situation when there is not enough data to read the length of the Array.
TEST(Array, NotEnoughDataForLength) {
  Array<Int16> field;

  Buffer::OwnedImpl data;
  // Data field is 2 bytes long. Write just one byte.
  data.writeBEInt<uint8_t>(1);

  uint64_t pos = 0;
  uint64_t left = 1;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationFailed);
}

// Test situation when there is not enough data in the buffer to read one of the elements
// in the array.
TEST(Array, NotEnoughDataForValues) {
  Array<Int32> field;

  Buffer::OwnedImpl data;
  // There will be 2 elements in the array.
  // The first element is 4 bytes long.
  // The second element should be 4 bytes long but is only 2 bytes long.
  data.writeBEInt<uint16_t>(2);
  data.writeBEInt<uint32_t>(101);
  data.writeBEInt<uint16_t>(102);

  uint64_t pos = 0;
  uint64_t left = 2 + 4 + 2;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationFailed);
}

// Repeated composite type tests.
TEST(Repeated, BasicTestWithStrings) {
  Repeated<String> field;

  Buffer::OwnedImpl data;
  // Write some data to simulate message header.
  // It will be ignored.
  data.writeBEInt<uint32_t>(101);
  data.writeBEInt<uint8_t>(102);
  uint64_t pos = 5;
  uint64_t left = 5;
  // Write the first string without terminating zero.
  data.add("test1");
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationFailed);
  left = 6;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationNeedMoreData);
  // Add terminating zero.
  data.writeBEInt<int8_t>(0);
  left = 5;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationFailed);
  left = 7;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationNeedMoreData);
  left = 6;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationOK);
  // Add two additional strings
  data.add("test2");
  data.writeBEInt<uint8_t>(0);
  data.add("test3");
  data.writeBEInt<uint8_t>(0);
  pos = 5;
  left = 3 * 6 - 1;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationFailed);
  left = 3 * 6 + 1;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationNeedMoreData);
  left = 3 * 6;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationOK);
  ASSERT_THAT(pos, 5 + 3 * 6);
  ASSERT_THAT(left, 0);
  pos = 5;
  left = 3 * 6;
  ASSERT_TRUE(field.read(data, pos, left));
  ASSERT_THAT(pos, 5 + 3 * 6);
  ASSERT_THAT(left, 0);

  auto out = field.toString();
  ASSERT_TRUE(out.find("test1") != std::string::npos);
  ASSERT_TRUE(out.find("test2") != std::string::npos);
  ASSERT_TRUE(out.find("test3") != std::string::npos);
}

// Sequence composite type tests.
TEST(Sequence, Int32SingleValue) {
  Sequence<Int32> field;

  Buffer::OwnedImpl data;
  data.writeBEInt<uint32_t>(101);

  uint64_t pos = 0;
  uint64_t left = 4;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationOK);
  ASSERT_THAT(pos, 4);
  ASSERT_THAT(left, 0);
  pos = 0;
  left = 4;
  ASSERT_TRUE(field.read(data, pos, left));
  ASSERT_THAT(pos, 4);
  ASSERT_THAT(left, 0);

  auto out = field.toString();
  ASSERT_TRUE(out.find("101") != std::string::npos);
}

TEST(Sequence, Int16SingleValue) {
  Sequence<Int16> field;

  Buffer::OwnedImpl data;
  data.writeBEInt<uint16_t>(101);

  uint64_t pos = 0;
  uint64_t left = 2;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationOK);
  ASSERT_THAT(pos, 2);
  ASSERT_THAT(left, 0);
  pos = 0;
  left = 2;
  ASSERT_TRUE(field.read(data, pos, left));
  ASSERT_THAT(pos, 2);
  ASSERT_THAT(left, 0);

  auto out = field.toString();
  ASSERT_TRUE(out.find("101") != std::string::npos);
}

TEST(Sequence, BasicMultipleValues1) {
  Sequence<Int32, String> field;

  Buffer::OwnedImpl data;
  data.writeBEInt<uint32_t>(101);
  data.add("test");
  data.writeBEInt<uint8_t>(0);

  uint64_t pos = 0;
  uint64_t left = 4 + 5;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationOK);
  ASSERT_THAT(pos, 4 + 5);
  ASSERT_THAT(left, 0);
  pos = 0;
  left = 4 + 5;
  ASSERT_TRUE(field.read(data, pos, left));
  ASSERT_THAT(pos, 4 + 5);
  ASSERT_THAT(left, 0);

  auto out = field.toString();
  ASSERT_TRUE(out.find("101") != std::string::npos);
  ASSERT_TRUE(out.find("test") != std::string::npos);
}

TEST(Sequence, BasicMultipleValues2) {
  Sequence<Int32, Int16> field;

  Buffer::OwnedImpl data;
  data.writeBEInt<uint32_t>(100);
  data.writeBEInt<uint16_t>(101);

  uint64_t pos = 0;
  uint64_t left = 4 + 2;
  uint64_t expected_pos = left;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationOK);
  ASSERT_THAT(pos, expected_pos);
  ASSERT_THAT(left, 0);
  pos = 0;
  left = 4 + 2;
  ASSERT_TRUE(field.read(data, pos, left));
  ASSERT_THAT(pos, expected_pos);
  ASSERT_THAT(left, 0);

  auto out = field.toString();
  ASSERT_TRUE(out.find("100") != std::string::npos);
  ASSERT_TRUE(out.find("101") != std::string::npos);
}

TEST(Sequence, BasicMultipleValues3) {
  Sequence<Int32, Int16, Int32, Int16> field;

  Buffer::OwnedImpl data;
  data.writeBEInt<uint32_t>(100);
  data.writeBEInt<uint16_t>(101);
  data.writeBEInt<uint32_t>(102);
  data.writeBEInt<uint16_t>(103);

  uint64_t pos = 0;
  uint64_t left = 4 + 2 + 4 + 2;
  uint64_t expected_pos = left;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationOK);
  ASSERT_THAT(pos, expected_pos);
  ASSERT_THAT(left, 0);
  pos = 0;
  left = 4 + 2 + 4 + 2;
  ASSERT_TRUE(field.read(data, pos, left));
  ASSERT_THAT(pos, expected_pos);
  ASSERT_THAT(left, 0);

  auto out = field.toString();
  ASSERT_TRUE(out.find("100") != std::string::npos);
  ASSERT_TRUE(out.find("101") != std::string::npos);
  ASSERT_TRUE(out.find("102") != std::string::npos);
  ASSERT_TRUE(out.find("103") != std::string::npos);
}

// Test versifies that read fails when reading of one element
// in Sequence fails.
TEST(Sequence, NotEnoughData) {
  Sequence<Int32, String> field;

  Buffer::OwnedImpl data;
  data.writeBEInt<uint32_t>(101);
  // Do not write terminating zero for the string.
  data.add("test");

  uint64_t pos = 0;
  uint64_t left = 4 + 4;
  ASSERT_THAT(field.validate(data, 0, pos, left), Message::ValidationFailed);
}

// Tests for Message interface and helper function createMsgBodyReader.
TEST(PostgresMessage, SingleFieldInt32) {
  std::unique_ptr<Message> msg = createMsgBodyReader<Int32>();

  Buffer::OwnedImpl data;
  // Validation of empty message should complain that there
  // is not enough data in the buffer.
  ASSERT_THAT(msg->validate(data, 0, 4), Message::ValidationNeedMoreData);

  data.writeBEInt<uint32_t>(12);

  // Simulate that message is longer than In32.
  ASSERT_THAT(msg->validate(data, 0, 5), Message::ValidationFailed);

  ASSERT_THAT(msg->validate(data, 0, 4), Message::ValidationOK);
  ASSERT_TRUE(msg->read(data, 4));
  auto out = msg->toString();
  ASSERT_THAT(out, "[12]");
}

TEST(PostgresMessage, SingleFieldInt16) {
  std::unique_ptr<Message> msg = createMsgBodyReader<Int16>();

  Buffer::OwnedImpl data;

  // Validation of empty message should complain that there
  // is not enough data in the buffer.
  ASSERT_THAT(msg->validate(data, 0, 2), Message::ValidationNeedMoreData);

  data.writeBEInt<uint16_t>(12);
  ASSERT_THAT(msg->validate(data, 0, 2), Message::ValidationOK);
  ASSERT_TRUE(msg->read(data, 2));
  auto out = msg->toString();
  ASSERT_THAT(out, "[12]");
}

TEST(PostgresMessage, SingleByteN) {
  std::unique_ptr<Message> msg = createMsgBodyReader<ByteN>();

  Buffer::OwnedImpl data;
  // Validation of empty message should complain that there
  // is not enough data in the buffer.
  ASSERT_THAT(msg->validate(data, 0, 4), Message::ValidationNeedMoreData);

  data.writeBEInt<uint8_t>(0);
  data.writeBEInt<uint8_t>(1);
  data.writeBEInt<uint8_t>(2);
  data.writeBEInt<uint8_t>(3);
  data.writeBEInt<uint8_t>(4);
  const uint64_t length = 5 * 1;
  ASSERT_THAT(msg->validate(data, 0, length), Message::ValidationOK);
  ASSERT_TRUE(msg->read(data, length));
  auto out = msg->toString();
  ASSERT_TRUE(out.find("0") != std::string::npos); // NOLINT
  ASSERT_TRUE(out.find("1") != std::string::npos); // NOLINT
  ASSERT_TRUE(out.find("2") != std::string::npos); // NOLINT
  ASSERT_TRUE(out.find("3") != std::string::npos); // NOLINT
  ASSERT_TRUE(out.find("4") != std::string::npos); // NOLINT
}

TEST(PostgresMessage, MultipleValues1) {
  std::unique_ptr<Message> msg = createMsgBodyReader<Int32, Int16>();

  Buffer::OwnedImpl data;

  // Validation of empty message should complain that there
  // is not enough data in the buffer.
  ASSERT_THAT(msg->validate(data, 0, 4), Message::ValidationNeedMoreData);

  data.writeBEInt<uint32_t>(12);
  data.writeBEInt<uint16_t>(13);
  const uint64_t length = 4 + 2;
  ASSERT_THAT(msg->validate(data, 0, length), Message::ValidationOK);
  ASSERT_TRUE(msg->read(data, length));
  auto out = msg->toString();
  ASSERT_TRUE(out.find("12") != std::string::npos);
  ASSERT_TRUE(out.find("13") != std::string::npos);
}

TEST(PostgresMessage, MultipleValues2) {
  std::unique_ptr<Message> msg = createMsgBodyReader<Int16, Int32, Int16>();

  Buffer::OwnedImpl data;
  data.writeBEInt<uint16_t>(13);
  data.writeBEInt<uint32_t>(14);
  data.writeBEInt<uint16_t>(15);
  const uint64_t length = 2 + 4 + 2;
  ASSERT_THAT(msg->validate(data, 0, length), Message::ValidationOK);
  ASSERT_TRUE(msg->read(data, length));
  auto out = msg->toString();
  ASSERT_TRUE(out.find("13") != std::string::npos);
  ASSERT_TRUE(out.find("14") != std::string::npos);
  ASSERT_TRUE(out.find("15") != std::string::npos);
}

TEST(PostgresMessage, MultipleValues3) {
  std::unique_ptr<Message> msg = createMsgBodyReader<Int32, Int16, Int32, Int16>();

  Buffer::OwnedImpl data;
  data.writeBEInt<uint32_t>(12);
  data.writeBEInt<uint16_t>(13);
  data.writeBEInt<uint32_t>(14);
  data.writeBEInt<uint16_t>(15);
  const uint64_t length = 4 + 2 + 4 + 2;
  ASSERT_THAT(msg->validate(data, 0, length), Message::ValidationOK);
  ASSERT_TRUE(msg->read(data, length));
  auto out = msg->toString();
  ASSERT_TRUE(out.find("12") != std::string::npos);
  ASSERT_TRUE(out.find("13") != std::string::npos);
  ASSERT_TRUE(out.find("14") != std::string::npos);
  ASSERT_TRUE(out.find("15") != std::string::npos);
}

TEST(PostgresMessage, MultipleValues4) {
  std::unique_ptr<Message> msg = createMsgBodyReader<Int16, Int32, Int16, Int32, Int16>();

  Buffer::OwnedImpl data;
  data.writeBEInt<uint16_t>(13);
  data.writeBEInt<uint32_t>(14);
  data.writeBEInt<uint16_t>(15);
  data.writeBEInt<uint32_t>(16);
  data.writeBEInt<uint16_t>(17);
  const uint64_t length = 2 + 4 + 2 + 4 + 2;
  ASSERT_THAT(msg->validate(data, 0, length), Message::ValidationOK);
  ASSERT_TRUE(msg->read(data, length));
  auto out = msg->toString();
  ASSERT_TRUE(out.find("13") != std::string::npos);
  ASSERT_TRUE(out.find("14") != std::string::npos);
  ASSERT_TRUE(out.find("15") != std::string::npos);
  ASSERT_TRUE(out.find("16") != std::string::npos);
  ASSERT_TRUE(out.find("17") != std::string::npos);
}

TEST(PostgresMessage, MultipleValues5) {
  std::unique_ptr<Message> msg = createMsgBodyReader<Int32, Int16, Int32, Int16, Int32, Int16>();

  Buffer::OwnedImpl data;
  data.writeBEInt<uint32_t>(12);
  data.writeBEInt<uint16_t>(13);
  data.writeBEInt<uint32_t>(14);
  data.writeBEInt<uint16_t>(15);
  data.writeBEInt<uint32_t>(16);
  data.writeBEInt<uint16_t>(17);
  const uint64_t length = 4 + 2 + 4 + 2 + 4 + 2;
  ASSERT_THAT(msg->validate(data, 0, length), Message::ValidationOK);
  ASSERT_TRUE(msg->read(data, length));
  auto out = msg->toString();
  ASSERT_TRUE(out.find("12") != std::string::npos);
  ASSERT_TRUE(out.find("13") != std::string::npos);
  ASSERT_TRUE(out.find("14") != std::string::npos);
  ASSERT_TRUE(out.find("15") != std::string::npos);
  ASSERT_TRUE(out.find("16") != std::string::npos);
  ASSERT_TRUE(out.find("17") != std::string::npos);
}

TEST(PostgresMessage, MultipleValues6) {
  std::unique_ptr<Message> msg =
      createMsgBodyReader<String, Int32, Int16, Int32, Int16, Int32, Int16>();

  Buffer::OwnedImpl data;
  data.add("test");
  data.writeBEInt<uint8_t>(0);
  data.writeBEInt<uint32_t>(12);
  data.writeBEInt<uint16_t>(13);
  data.writeBEInt<uint32_t>(14);
  data.writeBEInt<uint16_t>(15);
  data.writeBEInt<uint32_t>(16);
  data.writeBEInt<uint16_t>(17);
  const uint64_t length = 5 + 4 + 2 + 4 + 2 + 4 + 2;
  ASSERT_THAT(msg->validate(data, 0, length), Message::ValidationOK);
  ASSERT_TRUE(msg->read(data, length));
  auto out = msg->toString();
  ASSERT_TRUE(out.find("test") != std::string::npos);
  ASSERT_TRUE(out.find("12") != std::string::npos);
  ASSERT_TRUE(out.find("13") != std::string::npos);
  ASSERT_TRUE(out.find("14") != std::string::npos);
  ASSERT_TRUE(out.find("15") != std::string::npos);
  ASSERT_TRUE(out.find("16") != std::string::npos);
  ASSERT_TRUE(out.find("17") != std::string::npos);
}

TEST(PostgresMessage, MultipleValues7) {
  std::unique_ptr<Message> msg = createMsgBodyReader<String, Array<Int32>>();

  Buffer::OwnedImpl data;
  data.add("test");
  data.writeBEInt<uint8_t>(0);

  // Array of 3 elements.
  data.writeBEInt<int16_t>(3);
  data.writeBEInt<uint32_t>(13);
  data.writeBEInt<uint32_t>(14);
  data.writeBEInt<uint32_t>(15);
  const uint64_t length = 5 + 2 + 3 * 4;
  ASSERT_THAT(msg->validate(data, 0, length), Message::ValidationOK);
  ASSERT_TRUE(msg->read(data, length));
  auto out = msg->toString();
  ASSERT_TRUE(out.find("test") != std::string::npos);
  ASSERT_TRUE(out.find("13") != std::string::npos);
  ASSERT_TRUE(out.find("14") != std::string::npos);
  ASSERT_TRUE(out.find("15") != std::string::npos);
}

TEST(PostgresMessage, ArraySet1) {
  std::unique_ptr<Message> msg = createMsgBodyReader<Array<Int16>>();

  Buffer::OwnedImpl data;
  // There will be 3 elements in the array.
  data.writeBEInt<int16_t>(3);
  data.writeBEInt<uint16_t>(13);
  data.writeBEInt<uint16_t>(14);
  data.writeBEInt<uint16_t>(15);
  const uint64_t length = 2 + 3 * 2;
  ASSERT_THAT(msg->validate(data, 0, length), Message::ValidationOK);
  ASSERT_TRUE(msg->read(data, length));
  auto out = msg->toString();
  ASSERT_TRUE(out.find("13") != std::string::npos);
  ASSERT_TRUE(out.find("14") != std::string::npos);
  ASSERT_TRUE(out.find("15") != std::string::npos);
}

TEST(PostgresMessage, ArraySet2) {
  std::unique_ptr<Message> msg = createMsgBodyReader<Array<VarByteN>, Int16>();

  Buffer::OwnedImpl data;
  // Array of 1 element of VarByteN.
  data.writeBEInt<int16_t>(1);
  // VarByteN of 5 bytes long.
  data.writeBEInt<int32_t>(5);
  data.writeBEInt<uint8_t>(0);
  data.writeBEInt<uint8_t>(1);
  data.writeBEInt<uint8_t>(2);
  data.writeBEInt<uint8_t>(3);
  data.writeBEInt<uint8_t>(114);

  // 16-bits value.
  data.writeBEInt<uint16_t>(115);
  const uint64_t length = 2 + 4 + 5 + 2;
  ASSERT_THAT(msg->validate(data, 0, length), Message::ValidationOK);
  ASSERT_TRUE(msg->read(data, length));
  auto out = msg->toString();
  ASSERT_TRUE(out.find("114") != std::string::npos);
  ASSERT_TRUE(out.find("115") != std::string::npos);
}

TEST(PostgresMessage, ArraySet3) {
  std::unique_ptr<Message> msg = createMsgBodyReader<Array<Int16>, Array<VarByteN>, Int16>();

  Buffer::OwnedImpl data;
  // There will be 3 elements in the array.
  data.writeBEInt<int16_t>(3);
  data.writeBEInt<uint16_t>(13);
  data.writeBEInt<uint16_t>(14);
  data.writeBEInt<uint16_t>(15);

  // Array of 1 element of VarByteN.
  data.writeBEInt<int16_t>(1);
  // VarByteN of 5 bytes long.
  data.writeBEInt<int32_t>(5);
  data.writeBEInt<uint8_t>(0);
  data.writeBEInt<uint8_t>(1);
  data.writeBEInt<uint8_t>(2);
  data.writeBEInt<uint8_t>(3);
  data.writeBEInt<uint8_t>(4);

  // 16-bits value.
  data.writeBEInt<uint16_t>(115);
  const uint64_t length = 2 + 3 * 2 + 2 + 4 + 5 + 2;
  ASSERT_THAT(msg->validate(data, 0, length), Message::ValidationOK);
  ASSERT_TRUE(msg->read(data, length));
  auto out = msg->toString();
  ASSERT_TRUE(out.find("13") != std::string::npos);
  ASSERT_TRUE(out.find("115") != std::string::npos);
}

TEST(PostgresMessage, ArraySet4) {
  std::unique_ptr<Message> msg = createMsgBodyReader<Array<VarByteN>, Array<Int16>>();

  Buffer::OwnedImpl data;
  // Array of 1 element of VarByteN.
  data.writeBEInt<int16_t>(1);
  // VarByteN of 5 bytes long.
  data.writeBEInt<int32_t>(5);
  data.writeBEInt<uint8_t>(0);
  data.writeBEInt<uint8_t>(111);
  data.writeBEInt<uint8_t>(2);
  data.writeBEInt<uint8_t>(3);
  data.writeBEInt<uint8_t>(4);

  // Array of 2 elements in the second array.
  data.writeBEInt<int16_t>(2);
  data.writeBEInt<uint16_t>(113);
  data.writeBEInt<uint16_t>(114);
  const uint64_t length = 2 + 4 + 5 + 2 + 2 * 2;
  ASSERT_THAT(msg->validate(data, 0, length), Message::ValidationOK);
  ASSERT_TRUE(msg->read(data, length));
  auto out = msg->toString();
  ASSERT_TRUE(out.find("111") != std::string::npos);
  ASSERT_TRUE(out.find("114") != std::string::npos);
}

TEST(PostgresMessage, ArraySet5) {
  std::unique_ptr<Message> msg = createMsgBodyReader<Array<Int16>, Array<VarByteN>, Array<Int16>>();

  Buffer::OwnedImpl data;
  // There will be 3 elements in the first array.
  data.writeBEInt<int16_t>(3);
  data.writeBEInt<uint16_t>(13);
  data.writeBEInt<uint16_t>(14);
  data.writeBEInt<uint16_t>(15);

  // Array of 1 element of VarByteN.
  data.writeBEInt<int16_t>(1);
  // VarByteN of 5 bytes long.
  data.writeBEInt<int32_t>(5);
  data.writeBEInt<uint8_t>(0);
  data.writeBEInt<uint8_t>(1);
  data.writeBEInt<uint8_t>(2);
  data.writeBEInt<uint8_t>(3);
  data.writeBEInt<uint8_t>(4);

  // Array of 2 elements in the third array.
  data.writeBEInt<int16_t>(2);
  data.writeBEInt<uint16_t>(113);
  data.writeBEInt<uint16_t>(114);
  const uint64_t length = 2 + 3 * 2 + 2 + 4 + 5 + 2 + 2 * 2;
  ASSERT_THAT(msg->validate(data, 0, length), Message::ValidationOK);
  ASSERT_TRUE(msg->read(data, length));
  auto out = msg->toString();
  ASSERT_TRUE(out.find("13") != std::string::npos);
  ASSERT_TRUE(out.find("114") != std::string::npos);
}

TEST(PostgresMessage, ArraySet6) {
  std::unique_ptr<Message> msg =
      createMsgBodyReader<String, Array<Int16>, Array<VarByteN>, Array<Int16>>();

  Buffer::OwnedImpl data;
  // Write string.
  data.add("test");
  data.writeBEInt<int8_t>(0);

  // There will be 3 elements in the first array.
  data.writeBEInt<int16_t>(3);
  data.writeBEInt<uint16_t>(13);
  data.writeBEInt<uint16_t>(14);
  data.writeBEInt<uint16_t>(15);

  // Array of 1 element of VarByteN.
  data.writeBEInt<int16_t>(1);
  // VarByteN of 5 bytes long.
  data.writeBEInt<int32_t>(5);
  data.writeBEInt<uint8_t>(0);
  data.writeBEInt<uint8_t>(1);
  data.writeBEInt<uint8_t>(2);
  data.writeBEInt<uint8_t>(3);
  data.writeBEInt<uint8_t>(4);

  // Array of 2 elements in the third array.
  data.writeBEInt<int16_t>(2);
  data.writeBEInt<uint16_t>(113);
  data.writeBEInt<uint16_t>(114);

  const uint64_t length = 5 + 2 + 3 * 2 + 2 + 4 + 5 + 2 + 2 * 2;
  ASSERT_THAT(msg->validate(data, 0, length), Message::ValidationOK);
  ASSERT_TRUE(msg->read(data, length));
  auto out = msg->toString();
  ASSERT_TRUE(out.find("test") != std::string::npos);
  ASSERT_TRUE(out.find("13") != std::string::npos);
  ASSERT_TRUE(out.find("114") != std::string::npos);
}

TEST(PostgresMessage, Repeated1) {
  std::unique_ptr<Message> msg = createMsgBodyReader<Repeated<String>>();

  Buffer::OwnedImpl data;
  // Write 3 strings.
  data.add("test1");
  data.writeBEInt<int8_t>(0);
  data.add("test2");
  data.writeBEInt<int8_t>(0);
  data.add("test3");
  data.writeBEInt<int8_t>(0);

  const uint64_t length = 3 * 6;
  ASSERT_THAT(msg->validate(data, 0, length), Message::ValidationOK);
  ASSERT_TRUE(msg->read(data, length));
  auto out = msg->toString();
  ASSERT_TRUE(out.find("test1") != std::string::npos);
  ASSERT_TRUE(out.find("test2") != std::string::npos);
  ASSERT_TRUE(out.find("test3") != std::string::npos);
}

TEST(PostgresMessage, Repeated2) {
  std::unique_ptr<Message> msg = createMsgBodyReader<Int32, Repeated<String>>();

  Buffer::OwnedImpl data;
  data.writeBEInt<int32_t>(115);
  // Write 3 strings.
  data.add("test1");
  data.writeBEInt<int8_t>(0);
  data.add("test2");
  data.writeBEInt<int8_t>(0);
  data.add("test3");
  data.writeBEInt<int8_t>(0);

  const uint64_t length = 4 + 3 * 6;
  ASSERT_THAT(msg->validate(data, 0, length), Message::ValidationOK);
  ASSERT_TRUE(msg->read(data, length));
  auto out = msg->toString();
  ASSERT_TRUE(out.find("115") != std::string::npos);
  ASSERT_TRUE(out.find("test1") != std::string::npos);
  ASSERT_TRUE(out.find("test2") != std::string::npos);
  ASSERT_TRUE(out.find("test3") != std::string::npos);
}

TEST(PostgresMessage, NotEnoughData) {
  std::unique_ptr<Message> msg = createMsgBodyReader<Int32, String>();
  Buffer::OwnedImpl data;
  // Write only 3 bytes into the buffer.
  data.writeBEInt<uint8_t>(0);
  data.writeBEInt<uint8_t>(1);
  data.writeBEInt<uint8_t>(2);

  ASSERT_THAT(msg->validate(data, 0, 4), Message::ValidationNeedMoreData);
  ASSERT_THAT(msg->validate(data, 0, 2), Message::ValidationFailed);
}

// Test checks validating a properly formatted message
// which starts at some offset in data buffer.
TEST(PostgresMessage, ValidateFromOffset) {
  std::unique_ptr<Message> msg = createMsgBodyReader<Int32, String>();
  Buffer::OwnedImpl data;

  // Write some data which should be skipped by validator.
  data.add("skip");
  data.writeBEInt<int8_t>(0);

  // Write valid data according to message syntax.
  data.writeBEInt<uint32_t>(110);
  data.add("test123");
  data.writeBEInt<int8_t>(0);

  // Skip first 5 bytes in the buffer.
  ASSERT_THAT(msg->validate(data, 5, 4 + 8), Message::ValidationOK);
}

} // namespace PostgresProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include <gmock/gmock.h>
#include <gtest/gtest.h>

#include "contrib/postgres_proxy/filters/network/source/postgres_decoder.h"
#include "contrib/postgres_proxy/filters/network/test/postgres_test_utils.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace PostgresProxy {

class DecoderCallbacksMock : public DecoderCallbacks {
public:
  MOCK_METHOD(void, incMessagesBackend, (), (override));
  MOCK_METHOD(void, incMessagesFrontend, (), (override));
  MOCK_METHOD(void, incMessagesUnknown, (), (override));
  MOCK_METHOD(void, incSessionsEncrypted, (), (override));
  MOCK_METHOD(void, incSessionsUnencrypted, (), (override));
  MOCK_METHOD(void, incStatements, (StatementType), (override));
  MOCK_METHOD(void, incTransactions, (), (override));
  MOCK_METHOD(void, incTransactionsCommit, (), (override));
  MOCK_METHOD(void, incTransactionsRollback, (), (override));
  MOCK_METHOD(void, incNotices, (NoticeType), (override));
  MOCK_METHOD(void, incErrors, (ErrorType), (override));
  MOCK_METHOD(void, processQuery, (const std::string&), (override));
  MOCK_METHOD(bool, onSSLRequest, (), (override));
  MOCK_METHOD(bool, shouldEncryptUpstream, (), (const));
  MOCK_METHOD(void, sendUpstream, (Buffer::Instance&));
  MOCK_METHOD(bool, encryptUpstream, (bool, Buffer::Instance&));
};

// Define fixture class with decoder and mock callbacks.
class PostgresProxyDecoderTestBase {
public:
  PostgresProxyDecoderTestBase() {
    decoder_ = std::make_unique<DecoderImpl>(&callbacks_);
    decoder_->initialize();
    decoder_->state(DecoderImpl::State::InSyncState);
  }

protected:
  ::testing::NiceMock<DecoderCallbacksMock> callbacks_;
  std::unique_ptr<DecoderImpl> decoder_;

  // fields often used
  Buffer::OwnedImpl data_;
  char buf_[256]{};
  std::string payload_;
};

class PostgresProxyDecoderTest : public PostgresProxyDecoderTestBase, public ::testing::Test {};

// Class is used for parameterized tests for frontend messages.
class PostgresProxyFrontendDecoderTest : public PostgresProxyDecoderTestBase,
                                         public ::testing::TestWithParam<std::string> {};

// Class is used for parameterized tests for encrypted messages.
class PostgresProxyFrontendEncrDecoderTest : public PostgresProxyDecoderTestBase,
                                             public ::testing::TestWithParam<uint32_t> {};

// Class is used for parameterized tests for backend messages.
class PostgresProxyBackendDecoderTest : public PostgresProxyDecoderTestBase,
                                        public ::testing::TestWithParam<std::string> {};

class PostgresProxyBackendStatementTest
    : public PostgresProxyDecoderTestBase,
      public ::testing::TestWithParam<std::pair<std::string, bool>> {};

class PostgresProxyErrorTest
    : public PostgresProxyDecoderTestBase,
      public ::testing::TestWithParam<std::tuple<std::string, DecoderCallbacks::ErrorType>> {};

class PostgresProxyNoticeTest
    : public PostgresProxyDecoderTestBase,
      public ::testing::TestWithParam<std::tuple<std::string, DecoderCallbacks::NoticeType>> {};

// Test processing the startup message from a client.
// For historical reasons, the first message does not include
// command (first byte). It starts with length. The startup
// message contains the protocol version. After processing the
// startup message the server should start using message format
// with command as 1st byte.
TEST_F(PostgresProxyDecoderTest, StartupMessage) {
  decoder_->state(DecoderImpl::State::InitState);

  buf_[0] = '\0';
  // Startup message has the following structure:
  // Length (4 bytes) - payload and length field
  // version (4 bytes)
  // Attributes: key/value pairs separated by '\0'
  data_.writeBEInt<uint32_t>(53);
  // Add version code
  data_.writeBEInt<uint32_t>(0x00030000);
  // user-postgres key-pair
  data_.add("user"); // 4 bytes
  data_.add(buf_, 1);
  data_.add("postgres"); // 8 bytes
  data_.add(buf_, 1);
  // database-test-db key-pair
  data_.add("database"); // 8 bytes
  data_.add(buf_, 1);
  data_.add("testdb"); // 6 bytes
  data_.add(buf_, 1);
  // Some other attribute
  data_.add("attribute"); // 9 bytes
  data_.add(buf_, 1);
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::NeedMoreData);
  data_.add("blah"); // 4 bytes
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::NeedMoreData);
  data_.add(buf_, 1);
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::ReadyForNext);
  ASSERT_THAT(data_.length(), 0);
  // Decoder should move to InSyncState
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  // Verify parsing attributes
  ASSERT_THAT(decoder_->getAttributes().at("user"), "postgres");
  ASSERT_THAT(decoder_->getAttributes().at("database"), "testdb");
  // This attribute should not be found
  ASSERT_THAT(decoder_->getAttributes().find("no"), decoder_->getAttributes().end());
}

// Test verifies that when Startup message does not carry
// "database" attribute, it is derived from "user".
TEST_F(PostgresProxyDecoderTest, StartupMessageNoAttr) {
  decoder_->state(DecoderImpl::State::InitState);

  createInitialPostgresRequest(data_);

  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  ASSERT_THAT(data_.length(), 0);

  // Verify parsing attributes
  ASSERT_THAT(decoder_->getAttributes().at("user"), "postgres");
  ASSERT_THAT(decoder_->getAttributes().at("database"), "postgres");
  // This attribute should not be found
  ASSERT_THAT(decoder_->getAttributes().find("no"), decoder_->getAttributes().end());
}

TEST_F(PostgresProxyDecoderTest, InvalidStartupMessage) {
  decoder_->state(DecoderImpl::State::InitState);

  // Create a bogus message with incorrect syntax.
  // Length is 10 bytes.
  data_.writeBEInt<uint32_t>(10);
  for (auto i = 0; i < 6; i++) {
    data_.writeBEInt<uint8_t>(i);
  }

  // Decoder should move to OutOfSync state.
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::OutOfSyncState);
  ASSERT_THAT(data_.length(), 0);

  // All-zeros message.
  data_.writeBEInt<uint32_t>(0);
  for (auto i = 0; i < 6; i++) {
    data_.writeBEInt<uint8_t>(0);
  }

  // Decoder should move to OutOfSync state.
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::OutOfSyncState);
  ASSERT_THAT(data_.length(), 0);
}

// Test that decoder does not crash when it receives
// random data in InitState.
TEST_F(PostgresProxyDecoderTest, StartupMessageRandomData) {
  srand(time(nullptr));
  for (auto i = 0; i < 10000; i++) {
    decoder_->state(DecoderImpl::State::InSyncState);
    // Generate random length.
    uint32_t len = rand() % 20000;
    // Now fill the buffer with random data.
    for (uint32_t j = 0; j < len; j++) {
      data_.writeBEInt<uint32_t>(rand() % 1024);
      uint8_t data = static_cast<uint8_t>(rand() % 256);
      data_.writeBEInt<uint8_t>(data);
    }
    // Feed the buffer to the decoder. It should not crash.
    decoder_->onData(data_, true);

    // Reset the buffer for the next iteration.
    data_.drain(data_.length());
  }
}

//Test processing messages which map 1:1 with buffer.
// The buffer contains just a single entire message and
// nothing more.
TEST_F(PostgresProxyDecoderTest, ReadingBufferSingleMessages) {
  decoder_->state(DecoderImpl::State::InSyncState);
  // Feed empty buffer - should not crash.
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::NeedMoreData);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);

  // Put one byte. This is not enough to parse the message and that byte
  // should stay in the buffer.
  data_.add("H");
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::NeedMoreData);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  ASSERT_THAT(data_.length(), 1);

  // Add length of 4 bytes. It would mean completely empty message.
  // but it should be consumed.
  data_.writeBEInt<uint32_t>(4);
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  ASSERT_THAT(data_.length(), 0);

  // Create a message with 5 additional bytes.
  data_.add("d");
  // Add length.
  data_.writeBEInt<uint32_t>(9); // 4 bytes of length field + 5 of data.
  data_.add(buf_, 5);
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::ReadyForNext);
  ASSERT_THAT(data_.length(), 0);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
}

// Test simulates situation when decoder is called with incomplete message.
// The message should not be processed until the buffer is filled
// with missing bytes.
TEST_F(PostgresProxyDecoderTest, ReadingBufferLargeMessages) {
  decoder_->state(DecoderImpl::State::InSyncState);
  // Fill the buffer with message of 100 bytes long
  // but the buffer contains only 98 bytes.
  // It should not be processed.
  data_.add("d");
  // Add length.
  data_.writeBEInt<uint32_t>(100); // This also includes length field
  data_.add(buf_, 94);
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::NeedMoreData);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  // The buffer contains command (1 byte), length (4 bytes) and 94 bytes of message.
  ASSERT_THAT(data_.length(), 99);

  // Add 2 missing bytes and feed again to decoder.
  data_.add("AB");
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  ASSERT_THAT(data_.length(), 0);
}

// Test simulates situation when a buffer contains more than one
// message. Call to the decoder should consume only one message
// at a time and only when the buffer contains the entire message.
TEST_F(PostgresProxyDecoderTest, TwoMessagesInOneBuffer) {
  decoder_->state(DecoderImpl::State::InSyncState);
  // Create the first message of 50 bytes long (+1 for command).
  data_.add("d");
  // Add length.
  data_.writeBEInt<uint32_t>(50);
  data_.add(buf_, 46);

  // Create the second message of 50 + 46 bytes (+1 for command).
  data_.add("d");
  // Add length.
  data_.writeBEInt<uint32_t>(96);
  data_.add(buf_, 46);
  data_.add(buf_, 46);

  // The buffer contains two messaged:
  // 1st: command (1 byte), length (4 bytes), 46 bytes of data
  // 2nd: command (1 byte), length (4 bytes), 92 bytes of data
  ASSERT_THAT(data_.length(), 148);
  // Process the first message.
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  ASSERT_THAT(data_.length(), 97);
  // Process the second message.
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  ASSERT_THAT(data_.length(), 0);
}

TEST_F(PostgresProxyDecoderTest, Unknown) {
  decoder_->state(DecoderImpl::State::InSyncState);
  // Create invalid message. The first byte is invalid "="
  // Message must be at least 5 bytes to be parsed.
  EXPECT_CALL(callbacks_, incMessagesUnknown());
  createPostgresMsg(data_, "=", "some not important string which will be ignored anyways");
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::ReadyForNext);
  ASSERT_THAT(data_.length(), 0);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
}

// Test verifies that decoder goes into OutOfSyncState when
// it encounters a message with wrong syntax.
TEST_F(PostgresProxyDecoderTest, IncorrectMessages) {
  decoder_->state(DecoderImpl::State::InSyncState);

  // Create incorrect message. Message syntax is
  // 1 byte type ('f'), 4 bytes of length and zero terminated string.
  data_.add("f");
  data_.writeBEInt<uint32_t>(8);
  // Do not write terminating zero for the string.
  data_.add("test");

  // The decoder will indicate that is is ready for more data, but
  // will enter OutOfSyncState.
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::OutOfSyncState);
}

// Test if frontend command calls incMessagesFrontend() method.
TEST_F(PostgresProxyFrontendDecoderTest, FrontendInc) {
  decoder_->state(DecoderImpl::State::InSyncState);
  EXPECT_CALL(callbacks_, incMessagesFrontend());
  createPostgresMsg(data_, "f", "some text");
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);

  // Make sure that decoder releases memory used during message processing.
  ASSERT_TRUE(decoder_->getMessage().empty());
}

// Test if X message triggers incRollback and sets proper state in transaction.
TEST_F(PostgresProxyFrontendDecoderTest, TerminateMessage) {
  decoder_->state(DecoderImpl::State::InSyncState);
  // Set decoder state NOT to be in_transaction.
  decoder_->getSession().setInTransaction(false);
  EXPECT_CALL(callbacks_, incTransactionsRollback()).Times(0);
  createPostgresMsg(data_, "X");
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);

  // Now set the decoder to be in_transaction state.
  decoder_->getSession().setInTransaction(true);
  EXPECT_CALL(callbacks_, incTransactionsRollback());
  createPostgresMsg(data_, "X");
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  ASSERT_FALSE(decoder_->getSession().inTransaction());
}

// Query message should invoke filter's callback message
TEST_F(PostgresProxyFrontendDecoderTest, QueryMessage) {
  EXPECT_CALL(callbacks_, processQuery);
  createPostgresMsg(data_, "Q", "SELECT * FROM whatever;");
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
}

// Parse message has optional Query name which may be in front of actual
// query statement. This test verifies that both formats are processed
// correctly.
TEST_F(PostgresProxyFrontendDecoderTest, ParseMessage) {
  std::string query = "SELECT * FROM whatever;";
  std::string query_name, query_params;

  // Should be called twice with the same query.
  EXPECT_CALL(callbacks_, processQuery(query)).Times(2);

  // Set params to be zero.
  query_params.reserve(2);
  query_params += '\0';
  query_params += '\0';

  // Message without optional query name.
  query_name.reserve(1);
  query_name += '\0';
  createPostgresMsg(data_, "P", query_name + query + query_params);
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);

  // Message with optional name query_name
  query_name.clear();
  query_name.reserve(5);
  query_name += "P0_8";
  query_name += '\0';
  createPostgresMsg(data_, "P", query_name + query + query_params);
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
}

// Test if backend command calls incMessagesBackend()) method.
TEST_F(PostgresProxyBackendDecoderTest, BackendInc) {
  EXPECT_CALL(callbacks_, incMessagesBackend());
  createPostgresMsg(data_, "I");
  ASSERT_THAT(decoder_->onData(data_, false), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
}

// Test parsing backend messages.
// The parser should react only to the first word until the space.
TEST_F(PostgresProxyBackendDecoderTest, ParseStatement) {
  // Payload contains a space after the keyword
  // Rollback counter should be bumped up.
  EXPECT_CALL(callbacks_, incTransactionsRollback());
  createPostgresMsg(data_, "C", "ROLLBACK 123");
  ASSERT_THAT(decoder_->onData(data_, false), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  data_.drain(data_.length());

  // Now try just keyword without a space at the end.
  EXPECT_CALL(callbacks_, incTransactionsRollback());
  createPostgresMsg(data_, "C", "ROLLBACK");
  ASSERT_THAT(decoder_->onData(data_, false), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  data_.drain(data_.length());

  // Partial message should be ignored.
  EXPECT_CALL(callbacks_, incTransactionsRollback()).Times(0);
  EXPECT_CALL(callbacks_, incStatements(DecoderCallbacks::StatementType::Other));
  createPostgresMsg(data_, "C", "ROLL");
  ASSERT_THAT(decoder_->onData(data_, false), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  data_.drain(data_.length());

  // Keyword without a space  should be ignored.
  EXPECT_CALL(callbacks_, incTransactionsRollback()).Times(0);
  EXPECT_CALL(callbacks_, incStatements(DecoderCallbacks::StatementType::Other));
  createPostgresMsg(data_, "C", "ROLLBACK123");
  ASSERT_THAT(decoder_->onData(data_, false), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  data_.drain(data_.length());
}

// Test Backend messages and make sure that they
// trigger proper stats updates.
TEST_F(PostgresProxyDecoderTest, Backend) {
  decoder_->state(DecoderImpl::State::InSyncState);
  // C message
  EXPECT_CALL(callbacks_, incStatements(DecoderCallbacks::StatementType::Other));
  createPostgresMsg(data_, "C", "BEGIN 123");
  ASSERT_THAT(decoder_->onData(data_, false), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  ASSERT_THAT(data_.length(), 0);
  ASSERT_TRUE(decoder_->getSession().inTransaction());

  EXPECT_CALL(callbacks_, incStatements(DecoderCallbacks::StatementType::Other));
  createPostgresMsg(data_, "C", "START TR");
  ASSERT_THAT(decoder_->onData(data_, false), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  ASSERT_THAT(data_.length(), 0);

  EXPECT_CALL(callbacks_, incStatements(DecoderCallbacks::StatementType::Other));
  EXPECT_CALL(callbacks_, incTransactionsCommit());
  createPostgresMsg(data_, "C", "COMMIT");
  ASSERT_THAT(decoder_->onData(data_, false), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  ASSERT_THAT(data_.length(), 0);

  EXPECT_CALL(callbacks_, incStatements(DecoderCallbacks::StatementType::Select));
  EXPECT_CALL(callbacks_, incTransactionsCommit());
  createPostgresMsg(data_, "C", "SELECT");
  ASSERT_THAT(decoder_->onData(data_, false), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  ASSERT_THAT(data_.length(), 0);

  EXPECT_CALL(callbacks_, incStatements(DecoderCallbacks::StatementType::Other));
  EXPECT_CALL(callbacks_, incTransactionsRollback());
  createPostgresMsg(data_, "C", "ROLLBACK");
  ASSERT_THAT(decoder_->onData(data_, false), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  ASSERT_THAT(data_.length(), 0);

  EXPECT_CALL(callbacks_, incStatements(DecoderCallbacks::StatementType::Insert));
  EXPECT_CALL(callbacks_, incTransactionsCommit());
  createPostgresMsg(data_, "C", "INSERT 1");
  ASSERT_THAT(decoder_->onData(data_, false), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  ASSERT_THAT(data_.length(), 0);

  EXPECT_CALL(callbacks_, incStatements(DecoderCallbacks::StatementType::Update));
  EXPECT_CALL(callbacks_, incTransactionsCommit());
  createPostgresMsg(data_, "C", "UPDATE 123");
  ASSERT_THAT(decoder_->onData(data_, false), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  ASSERT_THAT(data_.length(), 0);

  EXPECT_CALL(callbacks_, incStatements(DecoderCallbacks::StatementType::Delete));
  EXPECT_CALL(callbacks_, incTransactionsCommit());
  createPostgresMsg(data_, "C", "DELETE 88");
  ASSERT_THAT(decoder_->onData(data_, false), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  ASSERT_THAT(data_.length(), 0);
}

// Test checks deep inspection of the R message.
// During login/authentication phase client and server exchange
// multiple R messages. Only payload with length is 8 and
// payload with uint32 number equal to 0 indicates
// successful authentication.
TEST_F(PostgresProxyBackendDecoderTest, AuthenticationMsg) {
  // Create authentication message which does not
  // mean that authentication was OK. The number of
  // sessions must not be increased.
  EXPECT_CALL(callbacks_, incSessionsUnencrypted()).Times(0);
  createPostgresMsg(data_, "R", "blah blah");
  ASSERT_THAT(decoder_->onData(data_, false), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  data_.drain(data_.length());

  // Create the correct payload which means that
  // authentication completed successfully.
  EXPECT_CALL(callbacks_, incSessionsUnencrypted());
  data_.add("R");
  // Add length.
  data_.writeBEInt<uint32_t>(8);
  // Add 4-byte code.
  data_.writeBEInt<uint32_t>(0);
  ASSERT_THAT(decoder_->onData(data_, false), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
  data_.drain(data_.length());
}

// Test check parsing of E message. The message
// indicates error.
TEST_P(PostgresProxyErrorTest, ParseErrorMsgs) {
  EXPECT_CALL(callbacks_, incErrors(std::get<1>(GetParam())));
  createPostgresMsg(data_, "E", std::get<0>(GetParam()));
  ASSERT_THAT(decoder_->onData(data_, false), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
}

INSTANTIATE_TEST_SUITE_P(
    PostgresProxyErrorTestSuite, PostgresProxyErrorTest,
    ::testing::Values(
        std::make_tuple("blah blah", DecoderCallbacks::ErrorType::Unknown),
        std::make_tuple("SERRORC1234", DecoderCallbacks::ErrorType::Error),
        std::make_tuple("SERRORVERRORC1234", DecoderCallbacks::ErrorType::Error),
        std::make_tuple("SFATALVFATALC22012", DecoderCallbacks::ErrorType::Fatal),
        std::make_tuple("SPANICVPANICC22012", DecoderCallbacks::ErrorType::Panic),
        // This is the real German message in Postgres > 9.6. It contains keyword
        // in English with V prefix.
        std::make_tuple("SPANIKVPANICC42501Mkonnte Datei pg_wal/000000010000000100000096 nicht "
                        "ffnen: Permission deniedFxlog.cL3229RXLogFileInit",
                        DecoderCallbacks::ErrorType::Panic),
        // This is German message indicating error. The comment field contains word PANIC.
        // Since we do not decode other languages, it should go into Other bucket.
        // This situation can only happen in Postgres < 9.6. Starting with version 9.6
        // messages must have severity in English with prefix V.
        std::make_tuple("SFEHLERCP0001MMy PANIC ugly messageFpl_exec.cL3216Rexec_stmt_raise",
                        DecoderCallbacks::ErrorType::Unknown)));

// Test parsing N message. It indicate notice
// and carries additional information about the
// purpose of the message.
TEST_P(PostgresProxyNoticeTest, ParseNoticeMsgs) {
  EXPECT_CALL(callbacks_, incNotices(std::get<1>(GetParam())));
  createPostgresMsg(data_, "N", std::get<0>(GetParam()));
  ASSERT_THAT(decoder_->onData(data_, false), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
}

INSTANTIATE_TEST_SUITE_P(
    PostgresProxyNoticeTestSuite, PostgresProxyNoticeTest,
    ::testing::Values(std::make_tuple("blah blah", DecoderCallbacks::NoticeType::Unknown),
                      std::make_tuple("SblalalaC2345", DecoderCallbacks::NoticeType::Unknown),
                      std::make_tuple("SblahVWARNING23345", DecoderCallbacks::NoticeType::Warning),
                      std::make_tuple("SNOTICEERRORbbal4", DecoderCallbacks::NoticeType::Notice),
                      std::make_tuple("SINFOVblabla", DecoderCallbacks::NoticeType::Info),
                      std::make_tuple("SDEBUGDEBUG", DecoderCallbacks::NoticeType::Debug),
                      std::make_tuple("SLOGGGGINFO", DecoderCallbacks::NoticeType::Log)));

// Test checks if the decoder can detect initial message which indicates
// that protocol uses encryption.
TEST_P(PostgresProxyFrontendEncrDecoderTest, EncyptedTraffic) {
  // Set decoder to wait for initial message.
  decoder_->state(DecoderImpl::State::InitState);

  // Initial state is no-encryption.
  // ASSERT_FALSE(decoder_->encrypted());

  // Indicate that decoder should continue with processing the message.
  ON_CALL(callbacks_, onSSLRequest).WillByDefault(testing::Return(true));

  // Create SSLRequest.
  EXPECT_CALL(callbacks_, incSessionsEncrypted());
  // Add length.
  data_.writeBEInt<uint32_t>(8);
  // 1234 in the most significant 16 bits, and some code in the least significant 16 bits.
  // Add 4 bytes long code
  data_.writeBEInt<uint32_t>(GetParam());
  // Decoder should indicate that it is ready for mode data and entered
  // encrypted state.
  ASSERT_THAT(decoder_->onData(data_, false), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::EncryptedState);
  // ASSERT_TRUE(decoder_->encrypted());
  // Decoder should drain data.
  ASSERT_THAT(data_.length(), 0);

  // Now when decoder detected encrypted traffic is should not
  // react to any messages (even not encrypted ones).
  EXPECT_CALL(callbacks_, incMessagesFrontend()).Times(0);

  createPostgresMsg(data_, "P", "Some message just to fill the payload.");
  ASSERT_THAT(decoder_->onData(data_, false), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::EncryptedState);
  // Decoder should drain data.
  ASSERT_THAT(data_.length(), 0);
}

// Run encryption tests.
// 80877103 is SSL code
// 80877104 is GSS code
INSTANTIATE_TEST_SUITE_P(FrontendEncryptedMessagesTests, PostgresProxyFrontendEncrDecoderTest,
                         ::testing::Values(80877103, 80877104));

// Test onSSLRequest callback.
TEST_F(PostgresProxyDecoderTest, TerminateSSL) {
  // Set decoder to wait for initial message.
  decoder_->state(DecoderImpl::State::InitState);

  // Indicate that decoder should not continue with processing the message
  // because filter will try to terminate SSL session.
  EXPECT_CALL(callbacks_, onSSLRequest).WillOnce(testing::Return(false));

  // Send initial message requesting SSL.
  data_.writeBEInt<uint32_t>(8);
  // 1234 in the most significant 16 bits, and some code in the least significant 16 bits.
  // Add 4 bytes long code
  data_.writeBEInt<uint32_t>(80877103);
  ASSERT_THAT(decoder_->onData(data_, false), Decoder::Result::Stopped);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InitState);

  // Decoder should interpret the session as clear-text stream.
  ASSERT_FALSE(decoder_->encrypted());
}

class PostgresProxyUpstreamSSLTest
    : public PostgresProxyDecoderTestBase,
      public ::testing::TestWithParam<std::tuple<std::string, bool, DecoderImpl::State>> {};

TEST_F(PostgresProxyDecoderTest, UpstreamSSLDisabled) {
  // Set decoder to wait for initial message.
  decoder_->state(DecoderImpl::State::InitState);

  createInitialPostgresRequest(data_);

  EXPECT_CALL(callbacks_, shouldEncryptUpstream).WillOnce(testing::Return(false));
  EXPECT_CALL(callbacks_, encryptUpstream(testing::_, testing::_)).Times(0);
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
}

TEST_P(PostgresProxyUpstreamSSLTest, UpstreamSSLEnabled) {
  // Set decoder to wait for initial message.
  decoder_->state(DecoderImpl::State::InitState);

  // Create initial message
  createInitialPostgresRequest(data_);

  EXPECT_CALL(callbacks_, shouldEncryptUpstream).WillOnce(testing::Return(true));
  EXPECT_CALL(callbacks_, sendUpstream);
  ASSERT_THAT(decoder_->onData(data_, true), Decoder::Result::Stopped);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::NegotiatingUpstreamSSL);

  // Simulate various responses from the upstream server.
  // Only "S" and "N" are valid responses.
  data_.add(std::get<0>(GetParam()));

  EXPECT_CALL(callbacks_, encryptUpstream(std::get<1>(GetParam()), testing::_));
  // The reply from upstream should not be delivered to the client.
  ASSERT_THAT(decoder_->onData(data_, false), Decoder::Result::Stopped);
  ASSERT_THAT(decoder_->state(), std::get<2>(GetParam()));
  ASSERT_TRUE(data_.length() == 0);
}

INSTANTIATE_TEST_SUITE_P(BackendEncryptedMessagesTests, PostgresProxyUpstreamSSLTest,
                         ::testing::Values(
                             // Correct response from the server (encrypt).
                             std::make_tuple("S", true, DecoderImpl::State::InitState),
                             // Correct response from the server (do not encrypt).
                             std::make_tuple("N", false, DecoderImpl::State::InitState),
                             // Incorrect response from the server. Move to out-of-sync state.
                             std::make_tuple("W", false, DecoderImpl::State::OutOfSyncState),
                             std::make_tuple("WRONG", false, DecoderImpl::State::OutOfSyncState)));

class FakeBuffer : public Buffer::Instance {
public:
  MOCK_METHOD(void, addDrainTracker, (std::function<void()>), (override));
  MOCK_METHOD(void, bindAccount, (Buffer::BufferMemoryAccountSharedPtr), (override));
  MOCK_METHOD(void, add, (const void*, uint64_t), (override));
  MOCK_METHOD(void, addBufferFragment, (Buffer::BufferFragment&), (override));
  MOCK_METHOD(void, add, (absl::string_view), (override));
  MOCK_METHOD(void, add, (const Instance&), (override));
  MOCK_METHOD(void, prepend, (absl::string_view), (override));
  MOCK_METHOD(void, prepend, (Instance&), (override));
  MOCK_METHOD(void, copyOut, (size_t, uint64_t, void*), (const, override));
  MOCK_METHOD(uint64_t, copyOutToSlices,
              (uint64_t size, Buffer::RawSlice* slices, uint64_t num_slice), (const, override));
  MOCK_METHOD(void, drain, (uint64_t), (override));
  MOCK_METHOD(Buffer::RawSliceVector, getRawSlices, (absl::optional<uint64_t>), (const, override));
  MOCK_METHOD(Buffer::RawSlice, frontSlice, (), (const, override));
  MOCK_METHOD(Buffer::SliceDataPtr, extractMutableFrontSlice, (), (override));
  MOCK_METHOD(uint64_t, length, (), (const, override));
  MOCK_METHOD(void*, linearize, (uint32_t), (override));
  MOCK_METHOD(void, move, (Instance&), (override));
  MOCK_METHOD(void, move, (Instance&, uint64_t), (override));
  MOCK_METHOD(void, move, (Instance&, uint64_t, bool), (override));
  MOCK_METHOD(Buffer::Reservation, reserveForRead, (), (override));
  MOCK_METHOD(Buffer::ReservationSingleSlice, reserveSingleSlice, (uint64_t, bool), (override));
  MOCK_METHOD(void, commit,
              (uint64_t, absl::Span<Buffer::RawSlice>, Buffer::ReservationSlicesOwnerPtr),
              (override));
  MOCK_METHOD(ssize_t, search, (const void*, uint64_t, size_t, size_t), (const, override));
  MOCK_METHOD(bool, startsWith, (absl::string_view), (const, override));
  MOCK_METHOD(std::string, toString, (), (const, override));
  MOCK_METHOD(void, setWatermarks, (uint32_t, uint32_t), (override));
  MOCK_METHOD(uint32_t, highWatermark, (), (const, override));
  MOCK_METHOD(bool, highWatermarkTriggered, (), (const, override));
  MOCK_METHOD(size_t, addFragments, (absl::Span<const absl::string_view>));
};

// Test verifies that decoder calls Buffer::linearize method
// for messages which have associated 'action'.
TEST_F(PostgresProxyDecoderTest, Linearize) {
  decoder_->state(DecoderImpl::State::InSyncState);
  testing::NiceMock<FakeBuffer> fake_buf;
  uint8_t body[] = "test\0";

  // Simulate that decoder reads message which needs processing.
  // Query 'Q' message's body is just string.
  // Message header is 5 bytes and body will contain string "test\0".
  EXPECT_CALL(fake_buf, length).WillRepeatedly(testing::Return(10));
  // The decoder will first ask for 1-byte message type
  // Then for length and finally for message body.
  EXPECT_CALL(fake_buf, copyOut)
      .WillOnce([](size_t start, uint64_t size, void* data) {
        ASSERT_THAT(start, 0);
        ASSERT_THAT(size, 1);
        *(static_cast<char*>(data)) = 'Q';
      })
      .WillOnce([](size_t start, uint64_t size, void* data) {
        ASSERT_THAT(start, 1);
        ASSERT_THAT(size, 4);
        *(static_cast<uint32_t*>(data)) = htonl(9);
      })
      .WillRepeatedly([=](size_t start, uint64_t size, void* data) {
        ASSERT_THAT(start, 0);
        ASSERT_THAT(size, 5);
        memcpy(data, body, 5);
      });

  // It should call "Buffer::linearize".
  EXPECT_CALL(fake_buf, linearize).WillOnce([&](uint32_t) -> void* { return body; });

  ASSERT_THAT(decoder_->onData(fake_buf, false), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);

  // Simulate that decoder reads message which does not need processing.
  // BindComplete message has type '2' and empty body.
  // Total message length is equal to length of header (5 bytes).
  EXPECT_CALL(fake_buf, length).WillRepeatedly(testing::Return(5));
  // The decoder will first ask for 1-byte message type and next for length.
  EXPECT_CALL(fake_buf, copyOut)
      .WillOnce([](size_t start, uint64_t size, void* data) {
        ASSERT_THAT(start, 0);
        ASSERT_THAT(size, 1);
        *(static_cast<char*>(data)) = '2';
      })
      .WillOnce([](size_t start, uint64_t size, void* data) {
        ASSERT_THAT(start, 1);
        ASSERT_THAT(size, 4);
        *(static_cast<uint32_t*>(data)) = htonl(4);
      });

  // Make sure that decoder does not call linearize.
  EXPECT_CALL(fake_buf, linearize).Times(0);

  ASSERT_THAT(decoder_->onData(fake_buf, false), Decoder::Result::ReadyForNext);
  ASSERT_THAT(decoder_->state(), DecoderImpl::State::InSyncState);
}

} // namespace PostgresProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/postgres_proxy/filters/network/test/postgres_test_utils.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace PostgresProxy {

// Helper function to create postgres messages.
void createPostgresMsg(Buffer::Instance& data, std::string type, std::string payload) {
  data.drain(data.length());
  ASSERT(1 == type.length());
  data.add(type);
  data.writeBEInt<uint32_t>(4 + (payload.empty() ? 0 : (payload.length() + 1)));
  if (!payload.empty()) {
    data.add(payload);
    data.writeBEInt<uint8_t>(0);
  }
}

// Helper function to create an initial postgres message.
void createInitialPostgresRequest(Buffer::Instance& data) {
  // Startup message has the following structure:
  // Length (4 bytes) - payload and length field
  // version (4 bytes)
  // Attributes: key/value pairs separated by '\0'
  data.writeBEInt<uint32_t>(37);
  // Add version code
  data.writeBEInt<uint32_t>(0x00030000);
  // user-postgres key-pair
  data.add("user"); // 4 bytes
  data.writeBEInt<uint8_t>(0);
  data.add("postgres"); // 8 bytes
  data.writeBEInt<uint8_t>(0);
  // database-test-db key-pair
  // Some other attribute
  data.add("attribute"); // 9 bytes
  data.writeBEInt<uint8_t>(0);
  data.add("blah"); // 4 bytes
  data.writeBEInt<uint8_t>(0);
}

} // namespace PostgresProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "source/common/network/connection_impl.h"
#include "source/extensions/filters/network/common/factory_base.h"
#include "source/extensions/transport_sockets/tls/context_config_impl.h"
#include "source/extensions/transport_sockets/tls/ssl_socket.h"

#include "test/integration/fake_upstream.h"
#include "test/integration/integration.h"
#include "test/integration/utility.h"
#include "test/mocks/network/mocks.h"
#include "test/test_common/network_utility.h"
#include "test/test_common/registry.h"

#include "contrib/envoy/extensions/filters/network/postgres_proxy/v3alpha/postgres_proxy.pb.h"
#include "contrib/envoy/extensions/filters/network/postgres_proxy/v3alpha/postgres_proxy.pb.validate.h"
#include "contrib/postgres_proxy/filters/network/test/postgres_integration_test.pb.h"
#include "contrib/postgres_proxy/filters/network/test/postgres_integration_test.pb.validate.h"
#include "contrib/postgres_proxy/filters/network/test/postgres_test_utils.h"
#include "gmock/gmock.h"
#include "gtest/gtest.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace PostgresProxy {

class PostgresBaseIntegrationTest : public testing::TestWithParam<Network::Address::IpVersion>,
                                    public BaseIntegrationTest {
public:
  // Tuple to store upstream and downstream startTLS configuration.
  // The first string contains string to enable/disable SSL.
  // The second string contains transport socket configuration.
  using SSLConfig = std::tuple<const absl::string_view, const absl::string_view>;

  std::string postgresConfig(SSLConfig downstream_ssl_config, SSLConfig upstream_ssl_config,
                             std::string additional_filters) {
    std::string main_config = fmt::format(
        TestEnvironment::readFileToStringForTest(TestEnvironment::runfilesPath(
            "contrib/postgres_proxy/filters/network/test/postgres_test_config.yaml-template")),
        Platform::null_device_path, Network::Test::getLoopbackAddressString(GetParam()),
        Network::Test::getLoopbackAddressString(GetParam()),
        std::get<1>(upstream_ssl_config), // upstream SSL transport socket
        Network::Test::getAnyAddressString(GetParam()),
        std::get<0>(downstream_ssl_config),  // downstream SSL termination
        std::get<0>(upstream_ssl_config),    // upstream_SSL option
        additional_filters,                  // additional filters to insert after postgres
        std::get<1>(downstream_ssl_config)); // downstream SSL transport socket

    return main_config;
  }

  PostgresBaseIntegrationTest(SSLConfig downstream_ssl_config, SSLConfig upstream_ssl_config,
                              std::string additional_filters = "")
      : BaseIntegrationTest(GetParam(), postgresConfig(downstream_ssl_config, upstream_ssl_config,
                                                       additional_filters)) {
    skip_tag_extraction_rule_check_ = true;
  };

  void SetUp() override { BaseIntegrationTest::initialize(); }

  static constexpr absl::string_view empty_config_string_{""};
  static constexpr SSLConfig NoUpstreamSSL{empty_config_string_, empty_config_string_};
  static constexpr SSLConfig NoDownstreamSSL{empty_config_string_, empty_config_string_};
  FakeRawConnectionPtr fake_upstream_connection_;
};

// Base class for tests with `terminate_ssl` disabled and without
// `starttls` transport socket.
class BasicPostgresIntegrationTest : public PostgresBaseIntegrationTest {
public:
  BasicPostgresIntegrationTest() : PostgresBaseIntegrationTest(NoDownstreamSSL, NoUpstreamSSL) {}
};

// Test that the filter is properly chained and reacts to successful login
// message.
TEST_P(BasicPostgresIntegrationTest, Login) {
  std::string str;
  std::string recv;

  IntegrationTcpClientPtr tcp_client = makeTcpConnection(lookupPort("listener_0"));
  FakeRawConnectionPtr fake_upstream_connection;
  ASSERT_TRUE(fake_upstreams_[0]->waitForRawConnection(fake_upstream_connection));

  // Send the startup message.
  Buffer::OwnedImpl data;
  std::string rcvd;
  char buf[32];

  memset(buf, 0, sizeof(buf));
  // Add length.
  data.writeBEInt<uint32_t>(12);
  // Add 8 bytes of some data.
  data.add(buf, 8);
  ASSERT_TRUE(tcp_client->write(data.toString()));
  ASSERT_TRUE(fake_upstream_connection->waitForData(data.toString().length(), &rcvd));
  data.drain(data.length());

  // TCP session is up. Just send the AuthenticationOK downstream.
  data.add("R");
  // Add length.
  data.writeBEInt<uint32_t>(8);
  uint32_t code = 0;
  data.add(&code, sizeof(code));

  rcvd.clear();
  ASSERT_TRUE(fake_upstream_connection->write(data.toString()));
  rcvd.append(data.toString());
  tcp_client->waitForData(rcvd, true);

  tcp_client->close();
  ASSERT_TRUE(fake_upstream_connection->waitForDisconnect());

  // Make sure that the successful login bumped up the number of sessions.
  test_server_->waitForCounterEq("postgres.postgres_stats.sessions", 1);
}
INSTANTIATE_TEST_SUITE_P(IpVersions, BasicPostgresIntegrationTest,
                         testing::ValuesIn(TestEnvironment::getIpVersionsForTest()));

// Base class for tests with `terminate_ssl` enabled and `starttls` transport socket added.
class DownstreamSSLPostgresIntegrationTest : public PostgresBaseIntegrationTest {
public:
  DownstreamSSLPostgresIntegrationTest()
      : PostgresBaseIntegrationTest(
            std::make_tuple(
                "terminate_ssl: true",
                fmt::format(
                    R"EOF(transport_socket:
        name: "starttls"
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.transport_sockets.starttls.v3.StartTlsConfig
          cleartext_socket_config:
          tls_socket_config:
            common_tls_context:
              tls_certificates:
                certificate_chain:
                  filename: {}
                private_key:
                  filename: {}
   )EOF",
                    TestEnvironment::runfilesPath("test/config/integration/certs/servercert.pem"),
                    TestEnvironment::runfilesPath("test/config/integration/certs/serverkey.pem"))),
            NoUpstreamSSL) {}
};

// Test verifies that Postgres filter replies with correct code upon
// receiving request to terminate SSL.
TEST_P(DownstreamSSLPostgresIntegrationTest, TerminateSSL) {
  Buffer::OwnedImpl data;

  IntegrationTcpClientPtr tcp_client = makeTcpConnection(lookupPort("listener_0"));
  FakeRawConnectionPtr fake_upstream_connection;
  ASSERT_TRUE(fake_upstreams_[0]->waitForRawConnection(fake_upstream_connection));

  // Send the startup message requesting SSL.
  // Message is 8 bytes long. The first 4 bytes contain length (8)
  // The next 8 bytes contain message code (RequestSSL=80877103)
  data.writeBEInt<uint32_t>(8);
  data.writeBEInt<uint32_t>(80877103);

  // Message will be processed by Postgres filter which
  // is configured to accept SSL termination and confirm it
  // by returning single byte 'S'.
  ASSERT_TRUE(tcp_client->write(data.toString()));
  data.drain(data.length());

  tcp_client->waitForData("S", true);

  tcp_client->close();
  ASSERT_TRUE(fake_upstream_connection->waitForDisconnect());

  // Make sure that the successful login bumped up the number of sessions.
  test_server_->waitForCounterEq("postgres.postgres_stats.sessions_terminated_ssl", 1);
}

INSTANTIATE_TEST_SUITE_P(IpVersions, DownstreamSSLPostgresIntegrationTest,
                         testing::ValuesIn(TestEnvironment::getIpVersionsForTest()));

class DownstreamSSLWrongConfigPostgresIntegrationTest : public PostgresBaseIntegrationTest {
public:
  DownstreamSSLWrongConfigPostgresIntegrationTest()
      // Enable SSL termination but do not configure downstream transport socket.
      : PostgresBaseIntegrationTest(std::make_tuple("terminate_ssl: true", ""), NoUpstreamSSL) {}
};

// Test verifies that Postgres filter closes connection when it is configured to
// terminate SSL, but underlying transport socket does not allow for such operation.
TEST_P(DownstreamSSLWrongConfigPostgresIntegrationTest, TerminateSSLNoStartTlsTransportSocket) {
  Buffer::OwnedImpl data;

  IntegrationTcpClientPtr tcp_client = makeTcpConnection(lookupPort("listener_0"));
  FakeRawConnectionPtr fake_upstream_connection;
  ASSERT_TRUE(fake_upstreams_[0]->waitForRawConnection(fake_upstream_connection));

  // Send the startup message requesting SSL.
  // Message is 8 bytes long. The first 4 bytes contain length (8)
  // The next 8 bytes contain message code (RequestSSL=80877103)
  data.writeBEInt<uint32_t>(8);
  data.writeBEInt<uint32_t>(80877103);

  // Message will be processed by Postgres filter which
  // is configured to accept SSL termination and confirm it
  // by returning single byte 'S'.
  // The write can see disconnect upon completion so we do
  // not verify the result.
  ASSERT_TRUE(tcp_client->write(data.toString(), false, false));
  data.drain(data.length());

  tcp_client->waitForData("S", true);

  tcp_client->waitForDisconnect();
  ASSERT_TRUE(fake_upstream_connection->waitForDisconnect());

  test_server_->waitForCounterEq("postgres.postgres_stats.sessions_terminated_ssl", 0);
}

INSTANTIATE_TEST_SUITE_P(IpVersions, DownstreamSSLWrongConfigPostgresIntegrationTest,
                         testing::ValuesIn(TestEnvironment::getIpVersionsForTest()));

// Upstream SSL integration tests.
// Tests do not use the real postgres server and concentrate only on initial exchange.
// The initial packet
// sent by the downstream client, SSL request sent to fake upstream and SSL response sent back by
// fake client  are valid postgres payloads, because they must be parsed by postgres filter.

class UpstreamSSLBaseIntegrationTest : public PostgresBaseIntegrationTest {
public:
  UpstreamSSLBaseIntegrationTest(SSLConfig upstream_ssl_config,
                                 SSLConfig downstream_ssl_config = NoDownstreamSSL)
      // Disable downstream SSL and attach synchronization filter.
      : PostgresBaseIntegrationTest(downstream_ssl_config, upstream_ssl_config, R"EOF(
      -  name: sync
         typed_config:
           "@type": type.googleapis.com/test.integration.postgres.SyncWriteFilterConfig
)EOF") {}

  // Helper synchronization filter which is injected between postgres filter and tcp proxy.
  // Its goal is to eliminate race conditions and synchronize operations between fake upstream and
  // postgres filter.
  struct SyncWriteFilter : public Network::WriteFilter {
    SyncWriteFilter(absl::Notification& proceed_sync, absl::Notification& recv_sync)
        : proceed_sync_(proceed_sync), recv_sync_(recv_sync) {}

    Network::FilterStatus onWrite(Buffer::Instance& data, bool) override {
      if (data.length() > 0) {
        // Notify fake upstream that payload has been received.
        recv_sync_.Notify();
        // Wait for signal to continue. This is to give fake upstream
        // some time to create and attach TLS transport socket.
        proceed_sync_.WaitForNotification();
      }
      return Network::FilterStatus::Continue;
    }

    void initializeWriteFilterCallbacks(Network::WriteFilterCallbacks& callbacks) override {
      read_callbacks_ = &callbacks;
    }

    Network::WriteFilterCallbacks* read_callbacks_{};
    // Synchronization object used to stop Envoy processing to allow fake upstream to
    // create and attach TLS transport socket.
    absl::Notification& proceed_sync_;
    // Synchronization object used to notify fake upstream that a message sent
    // by fake upstream was received by Envoy.
    absl::Notification& recv_sync_;
  };

  // Config factory for sync helper filter.
  class SyncWriteFilterConfigFactory : public Extensions::NetworkFilters::Common::FactoryBase<
                                           test::integration::postgres::SyncWriteFilterConfig> {
  public:
    explicit SyncWriteFilterConfigFactory(const std::string& name,
                                          Network::ConnectionCallbacks& /* upstream_callbacks*/)
        : FactoryBase(name) {}

    Network::FilterFactoryCb
    createFilterFactoryFromProtoTyped(const test::integration::postgres::SyncWriteFilterConfig&,
                                      Server::Configuration::FactoryContext&) override {
      return [&](Network::FilterManager& filter_manager) -> void {
        filter_manager.addWriteFilter(std::make_shared<SyncWriteFilter>(proceed_sync_, recv_sync_));
      };
    }

    std::string name() const override { return name_; }

    // See SyncWriteFilter for purpose and description of the following sync objects.
    absl::Notification proceed_sync_, recv_sync_;

  private:
    const std::string name_;
  };

  // Method prepares TLS context to be injected to fake upstream.
  // Method creates and attaches TLS transport socket to fake upstream.
  void enableTLSOnFakeUpstream() {
    // Setup factory and context for tls transport socket.
    // The tls transport socket will be inserted into fake_upstream when
    // Envoy's upstream starttls transport socket is converted to secure mode.
    std::unique_ptr<Ssl::ContextManager> tls_context_manager =
        std::make_unique<Extensions::TransportSockets::Tls::ContextManagerImpl>(timeSystem());

    envoy::extensions::transport_sockets::tls::v3::DownstreamTlsContext downstream_tls_context;

    std::string yaml_plain = R"EOF(
  common_tls_context:
    validation_context:
      trusted_ca:
        filename: "{{ test_rundir }}/test/config/integration/certs/upstreamcacert.pem"
    tls_certificates:
      certificate_chain:
        filename: "{{ test_rundir }}/test/config/integration/certs/upstreamcert.pem"
      private_key:
        filename: "{{ test_rundir }}/test/config/integration/certs/upstreamkey.pem"
)EOF";

    TestUtility::loadFromYaml(TestEnvironment::substitute(yaml_plain), downstream_tls_context);

    NiceMock<Server::Configuration::MockTransportSocketFactoryContext> mock_factory_ctx;
    ON_CALL(mock_factory_ctx.server_context_, api()).WillByDefault(testing::ReturnRef(*api_));
    auto cfg = std::make_unique<Extensions::TransportSockets::Tls::ServerContextConfigImpl>(
        downstream_tls_context, mock_factory_ctx);
    static auto* client_stats_store = new Stats::TestIsolatedStoreImpl();
    Network::DownstreamTransportSocketFactoryPtr tls_context =
        Network::DownstreamTransportSocketFactoryPtr{
            new Extensions::TransportSockets::Tls::ServerSslSocketFactory(
                std::move(cfg), *tls_context_manager, *(client_stats_store->rootScope()), {})};

    Network::TransportSocketPtr ts = tls_context->createDownstreamTransportSocket();
    // Synchronization object used to suspend execution
    // until dispatcher completes transport socket conversion.
    absl::Notification notification;

    // Execute transport socket conversion to TLS on the same thread where received data
    // is dispatched. Otherwise conversion may collide with data processing.
    fake_upstreams_[0]->dispatcher()->post([&]() {
      auto connection =
          dynamic_cast<Envoy::Network::ConnectionImpl*>(&fake_upstream_connection_->connection());
      connection->transportSocket() = std::move(ts);
      connection->transportSocket()->setTransportSocketCallbacks(*connection);
      notification.Notify();
    });

    // Wait until the transport socket conversion completes.
    notification.WaitForNotification();
  }

  NiceMock<Network::MockConnectionCallbacks> upstream_callbacks_;
  SyncWriteFilterConfigFactory config_factory_{"sync", upstream_callbacks_};
  Registry::InjectFactory<Server::Configuration::NamedNetworkFilterConfigFactory>
      registered_config_factory_{config_factory_};
};

// Base class for tests with disabled upstream SSL. It should behave exactly
// as without any upstream configuration specified and pass
// messages in clear-text.
class UpstreamSSLDisabledPostgresIntegrationTest : public UpstreamSSLBaseIntegrationTest {
public:
  // Disable downstream SSL and upstream SSL.
  UpstreamSSLDisabledPostgresIntegrationTest()
      : UpstreamSSLBaseIntegrationTest(std::make_tuple("upstream_ssl: DISABLE", "")) {}
};

// Verify that postgres filter does not send any additional messages when
// upstream SSL is disabled. Fake upstream should receive only the initial
// postgres message.
TEST_P(UpstreamSSLDisabledPostgresIntegrationTest, BasicConnectivityTest) {
  IntegrationTcpClientPtr tcp_client = makeTcpConnection(lookupPort("listener_0"));
  ASSERT_TRUE(fake_upstreams_[0]->waitForRawConnection(fake_upstream_connection_));

  // Send the startup message.
  Buffer::OwnedImpl data;
  std::string rcvd;
  createInitialPostgresRequest(data);
  ASSERT_TRUE(tcp_client->write(data.toString()));
  // Make sure that upstream receives startup message in clear-text (no SSL negotiation takes
  // place).
  ASSERT_TRUE(fake_upstream_connection_->waitForData(data.toString().length(), &rcvd));
  data.drain(data.length());

  tcp_client->close();
  ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());

  test_server_->waitForCounterEq("postgres.postgres_stats.sessions_upstream_ssl_success", 0);
  test_server_->waitForCounterEq("postgres.postgres_stats.sessions_upstream_ssl_failed", 0);
}

INSTANTIATE_TEST_SUITE_P(IpVersions, UpstreamSSLDisabledPostgresIntegrationTest,
                         testing::ValuesIn(TestEnvironment::getIpVersionsForTest()));

// Base class for parameterized tests with REQUIRE option for upstream SSL.
class UpstreamSSLRequirePostgresIntegrationTest : public UpstreamSSLBaseIntegrationTest {
public:
  UpstreamSSLRequirePostgresIntegrationTest()
      : UpstreamSSLBaseIntegrationTest(std::make_tuple("upstream_ssl: REQUIRE",
                                                       R"EOF(transport_socket:
      name: "starttls"
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.transport_sockets.starttls.v3.UpstreamStartTlsConfig
        tls_socket_config:
          common_tls_context: {}
)EOF")) {}
};

// Test verifies that postgres filter starts upstream SSL negotiation with
// fake upstream upon receiving initial postgres packet. When server agrees
// to use SSL, TLS transport socket is attached to fake upstream and
// fake upstream receives initial postgres packet over encrypted connection.
TEST_P(UpstreamSSLRequirePostgresIntegrationTest, ServerAgreesForSSLTest) {
  IntegrationTcpClientPtr tcp_client = makeTcpConnection(lookupPort("listener_0"));
  ASSERT_TRUE(fake_upstreams_[0]->waitForRawConnection(fake_upstream_connection_));

  // Send the startup message.
  Buffer::OwnedImpl data;
  Buffer::OwnedImpl upstream_data;
  std::string rcvd;
  createInitialPostgresRequest(data);
  ASSERT_TRUE(tcp_client->write(data.toString()));
  // Postgres filter should buffer the original message and negotiate SSL upstream.
  // The first 4 bytes should be length on the message (8 bytes).
  // The next 4 bytes should be SSL code.
  ASSERT_TRUE(fake_upstream_connection_->waitForData(8, &rcvd));
  upstream_data.add(rcvd);
  ASSERT_EQ(8, upstream_data.peekBEInt<uint32_t>(0));
  ASSERT_EQ(80877103, upstream_data.peekBEInt<uint32_t>(4));
  upstream_data.drain(upstream_data.length());
  fake_upstream_connection_->clearData();

  // Reply to Envoy with 'S' and attach TLS socket to upstream.
  upstream_data.add("S");
  ASSERT_TRUE(fake_upstream_connection_->write(upstream_data.toString()));

  config_factory_.recv_sync_.WaitForNotification();
  enableTLSOnFakeUpstream();
  config_factory_.proceed_sync_.Notify();

  ASSERT_TRUE(fake_upstream_connection_->waitForData(data.length(), &rcvd));
  // Make sure that upstream received initial postgres request, which
  // triggered upstream SSL negotiation and TLS handshake.
  ASSERT_EQ(data.toString(), rcvd);

  data.drain(data.length());

  tcp_client->close();
  ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());

  test_server_->waitForCounterEq("postgres.postgres_stats.sessions_upstream_ssl_success", 1);
  test_server_->waitForCounterEq("postgres.postgres_stats.sessions_upstream_ssl_failed", 0);
}

// Test verifies that postgres filter will not continue when upstream SSL
// is required and fake upstream does not agree for SSL.
TEST_P(UpstreamSSLRequirePostgresIntegrationTest, ServerDeniesSSLTest) {
  IntegrationTcpClientPtr tcp_client = makeTcpConnection(lookupPort("listener_0"));
  ASSERT_TRUE(fake_upstreams_[0]->waitForRawConnection(fake_upstream_connection_));

  // Send the startup message.
  Buffer::OwnedImpl data;
  Buffer::OwnedImpl upstream_data;
  std::string rcvd;
  createInitialPostgresRequest(data);
  ASSERT_TRUE(tcp_client->write(data.toString()));
  // Postgres filter should buffer the original message and negotiate SSL upstream.
  // The first 4 bytes should be length on the message (8 bytes).
  // The next 4 bytes should be SSL code.
  ASSERT_TRUE(fake_upstream_connection_->waitForData(8, &rcvd));
  upstream_data.add(rcvd);
  ASSERT_EQ(8, upstream_data.peekBEInt<uint32_t>(0));
  ASSERT_EQ(80877103, upstream_data.peekBEInt<uint32_t>(4));
  upstream_data.drain(upstream_data.length());

  // Reply to Envoy with 'N' (SSL not allowed).
  upstream_data.add("N");
  ASSERT_TRUE(fake_upstream_connection_->write(upstream_data.toString()));
  config_factory_.proceed_sync_.Notify();

  data.drain(data.length());

  // Connection to client should be closed.
  tcp_client->waitForDisconnect();
  ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());

  test_server_->waitForCounterEq("postgres.postgres_stats.sessions_upstream_ssl_success", 0);
  test_server_->waitForCounterEq("postgres.postgres_stats.sessions_upstream_ssl_failed", 1);
}

INSTANTIATE_TEST_SUITE_P(IpVersions, UpstreamSSLRequirePostgresIntegrationTest,
                         testing::ValuesIn(TestEnvironment::getIpVersionsForTest()));

// Base class for parameterized tests when upstream and downstream SSL is enabled.
class UpstreamAndDownstreamSSLIntegrationTest : public UpstreamSSLBaseIntegrationTest {
public:
  UpstreamAndDownstreamSSLIntegrationTest()
      : UpstreamSSLBaseIntegrationTest(
            // Configure upstream SSL
            std::make_tuple("upstream_ssl: REQUIRE",
                            R"EOF(transport_socket:
      name: "starttls"
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.transport_sockets.starttls.v3.UpstreamStartTlsConfig
        tls_socket_config:
          common_tls_context: {}
    )EOF"),
            // configure downstream SSL
            std::make_tuple(
                "terminate_ssl: true",
                fmt::format(
                    R"EOF(transport_socket:
        name: "starttls"
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.transport_sockets.starttls.v3.StartTlsConfig
          cleartext_socket_config:
          tls_socket_config:
            common_tls_context:
              tls_certificates:
                certificate_chain:
                  filename: {}
                private_key:
                  filename: {}
   )EOF",
                    TestEnvironment::runfilesPath("test/config/integration/certs/servercert.pem"),
                    TestEnvironment::runfilesPath(
                        "test/config/integration/certs/serverkey.pem")))) {}

  // Method changes IntegrationTcpClient's transport socket to TLS.
  // Sending any traffic to newly attached TLS transport socket will trigger
  // TLS handshake negotiation.
  void enableTLSonTCPClient(const IntegrationTcpClientPtr& tcp_client) {
    // Setup factory and context for tls transport socket.
    // The tls transport socket will be inserted into fake_upstream when
    // Envoy's upstream starttls transport socket is converted to secure mode.
    std::unique_ptr<Ssl::ContextManager> tls_context_manager =
        std::make_unique<Extensions::TransportSockets::Tls::ContextManagerImpl>(timeSystem());

    envoy::extensions::transport_sockets::tls::v3::UpstreamTlsContext upstream_tls_context;

    NiceMock<Server::Configuration::MockTransportSocketFactoryContext> mock_factory_ctx;
    ON_CALL(mock_factory_ctx.server_context_, api()).WillByDefault(testing::ReturnRef(*api_));
    auto cfg = std::make_unique<Extensions::TransportSockets::Tls::ClientContextConfigImpl>(
        upstream_tls_context, mock_factory_ctx);
    static auto* client_stats_store = new Stats::TestIsolatedStoreImpl();
    Network::UpstreamTransportSocketFactoryPtr tls_context =
        Network::UpstreamTransportSocketFactoryPtr{
            new Extensions::TransportSockets::Tls::ClientSslSocketFactory(
                std::move(cfg), *tls_context_manager, *(client_stats_store->rootScope()))};

    Network::TransportSocketOptionsConstSharedPtr options;

    auto connection = dynamic_cast<Envoy::Network::ConnectionImpl*>(tcp_client->connection());
    Network::TransportSocketPtr ts = tls_context->createTransportSocket(
        options, connection->streamInfo().upstreamInfo()->upstreamHost());
    connection->transportSocket() = std::move(ts);
    connection->transportSocket()->setTransportSocketCallbacks(*connection);
  }
};

// Integration test when both downstream and upstream SSL is enabled.
// In this scenario test client establishes SSL connection to Envoy. Envoy de-crypts the traffic.
// The traffic is encrypted again when sent to upstream server.
// The test follows the following scenario:
//
// Test client                     Envoy                  Upstream
// ----- Can I use SSL? ------------>
// <------- Yes---------------------
// <------- TLS handshake ---------->
// ------ Initial postgres msg ----->
//                                    ------ Can I use SSL? --->
//                                    <------- Yes--------------
//                                    <------- TLS handshake--->
//                                    --Initial postgres msg--->
// ------ close connection --------->
//                                    ------ close connection--->
//
TEST_P(UpstreamAndDownstreamSSLIntegrationTest, ServerAgreesForSSL) {
  Buffer::OwnedImpl data;

  IntegrationTcpClientPtr tcp_client = makeTcpConnection(lookupPort("listener_0"));
  ASSERT_TRUE(fake_upstreams_[0]->waitForRawConnection(fake_upstream_connection_));

  // Send the startup message requesting SSL.
  // Message is 8 bytes long. The first 4 bytes contain length (8)
  // The next 8 bytes contain message code (RequestSSL=80877103)
  data.writeBEInt<uint32_t>(8);
  data.writeBEInt<uint32_t>(80877103);

  // Message will be processed by Postgres filter which
  // is configured to accept SSL termination and confirm it
  // by returning single byte 'S'.
  ASSERT_TRUE(tcp_client->write(data.toString()));
  data.drain(data.length());

  tcp_client->waitForData("S", true);

  // Attach TLS to tcp_client.
  enableTLSonTCPClient(tcp_client);

  // Write initial postgres message. This should trigger SSL negotiation between test TCP client and
  // Envoy downstream transport socket. Postgres filter should ask the fake upstream server if it
  // will accept encrypted connection.
  Buffer::OwnedImpl upstream_data;
  std::string rcvd;
  createInitialPostgresRequest(data);
  ASSERT_TRUE(tcp_client->write(data.toString()));
  // Postgres filter should buffer the original message and negotiate SSL upstream.
  // The first 4 bytes should be length on the message (8 bytes).
  // The next 4 bytes should be SSL code.
  ASSERT_TRUE(fake_upstream_connection_->waitForData(8, &rcvd));
  upstream_data.add(rcvd);
  ASSERT_EQ(8, upstream_data.peekBEInt<uint32_t>(0));
  ASSERT_EQ(80877103, upstream_data.peekBEInt<uint32_t>(4));
  upstream_data.drain(upstream_data.length());

  // Reply to Envoy with 'S' and attach TLS socket to upstream.
  upstream_data.add("S");
  ASSERT_TRUE(fake_upstream_connection_->write(upstream_data.toString()));
  fake_upstream_connection_->clearData();

  config_factory_.recv_sync_.WaitForNotification();
  enableTLSOnFakeUpstream();
  config_factory_.proceed_sync_.Notify();

  ASSERT_TRUE(fake_upstream_connection_->waitForData(data.length(), &rcvd));
  // Make sure that upstream received initial postgres request, which
  // triggered upstream SSL negotiation and TLS handshake.
  ASSERT_EQ(data.toString(), rcvd);

  data.drain(data.length());

  tcp_client->close();
  ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());

  test_server_->waitForCounterEq("postgres.postgres_stats.sessions_terminated_ssl", 1);
  test_server_->waitForCounterEq("postgres.postgres_stats.sessions_upstream_ssl_success", 1);
  test_server_->waitForCounterEq("postgres.postgres_stats.sessions_upstream_ssl_failed", 0);
}

// Integration test when both downstream and upstream SSL is enabled.
// In this scenario test client establishes SSL connection to Envoy. Envoy de-crypts the traffic.
// The traffic is encrypted again when sent to upstream server, but the server
// rejects request for SSL.
// The test follows the following scenario:
//
// Test client                     Envoy                  Upstream
// ----- Can I use SSL? ------------>
// <------- Yes---------------------
// <------- TLS handshake ---------->
// ------ Initial postgres msg ----->
//                                    ------ Can I use SSL? --->
//                                    <------- No---------------
// <----- close connection ----------
//                                    ------ close connection--->
TEST_P(UpstreamAndDownstreamSSLIntegrationTest, ServerRejectsSSL) {
  Buffer::OwnedImpl data;

  IntegrationTcpClientPtr tcp_client = makeTcpConnection(lookupPort("listener_0"));
  ASSERT_TRUE(fake_upstreams_[0]->waitForRawConnection(fake_upstream_connection_));

  // Send the startup message requesting SSL.
  // Message is 8 bytes long. The first 4 bytes contain length (8)
  // The next 8 bytes contain message code (RequestSSL=80877103)
  data.writeBEInt<uint32_t>(8);
  data.writeBEInt<uint32_t>(80877103);

  // Message will be processed by Postgres filter which
  // is configured to accept SSL termination and confirm it
  // by returning single byte 'S'.
  ASSERT_TRUE(tcp_client->write(data.toString()));
  data.drain(data.length());

  tcp_client->waitForData("S", true);

  // Attach TLS to tcp_client.
  enableTLSonTCPClient(tcp_client);

  // Write initial postgres message. This should trigger SSL negotiation between test TCP client and
  // Envoy downstream transport socket. Postgres filter should ask the fake upstream server if it
  // will accept encrypted connection.
  Buffer::OwnedImpl upstream_data;
  std::string rcvd;
  createInitialPostgresRequest(data);
  ASSERT_TRUE(tcp_client->write(data.toString()));
  // Postgres filter should buffer the original message and negotiate SSL upstream.
  // The first 4 bytes should be length on the message (8 bytes).
  // The next 4 bytes should be SSL code.
  ASSERT_TRUE(fake_upstream_connection_->waitForData(8, &rcvd));
  upstream_data.add(rcvd);
  ASSERT_EQ(8, upstream_data.peekBEInt<uint32_t>(0));
  ASSERT_EQ(80877103, upstream_data.peekBEInt<uint32_t>(4));
  upstream_data.drain(upstream_data.length());

  // Reply to Envoy with 'E' (SSL not allowed).
  upstream_data.add("E");
  ASSERT_TRUE(fake_upstream_connection_->write(upstream_data.toString()));
  config_factory_.proceed_sync_.Notify();

  data.drain(data.length());

  // Envoy should close the connection to test client.
  tcp_client->waitForDisconnect();
  ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());

  test_server_->waitForCounterEq("postgres.postgres_stats.sessions_terminated_ssl", 1);
  test_server_->waitForCounterEq("postgres.postgres_stats.sessions_upstream_ssl_success", 0);
  test_server_->waitForCounterEq("postgres.postgres_stats.sessions_upstream_ssl_failed", 1);
}

INSTANTIATE_TEST_SUITE_P(IpVersions, UpstreamAndDownstreamSSLIntegrationTest,
                         testing::ValuesIn(TestEnvironment::getIpVersionsForTest()));

} // namespace PostgresProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include <gmock/gmock.h>
#include <gtest/gtest.h>

#include <tuple>

#include "source/extensions/filters/network/well_known_names.h"

#include "test/mocks/network/mocks.h"

#include "contrib/postgres_proxy/filters/network/source/postgres_filter.h"
#include "contrib/postgres_proxy/filters/network/test/postgres_test_utils.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace PostgresProxy {

using testing::ReturnRef;
using ::testing::WithArgs;

// Decoder mock.
class MockDecoderTest : public Decoder {
public:
  MOCK_METHOD(Decoder::Result, onData, (Buffer::Instance&, bool), (override));
  MOCK_METHOD(PostgresSession&, getSession, (), (override));
};

// Fixture class.
class PostgresFilterTest
    : public ::testing::TestWithParam<
          std::tuple<std::function<void(PostgresFilter*, Buffer::Instance&, bool)>,
                     std::function<uint32_t(const PostgresFilter*)>>> {
public:
  PostgresFilterTest() {

    PostgresFilterConfig::PostgresFilterConfigOptions config_options{
        stat_prefix_, true, false,
        envoy::extensions::filters::network::postgres_proxy::v3alpha::
            PostgresProxy_SSLMode_DISABLE};

    config_ = std::make_shared<PostgresFilterConfig>(config_options, scope_);
    filter_ = std::make_unique<PostgresFilter>(config_);

    filter_->initializeReadFilterCallbacks(read_callbacks_);
    filter_->initializeWriteFilterCallbacks(write_callbacks_);
  }

  void setMetadata() {
    EXPECT_CALL(read_callbacks_, connection()).WillRepeatedly(ReturnRef(connection_));
    EXPECT_CALL(connection_, streamInfo()).WillRepeatedly(ReturnRef(stream_info_));
    ON_CALL(stream_info_, setDynamicMetadata(NetworkFilterNames::get().PostgresProxy, _))
        .WillByDefault(Invoke([this](const std::string&, const ProtobufWkt::Struct& obj) {
          stream_info_.metadata_.mutable_filter_metadata()->insert(
              Protobuf::MapPair<std::string, ProtobufWkt::Struct>(
                  NetworkFilterNames::get().PostgresProxy, obj));
        }));
  }

  Stats::IsolatedStoreImpl store_;
  Stats::Scope& scope_{*store_.rootScope()};
  std::string stat_prefix_{"test."};
  std::unique_ptr<PostgresFilter> filter_;
  PostgresFilterConfigSharedPtr config_;
  NiceMock<Network::MockReadFilterCallbacks> read_callbacks_;
  NiceMock<Network::MockWriteFilterCallbacks> write_callbacks_;
  NiceMock<Network::MockConnection> connection_;
  NiceMock<Envoy::StreamInfo::MockStreamInfo> stream_info_;

  // These variables are used internally in tests.
  Buffer::OwnedImpl data_;
  char buf_[256];
};

TEST_F(PostgresFilterTest, NewConnection) {
  EXPECT_EQ(Envoy::Network::FilterStatus::Continue, filter_->onNewConnection());
}

// Test reading buffer until the buffer is exhausted
// or decoder indicates that there is not enough data in a buffer
// to process a message.
TEST_P(PostgresFilterTest, ReadData) {
  // Create mock decoder, obtain raw pointer to it (required for EXPECT_CALL)
  // and pass the decoder to filter.
  std::unique_ptr<MockDecoderTest> decoder = std::make_unique<MockDecoderTest>();
  MockDecoderTest* decoderPtr = decoder.get();
  filter_->setDecoder(std::move(decoder));

  data_.add(buf_, 256);

  // Simulate reading entire buffer.
  EXPECT_CALL(*decoderPtr, onData)
      .WillOnce(WithArgs<0, 1>(Invoke([](Buffer::Instance& data, bool) -> Decoder::Result {
        data.drain(data.length());
        return Decoder::Result::ReadyForNext;
      })));
  std::get<0>(GetParam())(filter_.get(), data_, false);
  ASSERT_THAT(std::get<1>(GetParam())(filter_.get()), 0);

  // Simulate reading entire data in two steps.
  EXPECT_CALL(*decoderPtr, onData)
      .WillOnce(WithArgs<0, 1>(Invoke([](Buffer::Instance& data, bool) -> Decoder::Result {
        data.drain(100);
        return Decoder::Result::ReadyForNext;
      })))
      .WillOnce(WithArgs<0, 1>(Invoke([](Buffer::Instance& data, bool) -> Decoder::Result {
        data.drain(156);
        return Decoder::Result::ReadyForNext;
      })));
  std::get<0>(GetParam())(filter_.get(), data_, false);
  ASSERT_THAT(std::get<1>(GetParam())(filter_.get()), 0);

  // Simulate reading 3 packets. The first two were processed correctly and
  // for the third one there was not enough data. There should be 56 bytes
  // of unprocessed data.
  EXPECT_CALL(*decoderPtr, onData)
      .WillOnce(WithArgs<0, 1>(Invoke([](Buffer::Instance& data, bool) -> Decoder::Result {
        data.drain(100);
        return Decoder::Result::ReadyForNext;
      })))
      .WillOnce(WithArgs<0, 1>(Invoke([](Buffer::Instance& data, bool) -> Decoder::Result {
        data.drain(100);
        return Decoder::Result::ReadyForNext;
      })))
      .WillOnce(WithArgs<0, 1>(Invoke([](Buffer::Instance& data, bool) -> Decoder::Result {
        data.drain(0);
        return Decoder::Result::NeedMoreData;
      })));
  std::get<0>(GetParam())(filter_.get(), data_, false);
  ASSERT_THAT(std::get<1>(GetParam())(filter_.get()), 56);
}

// Parameterized test:
// First value in the tuple is method taking buffer with received data.
// Second value in the tuple is method returning how many bytes are left after processing.
INSTANTIATE_TEST_SUITE_P(ProcessDataTests, PostgresFilterTest,
                         ::testing::Values(std::make_tuple(&PostgresFilter::onData,
                                                           &PostgresFilter::getFrontendBufLength),
                                           std::make_tuple(&PostgresFilter::onWrite,
                                                           &PostgresFilter::getBackendBufLength)));

// Test generates various postgres payloads and feeds them into filter.
// It expects that certain statistics are updated.
TEST_F(PostgresFilterTest, BackendMsgsStats) {
  // pretend that startup message has been received.
  static_cast<DecoderImpl*>(filter_->getDecoder())->state(DecoderImpl::State::InSyncState);

  // unknown message
  createPostgresMsg(data_, "=", "blah blah blah");
  filter_->onWrite(data_, false);
  ASSERT_THAT(filter_->getStats().messages_unknown_.value(), 1);

  // implicit transactions
  createPostgresMsg(data_, "C", "SELECT blah");
  filter_->onWrite(data_, false);
  ASSERT_THAT(filter_->getStats().statements_.value(), 1);
  ASSERT_THAT(filter_->getStats().statements_select_.value(), 1);
  ASSERT_THAT(filter_->getStats().transactions_.value(), 1);
  ASSERT_THAT(filter_->getStats().transactions_commit_.value(), 1);
  ASSERT_THAT(filter_->getStats().transactions_rollback_.value(), 0);

  createPostgresMsg(data_, "C", "INSERT 123");
  filter_->onWrite(data_, false);
  ASSERT_THAT(filter_->getStats().statements_.value(), 2);
  ASSERT_THAT(filter_->getStats().statements_insert_.value(), 1);
  ASSERT_THAT(filter_->getStats().transactions_.value(), 2);
  ASSERT_THAT(filter_->getStats().transactions_commit_.value(), 2);
  ASSERT_THAT(filter_->getStats().transactions_rollback_.value(), 0);

  createPostgresMsg(data_, "C", "DELETE 123");
  filter_->onWrite(data_, false);
  ASSERT_THAT(filter_->getStats().statements_.value(), 3);
  ASSERT_THAT(filter_->getStats().statements_delete_.value(), 1);
  ASSERT_THAT(filter_->getStats().transactions_.value(), 3);
  ASSERT_THAT(filter_->getStats().transactions_commit_.value(), 3);
  ASSERT_THAT(filter_->getStats().transactions_rollback_.value(), 0);

  createPostgresMsg(data_, "C", "UPDATE 123");
  filter_->onWrite(data_, false);
  ASSERT_THAT(filter_->getStats().statements_.value(), 4);
  ASSERT_THAT(filter_->getStats().statements_update_.value(), 1);
  ASSERT_THAT(filter_->getStats().transactions_.value(), 4);
  ASSERT_THAT(filter_->getStats().transactions_commit_.value(), 4);
  ASSERT_THAT(filter_->getStats().transactions_rollback_.value(), 0);

  // explicit transactions (commit)
  createPostgresMsg(data_, "C", "BEGIN 123");
  filter_->onWrite(data_, false);
  ASSERT_THAT(filter_->getStats().statements_.value(), 5);
  ASSERT_THAT(filter_->getStats().statements_other_.value(), 1);
  ASSERT_THAT(filter_->getStats().transactions_.value(), 5);
  ASSERT_THAT(filter_->getStats().transactions_commit_.value(), 4);
  ASSERT_THAT(filter_->getStats().transactions_rollback_.value(), 0);

  createPostgresMsg(data_, "C", "INSERT 123");
  filter_->onWrite(data_, false);
  ASSERT_THAT(filter_->getStats().statements_.value(), 6);
  ASSERT_THAT(filter_->getStats().statements_insert_.value(), 2);
  ASSERT_THAT(filter_->getStats().transactions_.value(), 5);
  ASSERT_THAT(filter_->getStats().transactions_commit_.value(), 4);
  ASSERT_THAT(filter_->getStats().transactions_rollback_.value(), 0);

  createPostgresMsg(data_, "C", "COMMIT");
  filter_->onWrite(data_, false);
  ASSERT_THAT(filter_->getStats().statements_.value(), 7);
  ASSERT_THAT(filter_->getStats().statements_other_.value(), 2);
  ASSERT_THAT(filter_->getStats().transactions_.value(), 5);
  ASSERT_THAT(filter_->getStats().transactions_commit_.value(), 5);
  ASSERT_THAT(filter_->getStats().transactions_rollback_.value(), 0);

  // explicit transactions (rollback)
  createPostgresMsg(data_, "C", "BEGIN 123");
  filter_->onWrite(data_, false);
  ASSERT_THAT(filter_->getStats().statements_.value(), 8);
  ASSERT_THAT(filter_->getStats().statements_other_.value(), 3);
  ASSERT_THAT(filter_->getStats().transactions_.value(), 6);
  ASSERT_THAT(filter_->getStats().transactions_commit_.value(), 5);
  ASSERT_THAT(filter_->getStats().transactions_rollback_.value(), 0);

  createPostgresMsg(data_, "C", "INSERT 123");
  filter_->onWrite(data_, false);
  ASSERT_THAT(filter_->getStats().statements_.value(), 9);
  ASSERT_THAT(filter_->getStats().statements_insert_.value(), 3);
  ASSERT_THAT(filter_->getStats().transactions_.value(), 6);
  ASSERT_THAT(filter_->getStats().transactions_commit_.value(), 5);
  ASSERT_THAT(filter_->getStats().transactions_rollback_.value(), 0);

  createPostgresMsg(data_, "C", "ROLLBACK");
  filter_->onWrite(data_, false);
  ASSERT_THAT(filter_->getStats().statements_.value(), 10);
  ASSERT_THAT(filter_->getStats().statements_other_.value(), 4);
  ASSERT_THAT(filter_->getStats().transactions_.value(), 6);
  ASSERT_THAT(filter_->getStats().transactions_commit_.value(), 5);
  ASSERT_THAT(filter_->getStats().transactions_rollback_.value(), 1);
}

// Test sends series of E type error messages to the filter and
// verifies that statistic counters are increased.
TEST_F(PostgresFilterTest, ErrorMsgsStats) {
  // Pretend that startup message has been received.
  static_cast<DecoderImpl*>(filter_->getDecoder())->state(DecoderImpl::State::InSyncState);

  createPostgresMsg(data_, "E", "SERRORVERRORC22012");
  filter_->onWrite(data_, false);
  ASSERT_THAT(filter_->getStats().errors_.value(), 1);
  ASSERT_THAT(filter_->getStats().errors_error_.value(), 1);

  createPostgresMsg(data_, "E", "SFATALVFATALC22012");
  filter_->onWrite(data_, false);
  ASSERT_THAT(filter_->getStats().errors_.value(), 2);
  ASSERT_THAT(filter_->getStats().errors_fatal_.value(), 1);

  createPostgresMsg(data_, "E", "SPANICVPANICC22012");
  filter_->onWrite(data_, false);
  ASSERT_THAT(filter_->getStats().errors_.value(), 3);
  ASSERT_THAT(filter_->getStats().errors_panic_.value(), 1);

  createPostgresMsg(data_, "E", "SBLAHBLAHC22012");
  filter_->onWrite(data_, false);
  ASSERT_THAT(filter_->getStats().errors_.value(), 4);
  ASSERT_THAT(filter_->getStats().errors_unknown_.value(), 1);
}

// Test sends series of N type messages to the filter and verifies
// that corresponding stats counters are updated.
TEST_F(PostgresFilterTest, NoticeMsgsStats) {
  // Pretend that startup message has been received.
  static_cast<DecoderImpl*>(filter_->getDecoder())->state(DecoderImpl::State::InSyncState);

  createPostgresMsg(data_, "N", "SblalalaC2345");
  filter_->onWrite(data_, false);
  ASSERT_THAT(filter_->getStats().notices_.value(), 1);
  ASSERT_THAT(filter_->getStats().notices_unknown_.value(), 1);

  createPostgresMsg(data_, "N", "SblahVWARNING23345");
  filter_->onWrite(data_, false);
  ASSERT_THAT(filter_->getStats().notices_.value(), 2);
  ASSERT_THAT(filter_->getStats().notices_warning_.value(), 1);

  createPostgresMsg(data_, "N", "SNOTICEERRORbbal4");
  filter_->onWrite(data_, false);
  ASSERT_THAT(filter_->getStats().notices_.value(), 3);
  ASSERT_THAT(filter_->getStats().notices_notice_.value(), 1);

  createPostgresMsg(data_, "N", "SINFOVblabla");
  filter_->onWrite(data_, false);
  ASSERT_THAT(filter_->getStats().notices_.value(), 4);
  ASSERT_THAT(filter_->getStats().notices_info_.value(), 1);

  createPostgresMsg(data_, "N", "SDEBUGDEBUG");
  filter_->onWrite(data_, false);
  ASSERT_THAT(filter_->getStats().notices_.value(), 5);
  ASSERT_THAT(filter_->getStats().notices_debug_.value(), 1);

  createPostgresMsg(data_, "N", "SLOGGGGINFO");
  filter_->onWrite(data_, false);
  ASSERT_THAT(filter_->getStats().notices_.value(), 6);
  ASSERT_THAT(filter_->getStats().notices_log_.value(), 1);
}

// Encrypted sessions are detected based on the first received message.
TEST_F(PostgresFilterTest, EncryptedSessionStats) {
  data_.writeBEInt<uint32_t>(8);
  // 1234 in the most significant 16 bits and some code in the least significant 16 bits.
  data_.writeBEInt<uint32_t>(80877104); // SSL code.
  ASSERT_THAT(Network::FilterStatus::Continue, filter_->onData(data_, true));
  ASSERT_THAT(filter_->getStats().sessions_.value(), 1);
  ASSERT_THAT(filter_->getStats().sessions_encrypted_.value(), 1);
}

// Test verifies that incorrect SQL statement does not create
// Postgres metadata.
TEST_F(PostgresFilterTest, MetadataIncorrectSQL) {
  // Pretend that startup message has been received.
  static_cast<DecoderImpl*>(filter_->getDecoder())->state(DecoderImpl::State::InSyncState);
  setMetadata();

  createPostgresMsg(data_, "Q", "BLAH blah blah");
  ASSERT_THAT(Network::FilterStatus::Continue, filter_->onData(data_, true));

  // SQL statement was wrong. No metadata should have been created.
  ASSERT_THAT(filter_->connection().streamInfo().dynamicMetadata().filter_metadata().contains(
                  NetworkFilterNames::get().PostgresProxy),
              false);
  ASSERT_THAT(filter_->getStats().statements_parse_error_.value(), 1);
  ASSERT_THAT(filter_->getStats().statements_parsed_.value(), 0);
}

// Test verifies that Postgres metadata is created for correct SQL statement.
// and it happens only when parse_sql flag is true.
TEST_F(PostgresFilterTest, QueryMessageMetadata) {
  // Pretend that startup message has been received.
  static_cast<DecoderImpl*>(filter_->getDecoder())->state(DecoderImpl::State::InSyncState);
  setMetadata();

  // Disable creating parsing SQL and creating metadata.
  filter_->getConfig()->enable_sql_parsing_ = false;
  createPostgresMsg(data_, "Q", "SELECT * FROM whatever");
  ASSERT_THAT(Network::FilterStatus::Continue, filter_->onData(data_, false));

  ASSERT_THAT(filter_->connection().streamInfo().dynamicMetadata().filter_metadata().contains(
                  NetworkFilterNames::get().PostgresProxy),
              false);
  ASSERT_THAT(filter_->getStats().statements_parse_error_.value(), 0);
  ASSERT_THAT(filter_->getStats().statements_parsed_.value(), 0);

  // Now enable SQL parsing and creating metadata.
  filter_->getConfig()->enable_sql_parsing_ = true;
  ASSERT_THAT(Network::FilterStatus::Continue, filter_->onData(data_, false));

  auto& filter_meta = filter_->connection().streamInfo().dynamicMetadata().filter_metadata().at(
      NetworkFilterNames::get().PostgresProxy);
  auto& fields = filter_meta.fields();

  ASSERT_THAT(fields.size(), 1);
  ASSERT_THAT(fields.contains("whatever"), true);

  const auto& operations = fields.at("whatever").list_value();
  ASSERT_EQ("select", operations.values(0).string_value());

  ASSERT_THAT(filter_->getStats().statements_parse_error_.value(), 0);
  ASSERT_THAT(filter_->getStats().statements_parsed_.value(), 1);
}

// Test verifies that filter reacts to RequestSSL message.
// It should reply with "S" message and OnData should return
// Decoder::Stopped.
TEST_F(PostgresFilterTest, TerminateSSL) {
  filter_->getConfig()->terminate_ssl_ = true;
  EXPECT_CALL(read_callbacks_, connection()).WillRepeatedly(ReturnRef(connection_));
  Network::Connection::BytesSentCb cb;
  EXPECT_CALL(connection_, addBytesSentCallback(_)).WillOnce(testing::SaveArg<0>(&cb));
  Buffer::OwnedImpl buf;
  EXPECT_CALL(write_callbacks_, injectWriteDataToFilterChain(_, false))
      .WillOnce(testing::SaveArg<0>(&buf));
  data_.writeBEInt<uint32_t>(8);
  // 1234 in the most significant 16 bits and some code in the least significant 16 bits.
  data_.writeBEInt<uint32_t>(80877103); // SSL code.
  ASSERT_THAT(Network::FilterStatus::StopIteration, filter_->onData(data_, true));
  ASSERT_THAT('S', buf.peekBEInt<char>(0));
  ASSERT_THAT(filter_->getStats().messages_.value(), 1);
  ASSERT_THAT(filter_->getStats().messages_frontend_.value(), 1);

  // Now indicate through the callback that 1 bytes has been sent.
  // Filter should call startSecureTransport and should not close the connection.
  EXPECT_CALL(connection_, startSecureTransport()).WillOnce(testing::Return(true));
  EXPECT_CALL(connection_, close(_)).Times(0);
  cb(1);
  // Verify stats. This should not count as encrypted or unencrypted session.
  ASSERT_THAT(filter_->getStats().sessions_terminated_ssl_.value(), 1);
  ASSERT_THAT(filter_->getStats().sessions_encrypted_.value(), 0);
  ASSERT_THAT(filter_->getStats().sessions_unencrypted_.value(), 0);

  // Call callback again, but this time indicate that startSecureTransport failed.
  // Filter should close the connection.
  EXPECT_CALL(connection_, startSecureTransport()).WillOnce(testing::Return(false));
  EXPECT_CALL(connection_, close(_));
  cb(1);
  ASSERT_THAT(filter_->getStats().sessions_terminated_ssl_.value(), 1);
  ASSERT_THAT(filter_->getStats().sessions_encrypted_.value(), 0);
  ASSERT_THAT(filter_->getStats().sessions_unencrypted_.value(), 0);
}

TEST_F(PostgresFilterTest, UpstreamSSL) {
  EXPECT_CALL(read_callbacks_, connection()).WillRepeatedly(ReturnRef(connection_));

  // Configure upstream SSL to be disabled. encryptUpstream must not be called.
  filter_->getConfig()->upstream_ssl_ =
      envoy::extensions::filters::network::postgres_proxy::v3alpha::PostgresProxy::DISABLE;
  ASSERT_FALSE(filter_->shouldEncryptUpstream());
  ASSERT_DEATH(filter_->encryptUpstream(true, data_), ".*");
  ASSERT_DEATH(filter_->encryptUpstream(false, data_), ".*");

  // Configure upstream SSL to be required. If upstream server does not agree for SSL or
  // converting upstream transport socket to secure mode fails, the filter should bump
  // proper stats and close the connection to downstream client.
  filter_->getConfig()->upstream_ssl_ =
      envoy::extensions::filters::network::postgres_proxy::v3alpha::PostgresProxy::REQUIRE;
  ASSERT_TRUE(filter_->shouldEncryptUpstream());
  // Simulate that upstream server agreed for SSL and conversion of upstream Transport socket was
  // successful.
  EXPECT_CALL(read_callbacks_, startUpstreamSecureTransport()).WillOnce(testing::Return(true));
  filter_->encryptUpstream(true, data_);
  ASSERT_EQ(1, filter_->getStats().sessions_upstream_ssl_success_.value());
  // Simulate that upstream server agreed for SSL but conversion of upstream Transport socket
  // failed.
  EXPECT_CALL(read_callbacks_, startUpstreamSecureTransport()).WillOnce(testing::Return(false));
  filter_->encryptUpstream(true, data_);
  ASSERT_EQ(1, filter_->getStats().sessions_upstream_ssl_failed_.value());
  // Simulate that upstream server does not agree for SSL. Filter should close the connection to
  // downstream client.
  EXPECT_CALL(read_callbacks_, startUpstreamSecureTransport()).Times(0);
  EXPECT_CALL(connection_, close(_));
  filter_->encryptUpstream(false, data_);
  ASSERT_EQ(2, filter_->getStats().sessions_upstream_ssl_failed_.value());
}

TEST_F(PostgresFilterTest, UpstreamSSLStats) {
  static_cast<DecoderImpl*>(filter_->getDecoder())->state(DecoderImpl::State::InitState);
  EXPECT_CALL(read_callbacks_, connection()).WillRepeatedly(ReturnRef(connection_));

  filter_->getConfig()->upstream_ssl_ =
      envoy::extensions::filters::network::postgres_proxy::v3alpha::PostgresProxy::REQUIRE;

  createInitialPostgresRequest(data_);
  filter_->onData(data_, false);

  Buffer::OwnedImpl upstream_data;
  upstream_data.add("S");
  EXPECT_CALL(read_callbacks_, startUpstreamSecureTransport()).WillOnce(testing::Return(true));
  ASSERT_THAT(Network::FilterStatus::StopIteration, filter_->onWrite(upstream_data, false));

  createPostgresMsg(upstream_data, "C", "SELECT blah");
  filter_->onWrite(upstream_data, false);
  ASSERT_THAT(filter_->getStats().sessions_upstream_ssl_success_.value(), 1);
  ASSERT_THAT(filter_->getStats().statements_.value(), 1);
  ASSERT_THAT(filter_->getStats().statements_select_.value(), 1);
  ASSERT_THAT(filter_->getStats().transactions_.value(), 1);
  ASSERT_THAT(filter_->getStats().transactions_commit_.value(), 1);
  ASSERT_THAT(filter_->getStats().transactions_rollback_.value(), 0);
}

} // namespace PostgresProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
load(
    "//bazel:envoy_build_system.bzl",
    "envoy_cc_test",
    "envoy_cc_test_library",
    "envoy_contrib_package",
    "envoy_proto_library",
)

licenses(["notice"])  # Apache 2

envoy_contrib_package()

envoy_cc_test_library(
    name = "postgres_test_utils_lib",
    srcs = ["postgres_test_utils.cc"],
    hdrs = ["postgres_test_utils.h"],
    deps = [
        "//contrib/postgres_proxy/filters/network/source:filter",
        "//source/common/buffer:buffer_lib",
    ],
)

envoy_cc_test(
    name = "postgres_decoder_tests",
    srcs = [
        "postgres_decoder_test.cc",
    ],
    deps = [
        ":postgres_test_utils_lib",
        "//contrib/postgres_proxy/filters/network/source:filter",
        "//test/mocks/network:network_mocks",
    ],
)

envoy_cc_test(
    name = "postgres_message_tests",
    srcs = [
        "postgres_message_test.cc",
    ],
    deps = [
        "//contrib/postgres_proxy/filters/network/source:filter",
        "//source/common/buffer:buffer_lib",
    ],
)

envoy_cc_test(
    name = "postgres_filter_tests",
    srcs = [
        "postgres_filter_test.cc",
    ],
    deps = [
        ":postgres_test_utils_lib",
        "//contrib/postgres_proxy/filters/network/source:filter",
        "//test/mocks/network:network_mocks",
    ],
)

envoy_proto_library(
    name = "postgres_integration_proto",
    srcs = [":postgres_integration_test.proto"],
)

envoy_cc_test(
    name = "postgres_integration_test",
    srcs = [
        "postgres_integration_test.cc",
    ],
    data = [
        "postgres_test_config.yaml-template",
        "//test/config/integration/certs",
    ],
    deps = [
        ":postgres_integration_proto_cc_proto",
        ":postgres_test_utils_lib",
        "//contrib/postgres_proxy/filters/network/source:config",
        "//contrib/postgres_proxy/filters/network/source:filter",
        "//source/common/tcp_proxy",
        "//source/extensions/filters/network/tcp_proxy:config",
        "//source/extensions/transport_sockets/starttls:config",
        "//test/integration:integration_lib",
        "//test/test_common:registry_lib",
        "@envoy_api//contrib/envoy/extensions/filters/network/postgres_proxy/v3alpha:pkg_cc_proto",
    ],
)
syntax = "proto3";

package test.integration.postgres;

message SyncWriteFilterConfig {
}
#pragma once
#include <cstdint>

#include "envoy/common/platform.h"

#include "source/common/buffer/buffer_impl.h"
#include "source/common/common/logger.h"

#include "absl/container/flat_hash_map.h"
#include "contrib/common/sqlutils/source/sqlutils.h"
#include "contrib/postgres_proxy/filters/network/source/postgres_message.h"
#include "contrib/postgres_proxy/filters/network/source/postgres_session.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace PostgresProxy {

// General callbacks for dispatching decoded Postgres messages to a sink.
class DecoderCallbacks {
public:
  virtual ~DecoderCallbacks() = default;

  virtual void incMessagesBackend() PURE;
  virtual void incMessagesFrontend() PURE;
  virtual void incMessagesUnknown() PURE;

  virtual void incSessionsEncrypted() PURE;
  virtual void incSessionsUnencrypted() PURE;

  enum class StatementType { Insert, Delete, Select, Update, Other, Noop };
  virtual void incStatements(StatementType) PURE;

  virtual void incTransactions() PURE;
  virtual void incTransactionsCommit() PURE;
  virtual void incTransactionsRollback() PURE;

  enum class NoticeType { Warning, Notice, Debug, Info, Log, Unknown };
  virtual void incNotices(NoticeType) PURE;

  enum class ErrorType { Error, Fatal, Panic, Unknown };
  virtual void incErrors(ErrorType) PURE;

  virtual void processQuery(const std::string&) PURE;

  virtual bool onSSLRequest() PURE;
  virtual bool shouldEncryptUpstream() const PURE;
  virtual void sendUpstream(Buffer::Instance&) PURE;
  virtual bool encryptUpstream(bool, Buffer::Instance&) PURE;
};

// Postgres message decoder.
class Decoder {
public:
  virtual ~Decoder() = default;

  // The following values are returned by the decoder, when filter
  // passes bytes of data via onData method:
  enum class Result {
    ReadyForNext, // Decoder processed previous message and is ready for the next message.
    NeedMoreData, // Decoder needs more data to reconstruct the message.
    Stopped // Received and processed message disrupts the current flow. Decoder stopped accepting
            // data. This happens when decoder wants filter to perform some action, for example to
            // call starttls transport socket to enable TLS.
  };
  virtual Result onData(Buffer::Instance& data, bool frontend) PURE;
  virtual PostgresSession& getSession() PURE;

  const Extensions::Common::SQLUtils::SQLUtils::DecoderAttributes& getAttributes() const {
    return attributes_;
  }

protected:
  // Decoder attributes extracted from Startup message.
  // It can be username, database name, client app type, etc.
  Extensions::Common::SQLUtils::SQLUtils::DecoderAttributes attributes_;
};

using DecoderPtr = std::unique_ptr<Decoder>;

class DecoderImpl : public Decoder, Logger::Loggable<Logger::Id::filter> {
public:
  DecoderImpl(DecoderCallbacks* callbacks) : callbacks_(callbacks) { initialize(); }

  Result onData(Buffer::Instance& data, bool frontend) override;
  PostgresSession& getSession() override { return session_; }

  std::string getMessage() { return message_; }

  void initialize();

  bool encrypted() const { return encrypted_; }

  enum class State {
    InitState,
    InSyncState,
    OutOfSyncState,
    EncryptedState,
    NegotiatingUpstreamSSL
  };
  State state() const { return state_; }
  void state(State state) { state_ = state; }

protected:
  State state_{State::InitState};

  Result onDataInit(Buffer::Instance& data, bool frontend);
  Result onDataInSync(Buffer::Instance& data, bool frontend);
  Result onDataIgnore(Buffer::Instance& data, bool frontend);
  Result onDataInNegotiating(Buffer::Instance& data, bool frontend);

  // MsgAction defines the Decoder's method which will be invoked
  // when a specific message has been decoded.
  using MsgAction = std::function<void(DecoderImpl*)>;

  // MsgBodyReader is a function which returns a pointer to a Message
  // class which is able to read the Postgres message body.
  // The Postgres message body structure depends on the message type.
  using MsgBodyReader = std::function<std::unique_ptr<Message>()>;

  // MessageProcessor has the following fields:
  // first - string with message description
  // second - function which instantiates a Message object of specific type
  // which is capable of parsing the message's body.
  // third - vector of Decoder's methods which are invoked when the message
  // is processed.
  using MessageProcessor = std::tuple<std::string, MsgBodyReader, std::vector<MsgAction>>;

  // Frontend and Backend messages.
  using MsgGroup = struct {
    // String describing direction (Frontend or Backend).
    absl::string_view direction_;
    // Hash map indexed by messages' 1st byte points to handlers used for processing messages.
    absl::flat_hash_map<char, MessageProcessor> messages_;
    // Handler used for processing messages not found in hash map.
    MessageProcessor unknown_;
  };

  // Hash map binding keyword found in a message to an
  // action to be executed when the keyword is found.
  using KeywordProcessor = absl::flat_hash_map<std::string, MsgAction>;

  // Structure is used for grouping keywords found in a specific message.
  // Known keywords are dispatched via hash map and unknown keywords
  // are handled by unknown_.
  using MsgParserDict = struct {
    // Handler for known keywords.
    KeywordProcessor keywords_;
    // Handler invoked when a keyword is not found in hash map.
    MsgAction unknown_;
  };

  void processMessageBody(Buffer::Instance& data, absl::string_view direction, uint32_t length,
                          MessageProcessor& msg, const std::unique_ptr<Message>& parser);
  void decode(Buffer::Instance& data);
  void decodeAuthentication();
  void decodeBackendStatements();
  void decodeBackendErrorResponse();
  void decodeBackendNoticeResponse();
  void decodeFrontendTerminate();
  void decodeErrorNotice(MsgParserDict& types);
  void onQuery();
  void onParse();
  void onStartup();

  void incMessagesUnknown() { callbacks_->incMessagesUnknown(); }
  void incSessionsEncrypted() { callbacks_->incSessionsEncrypted(); }
  void incSessionsUnencrypted() { callbacks_->incSessionsUnencrypted(); }

  // Helper method generating currently processed message in
  // displayable format.
  const std::string genDebugMessage(const std::unique_ptr<Message>& parser, Buffer::Instance& data,
                                    uint32_t message_len);

  DecoderCallbacks* callbacks_{};
  PostgresSession session_{};

  // The following fields store result of message parsing.
  char command_{'-'};
  std::string message_;
  uint32_t message_len_{};

  bool encrypted_{false}; // tells if exchange is encrypted

  // Dispatchers for Backend (BE) and Frontend (FE) messages.
  MsgGroup FE_messages_;
  MsgGroup BE_messages_;

  // Handler for startup postgres message.
  // Startup message message which does not start with 1 byte TYPE.
  // It starts with message length and must be therefore handled
  // differently.
  MessageProcessor first_;

  // hash map for dispatching backend transaction messages
  KeywordProcessor BE_statements_;

  MsgParserDict BE_errors_;
  MsgParserDict BE_notices_;

  // Buffer used to temporarily store a downstream postgres packet
  // while sending other packets. Currently used only when negotiating
  // upstream SSL.
  Buffer::OwnedImpl temp_storage_;

  // MAX_STARTUP_PACKET_LENGTH is defined in Postgres source code
  // as maximum size of initial packet.
  // https://github.com/postgres/postgres/search?q=MAX_STARTUP_PACKET_LENGTH&type=code
  static constexpr uint64_t MAX_STARTUP_PACKET_LENGTH = 10000;
};

} // namespace PostgresProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/postgres_proxy/filters/network/source/postgres_filter.h"

#include "envoy/buffer/buffer.h"
#include "envoy/network/connection.h"

#include "source/common/common/assert.h"
#include "source/extensions/filters/network/well_known_names.h"

#include "contrib/postgres_proxy/filters/network/source/postgres_decoder.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace PostgresProxy {

PostgresFilterConfig::PostgresFilterConfig(const PostgresFilterConfigOptions& config_options,
                                           Stats::Scope& scope)
    : enable_sql_parsing_(config_options.enable_sql_parsing_),
      terminate_ssl_(config_options.terminate_ssl_), upstream_ssl_(config_options.upstream_ssl_),
      scope_{scope}, stats_{generateStats(config_options.stats_prefix_, scope)} {}

PostgresFilter::PostgresFilter(PostgresFilterConfigSharedPtr config) : config_{config} {
  if (!decoder_) {
    decoder_ = createDecoder(this);
  }
}

// Network::ReadFilter
Network::FilterStatus PostgresFilter::onData(Buffer::Instance& data, bool) {
  ENVOY_CONN_LOG(trace, "postgres_proxy: got {} bytes", read_callbacks_->connection(),
                 data.length());

  // Frontend Buffer
  frontend_buffer_.add(data);
  Network::FilterStatus result = doDecode(frontend_buffer_, true);
  if (result == Network::FilterStatus::StopIteration) {
    ASSERT(frontend_buffer_.length() == 0);
    data.drain(data.length());
  }
  return result;
}

Network::FilterStatus PostgresFilter::onNewConnection() { return Network::FilterStatus::Continue; }

void PostgresFilter::initializeReadFilterCallbacks(Network::ReadFilterCallbacks& callbacks) {
  read_callbacks_ = &callbacks;
}

void PostgresFilter::initializeWriteFilterCallbacks(Network::WriteFilterCallbacks& callbacks) {
  write_callbacks_ = &callbacks;
}

// Network::WriteFilter
Network::FilterStatus PostgresFilter::onWrite(Buffer::Instance& data, bool) {

  // Backend Buffer
  backend_buffer_.add(data);
  Network::FilterStatus result = doDecode(backend_buffer_, false);
  if (result == Network::FilterStatus::StopIteration) {
    ASSERT(backend_buffer_.length() == 0);
    data.drain(data.length());
  }
  return result;
}

DecoderPtr PostgresFilter::createDecoder(DecoderCallbacks* callbacks) {
  return std::make_unique<DecoderImpl>(callbacks);
}

void PostgresFilter::incMessagesBackend() {
  config_->stats_.messages_.inc();
  config_->stats_.messages_backend_.inc();
}

void PostgresFilter::incMessagesFrontend() {
  config_->stats_.messages_.inc();
  config_->stats_.messages_frontend_.inc();
}

void PostgresFilter::incMessagesUnknown() {
  config_->stats_.messages_.inc();
  config_->stats_.messages_unknown_.inc();
}

void PostgresFilter::incSessionsEncrypted() {
  config_->stats_.sessions_.inc();
  config_->stats_.sessions_encrypted_.inc();
}

void PostgresFilter::incSessionsUnencrypted() {
  config_->stats_.sessions_.inc();
  config_->stats_.sessions_unencrypted_.inc();
}

void PostgresFilter::incTransactions() {
  if (!decoder_->getSession().inTransaction()) {
    config_->stats_.transactions_.inc();
  }
}

void PostgresFilter::incTransactionsCommit() {
  if (!decoder_->getSession().inTransaction()) {
    config_->stats_.transactions_commit_.inc();
  }
}

void PostgresFilter::incTransactionsRollback() {
  if (decoder_->getSession().inTransaction()) {
    config_->stats_.transactions_rollback_.inc();
  }
}

void PostgresFilter::incNotices(NoticeType type) {
  config_->stats_.notices_.inc();
  switch (type) {
  case DecoderCallbacks::NoticeType::Warning:
    config_->stats_.notices_warning_.inc();
    break;
  case DecoderCallbacks::NoticeType::Notice:
    config_->stats_.notices_notice_.inc();
    break;
  case DecoderCallbacks::NoticeType::Debug:
    config_->stats_.notices_debug_.inc();
    break;
  case DecoderCallbacks::NoticeType::Info:
    config_->stats_.notices_info_.inc();
    break;
  case DecoderCallbacks::NoticeType::Log:
    config_->stats_.notices_log_.inc();
    break;
  case DecoderCallbacks::NoticeType::Unknown:
    config_->stats_.notices_unknown_.inc();
    break;
  }
}

void PostgresFilter::incErrors(ErrorType type) {
  config_->stats_.errors_.inc();
  switch (type) {
  case DecoderCallbacks::ErrorType::Error:
    config_->stats_.errors_error_.inc();
    break;
  case DecoderCallbacks::ErrorType::Fatal:
    config_->stats_.errors_fatal_.inc();
    break;
  case DecoderCallbacks::ErrorType::Panic:
    config_->stats_.errors_panic_.inc();
    break;
  case DecoderCallbacks::ErrorType::Unknown:
    config_->stats_.errors_unknown_.inc();
    break;
  }
}

void PostgresFilter::incStatements(StatementType type) {
  config_->stats_.statements_.inc();

  switch (type) {
  case DecoderCallbacks::StatementType::Insert:
    config_->stats_.statements_insert_.inc();
    break;
  case DecoderCallbacks::StatementType::Delete:
    config_->stats_.statements_delete_.inc();
    break;
  case DecoderCallbacks::StatementType::Select:
    config_->stats_.statements_select_.inc();
    break;
  case DecoderCallbacks::StatementType::Update:
    config_->stats_.statements_update_.inc();
    break;
  case DecoderCallbacks::StatementType::Other:
    config_->stats_.statements_other_.inc();
    break;
  case DecoderCallbacks::StatementType::Noop:
    break;
  }
}

void PostgresFilter::processQuery(const std::string& sql) {
  if (config_->enable_sql_parsing_) {
    ProtobufWkt::Struct metadata;

    auto result = Common::SQLUtils::SQLUtils::setMetadata(sql, decoder_->getAttributes(), metadata);

    if (!result) {
      config_->stats_.statements_parse_error_.inc();
      ENVOY_CONN_LOG(trace, "postgres_proxy: cannot parse SQL: {}", read_callbacks_->connection(),
                     sql.c_str());
      return;
    }

    config_->stats_.statements_parsed_.inc();
    ENVOY_CONN_LOG(trace, "postgres_proxy: query processed {}", read_callbacks_->connection(),
                   sql.c_str());

    // Set dynamic metadata
    read_callbacks_->connection().streamInfo().setDynamicMetadata(
        NetworkFilterNames::get().PostgresProxy, metadata);
  }
}

bool PostgresFilter::onSSLRequest() {
  if (!config_->terminate_ssl_) {
    // Signal to the decoder to continue.
    return true;
  }
  // Send single bytes 'S' to indicate switch to TLS.
  // Refer to official documentation for protocol details:
  // https://www.postgresql.org/docs/current/protocol-flow.html
  Buffer::OwnedImpl buf;
  buf.add("S");
  // Add callback to be notified when the reply message has been
  // transmitted.
  read_callbacks_->connection().addBytesSentCallback([=](uint64_t bytes) -> bool {
    // Wait until 'S' has been transmitted.
    if (bytes >= 1) {
      if (!read_callbacks_->connection().startSecureTransport()) {
        ENVOY_CONN_LOG(
            info, "postgres_proxy: cannot enable downstream secure transport. Check configuration.",
            read_callbacks_->connection());
        read_callbacks_->connection().close(Network::ConnectionCloseType::NoFlush);
      } else {
        // Unsubscribe the callback.
        config_->stats_.sessions_terminated_ssl_.inc();
        ENVOY_CONN_LOG(trace, "postgres_proxy: enabled SSL termination.",
                       read_callbacks_->connection());
        // Switch to TLS has been completed.
        // Signal to the decoder to stop processing the current message (SSLRequest).
        // Because Envoy terminates SSL, the message was consumed and should not be
        // passed to other filters in the chain.
        return false;
      }
    }
    return true;
  });
  write_callbacks_->injectWriteDataToFilterChain(buf, false);

  return false;
}

bool PostgresFilter::shouldEncryptUpstream() const {
  return (config_->upstream_ssl_ ==
          envoy::extensions::filters::network::postgres_proxy::v3alpha::PostgresProxy::REQUIRE);
}

void PostgresFilter::sendUpstream(Buffer::Instance& data) {
  read_callbacks_->injectReadDataToFilterChain(data, false);
}

bool PostgresFilter::encryptUpstream(bool upstream_agreed, Buffer::Instance& data) {
  bool encrypted = false;
  RELEASE_ASSERT(
      config_->upstream_ssl_ !=
          envoy::extensions::filters::network::postgres_proxy::v3alpha::PostgresProxy::DISABLE,
      "encryptUpstream should not be called when upstream SSL is disabled.");
  if (!upstream_agreed) {
    ENVOY_CONN_LOG(info,
                   "postgres_proxy: upstream server rejected request to establish SSL connection. "
                   "Terminating.",
                   read_callbacks_->connection());
    read_callbacks_->connection().close(Network::ConnectionCloseType::NoFlush);

    config_->stats_.sessions_upstream_ssl_failed_.inc();
  } else {
    // Try to switch upstream connection to use a secure channel.
    if (read_callbacks_->startUpstreamSecureTransport()) {
      config_->stats_.sessions_upstream_ssl_success_.inc();
      read_callbacks_->injectReadDataToFilterChain(data, false);
      encrypted = true;
      ENVOY_CONN_LOG(trace, "postgres_proxy: upstream SSL enabled.", read_callbacks_->connection());
    } else {
      ENVOY_CONN_LOG(info,
                     "postgres_proxy: cannot enable upstream secure transport. Check "
                     "configuration. Terminating.",
                     read_callbacks_->connection());
      read_callbacks_->connection().close(Network::ConnectionCloseType::NoFlush);
      config_->stats_.sessions_upstream_ssl_failed_.inc();
    }
  }

  return encrypted;
}

Network::FilterStatus PostgresFilter::doDecode(Buffer::Instance& data, bool frontend) {
  // Keep processing data until buffer is empty or decoder says
  // that it cannot process data in the buffer.
  while (0 < data.length()) {
    switch (decoder_->onData(data, frontend)) {
    case Decoder::Result::NeedMoreData:
      return Network::FilterStatus::Continue;
    case Decoder::Result::ReadyForNext:
      continue;
    case Decoder::Result::Stopped:
      return Network::FilterStatus::StopIteration;
    }
  }
  return Network::FilterStatus::Continue;
}

} // namespace PostgresProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include "source/common/buffer/buffer_impl.h"

#include "absl/strings/str_cat.h"
#include "absl/strings/str_join.h"
#include "fmt/printf.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace PostgresProxy {

/**
 * Postgres messages are described in official Postgres documentation:
 * https://www.postgresql.org/docs/current/protocol-message-formats.html
 *
 * Most of messages start with 1-byte message identifier followed by 4-bytes length field. Few
 * messages are defined without starting 1-byte character and are used during well-defined initial
 * stage of connection process.
 *
 * Messages are composed from various fields: 8, 16, 32-bit integers, String, Arrays, etc.
 *
 * Structures defined below have the same naming as types used in official Postgres documentation.
 *
 * Each structure has the following methods:
 * read - to read number of bytes from received buffer. The number of bytes depends on structure
 * type. toString - method returns displayable representation of the structure value.
 *
 */

// Interface to Postgres message class.
class Message {
public:
  enum ValidationResult { ValidationFailed, ValidationOK, ValidationNeedMoreData };

  virtual ~Message() = default;

  // read method should read only as many bytes from data
  // buffer as it is indicated in message's length field.
  // "length" parameter indicates how many bytes were indicated in Postgres message's
  // length field. "data" buffer may contain more bytes than "length".
  virtual bool read(const Buffer::Instance& data, const uint64_t length) PURE;

  virtual ValidationResult validate(const Buffer::Instance& data, const uint64_t,
                                    const uint64_t) PURE;

  // toString method provides displayable representation of
  // the Postgres message.
  virtual std::string toString() const PURE;

protected:
  ValidationResult validation_result_{ValidationNeedMoreData};
};

// Template for integer types.
// Size of integer types is fixed and depends on the type of integer.
template <typename T> class Int {
public:
  /**
   * Read integer value from data buffer.
   * @param data reference to a buffer containing data to read.
   * @param pos offset in the buffer where data to read is located. Successful read will advance
   * this parameter.
   * @param left number of bytes to be read to reach the end of Postgres message.
   * Successful read will adjust this parameter.
   * @return boolean value indicating whether read was successful. If read returns
   * false "pos" and "left" params are not updated. When read is not successful,
   * the caller should not continue reading next values from the data buffer
   * for the current message.
   */
  bool read(const Buffer::Instance& data, uint64_t& pos, uint64_t& left) {
    value_ = data.peekBEInt<T>(pos);
    pos += sizeof(T);
    left -= sizeof(T);
    return true;
  }

  Message::ValidationResult validate(const Buffer::Instance& data, const uint64_t, uint64_t& pos,
                                     uint64_t& left) {
    if (left < sizeof(T)) {
      return Message::ValidationFailed;
    }

    if ((data.length() - pos) < sizeof(T)) {
      return Message::ValidationNeedMoreData;
    }

    pos += sizeof(T);
    left -= sizeof(T);
    return Message::ValidationOK;
  }

  std::string toString() const { return fmt::format("[{}]", value_); }

  T get() const { return value_; }

private:
  T value_{};
};

using Int32 = Int<uint32_t>;
using Int16 = Int<uint16_t>;
using Int8 = Int<uint8_t>;

// 8-bits character value.
using Byte1 = Int<char>;

// String type requires byte with zero value to indicate end of string.
class String {
public:
  /**
   * See above for parameter and return value description.
   */
  bool read(const Buffer::Instance& data, uint64_t& pos, uint64_t& left);
  std::string toString() const;
  Message::ValidationResult validate(const Buffer::Instance&, const uint64_t start_offset,
                                     uint64_t&, uint64_t&);

private:
  // start_ and end_ are set by validate method.
  uint64_t start_;
  uint64_t end_;
  std::string value_;
};

// ByteN type is used as the last type in the Postgres message and contains
// sequence of bytes. The length must be deduced from message length.
class ByteN {
public:
  /**
   * See above for parameter and return value description.
   */
  bool read(const Buffer::Instance& data, uint64_t& pos, uint64_t& left);
  std::string toString() const;
  Message::ValidationResult validate(const Buffer::Instance&, const uint64_t, uint64_t&, uint64_t&);

private:
  std::vector<uint8_t> value_;
};

// VarByteN represents the structure consisting of 4 bytes of length
// indicating how many bytes follow.
// In Postgres documentation it is described as:
// - Int32
//   The number of bytes in the structure (this count does not include itself). Can be
//   zero. As a special case, -1 indicates a NULL (no result). No value bytes follow in the NULL
// case.
//
// - ByteN
// The sequence of bytes representing the value. Bytes are present only when length has a positive
// value.
class VarByteN {
public:
  /**
   * See above for parameter and return value description.
   */
  bool read(const Buffer::Instance& data, uint64_t& pos, uint64_t& left);
  std::string toString() const;
  Message::ValidationResult validate(const Buffer::Instance&, const uint64_t, uint64_t&, uint64_t&);

private:
  int32_t len_;
  std::vector<uint8_t> value_;
};

// Array contains one or more values of the same type.
template <typename T> class Array {
public:
  /**
   * See above for parameter and return value description.
   */
  bool read(const Buffer::Instance& data, uint64_t& pos, uint64_t& left) {
    // Skip reading the size of array. The validator did it.
    pos += sizeof(uint16_t);
    left -= sizeof(uint16_t);
    for (uint16_t i = 0; i < size_; i++) {
      value_[i]->read(data, pos, left);
    }
    return true;
  }

  std::string toString() const {
    std::string out = fmt::format("[Array of {}:{{", value_.size());

    // Iterate through all elements in the array.
    // No delimiter is required between elements, as each
    // element is wrapped in "[]" or "{}".
    for (const auto& i : value_) {
      absl::StrAppend(&out, i->toString());
    }
    absl::StrAppend(&out, "}]");

    return out;
  }
  Message::ValidationResult validate(const Buffer::Instance& data, const uint64_t start_offset,
                                     uint64_t& pos, uint64_t& left) {
    // First read the 16 bits value which indicates how many
    // elements there are in the array.
    if (left < sizeof(uint16_t)) {
      return Message::ValidationFailed;
    }

    if ((data.length() - pos) < sizeof(uint16_t)) {
      return Message::ValidationNeedMoreData;
    }

    size_ = data.peekBEInt<uint16_t>(pos);
    uint64_t orig_pos = pos;
    uint64_t orig_left = left;
    pos += sizeof(uint16_t);
    left -= sizeof(uint16_t);
    if (size_ != 0) {
      for (uint16_t i = 0; i < size_; i++) {
        auto item = std::make_unique<T>();
        Message::ValidationResult result = item->validate(data, start_offset, pos, left);
        if (Message::ValidationOK != result) {
          pos = orig_pos;
          left = orig_left;
          value_.clear();
          return result;
        }
        value_.push_back(std::move(item));
      }
    }
    return Message::ValidationOK;
  }

private:
  uint16_t size_;
  std::vector<std::unique_ptr<T>> value_;
};

// Repeated is a composite type used at the end of the message.
// It indicates to read the value of the same type until the end
// of the Postgres message.
template <typename T> class Repeated {
public:
  /**
   * See above for parameter and return value description.
   */
  bool read(const Buffer::Instance& data, uint64_t& pos, uint64_t& left) {
    for (size_t i = 0; i < value_.size(); i++) {
      if (!value_[i]->read(data, pos, left)) {
        return false;
      }
    }
    return true;
  }

  std::string toString() const {
    std::string out;

    // Iterate through all repeated elements.
    // No delimiter is required between elements, as each
    // element is wrapped in "[]" or "{}".
    for (const auto& i : value_) {
      absl::StrAppend(&out, i->toString());
    }
    return out;
  }
  Message::ValidationResult validate(const Buffer::Instance& data, const uint64_t start_offset,
                                     uint64_t& pos, uint64_t& left) {
    if ((data.length() - pos) < left) {
      return Message::ValidationNeedMoreData;
    }

    // Validate until the end of the message.
    uint64_t orig_pos = pos;
    uint64_t orig_left = left;
    while (left != 0) {
      auto item = std::make_unique<T>();
      Message::ValidationResult result = item->validate(data, start_offset, pos, left);
      if (Message::ValidationOK != result) {
        pos = orig_pos;
        left = orig_left;
        value_.clear();
        return result;
      }
      value_.push_back(std::move(item));
    }

    return Message::ValidationOK;
  }

private:
  std::vector<std::unique_ptr<T>> value_;
};

// Sequence is tuple like structure, which binds together
// set of several fields of different types.
template <typename... Types> class Sequence;

template <typename FirstField, typename... Remaining> class Sequence<FirstField, Remaining...> {
  FirstField first_;
  Sequence<Remaining...> remaining_;

public:
  Sequence() = default;
  std::string toString() const { return absl::StrCat(first_.toString(), remaining_.toString()); }

  /**
   * Implementation of "read" method for variadic template.
   * It reads data for the current type and invokes read operation
   * for remaining types.
   * See above for parameter and return value description for individual types.
   */
  bool read(const Buffer::Instance& data, uint64_t& pos, uint64_t& left) {
    bool result = first_.read(data, pos, left);
    if (!result) {
      return false;
    }
    return remaining_.read(data, pos, left);
  }

  Message::ValidationResult validate(const Buffer::Instance& data, const uint64_t start_offset,
                                     uint64_t& pos, uint64_t& left) {
    Message::ValidationResult result = first_.validate(data, start_offset, pos, left);
    if (result != Message::ValidationOK) {
      return result;
    }
    return remaining_.validate(data, start_offset, pos, left);
  }
};

// Terminal template definition for variadic Sequence template.
template <> class Sequence<> {
public:
  Sequence<>() = default;
  std::string toString() const { return ""; }
  bool read(const Buffer::Instance&, uint64_t&, uint64_t&) { return true; }
  Message::ValidationResult validate(const Buffer::Instance&, const uint64_t, uint64_t&,
                                     uint64_t& left) {
    return left == 0 ? Message::ValidationOK : Message::ValidationFailed;
  }
};

template <typename... Types> class MessageImpl : public Message, public Sequence<Types...> {
public:
  ~MessageImpl() override = default;
  bool read(const Buffer::Instance& data, const uint64_t length) override {
    // Do not call read unless validation was successful.
    ASSERT(validation_result_ == ValidationOK);
    uint64_t pos = 0;
    uint64_t left = length;
    return Sequence<Types...>::read(data, pos, left);
  }
  Message::ValidationResult validate(const Buffer::Instance& data, const uint64_t start_pos,
                                     const uint64_t length) override {
    uint64_t pos = start_pos;
    uint64_t left = length;
    validation_result_ = Sequence<Types...>::validate(data, start_pos, pos, left);
    return validation_result_;
  }
  std::string toString() const override { return Sequence<Types...>::toString(); }

private:
  // Message::ValidationResult validation_result_;
};

// Helper function to create pointer to a Sequence structure and is used by Postgres
// decoder after learning the type of Postgres message.
template <typename... Types> std::unique_ptr<Message> createMsgBodyReader() {
  return std::make_unique<MessageImpl<Types...>>();
}

} // namespace PostgresProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include "source/extensions/filters/network/common/factory_base.h"
#include "source/extensions/filters/network/well_known_names.h"

#include "contrib/envoy/extensions/filters/network/postgres_proxy/v3alpha/postgres_proxy.pb.h"
#include "contrib/envoy/extensions/filters/network/postgres_proxy/v3alpha/postgres_proxy.pb.validate.h"
#include "contrib/postgres_proxy/filters/network/source/postgres_filter.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace PostgresProxy {

/**
 * Config registration for the Postgres proxy filter.
 */
class PostgresConfigFactory
    : public Common::FactoryBase<
          envoy::extensions::filters::network::postgres_proxy::v3alpha::PostgresProxy> {
public:
  PostgresConfigFactory() : FactoryBase{NetworkFilterNames::get().PostgresProxy} {}

private:
  Network::FilterFactoryCb createFilterFactoryFromProtoTyped(
      const envoy::extensions::filters::network::postgres_proxy::v3alpha::PostgresProxy&
          proto_config,
      Server::Configuration::FactoryContext& context) override;
};

} // namespace PostgresProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include "envoy/network/filter.h"
#include "envoy/stats/scope.h"
#include "envoy/stats/stats.h"
#include "envoy/stats/stats_macros.h"

#include "source/common/buffer/buffer_impl.h"
#include "source/common/common/logger.h"

#include "contrib/envoy/extensions/filters/network/postgres_proxy/v3alpha/postgres_proxy.pb.h"
#include "contrib/postgres_proxy/filters/network/source/postgres_decoder.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace PostgresProxy {

/**
 * All Postgres proxy stats. @see stats_macros.h
 */
#define ALL_POSTGRES_PROXY_STATS(COUNTER)                                                          \
  COUNTER(errors)                                                                                  \
  COUNTER(errors_error)                                                                            \
  COUNTER(errors_fatal)                                                                            \
  COUNTER(errors_panic)                                                                            \
  COUNTER(errors_unknown)                                                                          \
  COUNTER(messages)                                                                                \
  COUNTER(messages_backend)                                                                        \
  COUNTER(messages_frontend)                                                                       \
  COUNTER(messages_unknown)                                                                        \
  COUNTER(sessions)                                                                                \
  COUNTER(sessions_encrypted)                                                                      \
  COUNTER(sessions_terminated_ssl)                                                                 \
  COUNTER(sessions_unencrypted)                                                                    \
  COUNTER(sessions_upstream_ssl_success)                                                           \
  COUNTER(sessions_upstream_ssl_failed)                                                            \
  COUNTER(statements)                                                                              \
  COUNTER(statements_insert)                                                                       \
  COUNTER(statements_delete)                                                                       \
  COUNTER(statements_update)                                                                       \
  COUNTER(statements_select)                                                                       \
  COUNTER(statements_other)                                                                        \
  COUNTER(transactions)                                                                            \
  COUNTER(transactions_commit)                                                                     \
  COUNTER(transactions_rollback)                                                                   \
  COUNTER(statements_parsed)                                                                       \
  COUNTER(statements_parse_error)                                                                  \
  COUNTER(notices)                                                                                 \
  COUNTER(notices_notice)                                                                          \
  COUNTER(notices_warning)                                                                         \
  COUNTER(notices_debug)                                                                           \
  COUNTER(notices_info)                                                                            \
  COUNTER(notices_log)                                                                             \
  COUNTER(notices_unknown)

/**
 * Struct definition for all Postgres proxy stats. @see stats_macros.h
 */
struct PostgresProxyStats {
  ALL_POSTGRES_PROXY_STATS(GENERATE_COUNTER_STRUCT)
};

/**
 * Configuration for the Postgres proxy filter.
 */
class PostgresFilterConfig {
public:
  struct PostgresFilterConfigOptions {
    std::string stats_prefix_;
    bool enable_sql_parsing_;
    bool terminate_ssl_;
    envoy::extensions::filters::network::postgres_proxy::v3alpha::PostgresProxy::SSLMode
        upstream_ssl_;
  };
  PostgresFilterConfig(const PostgresFilterConfigOptions& config_options, Stats::Scope& scope);

  bool enable_sql_parsing_{true};
  bool terminate_ssl_{false};
  envoy::extensions::filters::network::postgres_proxy::v3alpha::PostgresProxy::SSLMode
      upstream_ssl_{
          envoy::extensions::filters::network::postgres_proxy::v3alpha::PostgresProxy::DISABLE};
  Stats::Scope& scope_;
  PostgresProxyStats stats_;

private:
  PostgresProxyStats generateStats(const std::string& prefix, Stats::Scope& scope) {
    return PostgresProxyStats{ALL_POSTGRES_PROXY_STATS(POOL_COUNTER_PREFIX(scope, prefix))};
  }
};

using PostgresFilterConfigSharedPtr = std::shared_ptr<PostgresFilterConfig>;

class PostgresFilter : public Network::Filter,
                       DecoderCallbacks,
                       Logger::Loggable<Logger::Id::filter> {
public:
  PostgresFilter(PostgresFilterConfigSharedPtr config);
  ~PostgresFilter() override = default;

  // Network::ReadFilter
  Network::FilterStatus onData(Buffer::Instance& data, bool end_stream) override;
  Network::FilterStatus onNewConnection() override;
  void initializeReadFilterCallbacks(Network::ReadFilterCallbacks& callbacks) override;
  void initializeWriteFilterCallbacks(Network::WriteFilterCallbacks& callbacks) override;

  // Network::WriteFilter
  Network::FilterStatus onWrite(Buffer::Instance& data, bool end_stream) override;

  // PostgresProxy::DecoderCallback
  void incErrors(ErrorType) override;
  void incMessagesBackend() override;
  void incMessagesFrontend() override;
  void incMessagesUnknown() override;
  void incNotices(NoticeType) override;
  void incSessionsEncrypted() override;
  void incSessionsUnencrypted() override;
  void incStatements(StatementType) override;
  void incTransactions() override;
  void incTransactionsCommit() override;
  void incTransactionsRollback() override;
  void processQuery(const std::string&) override;
  bool onSSLRequest() override;
  bool shouldEncryptUpstream() const override;
  void sendUpstream(Buffer::Instance&) override;
  bool encryptUpstream(bool, Buffer::Instance&) override;

  Network::FilterStatus doDecode(Buffer::Instance& data, bool);
  DecoderPtr createDecoder(DecoderCallbacks* callbacks);
  void setDecoder(std::unique_ptr<Decoder> decoder) { decoder_ = std::move(decoder); }
  Decoder* getDecoder() const { return decoder_.get(); }

  // Routines used during integration and unit tests
  uint32_t getFrontendBufLength() const { return frontend_buffer_.length(); }
  uint32_t getBackendBufLength() const { return backend_buffer_.length(); }
  const PostgresProxyStats& getStats() const { return config_->stats_; }
  Network::Connection& connection() const { return read_callbacks_->connection(); }
  const PostgresFilterConfigSharedPtr& getConfig() const { return config_; }

private:
  Network::ReadFilterCallbacks* read_callbacks_{};
  Network::WriteFilterCallbacks* write_callbacks_{};
  PostgresFilterConfigSharedPtr config_;
  Buffer::OwnedImpl frontend_buffer_;
  Buffer::OwnedImpl backend_buffer_;
  std::unique_ptr<Decoder> decoder_;
};

} // namespace PostgresProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/postgres_proxy/filters/network/source/postgres_message.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace PostgresProxy {

// String type methods.
bool String::read(const Buffer::Instance& data, uint64_t& pos, uint64_t& left) {
  // read method uses values set by validate method.
  // This avoids unnecessary repetition of scanning data looking for terminating zero.
  ASSERT(pos == start_);
  ASSERT(end_ >= start_);

  // Reserve that many bytes in the string.
  const uint64_t size = end_ - start_;
  value_.resize(size);
  // Now copy from buffer to string.
  data.copyOut(pos, size, value_.data());
  pos += (size + 1);
  left -= (size + 1);

  return true;
}

std::string String::toString() const { return absl::StrCat("[", value_, "]"); }

Message::ValidationResult String::validate(const Buffer::Instance& data,
                                           const uint64_t start_offset, uint64_t& pos,
                                           uint64_t& left) {
  // Try to find the terminating zero.
  // If found, all is good. If not found, we may need more data.
  const char zero = 0;
  const ssize_t index = data.search(&zero, 1, pos);
  if (index == -1) {
    if (left <= (data.length() - pos)) {
      // Message ended before finding terminating zero.
      return Message::ValidationFailed;
    } else {
      return Message::ValidationNeedMoreData;
    }
  }
  // Found, but after the message boundary.
  const uint64_t size = index - pos;
  if (size >= left) {
    return Message::ValidationFailed;
  }

  start_ = pos - start_offset;
  end_ = start_ + size;

  pos += (size + 1);
  left -= (size + 1);
  return Message::ValidationOK;
}

// ByteN type methods.
bool ByteN::read(const Buffer::Instance& data, uint64_t& pos, uint64_t& left) {
  if (left > (data.length() - pos)) {
    return false;
  }
  value_.resize(left);
  data.copyOut(pos, left, value_.data());
  pos += left;
  left = 0;
  return true;
}
// Since ByteN does not have a length field, it is not possible to verify
// its correctness.
Message::ValidationResult ByteN::validate(const Buffer::Instance& data, const uint64_t,
                                          uint64_t& pos, uint64_t& left) {
  if (left > (data.length() - pos)) {
    return Message::ValidationNeedMoreData;
  }

  pos += left;
  left = 0;

  return Message::ValidationOK;
}

std::string ByteN::toString() const {
  std::string out = "[";
  absl::StrAppend(&out, absl::StrJoin(value_, " "));
  absl::StrAppend(&out, "]");
  return out;
}

// VarByteN type methods.
bool VarByteN::read(const Buffer::Instance& data, uint64_t& pos, uint64_t& left) {
  // len_ was set by validator, skip it.
  pos += sizeof(int32_t);
  left -= sizeof(int32_t);
  if (len_ < 1) {
    // There is no payload if length is not positive.
    value_.clear();
    return true;
  }

  value_.resize(len_);
  data.copyOut(pos, len_, value_.data());
  pos += len_;
  left -= len_;
  return true;
}

std::string VarByteN::toString() const {
  std::string out;
  out = fmt::format("[({} bytes):", len_);
  absl::StrAppend(&out, absl::StrJoin(value_, " "));
  absl::StrAppend(&out, "]");
  return out;
}

Message::ValidationResult VarByteN::validate(const Buffer::Instance& data, const uint64_t,
                                             uint64_t& pos, uint64_t& left) {
  if (left < sizeof(int32_t)) {
    // Malformed message.
    return Message::ValidationFailed;
  }

  if ((data.length() - pos) < sizeof(int32_t)) {
    return Message::ValidationNeedMoreData;
  }

  // Read length of the VarByteN structure.
  len_ = data.peekBEInt<int32_t>(pos);
  if (static_cast<int64_t>(len_) > static_cast<int64_t>(left)) {
    // VarByteN would extend past the current message boundaries.
    // Lengths of message and individual fields do not match.
    return Message::ValidationFailed;
  }

  if (len_ < 1) {
    // There is no payload if length is not positive.
    pos += sizeof(int32_t);
    left -= sizeof(int32_t);
    return Message::ValidationOK;
  }

  if ((data.length() - pos) < (len_ + sizeof(int32_t))) {
    return Message::ValidationNeedMoreData;
  }

  pos += (len_ + sizeof(int32_t));
  left -= (len_ + sizeof(int32_t));

  return Message::ValidationOK;
}

} // namespace PostgresProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once
#include <cstdint>

#include "source/common/common/logger.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace PostgresProxy {

// Class stores data about the current state of a transaction between postgres client and server.
class PostgresSession {
public:
  bool inTransaction() { return in_transaction_; };
  void setInTransaction(bool in_transaction) { in_transaction_ = in_transaction; };

private:
  bool in_transaction_{false};
};

} // namespace PostgresProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
load(
    "//bazel:envoy_build_system.bzl",
    "envoy_cc_contrib_extension",
    "envoy_cc_library",
    "envoy_contrib_package",
)

licenses(["notice"])  # Apache 2

envoy_contrib_package()

#package(default_visibility = ["//visibility:public"])

# PostgresSQL proxy L7 network filter.
# Public docs: https://envoyproxy.io/docs/envoy/latest/configuration/listeners/network_filters/postgres_proxy_filter

envoy_cc_library(
    name = "filter",
    srcs = [
        "postgres_decoder.cc",
        "postgres_filter.cc",
        "postgres_message.cc",
    ],
    hdrs = [
        "postgres_decoder.h",
        "postgres_filter.h",
        "postgres_message.h",
        "postgres_session.h",
    ],
    repository = "@envoy",
    deps = [
        "//contrib/common/sqlutils/source:sqlutils_lib",
        "//envoy/network:filter_interface",
        "//envoy/server:filter_config_interface",
        "//envoy/stats:stats_interface",
        "//envoy/stats:stats_macros",
        "//source/common/buffer:buffer_lib",
        "//source/common/network:filter_lib",
        "//source/extensions/filters/network:well_known_names",
        "@envoy_api//contrib/envoy/extensions/filters/network/postgres_proxy/v3alpha:pkg_cc_proto",
    ],
)

envoy_cc_contrib_extension(
    name = "config",
    srcs = ["config.cc"],
    hdrs = ["config.h"],
    repository = "@envoy",
    deps = [
        ":filter",
        "//source/extensions/filters/network:well_known_names",
        "//source/extensions/filters/network/common:factory_base_lib",
        "@envoy_api//contrib/envoy/extensions/filters/network/postgres_proxy/v3alpha:pkg_cc_proto",
    ],
)
#include "contrib/postgres_proxy/filters/network/source/postgres_decoder.h"

#include <vector>

#include "absl/strings/str_split.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace PostgresProxy {

#define BODY_FORMAT(...)                                                                           \
  []() -> std::unique_ptr<Message> { return createMsgBodyReader<__VA_ARGS__>(); }
#define NO_BODY BODY_FORMAT()

constexpr absl::string_view FRONTEND = "Frontend";
constexpr absl::string_view BACKEND = "Backend";

void DecoderImpl::initialize() {
  // Special handler for first message of the transaction.
  first_ =
      MessageProcessor{"Startup", BODY_FORMAT(Int32, Repeated<String>), {&DecoderImpl::onStartup}};

  // Frontend messages.
  FE_messages_.direction_ = FRONTEND;

  // Setup handlers for known messages.
  absl::flat_hash_map<char, MessageProcessor>& FE_known_msgs = FE_messages_.messages_;

  // Handler for known Frontend messages.
  FE_known_msgs['B'] = MessageProcessor{
      "Bind", BODY_FORMAT(String, String, Array<Int16>, Array<VarByteN>, Array<Int16>), {}};
  FE_known_msgs['C'] = MessageProcessor{"Close", BODY_FORMAT(Byte1, String), {}};
  FE_known_msgs['d'] = MessageProcessor{"CopyData", BODY_FORMAT(ByteN), {}};
  FE_known_msgs['c'] = MessageProcessor{"CopyDone", NO_BODY, {}};
  FE_known_msgs['f'] = MessageProcessor{"CopyFail", BODY_FORMAT(String), {}};
  FE_known_msgs['D'] = MessageProcessor{"Describe", BODY_FORMAT(Byte1, String), {}};
  FE_known_msgs['E'] = MessageProcessor{"Execute", BODY_FORMAT(String, Int32), {}};
  FE_known_msgs['H'] = MessageProcessor{"Flush", NO_BODY, {}};
  FE_known_msgs['F'] = MessageProcessor{
      "FunctionCall", BODY_FORMAT(Int32, Array<Int16>, Array<VarByteN>, Int16), {}};
  FE_known_msgs['p'] =
      MessageProcessor{"PasswordMessage/GSSResponse/SASLInitialResponse/SASLResponse",
                       BODY_FORMAT(Int32, ByteN),
                       {}};
  FE_known_msgs['P'] =
      MessageProcessor{"Parse", BODY_FORMAT(String, String, Array<Int32>), {&DecoderImpl::onParse}};
  FE_known_msgs['Q'] = MessageProcessor{"Query", BODY_FORMAT(String), {&DecoderImpl::onQuery}};
  FE_known_msgs['S'] = MessageProcessor{"Sync", NO_BODY, {}};
  FE_known_msgs['X'] =
      MessageProcessor{"Terminate", NO_BODY, {&DecoderImpl::decodeFrontendTerminate}};

  // Handler for unknown Frontend messages.
  FE_messages_.unknown_ =
      MessageProcessor{"Other", BODY_FORMAT(ByteN), {&DecoderImpl::incMessagesUnknown}};

  // Backend messages.
  BE_messages_.direction_ = BACKEND;

  // Setup handlers for known messages.
  absl::flat_hash_map<char, MessageProcessor>& BE_known_msgs = BE_messages_.messages_;

  // Handler for known Backend messages.
  BE_known_msgs['R'] =
      MessageProcessor{"Authentication", BODY_FORMAT(ByteN), {&DecoderImpl::decodeAuthentication}};
  BE_known_msgs['K'] = MessageProcessor{"BackendKeyData", BODY_FORMAT(Int32, Int32), {}};
  BE_known_msgs['2'] = MessageProcessor{"BindComplete", NO_BODY, {}};
  BE_known_msgs['3'] = MessageProcessor{"CloseComplete", NO_BODY, {}};
  BE_known_msgs['C'] = MessageProcessor{
      "CommandComplete", BODY_FORMAT(String), {&DecoderImpl::decodeBackendStatements}};
  BE_known_msgs['d'] = MessageProcessor{"CopyData", BODY_FORMAT(ByteN), {}};
  BE_known_msgs['c'] = MessageProcessor{"CopyDone", NO_BODY, {}};
  BE_known_msgs['G'] = MessageProcessor{"CopyInResponse", BODY_FORMAT(Int8, Array<Int16>), {}};
  BE_known_msgs['H'] = MessageProcessor{"CopyOutResponse", BODY_FORMAT(Int8, Array<Int16>), {}};
  BE_known_msgs['W'] = MessageProcessor{"CopyBothResponse", BODY_FORMAT(Int8, Array<Int16>), {}};
  BE_known_msgs['D'] = MessageProcessor{"DataRow", BODY_FORMAT(Array<VarByteN>), {}};
  BE_known_msgs['I'] = MessageProcessor{"EmptyQueryResponse", NO_BODY, {}};
  BE_known_msgs['E'] = MessageProcessor{
      "ErrorResponse", BODY_FORMAT(Byte1, String), {&DecoderImpl::decodeBackendErrorResponse}};
  BE_known_msgs['V'] = MessageProcessor{"FunctionCallResponse", BODY_FORMAT(VarByteN), {}};
  BE_known_msgs['v'] = MessageProcessor{"NegotiateProtocolVersion", BODY_FORMAT(ByteN), {}};
  BE_known_msgs['n'] = MessageProcessor{"NoData", NO_BODY, {}};
  BE_known_msgs['N'] = MessageProcessor{
      "NoticeResponse", BODY_FORMAT(ByteN), {&DecoderImpl::decodeBackendNoticeResponse}};
  BE_known_msgs['A'] =
      MessageProcessor{"NotificationResponse", BODY_FORMAT(Int32, String, String), {}};
  BE_known_msgs['t'] = MessageProcessor{"ParameterDescription", BODY_FORMAT(Array<Int32>), {}};
  BE_known_msgs['S'] = MessageProcessor{"ParameterStatus", BODY_FORMAT(String, String), {}};
  BE_known_msgs['1'] = MessageProcessor{"ParseComplete", NO_BODY, {}};
  BE_known_msgs['s'] = MessageProcessor{"PortalSuspend", NO_BODY, {}};
  BE_known_msgs['Z'] = MessageProcessor{"ReadyForQuery", BODY_FORMAT(Byte1), {}};
  BE_known_msgs['T'] = MessageProcessor{
      "RowDescription",
      BODY_FORMAT(Array<Sequence<String, Int32, Int16, Int32, Int16, Int32, Int16>>),
      {}};

  // Handler for unknown Backend messages.
  BE_messages_.unknown_ =
      MessageProcessor{"Other", BODY_FORMAT(ByteN), {&DecoderImpl::incMessagesUnknown}};

  // Setup hash map for handling backend statements.
  BE_statements_["BEGIN"] = [this](DecoderImpl*) -> void {
    callbacks_->incStatements(DecoderCallbacks::StatementType::Other);
    callbacks_->incTransactions();
    session_.setInTransaction(true);
  };
  BE_statements_["ROLLBACK"] = [this](DecoderImpl*) -> void {
    callbacks_->incStatements(DecoderCallbacks::StatementType::Other);
    callbacks_->incTransactionsRollback();
    session_.setInTransaction(false);
  };
  BE_statements_["START"] = [this](DecoderImpl*) -> void {
    callbacks_->incStatements(DecoderCallbacks::StatementType::Other);
    callbacks_->incTransactions();
    session_.setInTransaction(true);
  };
  BE_statements_["COMMIT"] = [this](DecoderImpl*) -> void {
    callbacks_->incStatements(DecoderCallbacks::StatementType::Other);
    session_.setInTransaction(false);
    callbacks_->incTransactionsCommit();
  };
  BE_statements_["SELECT"] = [this](DecoderImpl*) -> void {
    callbacks_->incStatements(DecoderCallbacks::StatementType::Select);
    callbacks_->incTransactions();
    callbacks_->incTransactionsCommit();
  };
  BE_statements_["INSERT"] = [this](DecoderImpl*) -> void {
    callbacks_->incStatements(DecoderCallbacks::StatementType::Insert);
    callbacks_->incTransactions();
    callbacks_->incTransactionsCommit();
  };
  BE_statements_["UPDATE"] = [this](DecoderImpl*) -> void {
    callbacks_->incStatements(DecoderCallbacks::StatementType::Update);
    callbacks_->incTransactions();
    callbacks_->incTransactionsCommit();
  };
  BE_statements_["DELETE"] = [this](DecoderImpl*) -> void {
    callbacks_->incStatements(DecoderCallbacks::StatementType::Delete);
    callbacks_->incTransactions();
    callbacks_->incTransactionsCommit();
  };

  // Setup hash map for handling backend ErrorResponse messages.
  BE_errors_.keywords_["ERROR"] = [this](DecoderImpl*) -> void {
    callbacks_->incErrors(DecoderCallbacks::ErrorType::Error);
  };
  BE_errors_.keywords_["FATAL"] = [this](DecoderImpl*) -> void {
    callbacks_->incErrors(DecoderCallbacks::ErrorType::Fatal);
  };
  BE_errors_.keywords_["PANIC"] = [this](DecoderImpl*) -> void {
    callbacks_->incErrors(DecoderCallbacks::ErrorType::Panic);
  };
  // Setup handler which is called when decoder cannot decode the message and treats it as Unknown
  // Error message.
  BE_errors_.unknown_ = [this](DecoderImpl*) -> void {
    callbacks_->incErrors(DecoderCallbacks::ErrorType::Unknown);
  };

  // Setup hash map for handling backend NoticeResponse messages.
  BE_notices_.keywords_["WARNING"] = [this](DecoderImpl*) -> void {
    callbacks_->incNotices(DecoderCallbacks::NoticeType::Warning);
  };
  BE_notices_.keywords_["NOTICE"] = [this](DecoderImpl*) -> void {
    callbacks_->incNotices(DecoderCallbacks::NoticeType::Notice);
  };
  BE_notices_.keywords_["DEBUG"] = [this](DecoderImpl*) -> void {
    callbacks_->incNotices(DecoderCallbacks::NoticeType::Debug);
  };
  BE_notices_.keywords_["INFO"] = [this](DecoderImpl*) -> void {
    callbacks_->incNotices(DecoderCallbacks::NoticeType::Info);
  };
  BE_notices_.keywords_["LOG"] = [this](DecoderImpl*) -> void {
    callbacks_->incNotices(DecoderCallbacks::NoticeType::Log);
  };
  // Setup handler which is called when decoder cannot decode the message and treats it as Unknown
  // Notice message.
  BE_notices_.unknown_ = [this](DecoderImpl*) -> void {
    callbacks_->incNotices(DecoderCallbacks::NoticeType::Unknown);
  };
}

/* Main handler for incoming messages. Messages are dispatched based on the
   current decoder's state.
*/
Decoder::Result DecoderImpl::onData(Buffer::Instance& data, bool frontend) {
  switch (state_) {
  case State::InitState:
    return onDataInit(data, frontend);
  case State::OutOfSyncState:
  case State::EncryptedState:
    return onDataIgnore(data, frontend);
  case State::InSyncState:
    return onDataInSync(data, frontend);
  case State::NegotiatingUpstreamSSL:
    return onDataInNegotiating(data, frontend);
  default:
    PANIC("not implemented");
  }
}

/* Handler for messages when decoder is in Init State. There are very few message types which
   are allowed in this state.
   If the initial message has the correct syntax and  indicates that session should be in
   clear-text, the decoder will move to InSyncState. If the initial message has the correct syntax
   and indicates that session should be encrypted, the decoder stays in InitState, because the
   initial message will be received again after transport socket negotiates SSL. If the message
   syntax is incorrect, the decoder will move to OutOfSyncState, in which messages are not parsed.
*/
Decoder::Result DecoderImpl::onDataInit(Buffer::Instance& data, bool) {
  ASSERT(state_ == State::InitState);

  // In Init state the minimum size of the message sufficient for parsing is 4 bytes.
  if (data.length() < 4) {
    // not enough data in the buffer.
    return Decoder::Result::NeedMoreData;
  }

  // Validate the message before processing.
  const MsgBodyReader& f = std::get<1>(first_);
  const auto msgParser = f();
  // Run the validation.
  message_len_ = data.peekBEInt<uint32_t>(0);
  if (message_len_ > MAX_STARTUP_PACKET_LENGTH) {
    // Message does not conform to the expected format. Move to out-of-sync state.
    data.drain(data.length());
    state_ = State::OutOfSyncState;
    return Decoder::Result::ReadyForNext;
  }

  Message::ValidationResult validationResult = msgParser->validate(data, 4, message_len_ - 4);

  if (validationResult == Message::ValidationNeedMoreData) {
    return Decoder::Result::NeedMoreData;
  }

  if (validationResult == Message::ValidationFailed) {
    // Message does not conform to the expected format. Move to out-of-sync state.
    data.drain(data.length());
    state_ = State::OutOfSyncState;
    return Decoder::Result::ReadyForNext;
  }

  Decoder::Result result = Decoder::Result::ReadyForNext;
  uint32_t code = data.peekBEInt<uint32_t>(4);
  // Startup message with 1234 in the most significant 16 bits
  // indicate request to encrypt.
  if (code >= 0x04d20000) {
    encrypted_ = true;
    // Handler for SSLRequest (Int32(80877103) = 0x04d2162f)
    // See details in https://www.postgresql.org/docs/current/protocol-message-formats.html.
    if (code == 0x04d2162f) {
      // Notify the filter that `SSLRequest` message was decoded.
      // If the filter returns true, it means to pass the message upstream
      // to the server. If it returns false it means, that filter will try
      // to terminate SSL session and SSLRequest should not be passed to the
      // server.
      encrypted_ = callbacks_->onSSLRequest();
    }

    // Count it as recognized frontend message.
    callbacks_->incMessagesFrontend();
    if (encrypted_) {
      ENVOY_LOG(trace, "postgres_proxy: detected encrypted traffic.");
      incSessionsEncrypted();
      state_ = State::EncryptedState;
    } else {
      result = Decoder::Result::Stopped;
      // Stay in InitState. After switch to SSL, another init packet will be sent.
    }
  } else {
    ENVOY_LOG(debug, "Detected version {}.{} of Postgres", code >> 16, code & 0x0000FFFF);
    if (callbacks_->shouldEncryptUpstream()) {
      // Copy the received initial request.
      temp_storage_.add(data.linearize(data.length()), data.length());
      // Send SSL request to upstream.
      Buffer::OwnedImpl ssl_request;
      uint32_t len = 8;
      ssl_request.writeBEInt<uint32_t>(len);
      uint32_t ssl_code = 0x04d2162f;
      ssl_request.writeBEInt<uint32_t>(ssl_code);

      callbacks_->sendUpstream(ssl_request);
      result = Decoder::Result::Stopped;
      state_ = State::NegotiatingUpstreamSSL;
    } else {
      state_ = State::InSyncState;
    }
  }
  data.drain(4);

  processMessageBody(data, FRONTEND, message_len_ - 4, first_, msgParser);
  data.drain(message_len_);
  return result;
}

/*
  Method invokes actions associated with message type and generate debug logs.
*/
void DecoderImpl::processMessageBody(Buffer::Instance& data, absl::string_view direction,
                                     uint32_t length, MessageProcessor& msg,
                                     const std::unique_ptr<Message>& parser) {
  uint32_t bytes_to_read = length;

  std::vector<MsgAction>& actions = std::get<2>(msg);
  if (!actions.empty()) {
    // Linearize the message for processing.
    message_.assign(std::string(static_cast<char*>(data.linearize(bytes_to_read)), bytes_to_read));

    // Invoke actions associated with the type of received message.
    for (const auto& action : actions) {
      action(this);
    }

    // Drop the linearized message.
    message_.erase();
  }

  ENVOY_LOG(debug, "({}) command = {} ({})", direction, command_, std::get<0>(msg));
  ENVOY_LOG(debug, "({}) length = {}", direction, message_len_);
  ENVOY_LOG(debug, "({}) message = {}", direction, genDebugMessage(parser, data, bytes_to_read));

  ENVOY_LOG(trace, "postgres_proxy: {} bytes remaining in buffer", data.length());

  data.drain(length);
}

/*
  onDataInSync is called when decoder is on-track with decoding messages.
  All previous messages has been decoded properly and decoder is able to find
  message boundaries.
*/
Decoder::Result DecoderImpl::onDataInSync(Buffer::Instance& data, bool frontend) {
  ENVOY_LOG(trace, "postgres_proxy: decoding {} bytes", data.length());

  ENVOY_LOG(trace, "postgres_proxy: parsing message, len {}", data.length());

  // The minimum size of the message sufficient for parsing is 5 bytes.
  if (data.length() < 5) {
    // not enough data in the buffer.
    return Decoder::Result::NeedMoreData;
  }

  data.copyOut(0, 1, &command_);
  ENVOY_LOG(trace, "postgres_proxy: command is {}", command_);

  // The 1 byte message type and message length should be in the buffer
  // Find the message processor and validate the message syntax.

  MsgGroup& msg_processor = std::ref(frontend ? FE_messages_ : BE_messages_);
  frontend ? callbacks_->incMessagesFrontend() : callbacks_->incMessagesBackend();

  // Set processing to the handler of unknown messages.
  // If message is found, the processing will be updated.
  std::reference_wrapper<MessageProcessor> msg = msg_processor.unknown_;

  auto it = msg_processor.messages_.find(command_);
  if (it != msg_processor.messages_.end()) {
    msg = std::ref((*it).second);
  }

  // Validate the message before processing.
  const MsgBodyReader& f = std::get<1>(msg.get());
  message_len_ = data.peekBEInt<uint32_t>(1);
  const auto msgParser = f();
  // Run the validation.
  // Because the message validation may return NeedMoreData error, data must stay intact (no
  // draining) until the remaining data arrives and validator will run again. Validator therefore
  // starts at offset 5 (1 byte message type and 4 bytes of length). This is in contrast to
  // processing of the message, which assumes that message has been validated and starts at the
  // beginning of the message.
  Message::ValidationResult validationResult = msgParser->validate(data, 5, message_len_ - 4);

  if (validationResult == Message::ValidationNeedMoreData) {
    ENVOY_LOG(trace, "postgres_proxy: cannot parse message. Not enough bytes in the buffer.");
    return Decoder::Result::NeedMoreData;
  }

  if (validationResult == Message::ValidationFailed) {
    // Message does not conform to the expected format. Move to out-of-sync state.
    data.drain(data.length());
    state_ = State::OutOfSyncState;
    return Decoder::Result::ReadyForNext;
  }

  // Drain message code and length fields.
  // Processing the message assumes that message starts at the beginning of the buffer.
  data.drain(5);

  processMessageBody(data, msg_processor.direction_, message_len_ - 4, msg, msgParser);

  return Decoder::Result::ReadyForNext;
}
/*
  onDataIgnore method is called when the decoder does not inspect passing
  messages. This happens when the decoder detected encrypted packets or
  when the decoder could not validate passing messages and lost track of
  messages boundaries. In order not to interpret received values as message
  lengths and not to start buffering large amount of data, the decoder
  enters OutOfSync state and starts ignoring passing messages. Once the
  decoder enters OutOfSyncState it cannot leave that state.
*/
Decoder::Result DecoderImpl::onDataIgnore(Buffer::Instance& data, bool) {
  data.drain(data.length());
  return Decoder::Result::ReadyForNext;
}

// Method is called when C (CommandComplete) message has been
// decoded. It extracts the keyword from message's payload
// and updates stats associated with that keyword.
void DecoderImpl::decodeBackendStatements() {
  // The message_ contains the statement. Find space character
  // and the statement is the first word. If space cannot be found
  // try to find for the null terminator character (\0).
  std::size_t position = message_.find(' ');
  if (position == std::string::npos) {
    // If the null terminator character (\0) cannot be found then
    // take the whole message.
    position = message_.find('\0');
  }
  const std::string statement = message_.substr(0, position);

  auto it = BE_statements_.find(statement);
  if (it != BE_statements_.end()) {
    (*it).second(this);
  } else {
    callbacks_->incStatements(DecoderCallbacks::StatementType::Other);
    callbacks_->incTransactions();
    callbacks_->incTransactionsCommit();
  }
}

Decoder::Result DecoderImpl::onDataInNegotiating(Buffer::Instance& data, bool frontend) {
  if (frontend) {
    // No data from downstream is allowed when negotiating upstream SSL
    // with the server.
    data.drain(data.length());
    state_ = State::OutOfSyncState;
    return Decoder::Result::ReadyForNext;
  }

  // This should be reply from the server indicating if it accepted
  // request to use SSL. It is only one character long packet, where
  // 'S' means use SSL, 'N' means do not use.
  // See details in https://www.postgresql.org/docs/current/protocol-flow.html#PROTOCOL-FLOW-SSL

  // Indicate to the filter, the response and give the initial
  // packet temporarily buffered to be sent upstream.
  bool upstreamSSL = false;
  state_ = State::InitState;
  if (data.length() == 1) {
    const char c = data.peekInt<char, ByteOrder::Host, 1>(0);
    if (c == 'S') {
      upstreamSSL = true;
    } else {
      if (c != 'N') {
        state_ = State::OutOfSyncState;
      }
    }
  } else {
    state_ = State::OutOfSyncState;
  }

  data.drain(data.length());

  if (callbacks_->encryptUpstream(upstreamSSL, temp_storage_)) {
    state_ = State::InSyncState;
  }

  return Decoder::Result::Stopped;
}

// Method is called when X (Terminate) message
// is encountered by the decoder.
void DecoderImpl::decodeFrontendTerminate() {
  if (session_.inTransaction()) {
    session_.setInTransaction(false);
    callbacks_->incTransactionsRollback();
  }
}

// Method does deep inspection of Authentication message.
// It looks for 4 bytes of zeros, which means that login to
// database was successful.
void DecoderImpl::decodeAuthentication() {
  // Check if auth message indicates successful authentication.
  // Length must be 8 and payload must be 0.
  if ((8 == message_len_) && (0 == message_.data()[0]) && (0 == message_.data()[1]) &&
      (0 == message_.data()[2]) && (0 == message_.data()[3])) {
    incSessionsUnencrypted();
  }
}

// Method is used to parse Error and Notice messages. Their syntax is the same, but they
// use different keywords inside the message and statistics fields are different.
void DecoderImpl::decodeErrorNotice(MsgParserDict& types) {
  // Error/Notice message should start with character "S".
  if (message_[0] != 'S') {
    types.unknown_(this);
    return;
  }

  for (const auto& it : types.keywords_) {
    // Try to find a keyword with S prefix or V prefix.
    // Postgres versions prior to 9.6 use only S prefix while
    // versions higher than 9.6 use S and V prefixes.
    if ((message_.find("S" + it.first) != std::string::npos) ||
        (message_.find("V" + it.first) != std::string::npos)) {
      it.second(this);
      return;
    }
  }

  // Keyword was not found in the message. Count is as Unknown.
  types.unknown_(this);
}

// Method parses E (Error) message and looks for string
// indicating that error happened.
void DecoderImpl::decodeBackendErrorResponse() { decodeErrorNotice(BE_errors_); }

// Method parses N (Notice) message and looks for string
// indicating its meaning. It can be warning, notice, info, debug or log.
void DecoderImpl::decodeBackendNoticeResponse() { decodeErrorNotice(BE_notices_); }

// Method parses Parse message of the following format:
// String: The name of the destination prepared statement (an empty string selects the unnamed
// prepared statement).
//
// String: The query string to be parsed.
//
// Int16: The number of parameter data
// types specified (can be zero). Note that this is not an indication of the number of parameters
// that might appear in the query string, only the number that the frontend wants to pre-specify
// types for. Then, for each parameter, there is the following:
//
// Int32: Specifies the object ID of
// the parameter data type. Placing a zero here is equivalent to leaving the type unspecified.
void DecoderImpl::onParse() {
  // The first two strings are separated by \0.
  // The first string is optional. If no \0 is found it means
  // that the message contains query string only.
  std::vector<std::string> query_parts = absl::StrSplit(message_, absl::ByChar('\0'));
  callbacks_->processQuery(query_parts[1]);
}

void DecoderImpl::onQuery() { callbacks_->processQuery(message_); }

// Method is invoked on clear-text Startup message.
// The message format is continuous string of the following format:
// user<username>database<database-name>application_name<application>encoding<encoding-type>
void DecoderImpl::onStartup() {
  // First 4 bytes of startup message contains version code.
  // It is skipped. After that message contains attributes.
  attributes_ = absl::StrSplit(message_.substr(4), absl::ByChar('\0'), absl::SkipEmpty());

  // If "database" attribute is not found, default it to "user" attribute.
  if ((attributes_.find("database") == attributes_.end()) &&
      (attributes_.find("user") != attributes_.end())) {
    attributes_["database"] = attributes_["user"];
  }
}

// Method generates displayable format of currently processed message.
const std::string DecoderImpl::genDebugMessage(const std::unique_ptr<Message>& parser,
                                               Buffer::Instance& data, uint32_t message_len) {
  parser->read(data, message_len);
  return parser->toString();
}

} // namespace PostgresProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/postgres_proxy/filters/network/source/config.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace PostgresProxy {

/**
 * Config registration for the Postgres proxy filter. @see NamedNetworkFilterConfigFactory.
 */
Network::FilterFactoryCb
NetworkFilters::PostgresProxy::PostgresConfigFactory::createFilterFactoryFromProtoTyped(
    const envoy::extensions::filters::network::postgres_proxy::v3alpha::PostgresProxy& proto_config,
    Server::Configuration::FactoryContext& context) {
  ASSERT(!proto_config.stat_prefix().empty());

  PostgresFilterConfig::PostgresFilterConfigOptions config_options;
  config_options.stats_prefix_ = fmt::format("postgres.{}", proto_config.stat_prefix());
  config_options.enable_sql_parsing_ =
      PROTOBUF_GET_WRAPPED_OR_DEFAULT(proto_config, enable_sql_parsing, true);
  config_options.terminate_ssl_ = proto_config.terminate_ssl();
  config_options.upstream_ssl_ = proto_config.upstream_ssl();

  PostgresFilterConfigSharedPtr filter_config(
      std::make_shared<PostgresFilterConfig>(config_options, context.scope()));
  return [filter_config](Network::FilterManager& filter_manager) -> void {
    filter_manager.addFilter(std::make_shared<PostgresFilter>(filter_config));
  };
}

/**
 * Static registration for the Postgres proxy filter. @see RegisterFactory.
 */
REGISTER_FACTORY(PostgresConfigFactory, Server::Configuration::NamedNetworkFilterConfigFactory);

} // namespace PostgresProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/generic_proxy/filters/network/test/mocks/codec.h"

#include <memory>

using testing::ByMove;
using testing::NiceMock;
using testing::Return;

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

MockCodecFactory::MockCodecFactory() {
  ON_CALL(*this, createServerCodec())
      .WillByDefault(Return(ByMove(std::make_unique<NiceMock<MockServerCodec>>())));
  ON_CALL(*this, createClientCodec())
      .WillByDefault(Return(ByMove(std::make_unique<NiceMock<MockClientCodec>>())));
}

MockProxyFactory::MockProxyFactory() = default;

MockStreamCodecFactoryConfig::MockStreamCodecFactoryConfig() = default;

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include "source/common/config/metadata.h"

#include "contrib/generic_proxy/filters/network/source/interface/route.h"
#include "gmock/gmock.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

class MockRouteEntry : public RouteEntry {
public:
  MockRouteEntry();

  MOCK_METHOD(const std::string&, clusterName, (), (const));
  MOCK_METHOD(const RouteSpecificFilterConfig*, perFilterConfig, (absl::string_view), (const));
  MOCK_METHOD(const envoy::config::core::v3::Metadata&, metadata, (), (const));
  MOCK_METHOD(const Envoy::Config::TypedMetadata&, typedMetadata, (), (const));
  MOCK_METHOD(absl::string_view, name, (), (const));

  std::string cluster_name_{"fake_cluster_name"};

  envoy::config::core::v3::Metadata metadata_;
};

class MockRouteMatcher : public RouteMatcher {
public:
  MockRouteMatcher();

  MOCK_METHOD(RouteEntryConstSharedPtr, routeEntry, (const Request& request), (const));

  std::shared_ptr<const testing::NiceMock<MockRouteEntry>> route_entry_{
      std::make_shared<testing::NiceMock<MockRouteEntry>>()};
};

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/generic_proxy/filters/network/test/mocks/filter.h"

#include <cstdint>

#include "source/common/protobuf/protobuf.h"

using testing::_;
using testing::Invoke;
using testing::Return;

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

MockStreamFrameHandler::MockStreamFrameHandler() = default;

MockStreamFilterConfig::MockStreamFilterConfig() {
  ON_CALL(*this, createEmptyConfigProto()).WillByDefault(Invoke([]() {
    return std::make_unique<ProtobufWkt::Struct>();
  }));
  ON_CALL(*this, createFilterFactoryFromProto(_, _, _))
      .WillByDefault(Return([](FilterChainFactoryCallbacks&) {}));
  ON_CALL(*this, name()).WillByDefault(Return("envoy.filters.generic.mock_filter"));
  ON_CALL(*this, configTypes()).WillByDefault(Invoke([this]() {
    return NamedFilterConfigFactory::configTypes();
  }));
}

MockFilterChainManager::MockFilterChainManager() {
  ON_CALL(*this, applyFilterFactoryCb(_, _))
      .WillByDefault(Invoke([this](FilterContext context, FilterFactoryCb& factory) {
        contexts_.push_back(context);
        factory(callbacks_);
      }));
}

MockDecoderFilter::MockDecoderFilter() {
  ON_CALL(*this, onStreamDecoded(_)).WillByDefault(Return(FilterStatus::Continue));
}

MockEncoderFilter::MockEncoderFilter() {
  ON_CALL(*this, onStreamEncoded(_)).WillByDefault(Return(FilterStatus::Continue));
}

MockStreamFilter::MockStreamFilter() {
  ON_CALL(*this, onStreamEncoded(_)).WillByDefault(Return(FilterStatus::Continue));
  ON_CALL(*this, onStreamDecoded(_)).WillByDefault(Return(FilterStatus::Continue));
}

MockDecoderFilterCallback::MockDecoderFilterCallback() = default;

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include "contrib/generic_proxy/filters/network/source/interface/codec.h"
#include "gmock/gmock.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

class MockServerCodecCallbacks : public ServerCodecCallbacks {
public:
  MOCK_METHOD(void, onDecodingSuccess, (StreamFramePtr request));
  MOCK_METHOD(void, onDecodingFailure, ());
  MOCK_METHOD(void, writeToConnection, (Buffer::Instance & buffer));
  MOCK_METHOD(OptRef<Network::Connection>, connection, ());
};

class MockClientCodecCallbacks : public ClientCodecCallbacks {
public:
  MOCK_METHOD(void, onDecodingSuccess, (StreamFramePtr response));
  MOCK_METHOD(void, onDecodingFailure, ());
  MOCK_METHOD(void, writeToConnection, (Buffer::Instance & buffer));
  MOCK_METHOD(OptRef<Network::Connection>, connection, ());
};

class MockEncodingCallbacks : public EncodingCallbacks {
public:
  MOCK_METHOD(void, onEncodingSuccess, (Buffer::Instance & buffer, bool end_stream));
};

class MockServerCodec : public ServerCodec {
public:
  MOCK_METHOD(void, setCodecCallbacks, (ServerCodecCallbacks & callbacks));
  MOCK_METHOD(void, decode, (Buffer::Instance & buffer, bool end_stream));
  MOCK_METHOD(void, encode, (const StreamFrame&, EncodingCallbacks& callbacks));
  MOCK_METHOD(ResponsePtr, respond, (Status status, absl::string_view, const Request&));
};

class MockClientCodec : public ClientCodec {
public:
  MOCK_METHOD(void, setCodecCallbacks, (ClientCodecCallbacks & callbacks));
  MOCK_METHOD(void, decode, (Buffer::Instance & buffer, bool end_stream));
  MOCK_METHOD(void, encode, (const StreamFrame&, EncodingCallbacks& callbacks));
};

class MockCodecFactory : public CodecFactory {
public:
  MockCodecFactory();

  MOCK_METHOD(ServerCodecPtr, createServerCodec, (), (const));
  MOCK_METHOD(ClientCodecPtr, createClientCodec, (), (const));
};

class MockProxyFactory : public ProxyFactory {
public:
  MockProxyFactory();

  MOCK_METHOD(void, createProxy, (Network::FilterManager&, const FilterConfigSharedPtr&), (const));
};

class MockStreamCodecFactoryConfig : public CodecFactoryConfig {
public:
  MockStreamCodecFactoryConfig();

  MOCK_METHOD(CodecFactoryPtr, createCodecFactory,
              (const Protobuf::Message&, Envoy::Server::Configuration::FactoryContext&));
  MOCK_METHOD(ProxyFactoryPtr, createProxyFactory,
              (const Protobuf::Message&, Envoy::Server::Configuration::FactoryContext&));

  ProtobufTypes::MessagePtr createEmptyConfigProto() override {
    return std::make_unique<ProtobufWkt::Struct>();
  }
  std::set<std::string> configTypes() override { return {"envoy.generic_proxy.codecs.mock.type"}; }
  std::string name() const override { return "envoy.generic_proxy.codecs.mock"; }
};

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/generic_proxy/filters/network/test/mocks/route.h"

using testing::_;
using testing::Return;
using testing::ReturnRef;

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

MockRouteEntry::MockRouteEntry() {
  ON_CALL(*this, clusterName()).WillByDefault(ReturnRef(cluster_name_));
  ON_CALL(*this, metadata()).WillByDefault(ReturnRef(metadata_));
}

MockRouteMatcher::MockRouteMatcher() {
  ON_CALL(*this, routeEntry(_)).WillByDefault(Return(route_entry_));
}

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
load(
    "//bazel:envoy_build_system.bzl",
    "envoy_cc_mock",
    "envoy_contrib_package",
)

licenses(["notice"])  # Apache 2

envoy_contrib_package()

envoy_cc_mock(
    name = "filter_mocks",
    srcs = ["filter.cc"],
    hdrs = ["filter.h"],
    deps = [
        "//contrib/generic_proxy/filters/network/source/interface:config_interface",
        "//contrib/generic_proxy/filters/network/source/interface:filter_interface",
        "//source/common/protobuf",
        "//test/mocks/network:network_mocks",
        "//test/mocks/tcp:tcp_mocks",
        "//test/mocks/upstream:host_mocks",
    ],
)

envoy_cc_mock(
    name = "route_mocks",
    srcs = ["route.cc"],
    hdrs = ["route.h"],
    deps = [
        "//contrib/generic_proxy/filters/network/source/interface:route_interface",
        "//source/common/config:metadata_lib",
    ],
)

envoy_cc_mock(
    name = "codec_mocks",
    srcs = ["codec.cc"],
    hdrs = ["codec.h"],
    deps = [
        "//contrib/generic_proxy/filters/network/source/interface:codec_interface",
    ],
)
#pragma once

#include "test/mocks/tcp/mocks.h"
#include "test/mocks/upstream/host.h"

#include "contrib/generic_proxy/filters/network/source/interface/config.h"
#include "contrib/generic_proxy/filters/network/source/interface/filter.h"
#include "gmock/gmock.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

class MockStreamFrameHandler : public StreamFrameHandler {
public:
  MockStreamFrameHandler();

  MOCK_METHOD(void, onStreamFrame, (StreamFramePtr frame));
};

class MockDecoderFilter : public DecoderFilter {
public:
  MockDecoderFilter();

  MOCK_METHOD(void, onDestroy, ());

  MOCK_METHOD(void, setDecoderFilterCallbacks, (DecoderFilterCallback & callbacks));
  MOCK_METHOD(FilterStatus, onStreamDecoded, (Request & request));
};

class MockEncoderFilter : public EncoderFilter {
public:
  MockEncoderFilter();

  MOCK_METHOD(void, onDestroy, ());

  MOCK_METHOD(void, setEncoderFilterCallbacks, (EncoderFilterCallback & callbacks));
  MOCK_METHOD(FilterStatus, onStreamEncoded, (Response & response));
};

class MockStreamFilter : public StreamFilter {
public:
  MockStreamFilter();

  MOCK_METHOD(void, onDestroy, ());

  MOCK_METHOD(void, setEncoderFilterCallbacks, (EncoderFilterCallback & callbacks));
  MOCK_METHOD(FilterStatus, onStreamEncoded, (Response & response));

  MOCK_METHOD(void, setDecoderFilterCallbacks, (DecoderFilterCallback & callbacks));
  MOCK_METHOD(FilterStatus, onStreamDecoded, (Request & request));
};

class MockStreamFilterConfig : public NamedFilterConfigFactory {
public:
  MockStreamFilterConfig();

  MOCK_METHOD(FilterFactoryCb, createFilterFactoryFromProto,
              (const Protobuf::Message& config, const std::string& stat_prefix,
               Server::Configuration::FactoryContext& context));
  MOCK_METHOD(ProtobufTypes::MessagePtr, createEmptyConfigProto, ());
  MOCK_METHOD(ProtobufTypes::MessagePtr, createEmptyRouteConfigProto, ());
  MOCK_METHOD(RouteSpecificFilterConfigConstSharedPtr, createRouteSpecificFilterConfig,
              (const Protobuf::Message&, Server::Configuration::ServerFactoryContext&,
               ProtobufMessage::ValidationVisitor&));
  MOCK_METHOD(std::string, name, (), (const));
  MOCK_METHOD(absl::Status, validateCodec, (const TypedExtensionConfig&));
  MOCK_METHOD(std::set<std::string>, configTypes, ());
  MOCK_METHOD(bool, isTerminalFilter, ());
};

class MockFilterChainFactoryCallbacks : public FilterChainFactoryCallbacks {
public:
  MockFilterChainFactoryCallbacks() = default;

  MOCK_METHOD(void, addDecoderFilter, (DecoderFilterSharedPtr filter));
  MOCK_METHOD(void, addEncoderFilter, (EncoderFilterSharedPtr filter));
  MOCK_METHOD(void, addFilter, (StreamFilterSharedPtr filter));
};

class MockFilterChainManager : public FilterChainManager {
public:
  MockFilterChainManager();

  MOCK_METHOD(void, applyFilterFactoryCb, (FilterContext context, FilterFactoryCb& factory));

  testing::NiceMock<MockFilterChainFactoryCallbacks> callbacks_;
  std::vector<FilterContext> contexts_;
};

template <class Base> class MockStreamFilterCallbacks : public Base {
public:
  MOCK_METHOD(Envoy::Event::Dispatcher&, dispatcher, ());
  MOCK_METHOD(const CodecFactory&, downstreamCodec, ());
  MOCK_METHOD(const RouteEntry*, routeEntry, (), (const));
  MOCK_METHOD(const RouteSpecificFilterConfig*, perFilterConfig, (), (const));
  MOCK_METHOD(const StreamInfo::StreamInfo&, streamInfo, (), (const));
  MOCK_METHOD(StreamInfo::StreamInfo&, streamInfo, ());
  MOCK_METHOD(Tracing::Span&, activeSpan, ());
  MOCK_METHOD(OptRef<const Tracing::Config>, tracingConfig, (), (const));
  MOCK_METHOD(const Network::Connection*, connection, (), (const));
};

class MockDecoderFilterCallback : public MockStreamFilterCallbacks<DecoderFilterCallback> {
public:
  MockDecoderFilterCallback();

  MOCK_METHOD(void, sendLocalReply, (Status, absl::string_view, ResponseUpdateFunction));
  MOCK_METHOD(void, continueDecoding, ());
  MOCK_METHOD(void, onResponseStart, (StreamResponsePtr response));
  MOCK_METHOD(void, onResponseFrame, (StreamFramePtr frame));
  MOCK_METHOD(void, setRequestFramesHandler, (StreamFrameHandler & handler));
  MOCK_METHOD(void, completeDirectly, ());
};

class MockEncoderFilterCallback : public MockStreamFilterCallbacks<EncoderFilterCallback> {
public:
  MOCK_METHOD(void, continueEncoding, ());
};

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include <cstdint>
#include <memory>

#include "test/mocks/server/factory_context.h"

#include "contrib/generic_proxy/filters/network/source/codecs/kafka/config.h"
#include "contrib/generic_proxy/filters/network/test/mocks/codec.h"
#include "contrib/kafka/filters/network/source/external/requests.h"
#include "contrib/kafka/filters/network/source/external/responses.h"
#include "gtest/gtest.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {
namespace Codec {
namespace Kafka {
namespace {

using testing::NiceMock;

TEST(KafkaCodecTest, SimpleFrameTest) {

  {
    auto request =
        std::make_shared<NetworkFilters::Kafka::Request<NetworkFilters::Kafka::FetchRequest>>(
            NetworkFilters::Kafka::RequestHeader(NetworkFilters::Kafka::FETCH_REQUEST_API_KEY, 0, 3,
                                                 absl::nullopt),
            NetworkFilters::Kafka::FetchRequest({}, {}, {}, {}));

    KafkaRequestFrame frame(request);
    EXPECT_EQ(frame.frameFlags().streamFlags().streamId(), 3);
  }

  {
    KafkaResponseFrame frame(nullptr);
    EXPECT_EQ(frame.protocol(), "kafka");
    EXPECT_EQ(frame.frameFlags().streamFlags().streamId(), 0);
  }

  {
    auto response =
        std::make_shared<NetworkFilters::Kafka::Response<NetworkFilters::Kafka::FetchResponse>>(
            NetworkFilters::Kafka::ResponseMetadata(NetworkFilters::Kafka::FETCH_REQUEST_API_KEY, 0,
                                                    3),
            NetworkFilters::Kafka::FetchResponse({}, {}));

    KafkaResponseFrame frame(response);
    EXPECT_EQ(frame.frameFlags().streamFlags().streamId(), 3);
  }
}

TEST(KafkaCodecTest, KafkaRequestCallbacksTest) {
  NiceMock<GenericProxy::MockServerCodecCallbacks> callbacks;

  KafkaRequestCallbacks request_callbacks(callbacks);

  {
    EXPECT_CALL(callbacks, onDecodingSuccess(_));

    auto request =
        std::make_shared<NetworkFilters::Kafka::Request<NetworkFilters::Kafka::FetchRequest>>(
            NetworkFilters::Kafka::RequestHeader(NetworkFilters::Kafka::FETCH_REQUEST_API_KEY, 0, 3,
                                                 absl::nullopt),
            NetworkFilters::Kafka::FetchRequest({}, {}, {}, {}));

    request_callbacks.onMessage(request);
  }

  {
    EXPECT_CALL(callbacks, onDecodingFailure());
    request_callbacks.onFailedParse(nullptr);
  }
}

TEST(KafkaCodecTest, KafkaResponseCallbacksTest) {
  NiceMock<GenericProxy::MockClientCodecCallbacks> callbacks;

  KafkaResponseCallbacks response_callbacks(callbacks);

  {
    EXPECT_CALL(callbacks, onDecodingSuccess(_));

    auto response =
        std::make_shared<NetworkFilters::Kafka::Response<NetworkFilters::Kafka::FetchResponse>>(
            NetworkFilters::Kafka::ResponseMetadata(NetworkFilters::Kafka::FETCH_REQUEST_API_KEY, 0,
                                                    3),
            NetworkFilters::Kafka::FetchResponse({}, {}));

    response_callbacks.onMessage(response);
  }

  {
    EXPECT_CALL(callbacks, onDecodingFailure());
    response_callbacks.onFailedParse(nullptr);
  }
}

TEST(KafkaCodecTest, KafkaServerCodecTest) {
  NiceMock<GenericProxy::MockServerCodecCallbacks> callbacks;

  KafkaServerCodec server_codec;
  server_codec.setCodecCallbacks(callbacks);

  {
    // Test respond() method.

    auto request =
        std::make_shared<NetworkFilters::Kafka::Request<NetworkFilters::Kafka::FetchRequest>>(
            NetworkFilters::Kafka::RequestHeader(NetworkFilters::Kafka::FETCH_REQUEST_API_KEY, 0, 3,
                                                 absl::nullopt),
            NetworkFilters::Kafka::FetchRequest({}, {}, {}, {}));

    KafkaRequestFrame frame(request);
    auto local_response = server_codec.respond(absl::OkStatus(), "", frame);

    EXPECT_NE(local_response, nullptr);
    EXPECT_EQ(dynamic_cast<KafkaResponseFrame*>(local_response.get())->response_, nullptr);
  }

  {
    // Test decode() method.
    EXPECT_CALL(callbacks, onDecodingSuccess(_))
        .WillOnce(testing::Invoke([](StreamFramePtr request) {
          EXPECT_EQ(dynamic_cast<KafkaRequestFrame*>(request.get())
                        ->request_->request_header_.correlation_id_,
                    3);
        }));

    auto request =
        std::make_shared<NetworkFilters::Kafka::Request<NetworkFilters::Kafka::FetchRequest>>(
            NetworkFilters::Kafka::RequestHeader(NetworkFilters::Kafka::FETCH_REQUEST_API_KEY, 0, 3,
                                                 absl::nullopt),
            NetworkFilters::Kafka::FetchRequest({}, {}, {}, {}));

    Buffer::OwnedImpl buffer;
    const uint32_t size = htobe32(request->computeSize());
    buffer.add(&size, sizeof(size)); // Encode data length.

    request->encode(buffer);
    server_codec.decode(buffer, false);
  }

  {
    // Test encode() method with non-response frame.

    NiceMock<GenericProxy::MockEncodingCallbacks> encoding_callbacks;

    auto request =
        std::make_shared<NetworkFilters::Kafka::Request<NetworkFilters::Kafka::FetchRequest>>(
            NetworkFilters::Kafka::RequestHeader(NetworkFilters::Kafka::FETCH_REQUEST_API_KEY, 0, 3,
                                                 absl::nullopt),
            NetworkFilters::Kafka::FetchRequest({}, {}, {}, {}));
    KafkaRequestFrame request_frame(request);

    // Do nothiing.
    server_codec.encode(request_frame, encoding_callbacks);
  }

  {
    // Test encode() method without actual response.

    NiceMock<GenericProxy::MockEncodingCallbacks> encoding_callbacks;
    NiceMock<Network::MockServerConnection> mock_connection;

    KafkaResponseFrame response_frame(nullptr);

    // Expect close connection.
    EXPECT_CALL(callbacks, connection())
        .WillOnce(testing::Return(makeOptRef<Network::Connection>(mock_connection)));
    EXPECT_CALL(mock_connection, close(Network::ConnectionCloseType::FlushWrite));

    server_codec.encode(response_frame, encoding_callbacks);
  }

  {
    // Test encode() method with response.

    NiceMock<GenericProxy::MockEncodingCallbacks> encoding_callbacks;

    auto response =
        std::make_shared<NetworkFilters::Kafka::Response<NetworkFilters::Kafka::FetchResponse>>(
            NetworkFilters::Kafka::ResponseMetadata(NetworkFilters::Kafka::FETCH_REQUEST_API_KEY, 0,
                                                    3),
            NetworkFilters::Kafka::FetchResponse({}, {}));

    KafkaResponseFrame response_frame(response);

    Envoy::Buffer::OwnedImpl dst_buffer;
    const uint32_t size = htobe32(response->computeSize());
    dst_buffer.add(&size, sizeof(size)); // Encode data length.
    response->encode(dst_buffer);

    EXPECT_CALL(encoding_callbacks, onEncodingSuccess(_, true))
        .WillOnce(testing::Invoke([&](Buffer::Instance& buffer, bool) {
          EXPECT_EQ(buffer.toString(), dst_buffer.toString());
        }));
    server_codec.encode(response_frame, encoding_callbacks);
  }
}

TEST(KafkaCodecTest, KafkaClientCodecTest) {
  NiceMock<GenericProxy::MockClientCodecCallbacks> callbacks;

  KafkaClientCodec client_codec;
  client_codec.setCodecCallbacks(callbacks);

  {
    // Test decode() method.
    EXPECT_CALL(callbacks, onDecodingSuccess(_))
        .WillOnce(testing::Invoke([](StreamFramePtr response) {
          EXPECT_EQ(dynamic_cast<KafkaResponseFrame*>(response.get())
                        ->response_->metadata_.correlation_id_,
                    3);
        }));

    auto response =
        std::make_shared<NetworkFilters::Kafka::Response<NetworkFilters::Kafka::FetchResponse>>(
            NetworkFilters::Kafka::ResponseMetadata(NetworkFilters::Kafka::FETCH_REQUEST_API_KEY, 0,
                                                    3),
            NetworkFilters::Kafka::FetchResponse({}, {}));

    Buffer::OwnedImpl buffer;
    const uint32_t size = htobe32(response->computeSize());
    buffer.add(&size, sizeof(size)); // Encode data length.

    response->encode(buffer);

    client_codec.response_decoder_->expectResponse(3, 0, 0);
    client_codec.decode(buffer, false);
  }

  {
    // Test encode() method with non-request frame.

    NiceMock<GenericProxy::MockEncodingCallbacks> encoding_callbacks;

    auto response =
        std::make_shared<NetworkFilters::Kafka::Response<NetworkFilters::Kafka::FetchResponse>>(
            NetworkFilters::Kafka::ResponseMetadata(NetworkFilters::Kafka::FETCH_REQUEST_API_KEY, 0,
                                                    3),
            NetworkFilters::Kafka::FetchResponse({}, {}));
    KafkaResponseFrame response_frame(response);

    // Do nothiing.
    client_codec.encode(response_frame, encoding_callbacks);
  }

  {
    // Test encode() method with request.

    NiceMock<GenericProxy::MockEncodingCallbacks> encoding_callbacks;

    auto request =
        std::make_shared<NetworkFilters::Kafka::Request<NetworkFilters::Kafka::FetchRequest>>(
            NetworkFilters::Kafka::RequestHeader(NetworkFilters::Kafka::FETCH_REQUEST_API_KEY, 0, 3,
                                                 absl::nullopt),
            NetworkFilters::Kafka::FetchRequest({}, {}, {}, {}));

    KafkaRequestFrame request_frame(request);

    Envoy::Buffer::OwnedImpl dst_buffer;
    const uint32_t size = htobe32(request->computeSize());
    dst_buffer.add(&size, sizeof(size)); // Encode data length.
    request->encode(dst_buffer);

    EXPECT_CALL(encoding_callbacks, onEncodingSuccess(_, true))
        .WillOnce(testing::Invoke([&](Buffer::Instance& buffer, bool) {
          EXPECT_EQ(buffer.toString(), dst_buffer.toString());
        }));

    client_codec.encode(request_frame, encoding_callbacks);
  }
}

} // namespace
} // namespace Kafka
} // namespace Codec
} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
load(
    "//bazel:envoy_build_system.bzl",
    "envoy_cc_test",
    "envoy_contrib_package",
)

licenses(["notice"])  # Apache 2

envoy_contrib_package()

envoy_cc_test(
    name = "config_test",
    srcs = [
        "config_test.cc",
    ],
    deps = [
        "//contrib/generic_proxy/filters/network/source/codecs/kafka:config",
        "//contrib/generic_proxy/filters/network/test/mocks:codec_mocks",
        "//test/mocks/server:factory_context_mocks",
    ],
)
#include <cstdint>
#include <memory>

#include "source/extensions/common/dubbo/message_impl.h"

#include "test/extensions/common/dubbo/mocks.h"
#include "test/mocks/server/factory_context.h"

#include "contrib/generic_proxy/filters/network/source/codecs/dubbo/config.h"
#include "contrib/generic_proxy/filters/network/test/mocks/codec.h"
#include "gtest/gtest.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {
namespace Codec {
namespace Dubbo {
namespace {

using testing::_;
using testing::ByMove;
using testing::Return;

using namespace Common::Dubbo;

MessageMetadataSharedPtr createDubboRequst(bool one_way_request) {
  auto request = std::make_unique<RpcRequestImpl>();
  request->setServiceName("fake_service");
  request->setMethodName("fake_method");
  request->setServiceVersion("fake_version");
  request->setParametersLazyCallback([]() -> RpcRequestImpl::ParametersPtr {
    return std::make_unique<RpcRequestImpl::Parameters>();
  });
  request->setAttachmentLazyCallback([]() -> RpcRequestImpl::AttachmentPtr {
    auto map = std::make_unique<RpcRequestImpl::Attachment::Map>();
    Hessian2::ObjectPtr key_o = std::make_unique<Hessian2::StringObject>("group");
    Hessian2::ObjectPtr val_o = std::make_unique<Hessian2::StringObject>("fake_group");

    map->toMutableUntypedMap().value().get().emplace(std::move(key_o), std::move(val_o));
    return std::make_unique<RpcRequestImpl::Attachment>(std::move(map), 0);
  });

  auto context = std::make_unique<Context>();
  context->setMessageType(one_way_request ? MessageType::Oneway : MessageType::Request);
  context->setRequestId(123456);
  context->setSerializeType(SerializeType::Hessian2);

  auto metadata = std::make_shared<MessageMetadata>();
  metadata->setContext(std::move(context));
  metadata->setRequest(std::move(request));
  return metadata;
}

MessageMetadataSharedPtr createDubboResponse(DubboRequest& request, ResponseStatus status,
                                             absl::optional<RpcResponseType> type) {
  return DirectResponseUtil::localResponse(*request.inner_metadata_, status, type, "anything");
}

TEST(DubboRequestTest, DubboRequestTest) {
  DubboRequest request(createDubboRequst(false));

  // Static atrributes test.
  { EXPECT_EQ("dubbo", request.protocol()); }

  // Basic atrributes test.
  {
    EXPECT_EQ("fake_service", request.host());
    EXPECT_EQ("fake_service", request.path());
    EXPECT_EQ("fake_method", request.method());
    EXPECT_EQ("fake_version", request.get("version").value());
  }

  // Get and set headers.
  {
    EXPECT_EQ("fake_group", request.get("group").value());

    EXPECT_EQ(false, request.get("custom_key").has_value());

    request.set("custom_key", "custom_value");
    EXPECT_EQ("custom_value", request.get("custom_key").value());
  }

  // Iterate headers.
  {
    size_t attachment_size = 0;
    request.forEach([&attachment_size](absl::string_view, absl::string_view) {
      attachment_size++;
      return true;
    });
    // Version is not part of attachments. So there are only 2 attachments.
    EXPECT_EQ(2, attachment_size);
  }
}

TEST(DubboResponseTest, DubboResponseTest) {
  DubboRequest request(createDubboRequst(false));

  // Static atrributes test.
  {
    DubboResponse response(
        createDubboResponse(request, ResponseStatus::Ok, RpcResponseType::ResponseWithValue));
    EXPECT_EQ("dubbo", response.protocol());
  }

  // Response status check.
  {
    DubboResponse response(
        createDubboResponse(request, ResponseStatus::Ok, RpcResponseType::ResponseWithValue));
    EXPECT_EQ(20, response.status().code());
  }
  {
    DubboResponse response(
        createDubboResponse(request, ResponseStatus::Ok, RpcResponseType::ResponseWithException));
    EXPECT_EQ(20, response.status().code());
  }
  {
    DubboResponse response(createDubboResponse(
        request, ResponseStatus::Ok, RpcResponseType::ResponseWithExceptionWithAttachments));
    EXPECT_EQ(20, response.status().code());
  }
  {
    DubboResponse response(
        createDubboResponse(request, ResponseStatus::ClientTimeout, absl::nullopt));
    EXPECT_EQ(30, response.status().code());
  }
  {
    DubboResponse response(
        createDubboResponse(request, ResponseStatus::ServerTimeout, absl::nullopt));
    EXPECT_EQ(31, response.status().code());
  }
  {
    DubboResponse response(createDubboResponse(request, ResponseStatus::BadRequest, absl::nullopt));
    EXPECT_EQ(40, response.status().code());
  }
  {
    DubboResponse response(
        createDubboResponse(request, ResponseStatus::BadResponse, absl::nullopt));
    EXPECT_EQ(50, response.status().code());
  }
  {
    DubboResponse response(
        createDubboResponse(request, ResponseStatus::ServiceNotFound, absl::nullopt));
    EXPECT_EQ(60, response.status().code());
  }
  {
    DubboResponse response(
        createDubboResponse(request, ResponseStatus::ServiceError, absl::nullopt));
    EXPECT_EQ(70, response.status().code());
  }
  {
    DubboResponse response(
        createDubboResponse(request, ResponseStatus::ServerError, absl::nullopt));
    EXPECT_EQ(80, response.status().code());
  }
  {
    DubboResponse response(
        createDubboResponse(request, ResponseStatus::ClientError, absl::nullopt));
    EXPECT_EQ(90, response.status().code());
  }
  {
    DubboResponse response(createDubboResponse(
        request, ResponseStatus::ServerThreadpoolExhaustedError, absl::nullopt));
    EXPECT_EQ(100, response.status().code());
  }

  // Getter and setter do nothing for response.
  {
    DubboResponse response(
        createDubboResponse(request, ResponseStatus::Ok, RpcResponseType::ResponseWithValue));

    EXPECT_EQ(false, response.get("custom_key").has_value());
    response.set("custom_key", "custom_value");
    EXPECT_EQ(false, response.get("custom_key").has_value());
  }

  // Iterate headers.
  {
    DubboResponse response(
        createDubboResponse(request, ResponseStatus::Ok, RpcResponseType::ResponseWithValue));

    size_t attachment_size = 0;
    response.forEach([&attachment_size](absl::string_view, absl::string_view) {
      attachment_size++;
      return true;
    });
    EXPECT_EQ(0, attachment_size);
  }
}

TEST(DubboServerCodecTest, DubboServerCodecTest) {
  auto codec = std::make_unique<DubboCodec>();
  codec->initilize(std::make_unique<MockSerializer>());

  MockServerCodecCallbacks callbacks;
  DubboServerCodec server_codec(std::move(codec));
  server_codec.setCodecCallbacks(callbacks);

  auto raw_serializer = const_cast<MockSerializer*>(
      dynamic_cast<const MockSerializer*>(server_codec.codec_->serializer().get()));

  // Decode failure.
  {
    server_codec.metadata_.reset();
    Buffer::OwnedImpl buffer;
    buffer.writeBEInt<int64_t>(0);
    buffer.writeBEInt<int64_t>(0);

    EXPECT_CALL(callbacks, onDecodingFailure());
    server_codec.decode(buffer, false);
  }

  // Waiting for header.
  {
    server_codec.metadata_.reset();

    Buffer::OwnedImpl buffer;
    buffer.add(std::string({'\xda', '\xbb', '\xc2', 0x00}));

    // No enough header bytes and do nothing.
    server_codec.decode(buffer, false);
  }

  // Waiting for data.
  {
    server_codec.metadata_.reset();

    Buffer::OwnedImpl buffer;
    buffer.add(std::string({'\xda', '\xbb', '\xc2', 0x00}));
    buffer.writeBEInt<int64_t>(1);
    buffer.writeBEInt<int32_t>(8);

    // No enough body bytes and do nothing.
    server_codec.decode(buffer, false);
  }

  // Decode request.
  {
    server_codec.metadata_.reset();

    Buffer::OwnedImpl buffer;
    buffer.add(std::string({'\xda', '\xbb', '\xc2', 0x00}));
    buffer.writeBEInt<int64_t>(1);
    buffer.writeBEInt<int32_t>(8);
    buffer.add("anything");

    EXPECT_CALL(*raw_serializer, deserializeRpcRequest(_, _))
        .WillOnce(Return(ByMove(std::make_unique<RpcRequestImpl>())));

    EXPECT_CALL(callbacks, onDecodingSuccess(_));
    server_codec.decode(buffer, false);
  }

  // Encode response.
  {

    MockEncodingCallbacks encoding_callbacks;
    DubboRequest request(createDubboRequst(false));
    DubboResponse response(
        createDubboResponse(request, ResponseStatus::Ok, RpcResponseType::ResponseWithValue));

    EXPECT_CALL(*raw_serializer, serializeRpcResponse(_, _));
    EXPECT_CALL(encoding_callbacks, onEncodingSuccess(_, _));

    server_codec.encode(response, encoding_callbacks);
  }

  {
    Status status = absl::OkStatus();
    DubboRequest request(createDubboRequst(false));

    auto response = server_codec.respond(status, "", request);
    auto* typed_response = static_cast<DubboResponse*>(response.get());
    auto* typed_inner_response =
        static_cast<RpcResponseImpl*>(&typed_response->inner_metadata_->mutableResponse());

    EXPECT_EQ(ResponseStatus::Ok, typed_response->inner_metadata_->responseStatus());
    EXPECT_EQ(RpcResponseType::ResponseWithException, typed_inner_response->responseType().value());
    EXPECT_EQ("exception_via_proxy", typed_inner_response->localRawMessage().value());
  }

  {
    Status status(StatusCode::kInvalidArgument, "test_message");
    DubboRequest request(createDubboRequst(false));

    auto response = server_codec.respond(status, "", request);
    auto* typed_response = static_cast<DubboResponse*>(response.get());
    auto* typed_inner_response =
        static_cast<RpcResponseImpl*>(&typed_response->inner_metadata_->mutableResponse());

    EXPECT_EQ(ResponseStatus::BadRequest, typed_response->inner_metadata_->responseStatus());
    EXPECT_EQ(false, typed_inner_response->responseType().has_value());
    EXPECT_EQ("test_message", typed_inner_response->localRawMessage().value());
  }

  {
    Status status(StatusCode::kAborted, "test_message2");
    DubboRequest request(createDubboRequst(false));

    auto response = server_codec.respond(status, "", request);
    auto* typed_response = static_cast<DubboResponse*>(response.get());
    auto* typed_inner_response =
        static_cast<RpcResponseImpl*>(&typed_response->inner_metadata_->mutableResponse());

    EXPECT_EQ(ResponseStatus::ServerError, typed_response->inner_metadata_->responseStatus());
    EXPECT_EQ(false, typed_inner_response->responseType().has_value());
    EXPECT_EQ("test_message2", typed_inner_response->localRawMessage().value());
  }
}

TEST(DubboClientCodecTest, DubboClientCodecTest) {
  auto codec = std::make_unique<DubboCodec>();
  codec->initilize(std::make_unique<MockSerializer>());

  MockClientCodecCallbacks callbacks;
  DubboClientCodec client_codec(std::move(codec));
  client_codec.setCodecCallbacks(callbacks);

  auto raw_serializer = const_cast<MockSerializer*>(
      dynamic_cast<const MockSerializer*>(client_codec.codec_->serializer().get()));

  // Decode failure.
  {
    client_codec.metadata_.reset();

    Buffer::OwnedImpl buffer;
    buffer.writeBEInt<int64_t>(0);
    buffer.writeBEInt<int64_t>(0);

    EXPECT_CALL(callbacks, onDecodingFailure());
    client_codec.decode(buffer, false);
  }

  // Waiting for header.
  {
    client_codec.metadata_.reset();

    Buffer::OwnedImpl buffer;
    buffer.add(std::string({'\xda', '\xbb', '\x02', 20}));

    // No enough header bytes and do nothing.
    client_codec.decode(buffer, false);
  }

  // Waiting for data.
  {
    client_codec.metadata_.reset();

    Buffer::OwnedImpl buffer;
    buffer.add(std::string({'\xda', '\xbb', '\x02', 20}));
    buffer.writeBEInt<int64_t>(1);
    buffer.writeBEInt<int32_t>(8);

    // No enough body bytes and do nothing.
    client_codec.decode(buffer, false);
  }

  // Decode response.
  {
    client_codec.metadata_.reset();

    Buffer::OwnedImpl buffer;
    buffer.add(std::string({'\xda', '\xbb', '\x02', 20}));
    buffer.writeBEInt<int64_t>(1);
    buffer.writeBEInt<int32_t>(8);
    buffer.add("anything");

    auto response = std::make_unique<RpcResponseImpl>();
    response->setResponseType(RpcResponseType::ResponseWithValue);

    EXPECT_CALL(*raw_serializer, deserializeRpcResponse(_, _))
        .WillOnce(Return(ByMove(std::move(response))));

    EXPECT_CALL(callbacks, onDecodingSuccess(_));
    client_codec.decode(buffer, false);
  }

  // Encode normal request.
  {
    MockEncodingCallbacks encoding_callbacks;

    DubboRequest request(createDubboRequst(false));

    EXPECT_CALL(*raw_serializer, serializeRpcRequest(_, _));
    EXPECT_CALL(encoding_callbacks, onEncodingSuccess(_, _));

    client_codec.encode(request, encoding_callbacks);
  }

  // Encode one-way request.
  {
    MockEncodingCallbacks encoding_callbacks;

    DubboRequest request(createDubboRequst(true));

    EXPECT_CALL(*raw_serializer, serializeRpcRequest(_, _));
    EXPECT_CALL(encoding_callbacks, onEncodingSuccess(_, _));

    client_codec.encode(request, encoding_callbacks);
  }
}

TEST(DubboCodecFactoryTest, DubboCodecFactoryTest) {
  DubboCodecFactory factory;

  EXPECT_NE(nullptr, factory.createClientCodec().get());
  EXPECT_NE(nullptr, factory.createServerCodec().get());
}

TEST(DubboCodecFactoryConfigTest, DubboCodecFactoryConfigTest) {
  DubboCodecFactoryConfig config;
  EXPECT_EQ("envoy.generic_proxy.codecs.dubbo", config.name());
  auto proto_config = config.createEmptyConfigProto();

  Server::Configuration::MockFactoryContext context;

  EXPECT_NE(nullptr, config.createCodecFactory(*proto_config, context));
}

} // namespace
} // namespace Dubbo
} // namespace Codec
} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
load(
    "//bazel:envoy_build_system.bzl",
    "envoy_cc_test",
    "envoy_contrib_package",
)

licenses(["notice"])  # Apache 2

envoy_contrib_package()

envoy_cc_test(
    name = "config_test",
    srcs = [
        "config_test.cc",
    ],
    deps = [
        "//contrib/generic_proxy/filters/network/source/codecs/dubbo:config",
        "//contrib/generic_proxy/filters/network/test/mocks:codec_mocks",
        "//test/extensions/common/dubbo:mocks_lib",
        "//test/mocks/server:factory_context_mocks",
    ],
)
#pragma once

#include <cstdint>

#include "source/common/buffer/buffer_impl.h"

#include "contrib/generic_proxy/filters/network/source/interface/codec.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

template <typename InterfaceType> class FakeStreamBase : public InterfaceType {
public:
  void forEach(StreamBase::IterateCallback callback) const override {
    for (const auto& pair : data_) {
      callback(pair.first, pair.second);
    }
  }
  absl::optional<absl::string_view> get(absl::string_view key) const override {
    auto iter = data_.find(key);
    if (iter == data_.end()) {
      return absl::nullopt;
    }
    return absl::make_optional<absl::string_view>(iter->second);
  }
  void set(absl::string_view key, absl::string_view val) override { data_[key] = std::string(val); }
  void erase(absl::string_view key) override { data_.erase(key); }

  // StreamFrame
  FrameFlags frameFlags() const override { return stream_frame_flags_; }

  FrameFlags stream_frame_flags_;

  absl::flat_hash_map<std::string, std::string> data_;
};

/**
 * Fake stream codec factory for test. A simple plain protocol is created for this fake
 * factory. The message format of this protocol is shown below.
 *
 * Fake request message format:
 *   <INT Message Size><Protocol>|<host>|<PATH>|<METHOD>|<key>:<value>;*
 * Fake response message format:
     <INT Message Size><INT Status><Protocol>|<Status Detail>|<key>:<value>;*
 */
class FakeStreamCodecFactory : public CodecFactory {
public:
  class FakeRequest : public FakeStreamBase<Request> {
  public:
    absl::string_view protocol() const override { return protocol_; }
    absl::string_view host() const override { return host_; }
    absl::string_view path() const override { return path_; }
    absl::string_view method() const override { return method_; }

    std::string protocol_;
    std::string host_;
    std::string path_;
    std::string method_;
  };

  class FakeResponse : public FakeStreamBase<Response> {
  public:
    absl::string_view protocol() const override { return protocol_; }
    StreamStatus status() const override { return status_; }

    std::string protocol_;
    StreamStatus status_;
    std::string message_;
  };

  class FakeServerCodec : public ServerCodec {
  public:
    bool parseRequestBody() {
      std::string body(message_size_.value(), 0);
      buffer_.copyOut(0, message_size_.value(), body.data());
      buffer_.drain(message_size_.value());
      message_size_.reset();

      std::vector<absl::string_view> result = absl::StrSplit(body, '|');
      if (result.size() != 5) {
        callback_->onDecodingFailure();
        return false;
      }

      auto request = std::make_unique<FakeRequest>();
      request->protocol_ = std::string(result[0]);
      request->host_ = std::string(result[1]);
      request->path_ = std::string(result[2]);
      request->method_ = std::string(result[3]);
      for (absl::string_view pair_str : absl::StrSplit(result[4], ';', absl::SkipEmpty())) {
        auto pair = absl::StrSplit(pair_str, absl::MaxSplits(':', 1));
        request->data_.emplace(pair);
      }
      absl::optional<uint64_t> stream_id;
      bool one_way_stream = false;
      if (auto it = request->data_.find("stream_id"); it != request->data_.end()) {
        stream_id = std::stoull(it->second);
      }
      if (auto it = request->data_.find("one_way"); it != request->data_.end()) {
        one_way_stream = it->second == "true";
      }

      // Mock multiple frames in one request.
      bool end_stream = true;
      if (auto it = request->data_.find("end_stream"); it != request->data_.end()) {
        end_stream = it->second == "true";
      }

      request->stream_frame_flags_ =
          FrameFlags(StreamFlags(stream_id.value_or(0), one_way_stream, false, false), end_stream);

      callback_->onDecodingSuccess(std::move(request));
      return true;
    }

    void setCodecCallbacks(ServerCodecCallbacks& callback) override { callback_ = &callback; }
    void decode(Buffer::Instance& buffer, bool) override {
      buffer_.move(buffer);
      while (true) {
        if (!message_size_.has_value()) {
          if (buffer_.length() < 4) {
            // Wait for more data.
            return;
          }
          // Parsing message size.
          message_size_ = buffer_.peekBEInt<uint32_t>();
          buffer_.drain(4);
        }

        if (buffer_.length() < message_size_.value()) {
          // Wait for more data.
          return;
        }
        // There is enough data to parse a request.
        if (!parseRequestBody()) {
          return;
        }
      }
    }

    void encode(const StreamFrame& response, EncodingCallbacks& callback) override {
      const FakeResponse* typed_response = dynamic_cast<const FakeResponse*>(&response);
      ASSERT(typed_response != nullptr);

      std::string body;
      body.reserve(512);
      body = typed_response->protocol_ + "|" + typed_response->message_ + "|";
      for (const auto& pair : typed_response->data_) {
        body += pair.first + ":" + pair.second + ";";
      }
      // Additional 4 bytes for status.
      encoding_buffer_.writeBEInt<uint32_t>(body.size() + 4);
      encoding_buffer_.writeBEInt<int>(typed_response->status_.code());
      encoding_buffer_.add(body);

      callback.onEncodingSuccess(encoding_buffer_, response.frameFlags().endStream());
    }

    ResponsePtr respond(Status status, absl::string_view, const Request&) override {
      auto response = std::make_unique<FakeResponse>();
      response->status_ = {status.raw_code(), status.ok()};
      response->message_ = status.message();
      response->protocol_ = "fake_protocol_for_test";
      return response;
    }

    absl::optional<uint32_t> message_size_;
    Buffer::OwnedImpl buffer_;
    Buffer::OwnedImpl encoding_buffer_;
    ServerCodecCallbacks* callback_{};
  };

  class FakeClientCodec : public ClientCodec {
  public:
    bool parseResponseBody() {
      int32_t status_code = buffer_.peekBEInt<int32_t>();
      buffer_.drain(4);
      message_size_ = message_size_.value() - 4;

      std::string body(message_size_.value(), 0);
      buffer_.copyOut(0, message_size_.value(), body.data());
      buffer_.drain(message_size_.value());
      message_size_.reset();

      std::vector<absl::string_view> result = absl::StrSplit(body, '|');
      if (result.size() != 3) {
        callback_->onDecodingFailure();
        return false;
      }

      auto response = std::make_unique<FakeResponse>();
      response->status_ = {status_code,
                           static_cast<absl::StatusCode>(status_code) == absl::StatusCode::kOk};
      response->protocol_ = std::string(result[0]);
      for (absl::string_view pair_str : absl::StrSplit(result[2], ';', absl::SkipEmpty())) {
        auto pair = absl::StrSplit(pair_str, absl::MaxSplits(':', 1));
        response->data_.emplace(pair);
      }

      absl::optional<uint64_t> stream_id;
      bool close_connection = false;
      if (auto it = response->data_.find("stream_id"); it != response->data_.end()) {
        stream_id = std::stoull(it->second);
      }
      if (auto it = response->data_.find("close_connection"); it != response->data_.end()) {
        close_connection = it->second == "true";
      }

      // Mock multiple frames in one response.
      bool end_stream = true;
      if (auto it = response->data_.find("end_stream"); it != response->data_.end()) {
        end_stream = it->second == "true";
      }

      response->stream_frame_flags_ = FrameFlags(
          StreamFlags(stream_id.value_or(0), false, close_connection, false), end_stream);

      callback_->onDecodingSuccess(std::move(response));
      return true;
    }

    void setCodecCallbacks(ClientCodecCallbacks& callback) override { callback_ = &callback; }
    void decode(Buffer::Instance& buffer, bool) override {
      buffer_.move(buffer);
      while (true) {
        if (!message_size_.has_value()) {
          if (buffer_.length() < 4) {
            // Wait for more data.
            return;
          }
          // Parsing message size.
          message_size_ = buffer_.peekBEInt<uint32_t>();
          buffer_.drain(4);

          if (message_size_.value() < 4) {
            callback_->onDecodingFailure();
            return;
          }
        }

        if (buffer_.length() < message_size_.value()) {
          // Wait for more data.
          return;
        }

        // There is enough data to parse a response.
        if (!parseResponseBody()) {
          return;
        }
      }
    }

    void encode(const StreamFrame& request, EncodingCallbacks& callback) override {
      const FakeRequest* typed_request = dynamic_cast<const FakeRequest*>(&request);
      ASSERT(typed_request != nullptr);

      std::string body;
      body.reserve(512);
      body = typed_request->protocol_ + "|" + typed_request->host_ + "|" + typed_request->path_ +
             "|" + typed_request->method_ + "|";
      for (const auto& pair : typed_request->data_) {
        body += pair.first + ":" + pair.second + ";";
      }
      encoding_buffer_.writeBEInt<uint32_t>(body.size());
      encoding_buffer_.add(body);

      callback.onEncodingSuccess(encoding_buffer_, request.frameFlags().endStream());
    }

    absl::optional<uint32_t> message_size_;
    Buffer::OwnedImpl buffer_;
    Buffer::OwnedImpl encoding_buffer_;
    ClientCodecCallbacks* callback_{};
  };

  ServerCodecPtr createServerCodec() const override;
  ClientCodecPtr createClientCodec() const override;
};

class FakeStreamCodecFactoryConfig : public CodecFactoryConfig {
public:
  // CodecFactoryConfig
  CodecFactoryPtr
  createCodecFactory(const Protobuf::Message& config,
                     Envoy::Server::Configuration::FactoryContext& context) override;
  ProtobufTypes::MessagePtr createEmptyConfigProto() override {
    return std::make_unique<ProtobufWkt::Struct>();
  }
  std::set<std::string> configTypes() override { return {"envoy.generic_proxy.codecs.fake.type"}; }
  std::string name() const override { return "envoy.generic_proxy.codecs.fake"; }
};

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include <chrono>
#include <cstdint>
#include <memory>
#include <string>
#include <utility>

#include "test/integration/base_integration_test.h"
#include "test/mocks/server/factory_context.h"
#include "test/test_common/registry.h"
#include "test/test_common/utility.h"

#include "contrib/generic_proxy/filters/network/source/proxy.h"
#include "contrib/generic_proxy/filters/network/test/fake_codec.h"
#include "contrib/generic_proxy/filters/network/test/mocks/codec.h"
#include "contrib/generic_proxy/filters/network/test/mocks/filter.h"
#include "contrib/generic_proxy/filters/network/test/mocks/route.h"
#include "gtest/gtest.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {
namespace {

class GenericProxyIntegrationTest : public BaseIntegrationTest {
public:
  GenericProxyIntegrationTest(const std::string config_yaml)
      : BaseIntegrationTest(Network::Address::IpVersion::v4, config_yaml) {
    skip_tag_extraction_rule_check_ = true;
  };
};

class IntegrationTest : public testing::TestWithParam<Network::Address::IpVersion> {
public:
  struct ConnectionCallbacks : public Network::ConnectionCallbacks {
    ConnectionCallbacks(IntegrationTest& parent) : parent_(parent) {}

    // Network::ConnectionCallbacks
    void onEvent(Network::ConnectionEvent event) override {
      if (event == Network::ConnectionEvent::Connected) {
        connection_connected_ = true;
      }
      parent_.integration_->dispatcher_->exit();
    }
    void onAboveWriteBufferHighWatermark() override {}
    void onBelowWriteBufferLowWatermark() override {}

    bool connection_connected_{};
    IntegrationTest& parent_;
  };
  using ConnectionCallbacksSharedPtr = std::shared_ptr<ConnectionCallbacks>;

  struct TestReadFilter : Network::ReadFilter {
    TestReadFilter(IntegrationTest& parent) : parent_(parent) {}

    // Network::ReadFilter
    Network::FilterStatus onData(Buffer::Instance& data, bool end_stream) override {
      parent_.client_codec_->decode(data, end_stream);
      return Network::FilterStatus::Continue;
    }
    Network::FilterStatus onNewConnection() override { return Network::FilterStatus::Continue; }
    void initializeReadFilterCallbacks(Network::ReadFilterCallbacks&) override {}

    IntegrationTest& parent_;
  };
  using TestReadFilterSharedPtr = std::shared_ptr<TestReadFilter>;

  struct TestRequestEncoderCallback : public EncodingCallbacks {
    void onEncodingSuccess(Buffer::Instance& buffer, bool) override { buffer_.move(buffer); }
    Buffer::OwnedImpl buffer_;
  };
  using TestRequestEncoderCallbackSharedPtr = std::shared_ptr<TestRequestEncoderCallback>;

  struct TestResponseEncoderCallback : public EncodingCallbacks {
    void onEncodingSuccess(Buffer::Instance& buffer, bool) override { buffer_.move(buffer); }
    Buffer::OwnedImpl buffer_;
  };
  using TestResponseEncoderCallbackSharedPtr = std::shared_ptr<TestResponseEncoderCallback>;

  struct TestResponseDecoderCallback : public ClientCodecCallbacks {
    TestResponseDecoderCallback(IntegrationTest& parent) : parent_(parent) {}

    struct SingleResponse {
      bool end_stream_{};
      ResponsePtr response_;
      std::list<StreamFramePtr> response_frames_;
    };

    void onDecodingSuccess(StreamFramePtr response_frame) override {
      auto& response = responses_[response_frame->frameFlags().streamFlags().streamId()];

      ASSERT(!response.end_stream_);
      response.end_stream_ = response_frame->frameFlags().endStream();

      if (response.response_ != nullptr) {
        response.response_frames_.push_back(std::move(response_frame));
      } else {
        ASSERT(response.response_frames_.empty());
        StreamFramePtrHelper<Response> helper(std::move(response_frame));
        ASSERT(helper.typed_frame_ != nullptr);
        response.response_ = std::move(helper.typed_frame_);
      }

      // Exit dispatcher if we have received all the expected response frames.
      if (responses_[waiting_for_stream_id_].end_stream_) {
        parent_.integration_->dispatcher_->exit();
      }
    }
    void onDecodingFailure() override {}
    void writeToConnection(Buffer::Instance&) override {}
    OptRef<Network::Connection> connection() override {
      if (parent_.upstream_connection_ != nullptr) {
        return parent_.upstream_connection_->connection();
      }
      return {};
    }

    uint64_t waiting_for_stream_id_{};
    std::map<uint64_t, SingleResponse> responses_;
    IntegrationTest& parent_;
  };
  using TestResponseDecoderCallbackSharedPtr = std::shared_ptr<TestResponseDecoderCallback>;

  void initialize(const std::string& config_yaml, CodecFactoryPtr codec_factory) {
    integration_ = std::make_unique<GenericProxyIntegrationTest>(config_yaml);
    integration_->initialize();

    // Create codec for downstream client to encode request and decode response.
    codec_factory_ = std::move(codec_factory);
    client_codec_ = codec_factory_->createClientCodec();

    request_encoder_callback_ = std::make_shared<TestRequestEncoderCallback>();
    response_decoder_callback_ = std::make_shared<TestResponseDecoderCallback>(*this);
    client_codec_->setCodecCallbacks(*response_decoder_callback_);

    // Helper codec for upstream server to encode response.
    server_codec_ = codec_factory_->createServerCodec();
    response_encoder_callback_ = std::make_shared<TestResponseEncoderCallback>();
  }

  std::string defaultConfig(bool bind_upstream_connection = false) {
    return absl::StrCat(ConfigHelper::baseConfig(false), fmt::format(R"EOF(
    filter_chains:
      filters:
        name: meta
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.v3.GenericProxy
          stat_prefix: config_test
          filters:
          - name: envoy.filters.generic.router
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.router.v3.Router
              bind_upstream_connection: {}
          codec_config:
            name: fake
            typed_config:
              "@type": type.googleapis.com/xds.type.v3.TypedStruct
              type_url: envoy.generic_proxy.codecs.fake.type
              value: {{}}
          route_config:
            name: test-routes
            virtual_hosts:
            - name: test
              hosts:
              - "*"
              routes:
                matcher_tree:
                  input:
                    name: request-service
                    typed_config:
                      "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.ServiceMatchInput
                  exact_match_map:
                    map:
                      service_name_0:
                        matcher:
                          matcher_list:
                            matchers:
                            - predicate:
                                single_predicate:
                                  input:
                                    name: request-properties
                                    typed_config:
                                      "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.PropertyMatchInput
                                      property_name: version
                                  value_match:
                                    exact: v1
                              on_match:
                                action:
                                  name: route
                                  typed_config:
                                    "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.action.v3.RouteAction
                                    cluster: cluster_0
)EOF",
                                                                     bind_upstream_connection));
  }

  // Create client connection.
  bool makeClientConnectionForTest() {
    connection_callbacks_ = std::make_shared<ConnectionCallbacks>(*this);
    test_read_filter_ = std::make_shared<TestReadFilter>(*this);

    client_connection_ = integration_->makeClientConnection(integration_->lookupPort("listener_0"));
    client_connection_->addConnectionCallbacks(*connection_callbacks_);
    client_connection_->addReadFilter(test_read_filter_);
    client_connection_->connect();
    integration_->dispatcher_->run(Envoy::Event::Dispatcher::RunType::Block);
    return connection_callbacks_->connection_connected_;
  }

  // Send downstream request.
  void sendRequestForTest(StreamFrame& request) {
    client_codec_->encode(request, *request_encoder_callback_);
    client_connection_->write(request_encoder_callback_->buffer_, false);
    client_connection_->dispatcher().run(Envoy::Event::Dispatcher::RunType::NonBlock);
    // Clear buffer for next encoding.
    request_encoder_callback_->buffer_.drain(request_encoder_callback_->buffer_.length());
  }

  // Waiting upstream connection to be created.
  void waitForUpstreamConnectionForTest() {
    integration_->waitForNextRawUpstreamConnection({0}, upstream_connection_);
  }

  // Waiting for upstream request data.
  void
  waitForUpstreamRequestForTest(const std::function<bool(const std::string&)>& data_validator) {
    auto result = upstream_connection_->waitForData(data_validator, nullptr);
    RELEASE_ASSERT(result, result.failure_message());
    // Clear data for next test.
    upstream_connection_->clearData();
  }

  // Send upstream response.
  void sendResponseForTest(const StreamFrame& response) {
    server_codec_->encode(response, *response_encoder_callback_);

    auto result =
        upstream_connection_->write(response_encoder_callback_->buffer_.toString(), false);
    // Clear buffer for next encoding.
    response_encoder_callback_->buffer_.drain(response_encoder_callback_->buffer_.length());
    RELEASE_ASSERT(result, result.failure_message());
  }

  // Waiting for downstream response.
  AssertionResult waitDownstreamResponseForTest(std::chrono::milliseconds timeout,
                                                uint64_t stream_id) {
    bool timer_fired = false;
    if (!response_decoder_callback_->responses_[stream_id].end_stream_) {
      Envoy::Event::TimerPtr timer(
          integration_->dispatcher_->createTimer([this, &timer_fired]() -> void {
            timer_fired = true;
            integration_->dispatcher_->exit();
          }));
      timer->enableTimer(timeout);
      response_decoder_callback_->waiting_for_stream_id_ = stream_id;
      integration_->dispatcher_->run(Envoy::Event::Dispatcher::RunType::Block);
      if (timer_fired) {
        return AssertionFailure() << "Timed out waiting for response";
      }
      if (timer->enabled()) {
        timer->disableTimer();
      }
    }
    if (!response_decoder_callback_->responses_[stream_id].end_stream_) {
      return AssertionFailure() << "No response or response not complete";
    }
    return AssertionSuccess();
  }

  void cleanup() {
    if (upstream_connection_ != nullptr) {
      AssertionResult result = upstream_connection_->close();
      RELEASE_ASSERT(result, result.message());
      result = upstream_connection_->waitForDisconnect();
      RELEASE_ASSERT(result, result.message());
      upstream_connection_.reset();
    }
    if (client_connection_ != nullptr) {
      client_connection_->close(Envoy::Network::ConnectionCloseType::NoFlush);
    }
  }

  // Codec.
  CodecFactoryPtr codec_factory_;
  ServerCodecPtr server_codec_;
  ClientCodecPtr client_codec_;

  TestRequestEncoderCallbackSharedPtr request_encoder_callback_;
  TestResponseDecoderCallbackSharedPtr response_decoder_callback_;
  TestResponseEncoderCallbackSharedPtr response_encoder_callback_;

  // Integration test server.
  std::unique_ptr<GenericProxyIntegrationTest> integration_;

  // Callbacks for downstream connection.
  ConnectionCallbacksSharedPtr connection_callbacks_;
  TestReadFilterSharedPtr test_read_filter_;

  // Client connection and upstream connection.
  Network::ClientConnectionPtr client_connection_;
  FakeRawConnectionPtr upstream_connection_;
};

INSTANTIATE_TEST_SUITE_P(IpVersions, IntegrationTest,
                         testing::ValuesIn(TestEnvironment::getIpVersionsForTest()),
                         TestUtility::ipTestParamsToString);

TEST_P(IntegrationTest, InitializeInstance) {
  FakeStreamCodecFactoryConfig codec_factory_config;
  Registry::InjectFactory<CodecFactoryConfig> registration(codec_factory_config);

  initialize(defaultConfig(), std::make_unique<FakeStreamCodecFactory>());
}

TEST_P(IntegrationTest, RequestRouteNotFound) {
  FakeStreamCodecFactoryConfig codec_factory_config;
  Registry::InjectFactory<CodecFactoryConfig> registration(codec_factory_config);

  initialize(defaultConfig(), std::make_unique<FakeStreamCodecFactory>());
  EXPECT_TRUE(makeClientConnectionForTest());

  FakeStreamCodecFactory::FakeRequest request;
  request.host_ = "service_name_0";
  request.method_ = "hello";
  request.path_ = "/path_or_anything";
  request.protocol_ = "fake_fake_fake";
  request.data_ = {{"version", "v2"}};

  sendRequestForTest(request);

  RELEASE_ASSERT(waitDownstreamResponseForTest(TestUtility::DefaultTimeout, 0),
                 "unexpected timeout");

  EXPECT_NE(response_decoder_callback_->responses_[0].response_, nullptr);
  EXPECT_EQ(response_decoder_callback_->responses_[0].response_->status().code(),
            static_cast<uint32_t>(absl::StatusCode::kNotFound));

  cleanup();
}

TEST_P(IntegrationTest, RequestAndResponse) {
  FakeStreamCodecFactoryConfig codec_factory_config;
  Registry::InjectFactory<CodecFactoryConfig> registration(codec_factory_config);

  initialize(defaultConfig(), std::make_unique<FakeStreamCodecFactory>());

  EXPECT_TRUE(makeClientConnectionForTest());

  FakeStreamCodecFactory::FakeRequest request;
  request.host_ = "service_name_0";
  request.method_ = "hello";
  request.path_ = "/path_or_anything";
  request.protocol_ = "fake_fake_fake";
  request.data_ = {{"version", "v1"}};

  sendRequestForTest(request);

  waitForUpstreamConnectionForTest();
  const std::function<bool(const std::string&)> data_validator =
      [](const std::string& data) -> bool { return data.find("v1") != std::string::npos; };
  waitForUpstreamRequestForTest(data_validator);

  FakeStreamCodecFactory::FakeResponse response;
  response.protocol_ = "fake_fake_fake";
  response.status_ = StreamStatus();
  response.data_["zzzz"] = "xxxx";

  sendResponseForTest(response);

  RELEASE_ASSERT(waitDownstreamResponseForTest(TestUtility::DefaultTimeout, 0),
                 "unexpected timeout");

  EXPECT_NE(response_decoder_callback_->responses_[0].response_, nullptr);
  EXPECT_EQ(response_decoder_callback_->responses_[0].response_->status().code(), 0);
  EXPECT_EQ(response_decoder_callback_->responses_[0].response_->get("zzzz"), "xxxx");

  cleanup();
}

TEST_P(IntegrationTest, MultipleRequestsWithSameStreamId) {
  FakeStreamCodecFactoryConfig codec_factory_config;
  Registry::InjectFactory<CodecFactoryConfig> registration(codec_factory_config);

  auto codec_factory = std::make_unique<FakeStreamCodecFactory>();

  initialize(defaultConfig(true), std::move(codec_factory));

  EXPECT_TRUE(makeClientConnectionForTest());

  FakeStreamCodecFactory::FakeRequest request_1;
  request_1.host_ = "service_name_0";
  request_1.method_ = "hello";
  request_1.path_ = "/path_or_anything";
  request_1.protocol_ = "fake_fake_fake";
  request_1.data_ = {{"version", "v1"}, {"stream_id", "1"}};

  sendRequestForTest(request_1);

  waitForUpstreamConnectionForTest();
  const std::function<bool(const std::string&)> data_validator =
      [](const std::string& data) -> bool { return data.find("v1") != std::string::npos; };
  waitForUpstreamRequestForTest(data_validator);

  FakeStreamCodecFactory::FakeRequest request_2;
  request_2.host_ = "service_name_0";
  request_2.method_ = "hello";
  request_2.path_ = "/path_or_anything";
  request_2.protocol_ = "fake_fake_fake";
  request_2.data_ = {{"version", "v1"}, {"stream_id", "1"}};

  // Send the second request with the same stream id and expect the connection to be closed.
  sendRequestForTest(request_2);

  // Wait for the connection to be closed.
  auto result = upstream_connection_->waitForDisconnect();
  RELEASE_ASSERT(result, result.message());

  cleanup();
}

TEST_P(IntegrationTest, MultipleRequests) {
  FakeStreamCodecFactoryConfig codec_factory_config;
  Registry::InjectFactory<CodecFactoryConfig> registration(codec_factory_config);

  auto codec_factory = std::make_unique<FakeStreamCodecFactory>();

  initialize(defaultConfig(true), std::move(codec_factory));

  EXPECT_TRUE(makeClientConnectionForTest());

  FakeStreamCodecFactory::FakeRequest request_1;
  request_1.host_ = "service_name_0";
  request_1.method_ = "hello";
  request_1.path_ = "/path_or_anything";
  request_1.protocol_ = "fake_fake_fake";
  request_1.data_ = {{"version", "v1"}, {"stream_id", "1"}, {"frame", "1_header"}};

  sendRequestForTest(request_1);

  waitForUpstreamConnectionForTest();
  const std::function<bool(const std::string&)> data_validator_1 =
      [](const std::string& data) -> bool {
    return data.find("frame:1_header") != std::string::npos;
  };
  waitForUpstreamRequestForTest(data_validator_1);

  FakeStreamCodecFactory::FakeRequest request_2;
  request_2.host_ = "service_name_0";
  request_2.method_ = "hello";
  request_2.path_ = "/path_or_anything";
  request_2.protocol_ = "fake_fake_fake";
  request_2.data_ = {{"version", "v1"}, {"stream_id", "2"}, {"frame", "2_header"}};

  // Reset request encoder callback.
  request_encoder_callback_ = std::make_shared<TestRequestEncoderCallback>();

  // Send the second request with the different stream id and expect the connection to be alive.
  sendRequestForTest(request_2);
  const std::function<bool(const std::string&)> data_validator_2 =
      [](const std::string& data) -> bool {
    return data.find("frame:2_header") != std::string::npos;
  };
  waitForUpstreamRequestForTest(data_validator_2);

  FakeStreamCodecFactory::FakeResponse response_2;
  response_2.protocol_ = "fake_fake_fake";
  response_2.status_ = StreamStatus();
  response_2.data_["zzzz"] = "xxxx";
  response_2.data_["stream_id"] = "2";

  sendResponseForTest(response_2);

  RELEASE_ASSERT(waitDownstreamResponseForTest(TestUtility::DefaultTimeout, 2),
                 "unexpected timeout");

  EXPECT_NE(response_decoder_callback_->responses_[2].response_, nullptr);
  EXPECT_EQ(response_decoder_callback_->responses_[2].response_->status().code(), 0);
  EXPECT_EQ(response_decoder_callback_->responses_[2].response_->get("zzzz"), "xxxx");
  EXPECT_EQ(response_decoder_callback_->responses_[2].response_->get("stream_id"), "2");

  FakeStreamCodecFactory::FakeResponse response_1;
  response_1.protocol_ = "fake_fake_fake";
  response_1.status_ = StreamStatus();
  response_1.data_["zzzz"] = "yyyy";
  response_1.data_["stream_id"] = "1";

  sendResponseForTest(response_1);

  RELEASE_ASSERT(waitDownstreamResponseForTest(TestUtility::DefaultTimeout, 1),
                 "unexpected timeout");

  EXPECT_NE(response_decoder_callback_->responses_[1].response_, nullptr);
  EXPECT_EQ(response_decoder_callback_->responses_[1].response_->status().code(), 0);
  EXPECT_EQ(response_decoder_callback_->responses_[1].response_->get("zzzz"), "yyyy");
  EXPECT_EQ(response_decoder_callback_->responses_[1].response_->get("stream_id"), "1");

  cleanup();
}

TEST_P(IntegrationTest, MultipleRequestsWithMultipleFrames) {
  FakeStreamCodecFactoryConfig codec_factory_config;
  Registry::InjectFactory<CodecFactoryConfig> registration(codec_factory_config);

  auto codec_factory = std::make_unique<FakeStreamCodecFactory>();

  initialize(defaultConfig(true), std::move(codec_factory));

  EXPECT_TRUE(makeClientConnectionForTest());

  FakeStreamCodecFactory::FakeRequest request_1;
  request_1.host_ = "service_name_0";
  request_1.method_ = "hello";
  request_1.path_ = "/path_or_anything";
  request_1.protocol_ = "fake_fake_fake";
  request_1.data_ = {
      {"version", "v1"}, {"stream_id", "1"}, {"end_stream", "false"}, {"frame", "1_header"}};

  FakeStreamCodecFactory::FakeRequest request_1_frame_1;
  request_1_frame_1.data_ = {{"stream_id", "1"}, {"end_stream", "false"}, {"frame", "1_frame_1"}};

  FakeStreamCodecFactory::FakeRequest request_1_frame_2;
  request_1_frame_2.data_ = {{"stream_id", "1"}, {"end_stream", "true"}, {"frame", "1_frame_2"}};

  FakeStreamCodecFactory::FakeRequest request_2;
  request_2.host_ = "service_name_0";
  request_2.method_ = "hello";
  request_2.path_ = "/path_or_anything";
  request_2.protocol_ = "fake_fake_fake";
  request_2.data_ = {
      {"version", "v1"}, {"stream_id", "2"}, {"end_stream", "false"}, {"frame", "2_header"}};

  FakeStreamCodecFactory::FakeRequest request_2_frame_1;
  request_2_frame_1.data_ = {{"stream_id", "2"}, {"end_stream", "false"}, {"frame", "2_frame_1"}};

  FakeStreamCodecFactory::FakeRequest request_2_frame_2;
  request_2_frame_2.data_ = {{"stream_id", "2"}, {"end_stream", "true"}, {"frame", "2_frame_2"}};

  // We handle frame one by one to make sure the order is correct.

  sendRequestForTest(request_1);
  waitForUpstreamConnectionForTest();

  // First frame of request 1.
  const std::function<bool(const std::string&)> data_validator_1 =
      [](const std::string& data) -> bool {
    return data.find("frame:1_header") != std::string::npos;
  };
  waitForUpstreamRequestForTest(data_validator_1);

  // Second frame of request 1.
  sendRequestForTest(request_1_frame_1);
  const std::function<bool(const std::string&)> data_validator_1_frame_1 =
      [](const std::string& data) -> bool {
    return data.find("frame:1_frame_1") != std::string::npos;
  };
  waitForUpstreamRequestForTest(data_validator_1_frame_1);

  // First frame of request 2.
  sendRequestForTest(request_2);
  const std::function<bool(const std::string&)> data_validator_2 =
      [](const std::string& data) -> bool {
    return data.find("frame:2_header") != std::string::npos;
  };
  waitForUpstreamRequestForTest(data_validator_2);

  // Second frame of request 2.
  sendRequestForTest(request_2_frame_1);
  const std::function<bool(const std::string&)> data_validator_2_frame_1 =
      [](const std::string& data) -> bool {
    return data.find("frame:2_frame_1") != std::string::npos;
  };
  waitForUpstreamRequestForTest(data_validator_2_frame_1);

  // Third frame of request 1.
  sendRequestForTest(request_1_frame_2);
  const std::function<bool(const std::string&)> data_validator_1_frame_2 =
      [](const std::string& data) -> bool {
    return data.find("frame:1_frame_2") != std::string::npos;
  };
  waitForUpstreamRequestForTest(data_validator_1_frame_2);

  // Third frame of request 2.
  sendRequestForTest(request_2_frame_2);
  const std::function<bool(const std::string&)> data_validator_2_frame_2 =
      [](const std::string& data) -> bool {
    return data.find("frame:2_frame_2") != std::string::npos;
  };
  waitForUpstreamRequestForTest(data_validator_2_frame_2);

  FakeStreamCodecFactory::FakeResponse response_2;
  response_2.protocol_ = "fake_fake_fake";
  response_2.status_ = StreamStatus();
  response_2.data_["zzzz"] = "xxxx";
  response_2.data_["stream_id"] = "2";
  response_2.data_["end_stream"] = "false";

  FakeStreamCodecFactory::FakeResponse response_2_frame_1;
  response_2_frame_1.data_["stream_id"] = "2";
  response_2_frame_1.data_["end_stream"] = "true";

  sendResponseForTest(response_2);
  sendResponseForTest(response_2_frame_1);

  RELEASE_ASSERT(waitDownstreamResponseForTest(TestUtility::DefaultTimeout, 2),
                 "unexpected timeout");

  EXPECT_NE(response_decoder_callback_->responses_[2].response_, nullptr);
  EXPECT_EQ(response_decoder_callback_->responses_[2].response_->status().code(), 0);
  EXPECT_EQ(response_decoder_callback_->responses_[2].response_->get("zzzz"), "xxxx");
  EXPECT_EQ(response_decoder_callback_->responses_[2].response_->get("stream_id"), "2");

  FakeStreamCodecFactory::FakeResponse response_1;
  response_1.protocol_ = "fake_fake_fake";
  response_1.status_ = StreamStatus();
  response_1.data_["zzzz"] = "yyyy";
  response_1.data_["stream_id"] = "1";
  response_1.data_["end_stream"] = "false";

  FakeStreamCodecFactory::FakeResponse response_1_frame_1;
  response_1_frame_1.data_["stream_id"] = "1";
  response_1_frame_1.data_["end_stream"] = "true";

  sendResponseForTest(response_1);
  sendResponseForTest(response_1_frame_1);

  RELEASE_ASSERT(waitDownstreamResponseForTest(TestUtility::DefaultTimeout, 1),
                 "unexpected timeout");

  EXPECT_NE(response_decoder_callback_->responses_[1].response_, nullptr);
  EXPECT_EQ(response_decoder_callback_->responses_[1].response_->status().code(), 0);
  EXPECT_EQ(response_decoder_callback_->responses_[1].response_->get("zzzz"), "yyyy");
  EXPECT_EQ(response_decoder_callback_->responses_[1].response_->get("stream_id"), "1");

  cleanup();
}

} // namespace
} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "envoy/admin/v3/config_dump_shared.pb.h"
#include "envoy/admin/v3/config_dump_shared.pb.validate.h"

#include "test/mocks/network/mocks.h"
#include "test/mocks/server/factory_context.h"
#include "test/test_common/registry.h"
#include "test/test_common/utility.h"

#include "contrib/envoy/extensions/filters/network/generic_proxy/v3/generic_proxy.pb.h"
#include "contrib/envoy/extensions/filters/network/generic_proxy/v3/generic_proxy.pb.validate.h"
#include "contrib/envoy/extensions/filters/network/generic_proxy/v3/route.pb.h"
#include "contrib/envoy/extensions/filters/network/generic_proxy/v3/route.pb.validate.h"
#include "contrib/generic_proxy/filters/network/source/config.h"
#include "contrib/generic_proxy/filters/network/test/fake_codec.h"
#include "contrib/generic_proxy/filters/network/test/mocks/codec.h"
#include "contrib/generic_proxy/filters/network/test/mocks/filter.h"
#include "contrib/generic_proxy/filters/network/test/mocks/route.h"
#include "gtest/gtest.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {
namespace {

using ::testing::Return;

// Keep empty until merge the latest API from main.
TEST(FactoryTest, FactoryTest) {
  const std::string yaml_config = R"EOF(
    stat_prefix: config_test
    filters:
    - name: envoy.filters.generic.router
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.router.v3.Router
    codec_config:
      name: fake
      typed_config:
        "@type": type.googleapis.com/xds.type.v3.TypedStruct
        type_url: envoy.generic_proxy.codecs.fake.type
        value: {}
    route_config:
      name: test-routes
      routes:
        matcher_tree:
          input:
            name: request-service
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.ServiceMatchInput
          exact_match_map:
            map:
              service_name_0:
                matcher:
                  matcher_list:
                    matchers:
                    - predicate:
                        single_predicate:
                          input:
                            name: request-properties
                            typed_config:
                              "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.PropertyMatchInput
                              property_name: version
                          value_match:
                            exact: v1
                      on_match:
                        action:
                          name: route
                          typed_config:
                            "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.action.v3.RouteAction
                            cluster: cluster_0
    )EOF";

  FakeStreamCodecFactoryConfig codec_factory_config;
  Registry::InjectFactory<CodecFactoryConfig> registration(codec_factory_config);

  NiceMock<Server::Configuration::MockFactoryContext> factory_context;

  Factory factory;
  ProxyConfig proto_config;
  TestUtility::loadFromYaml(yaml_config, proto_config);

  EXPECT_NE(nullptr, factory.createFilterFactoryFromProto(proto_config, factory_context));
}

TEST(FactoryTest, GenericRds) {
  const std::string config_yaml = R"EOF(
    stat_prefix: ingress
    filters:
    - name: envoy.filters.generic.router
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.router.v3.Router
    codec_config:
      name: fake
      typed_config:
        "@type": type.googleapis.com/xds.type.v3.TypedStruct
        type_url: envoy.generic_proxy.codecs.fake.type
        value: {}
    generic_rds:
      config_source: { resource_api_version: V3, ads: {} }
      route_config_name: test_route
    )EOF";

  const std::string response_yaml = (R"EOF(
version_info: "1"
resources:
  - "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.v3.RouteConfiguration
    name: test_route
    routes: {}
)EOF");

  FakeStreamCodecFactoryConfig codec_factory_config;
  Registry::InjectFactory<CodecFactoryConfig> registration(codec_factory_config);

  NiceMock<Server::Configuration::MockFactoryContext> factory_context;

  Factory factory;

  envoy::extensions::filters::network::generic_proxy::v3::GenericProxy config;
  TestUtility::loadFromYaml(config_yaml, config);

  Matchers::UniversalStringMatcher universal_name_matcher;
  Network::FilterFactoryCb cb = factory.createFilterFactoryFromProto(config, factory_context);
  auto response =
      TestUtility::parseYaml<envoy::service::discovery::v3::DiscoveryResponse>(response_yaml);
  const auto decoded_resources = TestUtility::decodeResources<
      envoy::extensions::filters::network::generic_proxy::v3::RouteConfiguration>(response);
  EXPECT_TRUE(
      factory_context.server_factory_context_.cluster_manager_.subscription_factory_.callbacks_
          ->onConfigUpdate(decoded_resources.refvec_, response.version_info())
          .ok());
  auto message_ptr = factory_context.server_factory_context_.admin_.config_tracker_
                         .config_tracker_callbacks_["genericrds_routes"](universal_name_matcher);
  const auto& dump =
      TestUtility::downcastAndValidate<const envoy::admin::v3::RoutesConfigDump&>(*message_ptr);
  EXPECT_EQ(1, dump.dynamic_route_configs().size());
  EXPECT_EQ(0, dump.static_route_configs().size());
}

TEST(FactoryTest, GenericRdsApiConfigSource) {
  const std::string config_yaml = R"EOF(
    stat_prefix: ingress
    filters:
    - name: envoy.filters.generic.router
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.router.v3.Router
    codec_config:
      name: fake
      typed_config:
        "@type": type.googleapis.com/xds.type.v3.TypedStruct
        type_url: envoy.generic_proxy.codecs.fake.type
        value: {}
    generic_rds:
      config_source:
        resource_api_version: V3
        api_config_source: { api_type: GRPC, transport_api_version: V3 }
      route_config_name: test_route
    )EOF";

  FakeStreamCodecFactoryConfig codec_factory_config;
  Registry::InjectFactory<CodecFactoryConfig> registration(codec_factory_config);

  NiceMock<Server::Configuration::MockFactoryContext> factory_context;

  Factory factory;

  envoy::extensions::filters::network::generic_proxy::v3::GenericProxy config;
  TestUtility::loadFromYaml(config_yaml, config);

  EXPECT_THROW_WITH_REGEX(factory.createFilterFactoryFromProto(config, factory_context),
                          EnvoyException,
                          "genericrds supports only aggregated api_type in api_config_source");
}

TEST(FactoryTest, CustomReadFilterFactory) {
  const std::string config_yaml = R"EOF(
    stat_prefix: ingress
    filters:
    - name: envoy.filters.generic.router
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.router.v3.Router
    codec_config:
      name: mock
      typed_config:
        "@type": type.googleapis.com/xds.type.v3.TypedStruct
        type_url: envoy.generic_proxy.codecs.mock.type
        value: {}
    generic_rds:
      config_source: { resource_api_version: V3, ads: {} }
      route_config_name: test_route
    )EOF";

  const std::string response_yaml = (R"EOF(
    version_info: "1"
    resources:
      - "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.v3.RouteConfiguration
        name: test_route
        routes: {}
    )EOF");

  MockStreamCodecFactoryConfig codec_factory_config;
  Registry::InjectFactory<CodecFactoryConfig> registration(codec_factory_config);

  NiceMock<Server::Configuration::MockFactoryContext> factory_context;

  Factory factory;

  envoy::extensions::filters::network::generic_proxy::v3::GenericProxy config;
  TestUtility::loadFromYaml(config_yaml, config);

  auto mock_codec_factory = std::make_unique<MockCodecFactory>();

  auto mock_proxy_factory = std::make_unique<MockProxyFactory>();
  auto raw_mock_proxy_factory = mock_proxy_factory.get();
  EXPECT_CALL(*raw_mock_proxy_factory, createProxy(_, _));

  EXPECT_CALL(codec_factory_config, createCodecFactory(_, _))
      .WillOnce(Return(testing::ByMove(std::move(mock_codec_factory))));
  EXPECT_CALL(codec_factory_config, createProxyFactory(_, _))
      .WillOnce(Return(testing::ByMove(std::move(mock_proxy_factory))));

  Network::FilterFactoryCb cb = factory.createFilterFactoryFromProto(config, factory_context);
  EXPECT_NE(nullptr, cb);
  Network::MockFilterManager filter_manager;
  cb(filter_manager);
}

/**
 * Test creating codec factory from typed extension config.
 */
TEST(BasicFilterConfigTest, CreatingCodecFactory) {

  {
    const std::string yaml_config = R"EOF(
      name: envoy.generic_proxy.codecs.fake
      typed_config:
        "@type": type.googleapis.com/xds.type.v3.TypedStruct
        type_url: envoy.generic_proxy.codecs.fake.type
        value: {}
      )EOF";
    NiceMock<Server::Configuration::MockFactoryContext> factory_context;

    envoy::config::core::v3::TypedExtensionConfig proto_config;
    TestUtility::loadFromYaml(yaml_config, proto_config);

    EXPECT_THROW(Factory::factoriesFromProto(proto_config, factory_context), EnvoyException);
  }

  {
    FakeStreamCodecFactoryConfig codec_factory_config;
    Registry::InjectFactory<CodecFactoryConfig> registration(codec_factory_config);

    const std::string yaml_config = R"EOF(
      name: envoy.generic_proxy.codecs.fake
      typed_config:
        "@type": type.googleapis.com/xds.type.v3.TypedStruct
        type_url: envoy.generic_proxy.codecs.fake.type
        value: {}
      )EOF";
    NiceMock<Server::Configuration::MockFactoryContext> factory_context;

    envoy::config::core::v3::TypedExtensionConfig proto_config;
    TestUtility::loadFromYaml(yaml_config, proto_config);

    EXPECT_NE(nullptr, Factory::factoriesFromProto(proto_config, factory_context).first);
    EXPECT_EQ(nullptr, Factory::factoriesFromProto(proto_config, factory_context).second);
  }
}

/**
 * Test creating L7 filter factories from proto config.
 */
TEST(BasicFilterConfigTest, CreatingFilterFactories) {
  NiceMock<Server::Configuration::MockFactoryContext> factory_context;

  ProtobufWkt::RepeatedPtrField<envoy::config::core::v3::TypedExtensionConfig> filters_proto_config;
  envoy::config::core::v3::TypedExtensionConfig codec_config;

  const std::string yaml_config_0 = R"EOF(
    name: mock_generic_proxy_filter_name_0
    typed_config:
      "@type": type.googleapis.com/xds.type.v3.TypedStruct
      type_url: mock_generic_proxy_filter_name_0
      value: {}
  )EOF";

  const std::string yaml_config_1 = R"EOF(
    name: mock_generic_proxy_filter_name_1
    typed_config:
      "@type": type.googleapis.com/xds.type.v3.TypedStruct
      type_url: mock_generic_proxy_filter_name_1
      value: {}
  )EOF";

  TestUtility::loadFromYaml(yaml_config_0, *filters_proto_config.Add());
  TestUtility::loadFromYaml(yaml_config_1, *filters_proto_config.Add());

  NiceMock<MockStreamFilterConfig> mock_filter_config_0;
  NiceMock<MockStreamFilterConfig> mock_filter_config_1;

  ON_CALL(mock_filter_config_0, name()).WillByDefault(Return("mock_generic_proxy_filter_name_0"));
  ON_CALL(mock_filter_config_1, name()).WillByDefault(Return("mock_generic_proxy_filter_name_1"));
  ON_CALL(mock_filter_config_0, configTypes())
      .WillByDefault(Return(std::set<std::string>{"mock_generic_proxy_filter_name_0"}));
  ON_CALL(mock_filter_config_1, configTypes())
      .WillByDefault(Return(std::set<std::string>{"mock_generic_proxy_filter_name_1"}));

  Registry::InjectFactory<NamedFilterConfigFactory> registration_0(mock_filter_config_0);
  Registry::InjectFactory<NamedFilterConfigFactory> registration_1(mock_filter_config_1);

  // No terminal filter.
  {
    EXPECT_THROW_WITH_MESSAGE(Factory::filtersFactoryFromProto(filters_proto_config, codec_config,
                                                               "test", factory_context),
                              EnvoyException,
                              "A terminal L7 filter is necessary for generic proxy");
  }

  // Error terminal filter position.
  {
    ON_CALL(mock_filter_config_0, isTerminalFilter()).WillByDefault(Return(true));

    EXPECT_THROW_WITH_MESSAGE(
        Factory::filtersFactoryFromProto(filters_proto_config, codec_config, "test",
                                         factory_context),
        EnvoyException,
        "Terminal filter: mock_generic_proxy_filter_name_0 must be the last generic L7 "
        "filter");
  }

  // Codec validation error.
  {
    ON_CALL(mock_filter_config_0, isTerminalFilter()).WillByDefault(Return(false));
    ON_CALL(mock_filter_config_0, validateCodec(_))
        .WillByDefault(Return(absl::InvalidArgumentError("codec validation error")));

    EXPECT_THROW_WITH_MESSAGE(Factory::filtersFactoryFromProto(filters_proto_config, codec_config,
                                                               "test", factory_context),
                              EnvoyException, "codec validation error");
  }

  {
    ON_CALL(mock_filter_config_0, isTerminalFilter()).WillByDefault(Return(false));
    ON_CALL(mock_filter_config_1, isTerminalFilter()).WillByDefault(Return(true));
    ON_CALL(mock_filter_config_0, validateCodec(_)).WillByDefault(Return(absl::OkStatus()));
    ON_CALL(mock_filter_config_1, validateCodec(_)).WillByDefault(Return(absl::OkStatus()));

    auto factories = Factory::filtersFactoryFromProto(filters_proto_config, codec_config, "test",
                                                      factory_context);
    EXPECT_EQ(2, factories.size());
  }
}

TEST(BasicFilterConfigTest, TestConfigurationWithTracing) {
  const std::string config_yaml = R"EOF(
    stat_prefix: ingress
    filters:
    - name: envoy.filters.generic.router
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.router.v3.Router
    codec_config:
      name: mock
      typed_config:
        "@type": type.googleapis.com/xds.type.v3.TypedStruct
        type_url: envoy.generic_proxy.codecs.mock.type
        value: {}
    generic_rds:
      config_source: { resource_api_version: V3, ads: {} }
      route_config_name: test_route
    tracing:
      max_path_tag_length: 128
      provider:
        name: zipkin
        typed_config:
          "@type": type.googleapis.com/envoy.config.trace.v3.ZipkinConfig
          collector_cluster: zipkin
          collector_endpoint: "/api/v2/spans"
          collector_endpoint_version: HTTP_JSON
    )EOF";

  NiceMock<MockStreamCodecFactoryConfig> codec_factory_config;
  Registry::InjectFactory<CodecFactoryConfig> registration(codec_factory_config);

  NiceMock<Network::MockListenerInfo> listener_info;
  NiceMock<Server::Configuration::MockFactoryContext> factory_context;
  ON_CALL(factory_context, listenerInfo()).WillByDefault(testing::ReturnRef(listener_info));
  factory_context.server_factory_context_.cluster_manager_.initializeClusters({"zipkin"}, {});
  factory_context.server_factory_context_.cluster_manager_.initializeThreadLocalClusters(
      {"zipkin"});

  Factory factory;

  envoy::extensions::filters::network::generic_proxy::v3::GenericProxy config;
  TestUtility::loadFromYaml(config_yaml, config);

  auto mock_codec_factory = std::make_unique<NiceMock<MockCodecFactory>>();

  EXPECT_CALL(codec_factory_config, createCodecFactory(_, _))
      .WillOnce(Return(testing::ByMove(std::move(mock_codec_factory))));

  Network::FilterFactoryCb cb = factory.createFilterFactoryFromProto(config, factory_context);
  EXPECT_NE(nullptr, cb);
  NiceMock<Network::MockFilterManager> filter_manager;
  cb(filter_manager);
}

TEST(BasicFilterConfigTest, TestConfigurationWithAccessLog) {
  const std::string config_yaml = R"EOF(
    stat_prefix: ingress
    filters:
    - name: envoy.filters.generic.router
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.router.v3.Router
    codec_config:
      name: mock
      typed_config:
        "@type": type.googleapis.com/xds.type.v3.TypedStruct
        type_url: envoy.generic_proxy.codecs.mock.type
        value: {}
    generic_rds:
      config_source: { resource_api_version: V3, ads: {} }
      route_config_name: test_route
    access_log:
    - name: envoy.generic_proxy.access_loggers.file
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.access_loggers.file.v3.FileAccessLog
        path: "/dev/stdout"
        log_format:
          text_format_source:
            inline_string: "%METHOD% %PATH% %HOST% %PROTOCOL% %REQUEST_PROPERTY(key)% RESPONSE_PROPERTY(key)\n"
    )EOF";

  NiceMock<MockStreamCodecFactoryConfig> codec_factory_config;
  Registry::InjectFactory<CodecFactoryConfig> registration(codec_factory_config);

  NiceMock<Server::Configuration::MockFactoryContext> factory_context;

  Factory factory;

  envoy::extensions::filters::network::generic_proxy::v3::GenericProxy config;
  TestUtility::loadFromYaml(config_yaml, config);

  auto mock_codec_factory = std::make_unique<NiceMock<MockCodecFactory>>();

  EXPECT_CALL(codec_factory_config, createCodecFactory(_, _))
      .WillOnce(Return(testing::ByMove(std::move(mock_codec_factory))));

  Network::FilterFactoryCb cb = factory.createFilterFactoryFromProto(config, factory_context);
  EXPECT_NE(nullptr, cb);
  NiceMock<Network::MockFilterManager> filter_manager;
  cb(filter_manager);
}

} // namespace
} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include <memory>
#include <string>
#include <utility>

#include "source/common/tracing/tracer_manager_impl.h"

#include "test/mocks/server/factory_context.h"
#include "test/test_common/registry.h"
#include "test/test_common/utility.h"

#include "contrib/generic_proxy/filters/network/source/proxy.h"
#include "contrib/generic_proxy/filters/network/test/fake_codec.h"
#include "contrib/generic_proxy/filters/network/test/mocks/codec.h"
#include "contrib/generic_proxy/filters/network/test/mocks/filter.h"
#include "contrib/generic_proxy/filters/network/test/mocks/route.h"
#include "gmock/gmock.h"
#include "gtest/gtest.h"

using testing::ByMove;
using testing::NiceMock;
using testing::Return;

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {
namespace {

static const std::string DEFAULT_LOG_FORMAT =
    "%HOST% %PATH% %METHOD% %PROTOCOL% %REQUEST_PROPERTY(request-key)% "
    "%RESPONSE_PROPERTY(response-key)% "
    "%REQUEST_PROPERTY(non-exist-key)% %RESPONSE_CODE% %RESPONSE_CODE_DETAILS%";

class MockRouteConfigProvider : public Rds::RouteConfigProvider {
public:
  MockRouteConfigProvider() { ON_CALL(*this, config()).WillByDefault(Return(route_config_)); }

  MOCK_METHOD(Rds::ConfigConstSharedPtr, config, (), (const));
  MOCK_METHOD(const absl::optional<Rds::RouteConfigProvider::ConfigInfo>&, configInfo, (), (const));
  MOCK_METHOD(SystemTime, lastUpdated, (), (const));
  MOCK_METHOD(absl::Status, onConfigUpdate, ());

  std::shared_ptr<NiceMock<MockRouteMatcher>> route_config_{new NiceMock<MockRouteMatcher>()};
};

class FilterConfigTest : public testing::Test {
public:
  void initializeFilterConfig(bool with_tracing = false, AccessLogInstanceSharedPtr logger = {}) {
    if (with_tracing) {
      tracer_ = std::make_shared<NiceMock<Tracing::MockTracer>>();

      const std::string tracing_config_yaml = R"EOF(
      max_path_tag_length: 128
      )EOF";

      Tracing::ConnectionManagerTracingConfigProto tracing_config;

      TestUtility::loadFromYaml(tracing_config_yaml, tracing_config);

      tracing_config_ = std::make_unique<Tracing::ConnectionManagerTracingConfigImpl>(
          envoy::config::core::v3::TrafficDirection::OUTBOUND, tracing_config);
    }

    std::vector<NamedFilterFactoryCb> factories;

    for (const auto& filter : mock_stream_filters_) {
      factories.push_back({filter.first, [f = filter.second](FilterChainFactoryCallbacks& cb) {
                             cb.addFilter(f);
                           }});
    }

    for (const auto& filter : mock_decoder_filters_) {
      factories.push_back({filter.first, [f = filter.second](FilterChainFactoryCallbacks& cb) {
                             cb.addDecoderFilter(f);
                           }});
    }
    for (const auto& filter : mock_encoder_filters_) {
      factories.push_back({filter.first, [f = filter.second](FilterChainFactoryCallbacks& cb) {
                             cb.addEncoderFilter(f);
                           }});
    }

    auto codec_factory = std::make_unique<NiceMock<MockCodecFactory>>();
    codec_factory_ = codec_factory.get();

    mock_route_entry_ = std::make_shared<NiceMock<MockRouteEntry>>();

    std::vector<AccessLogInstanceSharedPtr> access_logs;
    if (logger) {
      access_logs.push_back(logger);
    }

    filter_config_ = std::make_shared<FilterConfigImpl>(
        "generic_proxy.test_prefix.", std::move(codec_factory), route_config_provider_, factories,
        tracer_, std::move(tracing_config_), std::move(access_logs), code_or_flags_,
        factory_context_);
  }

  AccessLogInstanceSharedPtr loggerFormFormat(const std::string& format = DEFAULT_LOG_FORMAT) {
    envoy::config::core::v3::SubstitutionFormatString sff_config;
    sff_config.mutable_text_format_source()->set_inline_string(format);
    auto formatter =
        Envoy::Formatter::SubstitutionFormatStringUtils::fromProtoConfig<FormatterContext>(
            sff_config, factory_context_);

    return std::make_shared<FileAccessLog>(
        Filesystem::FilePathAndType{}, nullptr, std::move(formatter),
        factory_context_.server_factory_context_.accessLogManager());
  }

  NiceMock<Server::Configuration::MockFactoryContext> factory_context_;
  CodeOrFlags code_or_flags_{factory_context_.server_factory_context_};

  std::shared_ptr<NiceMock<Tracing::MockTracer>> tracer_;
  Tracing::ConnectionManagerTracingConfigPtr tracing_config_;

  std::shared_ptr<FilterConfig> filter_config_;

  std::shared_ptr<NiceMock<MockRouteConfigProvider>> route_config_provider_{
      new NiceMock<MockRouteConfigProvider>()};
  NiceMock<MockRouteMatcher>* route_matcher_ = route_config_provider_->route_config_.get();

  NiceMock<MockCodecFactory>* codec_factory_;

  using MockStreamFilterSharedPtr = std::shared_ptr<NiceMock<MockStreamFilter>>;
  using MockDecoderFilterSharedPtr = std::shared_ptr<NiceMock<MockDecoderFilter>>;
  using MockEncoderFilterSharedPtr = std::shared_ptr<NiceMock<MockEncoderFilter>>;

  std::vector<std::pair<std::string, MockStreamFilterSharedPtr>> mock_stream_filters_;
  std::vector<std::pair<std::string, MockDecoderFilterSharedPtr>> mock_decoder_filters_;
  std::vector<std::pair<std::string, MockEncoderFilterSharedPtr>> mock_encoder_filters_;

  std::shared_ptr<NiceMock<MockRouteEntry>> mock_route_entry_;
};

/**
 * Test the method that to get route entry.
 */
TEST_F(FilterConfigTest, RouteEntry) {
  initializeFilterConfig();

  EXPECT_CALL(*route_matcher_, routeEntry(_)).WillOnce(Return(mock_route_entry_));

  FakeStreamCodecFactory::FakeRequest fake_request;

  EXPECT_EQ(filter_config_->routeEntry(fake_request).get(), mock_route_entry_.get());
}

/**
 * Test creating an L7 filter chain.
 */
TEST_F(FilterConfigTest, CreateFilterChain) {
  auto mock_stream_filter = std::make_shared<NiceMock<MockStreamFilter>>();
  mock_stream_filters_ = {{"mock_0", mock_stream_filter},
                          {"mock_1", mock_stream_filter},
                          {"mock_2", mock_stream_filter}};

  initializeFilterConfig();

  NiceMock<MockFilterChainManager> cb;

  EXPECT_CALL(cb.callbacks_, addFilter(_))
      .Times(3)
      .WillRepeatedly(Invoke([&](StreamFilterSharedPtr filter) {
        EXPECT_EQ(filter.get(), mock_stream_filter.get());
      }));

  filter_config_->createFilterChain(cb);
}

/**
 * Simple test for getting codec factory.
 */
TEST_F(FilterConfigTest, CodecFactory) {
  initializeFilterConfig();

  EXPECT_EQ(&(filter_config_->codecFactory()), codec_factory_);
}

class FilterTest : public FilterConfigTest {
public:
  void initializeFilter(bool with_tracing = false, AccessLogInstanceSharedPtr logger = {}) {
    FilterConfigTest::initializeFilterConfig(with_tracing, logger);

    auto server_codec = std::make_unique<NiceMock<MockServerCodec>>();
    server_codec_ = server_codec.get();
    EXPECT_CALL(*codec_factory_, createServerCodec())
        .WillOnce(Return(ByMove(std::move(server_codec))));

    EXPECT_CALL(*server_codec_, setCodecCallbacks(_))
        .WillOnce(
            Invoke([this](ServerCodecCallbacks& callback) { decoder_callback_ = &callback; }));

    filter_ = std::make_shared<Filter>(filter_config_, factory_context_);

    EXPECT_EQ(filter_.get(), decoder_callback_);

    filter_->initializeReadFilterCallbacks(filter_callbacks_);
  }

  std::shared_ptr<Filter> filter_;

  ServerCodecCallbacks* decoder_callback_{};

  NiceMock<MockServerCodec>* server_codec_{};

  NiceMock<Network::MockReadFilterCallbacks> filter_callbacks_;
};

TEST_F(FilterTest, SimpleOnNewConnection) {
  initializeFilter();
  EXPECT_EQ(Network::FilterStatus::Continue, filter_->onNewConnection());
}

TEST_F(FilterTest, SimpleOnData) {
  initializeFilter();

  Buffer::OwnedImpl fake_empty_buffer;

  EXPECT_CALL(*server_codec_, decode(_, _));
  filter_->onData(fake_empty_buffer, false);
}

TEST_F(FilterTest, OnDecodingFailureWithoutActiveStreams) {
  initializeFilter();

  Buffer::OwnedImpl fake_empty_buffer;

  EXPECT_CALL(*server_codec_, decode(_, _));
  filter_->onData(fake_empty_buffer, false);

  EXPECT_CALL(filter_callbacks_.connection_, close(_));
  decoder_callback_->onDecodingFailure();

  EXPECT_EQ(filter_config_->stats().downstream_rq_decoding_error_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_total_.value(), 0);
  // No request was received and no request was reset.
  EXPECT_EQ(filter_config_->stats().downstream_rq_reset_.value(), 0);
}

TEST_F(FilterTest, OnDecodingSuccessWithNormalRequest) {
  auto mock_stream_filter = std::make_shared<NiceMock<MockStreamFilter>>();
  mock_stream_filters_ = {{"mock_0", mock_stream_filter},
                          {"mock_1", mock_stream_filter},
                          {"mock_2", mock_stream_filter}};

  initializeFilter();

  Buffer::OwnedImpl fake_empty_buffer;

  EXPECT_CALL(*server_codec_, decode(_, _));
  filter_->onData(fake_empty_buffer, false);

  auto request = std::make_unique<FakeStreamCodecFactory::FakeRequest>();

  // Three mock factories was added.
  EXPECT_CALL(*mock_stream_filter, onStreamDecoded(_)).Times(3);

  decoder_callback_->onDecodingSuccess(std::move(request));

  EXPECT_EQ(filter_config_->stats().downstream_rq_total_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_active_.value(), 1);

  EXPECT_EQ(1, filter_->activeStreamsForTest().size());
}

TEST_F(FilterTest, OnConnectedEvent) {
  initializeFilter();
  // Do nothing.
  filter_->onEvent(Network::ConnectionEvent::Connected);
}

TEST_F(FilterTest, OnConnectionClosedEvent) {
  initializeFilter();

  filter_->onEvent(Network::ConnectionEvent::RemoteClose);

  Buffer::OwnedImpl fake_empty_buffer;

  // Return directly.
  EXPECT_EQ(Network::FilterStatus::StopIteration, filter_->onData(fake_empty_buffer, false));
}

TEST_F(FilterTest, SendReplyDownstream) {
  initializeFilter();

  NiceMock<MockEncodingCallbacks> encoder_callback;

  auto response = std::make_unique<FakeStreamCodecFactory::FakeResponse>();

  Buffer::OwnedImpl response_buffer;

  EXPECT_CALL(filter_callbacks_.connection_, write(BufferStringEqual("test"), false));

  EXPECT_CALL(encoder_callback, onEncodingSuccess(_, _))
      .WillOnce(Invoke([&](Buffer::Instance& buffer, bool) {
        filter_callbacks_.connection_.write(buffer, false);
      }));

  EXPECT_CALL(*server_codec_, encode(_, _))
      .WillOnce(Invoke([&](const StreamFrame&, EncodingCallbacks& callback) {
        Buffer::OwnedImpl buffer;
        buffer.add("test");
        callback.onEncodingSuccess(buffer, true);
      }));

  filter_->sendFrameToDownstream(*response, encoder_callback);
}

TEST_F(FilterTest, GetConnection) {
  initializeFilter();

  EXPECT_EQ(&(filter_callbacks_.connection_), &filter_->downstreamConnection());
}

TEST_F(FilterTest, NewStreamAndResetStream) {
  initializeFilter();

  auto request = std::make_unique<FakeStreamCodecFactory::FakeRequest>();

  filter_->onDecodingSuccess(std::move(request));
  EXPECT_EQ(1, filter_->activeStreamsForTest().size());

  EXPECT_EQ(filter_config_->stats().downstream_rq_total_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_active_.value(), 1);

  auto active_stream = filter_->activeStreamsForTest().begin()->get();
  active_stream->resetStream(DownstreamStreamResetReason::ConnectionTermination);

  EXPECT_EQ(0, filter_->activeStreamsForTest().size());

  EXPECT_EQ(filter_config_->stats().downstream_rq_total_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_active_.value(), 0);
  EXPECT_EQ(filter_config_->stats().downstream_rq_reset_.value(), 1);

  EXPECT_EQ(
      factory_context_.store_.counter("generic_proxy.test_prefix.downstream_rq_flag.DC").value(),
      1);
}

TEST_F(FilterTest, SimpleBufferWaterMarkTest) {
  initializeFilter();
  filter_->onAboveWriteBufferHighWatermark();
  filter_->onBelowWriteBufferLowWatermark();
}

TEST_F(FilterTest, NewStreamAndDispatcher) {
  mock_stream_filters_.push_back({"mock_0", std::make_shared<NiceMock<MockStreamFilter>>()});

  initializeFilter();

  auto request = std::make_unique<FakeStreamCodecFactory::FakeRequest>();

  filter_->onDecodingSuccess(std::move(request));
  EXPECT_EQ(1, filter_->activeStreamsForTest().size());

  EXPECT_EQ(filter_config_->stats().downstream_rq_total_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_active_.value(), 1);

  auto active_stream = filter_->activeStreamsForTest().begin()->get();

  EXPECT_EQ(&active_stream->decoderFiltersForTest()[0]->dispatcher(), &active_stream->dispatcher());
}

TEST_F(FilterTest, OnDecodingFailureWithActiveStreams) {
  initializeFilter();

  auto request_0 = std::make_unique<FakeStreamCodecFactory::FakeRequest>();
  filter_->onDecodingSuccess(std::move(request_0));

  auto request_1 = std::make_unique<FakeStreamCodecFactory::FakeRequest>();
  filter_->onDecodingSuccess(std::move(request_1));

  EXPECT_EQ(2, filter_->activeStreamsForTest().size());

  EXPECT_EQ(filter_config_->stats().downstream_rq_total_.value(), 2);
  EXPECT_EQ(filter_config_->stats().downstream_rq_active_.value(), 2);

  Buffer::OwnedImpl fake_empty_buffer;
  EXPECT_CALL(*server_codec_, decode(_, _));
  filter_->onData(fake_empty_buffer, false);

  EXPECT_CALL(filter_callbacks_.connection_, close(_));
  decoder_callback_->onDecodingFailure();

  EXPECT_EQ(0, filter_->activeStreamsForTest().size());

  EXPECT_EQ(filter_config_->stats().downstream_rq_total_.value(), 2);
  EXPECT_EQ(filter_config_->stats().downstream_rq_active_.value(), 0);
  EXPECT_EQ(filter_config_->stats().downstream_rq_reset_.value(), 2);
  EXPECT_EQ(
      factory_context_.store_.counter("generic_proxy.test_prefix.downstream_rq_flag.DPE").value(),
      2);
}

TEST_F(FilterTest, ActiveStreamRouteEntry) {
  initializeFilter();

  auto request = std::make_unique<FakeStreamCodecFactory::FakeRequest>();

  filter_->onDecodingSuccess(std::move(request));
  EXPECT_EQ(1, filter_->activeStreamsForTest().size());

  EXPECT_EQ(filter_config_->stats().downstream_rq_total_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_active_.value(), 1);

  auto active_stream = filter_->activeStreamsForTest().begin()->get();
  EXPECT_EQ(active_stream->routeEntry(), route_matcher_->route_entry_.get());
}

TEST_F(FilterTest, ActiveStreamPerFilterConfig) {
  mock_stream_filters_.push_back(
      {"fake_test_filter_name_0", std::make_shared<NiceMock<MockStreamFilter>>()});

  initializeFilter();

  EXPECT_CALL(*route_matcher_, routeEntry(_)).WillOnce(Return(mock_route_entry_));

  auto request = std::make_unique<FakeStreamCodecFactory::FakeRequest>();
  filter_->onDecodingSuccess(std::move(request));
  EXPECT_EQ(1, filter_->activeStreamsForTest().size());

  auto active_stream = filter_->activeStreamsForTest().begin()->get();

  EXPECT_EQ(1, active_stream->decoderFiltersForTest().size());
  EXPECT_EQ(1, active_stream->encoderFiltersForTest().size());
  EXPECT_EQ(1, active_stream->nextDecoderFilterIndexForTest());
  EXPECT_EQ(0, active_stream->nextEncoderFilterIndexForTest());

  EXPECT_CALL(*mock_route_entry_, perFilterConfig("fake_test_filter_name_0"))
      .WillOnce(Return(nullptr));
  EXPECT_EQ(nullptr, active_stream->decoderFiltersForTest()[0]->perFilterConfig());
}

TEST_F(FilterTest, ActiveStreamPerFilterConfigNoRouteEntry) {
  mock_stream_filters_.push_back(
      {"fake_test_filter_name_0", std::make_shared<NiceMock<MockStreamFilter>>()});

  initializeFilter();

  EXPECT_CALL(*route_matcher_, routeEntry(_)).WillOnce(Return(nullptr));

  auto request = std::make_unique<FakeStreamCodecFactory::FakeRequest>();
  filter_->onDecodingSuccess(std::move(request));
  EXPECT_EQ(1, filter_->activeStreamsForTest().size());

  auto active_stream = filter_->activeStreamsForTest().begin()->get();

  EXPECT_EQ(1, active_stream->decoderFiltersForTest().size());
  EXPECT_EQ(1, active_stream->encoderFiltersForTest().size());
  EXPECT_EQ(1, active_stream->nextDecoderFilterIndexForTest());
  EXPECT_EQ(0, active_stream->nextEncoderFilterIndexForTest());

  EXPECT_EQ(nullptr, active_stream->decoderFiltersForTest()[0]->perFilterConfig());
}

TEST_F(FilterTest, ActiveStreamConnection) {
  mock_stream_filters_.push_back(
      {"fake_test_filter_name_0", std::make_shared<NiceMock<MockStreamFilter>>()});

  initializeFilter();

  auto request = std::make_unique<FakeStreamCodecFactory::FakeRequest>();
  filter_->onDecodingSuccess(std::move(request));
  EXPECT_EQ(1, filter_->activeStreamsForTest().size());

  auto active_stream = filter_->activeStreamsForTest().begin()->get();

  EXPECT_EQ(1, active_stream->decoderFiltersForTest().size());
  EXPECT_EQ(1, active_stream->encoderFiltersForTest().size());
  EXPECT_EQ(1, active_stream->nextDecoderFilterIndexForTest());
  EXPECT_EQ(0, active_stream->nextEncoderFilterIndexForTest());

  EXPECT_EQ(&filter_callbacks_.connection_,
            active_stream->decoderFiltersForTest()[0]->connection());
}

TEST_F(FilterTest, ActiveStreamAddFilters) {
  initializeFilter();

  auto request = std::make_unique<FakeStreamCodecFactory::FakeRequest>();

  filter_->onDecodingSuccess(std::move(request));
  EXPECT_EQ(1, filter_->activeStreamsForTest().size());

  auto active_stream = filter_->activeStreamsForTest().begin()->get();

  EXPECT_EQ(0, active_stream->decoderFiltersForTest().size());
  EXPECT_EQ(0, active_stream->encoderFiltersForTest().size());

  EXPECT_EQ(0, active_stream->nextDecoderFilterIndexForTest());
  EXPECT_EQ(0, active_stream->nextEncoderFilterIndexForTest());

  ActiveStream::FilterChainFactoryCallbacksHelper helper(*active_stream, {"fake_test"});

  auto new_filter_0 = std::make_shared<NiceMock<MockStreamFilter>>();
  auto new_filter_1 = std::make_shared<NiceMock<MockStreamFilter>>();
  auto new_filter_3 = std::make_shared<NiceMock<MockStreamFilter>>();

  helper.addDecoderFilter(new_filter_0);
  helper.addEncoderFilter(new_filter_0);

  helper.addDecoderFilter(new_filter_1);
  helper.addFilter(new_filter_3);

  EXPECT_EQ(3, active_stream->decoderFiltersForTest().size());
  EXPECT_EQ(2, active_stream->encoderFiltersForTest().size());

  EXPECT_EQ("fake_test", active_stream->decoderFiltersForTest()[0]->context_.config_name);
  EXPECT_EQ("fake_test", active_stream->encoderFiltersForTest()[0]->context_.config_name);

  active_stream->continueDecoding();

  EXPECT_EQ(3, active_stream->nextDecoderFilterIndexForTest());
  EXPECT_EQ(0, active_stream->nextEncoderFilterIndexForTest());
}

TEST_F(FilterTest, ActiveStreamAddFiltersOrder) {
  auto filter_0 = std::make_shared<NiceMock<MockStreamFilter>>();
  auto filter_1 = std::make_shared<NiceMock<MockStreamFilter>>();
  auto filter_2 = std::make_shared<NiceMock<MockStreamFilter>>();

  mock_stream_filters_ = {{"fake_test_filter_name_0", filter_0},
                          {"fake_test_filter_name_1", filter_1},
                          {"fake_test_filter_name_2", filter_2}};

  initializeFilter();

  auto request = std::make_unique<FakeStreamCodecFactory::FakeRequest>();

  filter_->onDecodingSuccess(std::move(request));
  EXPECT_EQ(1, filter_->activeStreamsForTest().size());

  auto active_stream = filter_->activeStreamsForTest().begin()->get();

  EXPECT_EQ(3, active_stream->decoderFiltersForTest().size());
  EXPECT_EQ(3, active_stream->encoderFiltersForTest().size());

  EXPECT_EQ(filter_0.get(), active_stream->decoderFiltersForTest()[0]->filter_.get());
  EXPECT_EQ(filter_1.get(), active_stream->decoderFiltersForTest()[1]->filter_.get());
  EXPECT_EQ(filter_2.get(), active_stream->decoderFiltersForTest()[2]->filter_.get());

  EXPECT_EQ(filter_2.get(), active_stream->encoderFiltersForTest()[0]->filter_.get());
  EXPECT_EQ(filter_1.get(), active_stream->encoderFiltersForTest()[1]->filter_.get());
  EXPECT_EQ(filter_0.get(), active_stream->encoderFiltersForTest()[2]->filter_.get());
}

TEST_F(FilterTest, ActiveStreamFiltersContinueDecoding) {
  auto mock_stream_filter_0 = std::make_shared<NiceMock<MockStreamFilter>>();
  auto mock_stream_filter_1 = std::make_shared<NiceMock<MockStreamFilter>>();
  auto mock_stream_filter_2 = std::make_shared<NiceMock<MockStreamFilter>>();

  mock_stream_filters_ = {{"mock_0", mock_stream_filter_0},
                          {"mock_1", mock_stream_filter_1},
                          {"mock_2", mock_stream_filter_2}};

  auto mock_encoder_filter = std::make_shared<NiceMock<MockEncoderFilter>>();
  mock_encoder_filters_ = {{"mock_encoder_0", mock_encoder_filter},
                           {"mock_encoder_1", mock_encoder_filter},
                           {"mock_encoder_2", mock_encoder_filter}};

  ON_CALL(*mock_stream_filter_1, onStreamDecoded(_))
      .WillByDefault(Return(FilterStatus::StopIteration));

  initializeFilter();

  auto request = std::make_unique<FakeStreamCodecFactory::FakeRequest>();

  filter_->onDecodingSuccess(std::move(request));
  EXPECT_EQ(1, filter_->activeStreamsForTest().size());

  auto active_stream = filter_->activeStreamsForTest().begin()->get();

  EXPECT_EQ(3, active_stream->decoderFiltersForTest().size());
  EXPECT_EQ(6, active_stream->encoderFiltersForTest().size());

  // Decoding will be stopped when `onStreamDecoded` of `mock_stream_filter_1` is called.
  EXPECT_EQ(2, active_stream->nextDecoderFilterIndexForTest());
  EXPECT_EQ(0, active_stream->nextEncoderFilterIndexForTest());

  active_stream->decoderFiltersForTest()[1]->continueDecoding();

  EXPECT_EQ(3, active_stream->nextDecoderFilterIndexForTest());
  EXPECT_EQ(0, active_stream->nextEncoderFilterIndexForTest());
}

TEST_F(FilterTest, ActiveStreamFiltersContinueEncoding) {
  auto mock_stream_filter_0 = std::make_shared<NiceMock<MockStreamFilter>>();
  auto mock_stream_filter_1 = std::make_shared<NiceMock<MockStreamFilter>>();
  auto mock_stream_filter_2 = std::make_shared<NiceMock<MockStreamFilter>>();

  mock_stream_filters_ = {{"mock_0", mock_stream_filter_0},
                          {"mock_1", mock_stream_filter_1},
                          {"mock_2", mock_stream_filter_2}};

  auto mock_decoder_filter = std::make_shared<NiceMock<MockDecoderFilter>>();
  mock_decoder_filters_ = {{"mock_decoder_0", mock_decoder_filter},
                           {"mock_decoder_1", mock_decoder_filter},
                           {"mock_decoder_2", mock_decoder_filter}};

  ON_CALL(*mock_stream_filter_1, onStreamEncoded(_))
      .WillByDefault(Return(FilterStatus::StopIteration));

  initializeFilter();

  auto request = std::make_unique<FakeStreamCodecFactory::FakeRequest>();

  filter_->onDecodingSuccess(std::move(request));
  EXPECT_EQ(1, filter_->activeStreamsForTest().size());

  auto active_stream = filter_->activeStreamsForTest().begin()->get();

  EXPECT_EQ(6, active_stream->decoderFiltersForTest().size());
  EXPECT_EQ(3, active_stream->encoderFiltersForTest().size());

  // All decoder filters are completed directly.
  EXPECT_EQ(6, active_stream->nextDecoderFilterIndexForTest());
  EXPECT_EQ(0, active_stream->nextEncoderFilterIndexForTest());

  auto response = std::make_unique<FakeStreamCodecFactory::FakeResponse>();
  // `continueEncoding` will be called in the `onResponseStart`.
  active_stream->onResponseStart(std::move(response));

  // Encoding will be stopped when `onStreamEncoded` of `mock_stream_filter_1` is called.
  EXPECT_EQ(2, active_stream->nextEncoderFilterIndexForTest());

  EXPECT_CALL(filter_callbacks_.connection_, write(BufferStringEqual("test"), false));

  EXPECT_CALL(*server_codec_, encode(_, _))
      .WillOnce(Invoke([&](const StreamFrame&, EncodingCallbacks& callback) {
        Buffer::OwnedImpl buffer;
        buffer.add("test");
        callback.onEncodingSuccess(buffer, true);
      }));

  active_stream->encoderFiltersForTest()[1]->continueEncoding();
}

TEST_F(FilterTest, ActiveStreamSendLocalReply) {
  initializeFilter(false, loggerFormFormat());

  auto request = std::make_unique<FakeStreamCodecFactory::FakeRequest>();
  request->host_ = "host-value";
  request->path_ = "/path-value";
  request->method_ = "method-value";
  request->protocol_ = "protocol-value";
  request->data_["request-key"] = "request-value";

  filter_->onDecodingSuccess(std::move(request));
  EXPECT_EQ(1, filter_->activeStreamsForTest().size());

  EXPECT_EQ(filter_config_->stats().downstream_rq_total_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_active_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_local_.value(), 0);

  auto active_stream = filter_->activeStreamsForTest().begin()->get();

  EXPECT_CALL(*server_codec_, respond(_, _, _))
      .WillOnce(Invoke([&](Status status, absl::string_view, const Request&) -> ResponsePtr {
        auto response = std::make_unique<FakeStreamCodecFactory::FakeResponse>();
        response->status_ = {static_cast<int>(status.code()), status.code() == StatusCode::kOk};
        response->message_ = status.message();
        return response;
      }));

  EXPECT_CALL(*factory_context_.server_factory_context_.access_log_manager_.file_,
              write("host-value /path-value method-value protocol-value request-value "
                    "response-value - 2 test_detail"));

  EXPECT_CALL(factory_context_.drain_manager_, drainClose()).WillOnce(Return(false));
  EXPECT_CALL(filter_callbacks_.connection_.dispatcher_, deferredDelete_(_));

  EXPECT_CALL(filter_callbacks_.connection_, write(BufferStringEqual("test"), false));

  EXPECT_CALL(*server_codec_, encode(_, _))
      .WillOnce(Invoke([&](const StreamFrame& response, EncodingCallbacks& callback) {
        Buffer::OwnedImpl buffer;
        EXPECT_EQ(dynamic_cast<const Response*>(&response)->status().code(),
                  static_cast<uint32_t>(StatusCode::kUnknown));
        buffer.add("test");
        callback.onEncodingSuccess(buffer, true);
      }));

  active_stream->sendLocalReply(
      Status(StatusCode::kUnknown, "test_detail"), {},
      [](StreamResponse& response) { response.set("response-key", "response-value"); });

  EXPECT_EQ(filter_config_->stats().downstream_rq_total_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_active_.value(), 0);
  EXPECT_EQ(filter_config_->stats().downstream_rq_local_.value(), 1);
}

TEST_F(FilterTest, ActiveStreamCompleteDirectly) {
  initializeFilter();

  auto request = std::make_unique<FakeStreamCodecFactory::FakeRequest>();

  filter_->onDecodingSuccess(std::move(request));
  EXPECT_EQ(1, filter_->activeStreamsForTest().size());

  EXPECT_EQ(filter_config_->stats().downstream_rq_total_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_active_.value(), 1);

  auto active_stream = filter_->activeStreamsForTest().begin()->get();

  active_stream->completeDirectly();

  EXPECT_EQ(filter_config_->stats().downstream_rq_total_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_active_.value(), 0);

  EXPECT_EQ(0, filter_->activeStreamsForTest().size());
}

TEST_F(FilterTest, ActiveStreamCompleteDirectlyFromFilter) {
  mock_stream_filters_.push_back({"mock_0", std::make_shared<NiceMock<MockStreamFilter>>()});

  initializeFilter();

  auto request = std::make_unique<FakeStreamCodecFactory::FakeRequest>();

  filter_->onDecodingSuccess(std::move(request));
  EXPECT_EQ(1, filter_->activeStreamsForTest().size());

  EXPECT_EQ(filter_config_->stats().downstream_rq_total_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_active_.value(), 1);

  auto active_stream = filter_->activeStreamsForTest().begin()->get();

  active_stream->decoderFiltersForTest()[0]->completeDirectly();

  EXPECT_EQ(filter_config_->stats().downstream_rq_total_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_active_.value(), 0);

  EXPECT_EQ(0, filter_->activeStreamsForTest().size());
}

TEST_F(FilterTest, NewStreamAndReplyNormally) {
  auto mock_decoder_filter_0 = std::make_shared<NiceMock<MockDecoderFilter>>();
  mock_decoder_filters_ = {{"mock_0", mock_decoder_filter_0}};

  // The logger is used to test the log format.
  initializeFilter(false, loggerFormFormat());

  auto request = std::make_unique<FakeStreamCodecFactory::FakeRequest>();
  request->host_ = "host-value";
  request->path_ = "/path-value";
  request->method_ = "method-value";
  request->protocol_ = "protocol-value";
  request->data_["request-key"] = "request-value";

  filter_->onDecodingSuccess(std::move(request));
  EXPECT_EQ(1, filter_->activeStreamsForTest().size());

  EXPECT_EQ(filter_config_->stats().downstream_rq_total_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_active_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_error_.value(), 0);
  EXPECT_EQ(filter_config_->stats().downstream_rq_reset_.value(), 0);

  auto active_stream = filter_->activeStreamsForTest().begin()->get();

  EXPECT_CALL(filter_callbacks_.connection_, write(BufferStringEqual("test"), false));

  EXPECT_CALL(*server_codec_, encode(_, _))
      .WillOnce(Invoke([&](const StreamFrame&, EncodingCallbacks& callback) {
        Buffer::OwnedImpl buffer;
        buffer.add("test");
        callback.onEncodingSuccess(buffer, true);
      }));

  EXPECT_CALL(*factory_context_.server_factory_context_.access_log_manager_.file_,
              write("host-value /path-value method-value protocol-value request-value "
                    "response-value - 0 via_upstream"));

  EXPECT_CALL(factory_context_.drain_manager_, drainClose()).WillOnce(Return(false));
  EXPECT_CALL(filter_callbacks_.connection_.dispatcher_, deferredDelete_(_));

  auto response = std::make_unique<FakeStreamCodecFactory::FakeResponse>();
  response->status_ = {0, true};
  response->data_["response-key"] = "response-value";

  active_stream->onResponseStart(std::move(response));

  EXPECT_EQ(filter_config_->stats().downstream_rq_total_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_active_.value(), 0);
  EXPECT_EQ(filter_config_->stats().downstream_rq_error_.value(), 0);
  EXPECT_EQ(filter_config_->stats().downstream_rq_reset_.value(), 0);
  EXPECT_EQ(
      factory_context_.store_.counter("generic_proxy.test_prefix.downstream_rq_code.0").value(), 1);
}

TEST_F(FilterTest, NewStreamAndReplyNormallyWithMultipleFrames) {
  auto mock_decoder_filter_0 = std::make_shared<NiceMock<MockDecoderFilter>>();
  mock_decoder_filters_ = {{"mock_0", mock_decoder_filter_0}};

  NiceMock<MockStreamFrameHandler> mock_stream_frame_handler;

  EXPECT_CALL(*mock_decoder_filter_0, setDecoderFilterCallbacks(_))
      .WillOnce(Invoke([&mock_stream_frame_handler](DecoderFilterCallback& callbacks) {
        callbacks.setRequestFramesHandler(mock_stream_frame_handler);
      }));

  // The logger is used to test the log format.
  initializeFilter(false, loggerFormFormat());

  auto request = std::make_unique<FakeStreamCodecFactory::FakeRequest>();
  request->host_ = "host-value";
  request->path_ = "/path-value";
  request->method_ = "method-value";
  request->protocol_ = "protocol-value";
  request->data_["request-key"] = "request-value";
  request->stream_frame_flags_ = FrameFlags(StreamFlags(), false);

  // The first frame is not the end stream and we will create a frame handler for it.
  filter_->onDecodingSuccess(std::move(request));
  EXPECT_EQ(1, filter_->activeStreamsForTest().size());
  EXPECT_EQ(1, filter_->frameHandlersForTest().size());

  EXPECT_EQ(filter_config_->stats().downstream_rq_total_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_active_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_error_.value(), 0);

  // stream_frame_handler will be called twice to handle the two frames (except the first
  // StreamRequest frame).
  EXPECT_CALL(mock_stream_frame_handler, onStreamFrame(_)).Times(2);

  auto request_frame_1 = std::make_unique<FakeStreamCodecFactory::FakeRequest>();
  request_frame_1->stream_frame_flags_ = FrameFlags(StreamFlags(), false);
  filter_->onDecodingSuccess(std::move(request_frame_1));
  EXPECT_EQ(1, filter_->activeStreamsForTest().size());
  EXPECT_EQ(1, filter_->frameHandlersForTest().size());

  // When the last frame is the end stream, we will delete the frame handler.
  auto request_frame_2 = std::make_unique<FakeStreamCodecFactory::FakeRequest>();
  request_frame_2->stream_frame_flags_ = FrameFlags(StreamFlags(), true);
  filter_->onDecodingSuccess(std::move(request_frame_2));
  EXPECT_EQ(1, filter_->activeStreamsForTest().size());
  EXPECT_EQ(0, filter_->frameHandlersForTest().size());

  auto active_stream = filter_->activeStreamsForTest().begin()->get();

  EXPECT_CALL(*factory_context_.server_factory_context_.access_log_manager_.file_,
              write("host-value /path-value method-value protocol-value request-value "
                    "response-value - 123 via_upstream"));

  EXPECT_CALL(factory_context_.drain_manager_, drainClose()).WillOnce(Return(false));
  EXPECT_CALL(filter_callbacks_.connection_.dispatcher_, deferredDelete_(_));

  EXPECT_CALL(filter_callbacks_.connection_, write(BufferStringEqual("test"), false)).Times(2);
  EXPECT_CALL(*server_codec_, encode(_, _))
      .Times(2)
      .WillRepeatedly(Invoke([&](const StreamFrame& frame, EncodingCallbacks& callback) {
        Buffer::OwnedImpl buffer;
        buffer.add("test");
        callback.onEncodingSuccess(buffer, frame.frameFlags().endStream());
      }));

  auto response = std::make_unique<FakeStreamCodecFactory::FakeResponse>();
  response->data_["response-key"] = "response-value";
  response->stream_frame_flags_ = FrameFlags(StreamFlags(), false);
  response->status_ = {123, false}; // Response non-OK.

  active_stream->onResponseStart(std::move(response));

  auto response_frame_1 = std::make_unique<FakeStreamCodecFactory::FakeResponse>();
  response_frame_1->stream_frame_flags_ = FrameFlags(StreamFlags(), true);

  active_stream->onResponseFrame(std::move(response_frame_1));

  EXPECT_EQ(filter_config_->stats().downstream_rq_total_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_active_.value(), 0);
  EXPECT_EQ(filter_config_->stats().downstream_rq_error_.value(), 1);
  EXPECT_EQ(
      factory_context_.store_.counter("generic_proxy.test_prefix.downstream_rq_code.123").value(),
      1);
}

TEST_F(FilterTest, NewStreamAndReplyNormallyWithDrainClose) {
  auto mock_decoder_filter_0 = std::make_shared<NiceMock<MockDecoderFilter>>();
  mock_decoder_filters_ = {{"mock_0", mock_decoder_filter_0}};

  initializeFilter();

  auto request = std::make_unique<FakeStreamCodecFactory::FakeRequest>();

  filter_->onDecodingSuccess(std::move(request));
  EXPECT_EQ(1, filter_->activeStreamsForTest().size());

  EXPECT_EQ(filter_config_->stats().downstream_rq_total_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_active_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_error_.value(), 0);

  auto active_stream = filter_->activeStreamsForTest().begin()->get();

  EXPECT_CALL(filter_callbacks_.connection_, write(BufferStringEqual("test"), false));

  EXPECT_CALL(*server_codec_, encode(_, _))
      .WillOnce(Invoke([&](const StreamFrame&, EncodingCallbacks& callback) {
        Buffer::OwnedImpl buffer;
        buffer.add("test");
        callback.onEncodingSuccess(buffer, true);
      }));

  EXPECT_CALL(factory_context_.drain_manager_, drainClose()).WillOnce(Return(true));
  EXPECT_CALL(filter_callbacks_.connection_.dispatcher_, deferredDelete_(_));
  EXPECT_CALL(filter_callbacks_.connection_, close(Network::ConnectionCloseType::FlushWrite));

  auto response = std::make_unique<FakeStreamCodecFactory::FakeResponse>();
  response->status_ = {234, false}; // Response non-OK.
  active_stream->streamInfo().setResponseFlag(StreamInfo::ResponseFlag::UpstreamProtocolError);
  active_stream->onResponseStart(std::move(response));

  EXPECT_EQ(filter_config_->stats().downstream_rq_total_.value(), 1);
  EXPECT_EQ(filter_config_->stats().downstream_rq_active_.value(), 0);
  EXPECT_EQ(filter_config_->stats().downstream_rq_error_.value(), 1);
  EXPECT_EQ(
      factory_context_.store_.counter("generic_proxy.test_prefix.downstream_rq_code.234").value(),
      1);
  EXPECT_EQ(
      factory_context_.store_.counter("generic_proxy.test_prefix.downstream_rq_flag.UPE").value(),
      1);
}

TEST_F(FilterTest, NewStreamAndReplyNormallyWithStreamDrainClose) {
  auto mock_decoder_filter_0 = std::make_shared<NiceMock<MockDecoderFilter>>();
  mock_decoder_filters_ = {{"mock_0", mock_decoder_filter_0}};

  initializeFilter();

  auto request = std::make_unique<FakeStreamCodecFactory::FakeRequest>();

  filter_->onDecodingSuccess(std::move(request));
  EXPECT_EQ(1, filter_->activeStreamsForTest().size());

  auto active_stream = filter_->activeStreamsForTest().begin()->get();

  EXPECT_CALL(filter_callbacks_.connection_, write(BufferStringEqual("test"), false));

  EXPECT_CALL(*server_codec_, encode(_, _))
      .WillOnce(Invoke([&](const StreamFrame&, EncodingCallbacks& callback) {
        Buffer::OwnedImpl buffer;
        buffer.add("test");
        callback.onEncodingSuccess(buffer, true);
      }));

  // The drain close of factory_context_.drain_manager_ is false, but the drain close of
  // active_stream is true.
  EXPECT_CALL(factory_context_.drain_manager_, drainClose()).WillOnce(Return(false));
  EXPECT_CALL(filter_callbacks_.connection_.dispatcher_, deferredDelete_(_));
  EXPECT_CALL(filter_callbacks_.connection_, close(Network::ConnectionCloseType::FlushWrite));

  auto response = std::make_unique<FakeStreamCodecFactory::FakeResponse>();
  response->stream_frame_flags_ = FrameFlags(StreamFlags(0, false, true, false), true);
  active_stream->onResponseStart(std::move(response));
}

TEST_F(FilterTest, NewStreamAndReplyNormallyWithTracing) {
  auto mock_decoder_filter_0 = std::make_shared<NiceMock<MockDecoderFilter>>();
  mock_decoder_filters_ = {{"mock_0", mock_decoder_filter_0}};

  initializeFilter(true);

  auto request = std::make_unique<FakeStreamCodecFactory::FakeRequest>();

  auto* span = new NiceMock<Tracing::MockSpan>();
  EXPECT_CALL(*tracer_, startSpan_(_, _, _, _))
      .WillOnce(
          Invoke([&](const Tracing::Config& config, Tracing::TraceContext&,
                     const StreamInfo::StreamInfo&, const Tracing::Decision) -> Tracing::Span* {
            EXPECT_EQ(Tracing::OperationName::Egress, config.operationName());
            return span;
          }));

  filter_->onDecodingSuccess(std::move(request));
  EXPECT_EQ(1, filter_->activeStreamsForTest().size());

  auto active_stream = filter_->activeStreamsForTest().begin()->get();

  EXPECT_CALL(*span, setTag(_, _)).Times(testing::AnyNumber());
  EXPECT_CALL(*span, finishSpan());

  EXPECT_CALL(filter_callbacks_.connection_, write(BufferStringEqual("test"), false));

  EXPECT_CALL(*server_codec_, encode(_, _))
      .WillOnce(Invoke([&](const StreamFrame&, EncodingCallbacks& callback) {
        Buffer::OwnedImpl buffer;
        buffer.add("test");
        callback.onEncodingSuccess(buffer, true);
      }));

  EXPECT_CALL(factory_context_.drain_manager_, drainClose()).WillOnce(Return(false));
  EXPECT_CALL(filter_callbacks_.connection_.dispatcher_, deferredDelete_(_));

  auto response = std::make_unique<FakeStreamCodecFactory::FakeResponse>();
  active_stream->onResponseStart(std::move(response));
}

} // namespace
} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/generic_proxy/filters/network/test/fake_codec.h"

#include <memory>

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

ServerCodecPtr FakeStreamCodecFactory::createServerCodec() const {
  return std::make_unique<FakeServerCodec>();
}

ClientCodecPtr FakeStreamCodecFactory::createClientCodec() const {
  return std::make_unique<FakeClientCodec>();
}

CodecFactoryPtr
FakeStreamCodecFactoryConfig::createCodecFactory(const Protobuf::Message&,
                                                 Envoy::Server::Configuration::FactoryContext&) {
  return std::make_unique<FakeStreamCodecFactory>();
}

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include <memory>

#include "test/mocks/server/factory_context.h"

#include "contrib/generic_proxy/filters/network/source/match.h"
#include "contrib/generic_proxy/filters/network/test/fake_codec.h"
#include "gtest/gtest.h"

using testing::NiceMock;

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {
namespace {

TEST(ServiceMatchDataInputTest, ServiceMatchDataInputTest) {
  NiceMock<Server::Configuration::MockFactoryContext> factory_context;
  ServiceMatchDataInputFactory factory;
  auto proto_config = factory.createEmptyConfigProto();
  auto input =
      factory.createDataInputFactoryCb(*proto_config, factory_context.messageValidationVisitor())();

  FakeStreamCodecFactory::FakeRequest request;

  EXPECT_EQ("", absl::get<std::string>(input->get(request).data_));

  request.host_ = "fake_host_as_service";

  EXPECT_EQ("fake_host_as_service", absl::get<std::string>(input->get(request).data_));
}

TEST(HostMatchDataInputTest, HostMatchDataInputTest) {
  NiceMock<Server::Configuration::MockFactoryContext> factory_context;
  HostMatchDataInputFactory factory;
  auto proto_config = factory.createEmptyConfigProto();
  auto input =
      factory.createDataInputFactoryCb(*proto_config, factory_context.messageValidationVisitor())();

  FakeStreamCodecFactory::FakeRequest request;

  EXPECT_EQ("", absl::get<std::string>(input->get(request).data_));

  request.host_ = "fake_host_as_service";

  EXPECT_EQ("fake_host_as_service", absl::get<std::string>(input->get(request).data_));
}

TEST(PathMatchDataInputTest, PathMatchDataInputTest) {
  NiceMock<Server::Configuration::MockFactoryContext> factory_context;
  PathMatchDataInputFactory factory;
  auto proto_config = factory.createEmptyConfigProto();
  auto input =
      factory.createDataInputFactoryCb(*proto_config, factory_context.messageValidationVisitor())();

  FakeStreamCodecFactory::FakeRequest request;

  EXPECT_EQ("", absl::get<std::string>(input->get(request).data_));

  request.path_ = "fake_path";

  EXPECT_EQ("fake_path", absl::get<std::string>(input->get(request).data_));
}

TEST(MethodMatchDataInputTest, MethodMatchDataInputTest) {
  NiceMock<Server::Configuration::MockFactoryContext> factory_context;
  MethodMatchDataInputFactory factory;
  auto proto_config = factory.createEmptyConfigProto();
  auto input =
      factory.createDataInputFactoryCb(*proto_config, factory_context.messageValidationVisitor())();

  FakeStreamCodecFactory::FakeRequest request;

  EXPECT_EQ("", absl::get<std::string>(input->get(request).data_));

  request.method_ = "fake_method";

  EXPECT_EQ("fake_method", absl::get<std::string>(input->get(request).data_));
}

TEST(PropertyMatchDataInputTest, PropertyMatchDataInputTest) {
  NiceMock<Server::Configuration::MockFactoryContext> factory_context;
  PropertyMatchDataInputFactory factory;
  auto proto_config = factory.createEmptyConfigProto();

  auto& typed_proto_config = static_cast<PropertyDataInputProto&>(*proto_config);

  typed_proto_config.set_property_name("key_0");

  auto input =
      factory.createDataInputFactoryCb(*proto_config, factory_context.messageValidationVisitor())();

  FakeStreamCodecFactory::FakeRequest request;

  EXPECT_TRUE(absl::holds_alternative<absl::monostate>(input->get(request).data_));

  request.data_["key_0"] = "value_0";

  EXPECT_EQ("value_0", absl::get<std::string>(input->get(request).data_));
}

TEST(RequestMatchDataInputTest, RequestMatchDataInputTest) {
  NiceMock<Server::Configuration::MockFactoryContext> factory_context;
  RequestMatchDataInputFactory factory;
  auto proto_config = factory.createEmptyConfigProto();
  auto input =
      factory.createDataInputFactoryCb(*proto_config, factory_context.messageValidationVisitor())();

  FakeStreamCodecFactory::FakeRequest request;

  EXPECT_EQ(
      &request,
      &dynamic_cast<const RequestMatchData*>(
           absl::get<std::shared_ptr<Matcher::CustomMatchData>>(input->get(request).data_).get())
           ->request());
}

TEST(RequestMatchInputMatcherTest, RequestMatchInputMatcherTest) {
  NiceMock<Server::Configuration::MockFactoryContext> factory_context;
  RequestMatchDataInputMatcherFactory factory;
  auto proto_config = factory.createEmptyConfigProto();
  auto matcher =
      factory.createInputMatcherFactoryCb(*proto_config, factory_context.serverFactoryContext())();

  {
    Matcher::MatchingDataType input;
    EXPECT_FALSE(matcher->match(input));
  }

  {
    Matcher::MatchingDataType input = std::string("fake_data");
    EXPECT_FALSE(matcher->match(input));
  }

  {
    FakeStreamCodecFactory::FakeRequest request;
    Matcher::MatchingDataType input = std::make_shared<RequestMatchData>(request);
    EXPECT_TRUE(matcher->match(input));
  }
}

TEST(RequestMatchInputMatcherTest, SpecificRequestMatchInputMatcherTest) {
  // Empty matcher.
  {
    RequestMatcherProto matcher_proto;
    RequestMatchInputMatcher matcher(matcher_proto);

    FakeStreamCodecFactory::FakeRequest request;
    EXPECT_TRUE(matcher.match(request));
  }

  // Host match failed.
  {
    RequestMatcherProto matcher_proto;

    const std::string config_yaml = R"EOF(
    host:
      exact: fake_host
    )EOF";

    TestUtility::loadFromYaml(config_yaml, matcher_proto);

    RequestMatchInputMatcher matcher(matcher_proto);

    FakeStreamCodecFactory::FakeRequest request;
    request.host_ = "another_fake_host";
    EXPECT_FALSE(matcher.match(request));
  }

  // Path match failed.
  {
    RequestMatcherProto matcher_proto;

    const std::string config_yaml = R"EOF(
    host:
      exact: fake_host
    path:
      exact: fake_path
    )EOF";

    TestUtility::loadFromYaml(config_yaml, matcher_proto);

    RequestMatchInputMatcher matcher(matcher_proto);

    FakeStreamCodecFactory::FakeRequest request;
    request.host_ = "fake_host";
    request.path_ = "another_fake_path";
    EXPECT_FALSE(matcher.match(request));
  }

  // Method match failed.
  {
    RequestMatcherProto matcher_proto;

    const std::string config_yaml = R"EOF(
    host:
      exact: fake_host
    path:
      exact: fake_path
    method:
      exact: fake_method
    )EOF";

    TestUtility::loadFromYaml(config_yaml, matcher_proto);

    RequestMatchInputMatcher matcher(matcher_proto);

    FakeStreamCodecFactory::FakeRequest request;
    request.host_ = "fake_host";
    request.path_ = "fake_path";
    request.method_ = "another_fake_method";
    EXPECT_FALSE(matcher.match(request));
  }

  // Property match failed.
  {
    RequestMatcherProto matcher_proto;

    const std::string config_yaml = R"EOF(
    host:
      exact: fake_host
    path:
      exact: fake_path
    method:
      exact: fake_method
    properties:
      - name: key_0
        string_match:
          exact: value_0
    )EOF";

    TestUtility::loadFromYaml(config_yaml, matcher_proto);

    RequestMatchInputMatcher matcher(matcher_proto);

    FakeStreamCodecFactory::FakeRequest request;
    request.host_ = "fake_host";
    request.path_ = "fake_path";
    request.method_ = "fake_method";
    request.data_["key_0"] = "another_value_0";
    EXPECT_FALSE(matcher.match(request));
  }

  // All match.
  {
    RequestMatcherProto matcher_proto;

    const std::string config_yaml = R"EOF(
    host:
      exact: fake_host
    path:
      exact: fake_path
    method:
      exact: fake_method
    properties:
      - name: key_0
        string_match:
          exact: value_0
    )EOF";

    TestUtility::loadFromYaml(config_yaml, matcher_proto);

    RequestMatchInputMatcher matcher(matcher_proto);

    FakeStreamCodecFactory::FakeRequest request;
    request.host_ = "fake_host";
    request.path_ = "fake_path";
    request.method_ = "fake_method";
    request.data_["key_0"] = "value_0";
    EXPECT_TRUE(matcher.match(request));
  }
}

} // namespace
} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include <memory>

#include "source/common/config/metadata.h"

#include "test/mocks/server/factory_context.h"
#include "test/test_common/registry.h"
#include "test/test_common/test_runtime.h"
#include "test/test_common/utility.h"

#include "contrib/generic_proxy/filters/network/source/match.h"
#include "contrib/generic_proxy/filters/network/source/route.h"
#include "contrib/generic_proxy/filters/network/test/fake_codec.h"
#include "contrib/generic_proxy/filters/network/test/mocks/filter.h"
#include "contrib/generic_proxy/filters/network/test/mocks/route.h"
#include "gtest/gtest.h"

using testing::Invoke;
using testing::NiceMock;

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {
namespace {

class RouteEntryImplTest : public testing::Test {
public:
  class RouteConfig : public RouteSpecificFilterConfig {};

  void initialize(const std::string& yaml_config) {
    ProtoRouteAction proto_config;
    TestUtility::loadFromYaml(yaml_config, proto_config);

    route_ = std::make_shared<RouteEntryImpl>(proto_config, server_context_);
  }

protected:
  NiceMock<MockStreamFilterConfig> filter_config_;

  absl::flat_hash_map<std::string, RouteSpecificFilterConfigConstSharedPtr> route_config_map_;

  NiceMock<Server::Configuration::MockServerFactoryContext> server_context_;
  RouteEntryConstSharedPtr route_;
};

/**
 * Test the method that get cluster name from route entry.
 */
TEST_F(RouteEntryImplTest, SimpleClusterName) {
  const std::string yaml_config = R"EOF(
    cluster: cluster_0
  )EOF";
  initialize(yaml_config);

  EXPECT_EQ(route_->clusterName(), "cluster_0");
};

/**
 * Test the method that get filter metadata from the route entry.
 */
TEST_F(RouteEntryImplTest, RouteMetadata) {
  const std::string yaml_config = R"EOF(
    cluster: cluster_0
    metadata:
      filter_metadata:
        mock_filter:
          key_0: value_0
  )EOF";
  initialize(yaml_config);

  EXPECT_EQ(
      "value_0",
      Config::Metadata::metadataValue(&route_->metadata(), "mock_filter", "key_0").string_value());
};

struct Foo : public Envoy::Config::TypedMetadata::Object {};
struct Baz : public Envoy::Config::TypedMetadata::Object {
  Baz(std::string n) : name(n) {}
  std::string name;
};
class BazFactory : public RouteTypedMetadataFactory {
public:
  std::string name() const override { return "baz"; }
  // Returns nullptr (conversion failure) if d is empty.
  std::unique_ptr<const Envoy::Config::TypedMetadata::Object>
  parse(const ProtobufWkt::Struct& d) const override {
    if (d.fields().find("name") != d.fields().end()) {
      return std::make_unique<Baz>(d.fields().at("name").string_value());
    }
    throw EnvoyException("Cannot create a Baz when metadata is empty.");
  }

  std::unique_ptr<const Envoy::Config::TypedMetadata::Object>
  parse(const ProtobufWkt::Any&) const override {
    return nullptr;
  }
};

/**
 * Test the method that get filter metadata from the route entry.
 */
TEST_F(RouteEntryImplTest, RouteTypedMetadata) {
  BazFactory baz_factory;
  Registry::InjectFactory<RouteTypedMetadataFactory> registered_factory(baz_factory);

  const std::string yaml_config = R"EOF(
    cluster: cluster_0
    metadata:
      filter_metadata:
        foo:
          key_0: value_0
        baz:
          name: baz_name
  )EOF";
  initialize(yaml_config);

  // Only get valid value when type and name are matched.
  EXPECT_EQ("baz_name", route_->typedMetadata().get<Baz>(baz_factory.name())->name);

  EXPECT_EQ(nullptr, route_->typedMetadata().get<Foo>(baz_factory.name()));
  EXPECT_EQ(nullptr, route_->typedMetadata().get<Baz>("foo"));
  EXPECT_EQ(nullptr, route_->typedMetadata().get<Foo>("foo"));
};

/**
 * Test the method that get route level per filter config from the route entry. This test also
 * verifies that the proto per filter config can be loaded correctly.
 */
TEST_F(RouteEntryImplTest, RoutePerFilterConfig) {
  ON_CALL(filter_config_, createEmptyRouteConfigProto()).WillByDefault(Invoke([]() {
    return std::make_unique<ProtobufWkt::Struct>();
  }));
  Registry::InjectFactory<NamedFilterConfigFactory> registration(filter_config_);

  ON_CALL(filter_config_, createRouteSpecificFilterConfig(_, _, _))
      .WillByDefault(
          Invoke([this](const Protobuf::Message&, Server::Configuration::ServerFactoryContext&,
                        ProtobufMessage::ValidationVisitor&) {
            auto route_config = std::make_shared<RouteConfig>();
            route_config_map_.emplace(filter_config_.name(), route_config);
            return route_config;
          }));

  const std::string yaml_config = R"EOF(
    cluster: cluster_0
    per_filter_config:
      envoy.filters.generic.mock_filter:
        "@type": type.googleapis.com/google.protobuf.Struct
        value: { "key_0": "value_0" }
  )EOF";
  initialize(yaml_config);

  EXPECT_EQ(route_->perFilterConfig("envoy.filters.generic.mock_filter"),
            route_config_map_.at("envoy.filters.generic.mock_filter").get());
};

/**
 * Test the method that get route level per filter config from the route entry. In this case,
 * unexpected type is used to find the filter factory and finally an exception is thrown.
 */
TEST_F(RouteEntryImplTest, RoutePerFilterConfigWithUnknownType) {
  ON_CALL(filter_config_, createEmptyRouteConfigProto()).WillByDefault(Invoke([]() {
    return std::make_unique<ProtobufWkt::Struct>();
  }));
  Registry::InjectFactory<NamedFilterConfigFactory> registration(filter_config_);

  const std::string yaml_config = R"EOF(
    cluster: cluster_0
    per_filter_config:
      envoy.filters.generic.mock_filter:
        # The mock filter is registered with the type of google.protobuf.Struct.
        # So the google.protobuf.Value cannot be used to find the mock filter.
        "@type": type.googleapis.com/google.protobuf.Value
        value: { "key_0": "value_0" }
  )EOF";

  // The configuraton will be rejected because the extension cannot be found.
  EXPECT_THROW_WITH_MESSAGE(
      { initialize(yaml_config); }, EnvoyException,
      "Didn't find a registered implementation for 'envoy.filters.generic.mock_filter' with type "
      "URL: 'google.protobuf.Value'");
}

/**
 * Test the method that get route level per filter config from the route entry. In this case,
 * unexpected type is used to find the filter factory. But the extension lookup by name is enabled
 * and the mock filter is found.
 */
TEST_F(RouteEntryImplTest, RoutePerFilterConfigWithUnknownTypeButEnableExtensionLookupByName) {
  TestScopedRuntime scoped_runtime;
  scoped_runtime.mergeValues({{"envoy.reloadable_features.no_extension_lookup_by_name", "false"}});

  ON_CALL(filter_config_, createEmptyRouteConfigProto()).WillByDefault(Invoke([]() {
    return std::make_unique<ProtobufWkt::Struct>();
  }));
  Registry::InjectFactory<NamedFilterConfigFactory> registration(filter_config_);

  ON_CALL(filter_config_, createRouteSpecificFilterConfig(_, _, _))
      .WillByDefault(
          Invoke([this](const Protobuf::Message&, Server::Configuration::ServerFactoryContext&,
                        ProtobufMessage::ValidationVisitor&) {
            auto route_config = std::make_shared<RouteConfig>();
            route_config_map_.emplace(filter_config_.name(), route_config);
            return route_config;
          }));

  const std::string yaml_config = R"EOF(
    cluster: cluster_0
    per_filter_config:
      envoy.filters.generic.mock_filter:
        # The mock filter is registered with the type of google.protobuf.Struct.
        # So the google.protobuf.Value cannot be used to find the mock filter.
        "@type": type.googleapis.com/xds.type.v3.TypedStruct
        type_url: type.googleapis.com/google.protobuf.Value
        value:
          value: { "key_0": "value_0" }
  )EOF";

  initialize(yaml_config);

  EXPECT_EQ(route_->perFilterConfig("envoy.filters.generic.mock_filter"),
            route_config_map_.at("envoy.filters.generic.mock_filter").get());
}

/**
 * Test the case where there is no route level proto available for the filter.
 */
TEST_F(RouteEntryImplTest, NullRouteEmptyProto) {
  ON_CALL(filter_config_, createEmptyRouteConfigProto()).WillByDefault(Invoke([]() {
    return nullptr;
  }));
  Registry::InjectFactory<NamedFilterConfigFactory> registration(filter_config_);

  const std::string yaml_config = R"EOF(
    cluster: cluster_0
    per_filter_config:
      envoy.filters.generic.mock_filter:
        "@type": type.googleapis.com/google.protobuf.Struct
        value: { "key_0": "value_0" }
  )EOF";
  initialize(yaml_config);

  EXPECT_EQ(route_->perFilterConfig("envoy.filters.generic.mock_filter"), nullptr);
};

/**
 * Test the case where there is no route level config available for the filter.
 */
TEST_F(RouteEntryImplTest, NullRouteSpecificConfig) {
  Registry::InjectFactory<NamedFilterConfigFactory> registration(filter_config_);
  ON_CALL(filter_config_, createEmptyRouteConfigProto()).WillByDefault(Invoke([]() {
    return std::make_unique<ProtobufWkt::Struct>();
  }));

  const std::string yaml_config = R"EOF(
    cluster: cluster_0
    per_filter_config:
      envoy.filters.generic.mock_filter:
        "@type": type.googleapis.com/google.protobuf.Struct
        value: { "key_0": "value_0" }
  )EOF";
  initialize(yaml_config);

  EXPECT_EQ(route_->perFilterConfig("envoy.filters.generic.mock_filter"), nullptr);
};

/**
 * Test the simple route action wrapper.
 */
TEST(RouteMatchActionTest, SimpleRouteMatchActionTest) {
  auto entry = std::make_shared<NiceMock<MockRouteEntry>>();
  RouteMatchAction action(entry);

  EXPECT_EQ(action.route().get(), entry.get());
}

/**
 * Test the simple data input validator.
 */
TEST(RouteActionValidationVisitorTest, SimpleRouteActionValidationVisitorTest) {
  RouteActionValidationVisitor visitor;
  ServiceMatchDataInputFactory factory;

  EXPECT_EQ(visitor.performDataInputValidation(factory, ""), absl::OkStatus());
}

/**
 * Test the route match action factory.
 */
TEST(RouteMatchActionFactoryTest, SimpleRouteMatchActionFactoryTest) {
  RouteMatchActionFactory factory;
  NiceMock<Server::Configuration::MockServerFactoryContext> server_context;

  EXPECT_EQ("envoy.matching.action.generic_proxy.route", factory.name());

  EXPECT_EQ(factory.createEmptyConfigProto()->GetTypeName(), ProtoRouteAction().GetTypeName());

  const std::string yaml_config = R"EOF(
    cluster: cluster_0
    metadata:
      filter_metadata:
        mock_filter:
          key_0: value_0
  )EOF";
  ProtoRouteAction proto_config;
  TestUtility::loadFromYaml(yaml_config, proto_config);
  RouteActionContext context{server_context};

  auto factory_cb = factory.createActionFactoryCb(proto_config, context,
                                                  server_context.messageValidationVisitor());

  EXPECT_EQ(factory_cb()->getTyped<RouteMatchAction>().route().get(),
            factory_cb()->getTyped<RouteMatchAction>().route().get());

  EXPECT_EQ(factory_cb()->getTyped<RouteMatchAction>().route()->clusterName(), "cluster_0");
}

class RouteMatcherImplTest : public testing::Test {
public:
  void initialize(const std::string& yaml_config) {
    ProtoRouteConfiguration proto_config;
    TestUtility::loadFromYaml(yaml_config, proto_config);
    route_matcher_ = std::make_unique<RouteMatcherImpl>(proto_config, factory_context_);
  }

protected:
  NiceMock<Server::Configuration::MockServerFactoryContext> factory_context_;

  std::unique_ptr<RouteMatcherImpl> route_matcher_;
};

static const std::string RouteConfigurationYaml = R"EOF(
name: test_matcher_tree
virtual_hosts:
- name: service
  hosts:
  - service_0
  routes:
    matcher_list:
      matchers:
      - predicate:
          and_matcher:
            predicate:
            - single_predicate:
                input:
                  name: envoy.matching.generic_proxy.input.host
                  typed_config:
                    "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.HostMatchInput
                value_match:
                  exact: "service_0"
            - single_predicate:
                input:
                  name: envoy.matching.generic_proxy.input.method
                  typed_config:
                    "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.MethodMatchInput
                value_match:
                  exact: "method_0"
            - or_matcher:
                predicate:
                - single_predicate:
                    input:
                      name: envoy.matching.generic_proxy.input.property
                      typed_config:
                        "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.PropertyMatchInput
                        property_name: "key_0"
                    value_match:
                      exact: "value_0"
                - single_predicate:
                    input:
                      name: envoy.matching.generic_proxy.input.property
                      typed_config:
                        "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.PropertyMatchInput
                        property_name: "key_1"
                    value_match:
                      exact: "value_1"
        on_match:
          action:
            name: envoy.matching.action.generic_proxy.route
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.action.v3.RouteAction
              cluster: "cluster_0"
              metadata:
                filter_metadata:
                  mock_filter:
                    match_service: match_service
- name: prefix
  hosts:
  - "prefix*"
  routes:
    matcher_list:
      matchers:
      - predicate:
          and_matcher:
            predicate:
            - single_predicate:
                input:
                  name: envoy.matching.generic_proxy.input.host
                  typed_config:
                    "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.HostMatchInput
                value_match:
                  exact: "prefix_service_0"
            - single_predicate:
                input:
                  name: envoy.matching.generic_proxy.input.method
                  typed_config:
                    "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.MethodMatchInput
                value_match:
                  exact: "method_0"
            - or_matcher:
                predicate:
                - single_predicate:
                    input:
                      name: envoy.matching.generic_proxy.input.property
                      typed_config:
                        "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.PropertyMatchInput
                        property_name: "key_0"
                    value_match:
                      exact: "value_0"
                - single_predicate:
                    input:
                      name: envoy.matching.generic_proxy.input.property
                      typed_config:
                        "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.PropertyMatchInput
                        property_name: "key_1"
                    value_match:
                      exact: "value_1"
        on_match:
          action:
            name: envoy.matching.action.generic_proxy.route
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.action.v3.RouteAction
              cluster: "cluster_1"
              metadata:
                filter_metadata:
                  mock_filter:
                    match_prefix: match_prefix
- name: suffix
  hosts:
  - "*suffix"
  routes:
    matcher_list:
      matchers:
      - predicate:
          and_matcher:
            predicate:
            - single_predicate:
                input:
                  name: envoy.matching.generic_proxy.input.host
                  typed_config:
                    "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.HostMatchInput
                value_match:
                  exact: "service_0_suffix"
            - single_predicate:
                input:
                  name: envoy.matching.generic_proxy.input.method
                  typed_config:
                    "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.MethodMatchInput
                value_match:
                  exact: "method_0"
            - or_matcher:
                predicate:
                - single_predicate:
                    input:
                      name: envoy.matching.generic_proxy.input.property
                      typed_config:
                        "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.PropertyMatchInput
                        property_name: "key_0"
                    value_match:
                      exact: "value_0"
                - single_predicate:
                    input:
                      name: envoy.matching.generic_proxy.input.property
                      typed_config:
                        "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.PropertyMatchInput
                        property_name: "key_1"
                    value_match:
                      exact: "value_1"
        on_match:
          action:
            name: envoy.matching.action.generic_proxy.route
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.action.v3.RouteAction
              cluster: "cluster_2"
              metadata:
                filter_metadata:
                  mock_filter:
                    match_suffix: match_suffix
- name: catch_all
  hosts:
  - "*"
  routes:
    matcher_list:
      matchers:
      - predicate:
          single_predicate:
            input:
              name: envoy.matching.generic_proxy.input.property
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.PropertyMatchInput
                property_name: "catch_all"
            value_match:
              exact: "catch_all"
        on_match:
          action:
            name: envoy.matching.action.generic_proxy.route
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.action.v3.RouteAction
              cluster: "cluster_3"
              metadata:
                filter_metadata:
                  mock_filter:
                    catch_all: catch_all
)EOF";

/**
 * Test the simple name method.
 */
TEST_F(RouteMatcherImplTest, SimpleNameMethod) {
  initialize(RouteConfigurationYaml);
  EXPECT_EQ(route_matcher_->name(), "test_matcher_tree");
}

/**
 * Test the case where the request matches a route entry in the matching tree.
 */
TEST_F(RouteMatcherImplTest, RouteMatch) {
  initialize(RouteConfigurationYaml);

  // Exact host searching.
  {
    FakeStreamCodecFactory::FakeRequest fake_request_0;
    fake_request_0.host_ = "service_0";
    fake_request_0.method_ = "method_0";
    fake_request_0.data_.insert({"key_0", "value_0"});

    FakeStreamCodecFactory::FakeRequest fake_request_1;
    fake_request_1.host_ = "service_0";
    fake_request_1.method_ = "method_0";
    fake_request_1.data_.insert({"key_1", "value_1"});

    auto route_entry_0 = route_matcher_->routeEntry(fake_request_0);
    auto route_entry_1 = route_matcher_->routeEntry(fake_request_1);

    EXPECT_EQ(route_entry_0.get(), route_entry_1.get());
    EXPECT_NE(route_entry_0.get(), nullptr);

    EXPECT_EQ(route_entry_0->clusterName(), "cluster_0");
  }

  // Prefix host searching.
  {
    FakeStreamCodecFactory::FakeRequest fake_request_0;
    fake_request_0.host_ = "prefix_service_0";
    fake_request_0.method_ = "method_0";
    fake_request_0.data_.insert({"key_0", "value_0"});

    FakeStreamCodecFactory::FakeRequest fake_request_1;
    fake_request_1.host_ = "prefix_service_0";
    fake_request_1.method_ = "method_0";
    fake_request_1.data_.insert({"key_1", "value_1"});

    auto route_entry_0 = route_matcher_->routeEntry(fake_request_0);
    auto route_entry_1 = route_matcher_->routeEntry(fake_request_1);

    EXPECT_EQ(route_entry_0.get(), route_entry_1.get());
    EXPECT_NE(route_entry_0.get(), nullptr);

    EXPECT_EQ(route_entry_0->clusterName(), "cluster_1");
  }

  // Suffix host searching.
  {
    FakeStreamCodecFactory::FakeRequest fake_request_0;
    fake_request_0.host_ = "service_0_suffix";
    fake_request_0.method_ = "method_0";
    fake_request_0.data_.insert({"key_0", "value_0"});

    FakeStreamCodecFactory::FakeRequest fake_request_1;
    fake_request_1.host_ = "service_0_suffix";
    fake_request_1.method_ = "method_0";
    fake_request_1.data_.insert({"key_1", "value_1"});

    auto route_entry_0 = route_matcher_->routeEntry(fake_request_0);
    auto route_entry_1 = route_matcher_->routeEntry(fake_request_1);

    EXPECT_EQ(route_entry_0.get(), route_entry_1.get());
    EXPECT_NE(route_entry_0.get(), nullptr);

    EXPECT_EQ(route_entry_0->clusterName(), "cluster_2");
  }

  // Catch all host.
  {
    FakeStreamCodecFactory::FakeRequest fake_request_0;
    fake_request_0.host_ = "any_service";
    fake_request_0.method_ = "method_0";
    fake_request_0.data_.insert({"catch_all", "catch_all"});

    FakeStreamCodecFactory::FakeRequest fake_request_1;
    fake_request_1.host_ = "any_service";
    fake_request_1.method_ = "method_0";
    fake_request_1.data_.insert({"catch_all", "catch_all"});

    auto route_entry_0 = route_matcher_->routeEntry(fake_request_0);
    auto route_entry_1 = route_matcher_->routeEntry(fake_request_1);

    EXPECT_EQ(route_entry_0.get(), route_entry_1.get());
    EXPECT_NE(route_entry_0.get(), nullptr);

    EXPECT_EQ(route_entry_0->clusterName(), "cluster_3");
  }
}

/**
 * Test the case where the request not matches any route entry in the matching tree.
 */
TEST_F(RouteMatcherImplTest, RouteNotMatch) {
  initialize(RouteConfigurationYaml);

  // Test the service not match.
  {
    FakeStreamCodecFactory::FakeRequest fake_request;
    fake_request.host_ = "prefix_service_1";
    fake_request.method_ = "method_0";
    fake_request.data_.insert({"key_0", "value_0"});

    EXPECT_EQ(nullptr, route_matcher_->routeEntry(fake_request));
  }

  // Test the method not match.
  {
    FakeStreamCodecFactory::FakeRequest fake_request;
    fake_request.host_ = "service_0";
    fake_request.method_ = "method_x";
    fake_request.data_.insert({"key_0", "value_0"});

    EXPECT_EQ(nullptr, route_matcher_->routeEntry(fake_request));
  }

  // Test the headers not match.
  {
    FakeStreamCodecFactory::FakeRequest fake_request;
    fake_request.host_ = "service_0";
    fake_request.method_ = "method_0";
    EXPECT_EQ(nullptr, route_matcher_->routeEntry(fake_request));
  }
}

static const std::string RouteConfigurationYamlWithUnknownInput = R"EOF(
name: test_matcher_tree
virtual_hosts:
- hosts:
  - "*"
  routes:
    matcher_list:
      matchers:
      - predicate:
          single_predicate:
            input:
              name: envoy.matching.generic_proxy.input.unknown_input
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.UnknownInput
            value_match:
              exact: "service_0"
        on_match:
          action:
            name: envoy.matching.action.generic_proxy.route
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.action.v3.RouteAction
              cluster: "cluster_0"
              metadata:
                filter_metadata:
                  mock_filter:
                    key_0: value_0
)EOF";

TEST_F(RouteMatcherImplTest, RouteConfigurationWithUnknownInput) {
  EXPECT_THROW(initialize(RouteConfigurationYamlWithUnknownInput), EnvoyException);
  EXPECT_EQ(nullptr, route_matcher_.get());
}

static const std::string RouteConfigurationYamlWithoutDefaultHost = R"EOF(
name: test_matcher_tree
virtual_hosts:
- hosts:
  - "service_0"
  routes:
    matcher_list:
      matchers:
      - predicate:
          single_predicate:
            input:
              name: envoy.matching.generic_proxy.input.host
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.HostMatchInput
            value_match:
              exact: "service_0"
        on_match:
          action:
            name: envoy.matching.action.generic_proxy.route
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.action.v3.RouteAction
              cluster: "cluster_0"
              metadata:
                filter_metadata:
                  mock_filter:
                    key_0: value_0
)EOF";

TEST_F(RouteMatcherImplTest, NoHostMatch) {
  initialize(RouteConfigurationYamlWithoutDefaultHost);

  // Test the host not match.
  {
    FakeStreamCodecFactory::FakeRequest fake_request;
    fake_request.host_ = "any_service";
    fake_request.method_ = "method_0";
    fake_request.data_.insert({"key_0", "value_0"});

    EXPECT_EQ(nullptr, route_matcher_->routeEntry(fake_request));
  }
}

static const std::string RouteConfigurationYamlWithRepeatedHost = R"EOF(
name: test_matcher_tree
virtual_hosts:
- hosts:
  - "service_0"
  - "service_0"
  routes:
    matcher_list:
      matchers:
      - predicate:
          single_predicate:
            input:
              name: envoy.matching.generic_proxy.input.host
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.HostMatchInput
            value_match:
              exact: "service_0"
        on_match:
          action:
            name: envoy.matching.action.generic_proxy.route
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.action.v3.RouteAction
              cluster: "cluster_0"
              metadata:
                filter_metadata:
                  mock_filter:
                    key_0: value_0
)EOF";

TEST_F(RouteMatcherImplTest, RouteConfigurationYamlWithRepeatedHost) {
  EXPECT_THROW_WITH_MESSAGE(initialize(RouteConfigurationYamlWithRepeatedHost), EnvoyException,
                            "Only unique values for host are permitted. Duplicate "
                            "entry of domain service_0 in route test_matcher_tree");
  EXPECT_EQ(nullptr, route_matcher_.get());
}

static const std::string RouteConfigurationYamlWithMultipleWildcard = R"EOF(
name: test_matcher_tree
virtual_hosts:
- hosts:
  - "*"
  - "*"
  routes:
    matcher_list:
      matchers:
      - predicate:
          single_predicate:
            input:
              name: envoy.matching.generic_proxy.input.host
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.HostMatchInput
            value_match:
              exact: "service_0"
        on_match:
          action:
            name: envoy.matching.action.generic_proxy.route
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.action.v3.RouteAction
              cluster: "cluster_0"
              metadata:
                filter_metadata:
                  mock_filter:
                    key_0: value_0
)EOF";

TEST_F(RouteMatcherImplTest, RouteConfigurationYamlWithMultipleWildcard) {
  EXPECT_THROW_WITH_MESSAGE(
      initialize(RouteConfigurationYamlWithMultipleWildcard), EnvoyException,
      "Only a single wildcard domain is permitted in route test_matcher_tree");
  EXPECT_EQ(nullptr, route_matcher_.get());
}

static const std::string RouteConfigurationYamlWithMultipleWildcard2 = R"EOF(
name: test_matcher_tree
virtual_hosts:
- hosts:
  - "*"
  routes:
    matcher_list:
      matchers:
      - predicate:
          single_predicate:
            input:
              name: envoy.matching.generic_proxy.input.host
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.HostMatchInput
            value_match:
              exact: "service_0"
        on_match:
          action:
            name: envoy.matching.action.generic_proxy.route
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.action.v3.RouteAction
              cluster: "cluster_0"
              metadata:
                filter_metadata:
                  mock_filter:
                    key_0: value_0
routes:
  matcher_list:
    matchers:
    - predicate:
        single_predicate:
          input:
            name: envoy.matching.generic_proxy.input.host
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.HostMatchInput
          value_match:
            exact: "service_0"
      on_match:
        action:
          name: envoy.matching.action.generic_proxy.route
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.action.v3.RouteAction
            cluster: "cluster_0"
            metadata:
              filter_metadata:
                mock_filter:
                  key_0: value_0
)EOF";

TEST_F(RouteMatcherImplTest, RouteConfigurationYamlWithMultipleWildcard2) {
  EXPECT_THROW_WITH_MESSAGE(initialize(RouteConfigurationYamlWithMultipleWildcard2), EnvoyException,
                            "'routes' cannot be specified at the same time as a "
                            "catch-all ('*') virtual host in route test_matcher_tree");
  EXPECT_EQ(nullptr, route_matcher_.get());
}

static const std::string RouteConfigurationYamlWithEmptyHost = R"EOF(
name: test_matcher_tree
virtual_hosts:
- hosts:
  - ""
  routes:
    matcher_list:
      matchers:
      - predicate:
          single_predicate:
            input:
              name: envoy.matching.generic_proxy.input.host
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.matcher.v3.HostMatchInput
            value_match:
              exact: "service_0"
        on_match:
          action:
            name: envoy.matching.action.generic_proxy.route
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.network.generic_proxy.action.v3.RouteAction
              cluster: "cluster_0"
              metadata:
                filter_metadata:
                  mock_filter:
                    key_0: value_0
)EOF";

TEST_F(RouteMatcherImplTest, RouteConfigurationYamlWithEmptyHost) {
  EXPECT_THROW_WITH_MESSAGE(initialize(RouteConfigurationYamlWithEmptyHost), EnvoyException,
                            "Invalid empty host name in route test_matcher_tree");
  EXPECT_EQ(nullptr, route_matcher_.get());
}

} // namespace
} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
load(
    "//bazel:envoy_build_system.bzl",
    "envoy_cc_test",
    "envoy_cc_test_library",
    "envoy_contrib_package",
)

licenses(["notice"])  # Apache 2

envoy_contrib_package()

envoy_cc_test_library(
    name = "fake_codec_lib",
    srcs = [
        "fake_codec.cc",
    ],
    hdrs = ["fake_codec.h"],
    deps = [
        "//contrib/generic_proxy/filters/network/source/interface:codec_interface",
        "//source/common/buffer:buffer_lib",
    ],
)

envoy_cc_test(
    name = "route_test",
    srcs = [
        "route_test.cc",
    ],
    deps = [
        ":fake_codec_lib",
        "//contrib/generic_proxy/filters/network/source:route_lib",
        "//contrib/generic_proxy/filters/network/test/mocks:filter_mocks",
        "//contrib/generic_proxy/filters/network/test/mocks:route_mocks",
        "//source/common/buffer:buffer_lib",
        "//test/mocks/server:factory_context_mocks",
        "//test/test_common:registry_lib",
        "//test/test_common:test_runtime_lib",
        "//test/test_common:utility_lib",
    ],
)

envoy_cc_test(
    name = "proxy_test",
    srcs = [
        "proxy_test.cc",
    ],
    deps = [
        ":fake_codec_lib",
        "//contrib/generic_proxy/filters/network/source:proxy_lib",
        "//contrib/generic_proxy/filters/network/test/mocks:codec_mocks",
        "//contrib/generic_proxy/filters/network/test/mocks:filter_mocks",
        "//contrib/generic_proxy/filters/network/test/mocks:route_mocks",
        "//source/common/buffer:buffer_lib",
        "//test/mocks/server:factory_context_mocks",
        "//test/test_common:registry_lib",
        "//test/test_common:utility_lib",
    ],
)

envoy_cc_test(
    name = "config_test",
    srcs = [
        "config_test.cc",
    ],
    deps = [
        ":fake_codec_lib",
        "//contrib/generic_proxy/filters/network/source:config",
        "//contrib/generic_proxy/filters/network/test/mocks:codec_mocks",
        "//contrib/generic_proxy/filters/network/test/mocks:filter_mocks",
        "//contrib/generic_proxy/filters/network/test/mocks:route_mocks",
        "//source/common/buffer:buffer_lib",
        "//source/extensions/tracers/zipkin:config",
        "//test/mocks/network:network_mocks",
        "//test/mocks/server:factory_context_mocks",
        "//test/test_common:registry_lib",
        "//test/test_common:test_runtime_lib",
        "//test/test_common:utility_lib",
        "@envoy_api//contrib/envoy/extensions/filters/network/generic_proxy/v3:pkg_cc_proto",
        "@envoy_api//envoy/admin/v3:pkg_cc_proto",
    ],
)

envoy_cc_test(
    name = "integration_test",
    srcs = [
        "integration_test.cc",
    ],
    tags = [
        "cpu:3",
    ],
    deps = [
        ":fake_codec_lib",
        "//contrib/generic_proxy/filters/network/source:config",
        "//contrib/generic_proxy/filters/network/source:proxy_lib",
        "//contrib/generic_proxy/filters/network/test/mocks:codec_mocks",
        "//contrib/generic_proxy/filters/network/test/mocks:filter_mocks",
        "//contrib/generic_proxy/filters/network/test/mocks:route_mocks",
        "//envoy/event:timer_interface",
        "//source/common/buffer:buffer_lib",
        "//source/common/common:thread_annotations",
        "//source/common/network:socket_option_lib",
        "//source/extensions/access_loggers/file:config",
        "//source/extensions/transport_sockets/raw_buffer:config",
        "//test/common/upstream:utility_lib",
        "//test/integration:base_integration_test_lib",
        "//test/mocks/server:factory_context_mocks",
        "//test/mocks/upstream:cluster_info_mocks",
        "//test/test_common:registry_lib",
        "//test/test_common:utility_lib",
    ],
)

envoy_cc_test(
    name = "match_test",
    srcs = [
        "match_test.cc",
    ],
    deps = [
        ":fake_codec_lib",
        "//contrib/generic_proxy/filters/network/source:match_lib",
        "//test/mocks/server:factory_context_mocks",
    ],
)
#include "test/mocks/server/factory_context.h"

#include "contrib/generic_proxy/filters/network/source/router/config.h"
#include "contrib/generic_proxy/filters/network/test/mocks/filter.h"
#include "gtest/gtest.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {
namespace Router {
namespace {

TEST(RouterFactoryTest, RouterFactoryTest) {
  NiceMock<Server::Configuration::MockFactoryContext> factory_context;
  RouterFactory factory;

  envoy::extensions::filters::network::generic_proxy::router::v3::Router proto_config;

  EXPECT_NO_THROW(factory.createFilterFactoryFromProto(proto_config, "test", factory_context));

  EXPECT_NE(nullptr, factory.createEmptyConfigProto());
  EXPECT_EQ(nullptr, factory.createEmptyRouteConfigProto());
  EXPECT_EQ(nullptr, factory.createRouteSpecificFilterConfig(
                         proto_config, factory_context.serverFactoryContext(),
                         factory_context.messageValidationVisitor()));
  EXPECT_EQ("envoy.filters.generic.router", factory.name());
  EXPECT_EQ(true, factory.isTerminalFilter());

  proto_config.set_bind_upstream_connection(true);
  auto fn = factory.createFilterFactoryFromProto(proto_config, "test", factory_context);

  NiceMock<MockFilterChainFactoryCallbacks> mock_cb;

  EXPECT_CALL(mock_cb, addDecoderFilter(_));
  fn(mock_cb);
}

} // namespace
} // namespace Router
} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include <memory>

#include "source/common/tracing/common_values.h"

#include "test/mocks/server/factory_context.h"
#include "test/test_common/registry.h"
#include "test/test_common/utility.h"

#include "contrib/generic_proxy/filters/network/source/router/router.h"
#include "contrib/generic_proxy/filters/network/test/fake_codec.h"
#include "contrib/generic_proxy/filters/network/test/mocks/codec.h"
#include "contrib/generic_proxy/filters/network/test/mocks/filter.h"
#include "contrib/generic_proxy/filters/network/test/mocks/route.h"
#include "gtest/gtest.h"

using testing::ByMove;
using testing::NiceMock;
using testing::Return;
using testing::ReturnRef;

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {
namespace Router {
namespace {

#define ONLY_RUN_TEST_WITH_PARAM(param)                                                            \
  if (GetParam() != param) {                                                                       \
    return;                                                                                        \
  }

struct TestParameters {
  bool operator!=(const TestParameters& other) const {
    return with_tracing != other.with_tracing || bind_upstream != other.bind_upstream;
  }

  bool with_tracing{};
  bool bind_upstream{};
};

class RouterFilterTest : public testing::TestWithParam<TestParameters> {
public:
  RouterFilterTest() {
    // Common mock calls.
    ON_CALL(mock_filter_callback_, dispatcher()).WillByDefault(ReturnRef(dispatcher_));
    ON_CALL(mock_filter_callback_, activeSpan()).WillByDefault(ReturnRef(active_span_));
    ON_CALL(mock_filter_callback_, downstreamCodec()).WillByDefault(ReturnRef(mock_codec_factory_));
    ON_CALL(mock_filter_callback_, streamInfo()).WillByDefault(ReturnRef(mock_stream_info_));
    ON_CALL(mock_filter_callback_, connection())
        .WillByDefault(Return(&mock_downstream_connection_));

    auto parameter = GetParam();

    mock_downstream_connection_.stream_info_.filter_state_ =
        std::make_shared<StreamInfo::FilterStateImpl>(
            StreamInfo::FilterState::LifeSpan::Connection);

    envoy::extensions::filters::network::generic_proxy::router::v3::Router router_config;
    router_config.set_bind_upstream_connection(parameter.bind_upstream);
    config_ = std::make_shared<Router::RouterConfig>(router_config);
    with_tracing_ = parameter.with_tracing;
  }

  void setup(FrameFlags frame_flags = FrameFlags{}) {
    filter_ = std::make_shared<Router::RouterFilter>(config_, factory_context_);
    filter_->setDecoderFilterCallbacks(mock_filter_callback_);

    request_ = std::make_unique<FakeStreamCodecFactory::FakeRequest>();
    request_->stream_frame_flags_ = frame_flags;
  }

  void cleanUp() {
    filter_->onDestroy();
    filter_.reset();
    request_.reset();
  }

  BoundGenericUpstream* boundUpstreamConnection() {
    return mock_downstream_connection_.stream_info_.filter_state_
        ->getDataMutable<BoundGenericUpstream>("envoy.filters.generic.router");
  }

  void expectCreateConnection() {
    creating_connection_ = true;
    // New connection and response decoder will be created for this upstream request.
    auto client_codec = std::make_unique<NiceMock<MockClientCodec>>();
    mock_client_codec_ = client_codec.get();
    EXPECT_CALL(mock_codec_factory_, createClientCodec())
        .WillOnce(Return(ByMove(std::move(client_codec))));
    EXPECT_CALL(*mock_client_codec_, setCodecCallbacks(_))
        .WillOnce(Invoke([this](ClientCodecCallbacks& cb) { client_cb_ = &cb; }));

    EXPECT_CALL(factory_context_.server_factory_context_.cluster_manager_.thread_local_cluster_
                    .tcp_conn_pool_,
                newConnection(_));
  }

  void expectCancelConnect() {
    if (creating_connection_) {
      creating_connection_ = false;

      // Only cancel the connection if it is owned by the upstream request. If the connection is
      // bound to the downstream connection, then this won't be called.
      if (!config_->bindUpstreamConnection()) {
        EXPECT_CALL(factory_context_.server_factory_context_.cluster_manager_.thread_local_cluster_
                        .tcp_conn_pool_.handles_.back(),
                    cancel(_));
      }
    }
  }

  void expectUpstreamConnectionClose() {
    EXPECT_CALL(mock_upstream_connection_, close(Network::ConnectionCloseType::FlushWrite));
  }

  void notifyPoolFailure(Tcp::ConnectionPool::PoolFailureReason reason) {
    if (creating_connection_) {
      creating_connection_ = false;

      if (config_->bindUpstreamConnection()) {
        EXPECT_TRUE(!boundUpstreamConnection()->waitingUpstreamRequestsForTest().empty());
        EXPECT_TRUE(boundUpstreamConnection()->waitingResponseRequestsForTest().empty());
        EXPECT_CALL(mock_downstream_connection_, close(Network::ConnectionCloseType::FlushWrite));
      }

      factory_context_.server_factory_context_.cluster_manager_.thread_local_cluster_.tcp_conn_pool_
          .poolFailure(reason);

      if (config_->bindUpstreamConnection()) {
        EXPECT_TRUE(boundUpstreamConnection()->waitingUpstreamRequestsForTest().empty());
        EXPECT_TRUE(boundUpstreamConnection()->waitingResponseRequestsForTest().empty());
      }
    }
  }

  void notifyPoolReady() {
    if (creating_connection_) {
      creating_connection_ = false;

      if (config_->bindUpstreamConnection()) {
        EXPECT_TRUE(!boundUpstreamConnection()->waitingUpstreamRequestsForTest().empty());
        EXPECT_TRUE(boundUpstreamConnection()->waitingResponseRequestsForTest().empty());
      }

      EXPECT_CALL(mock_upstream_connection_, write(_, _)).Times(testing::AtLeast(1));
      factory_context_.server_factory_context_.cluster_manager_.thread_local_cluster_.tcp_conn_pool_
          .poolReady(mock_upstream_connection_);

      if (config_->bindUpstreamConnection()) {
        EXPECT_TRUE(boundUpstreamConnection()->waitingUpstreamRequestsForTest().empty());
      }
    }
  }

  void notifyConnectionClose(Network::ConnectionEvent event) {
    ASSERT(!filter_->upstreamRequestsForTest().empty());
    auto upstream_request = filter_->upstreamRequestsForTest().begin()->get();

    if (config_->bindUpstreamConnection()) {
      EXPECT_TRUE(boundUpstreamConnection()->waitingUpstreamRequestsForTest().empty());
      EXPECT_TRUE(!boundUpstreamConnection()->waitingResponseRequestsForTest().empty());
      EXPECT_CALL(mock_downstream_connection_, close(Network::ConnectionCloseType::FlushWrite));
    }

    upstream_request->generic_upstream_->onEvent(event);

    if (config_->bindUpstreamConnection()) {
      EXPECT_TRUE(boundUpstreamConnection()->waitingUpstreamRequestsForTest().empty());
      EXPECT_TRUE(boundUpstreamConnection()->waitingResponseRequestsForTest().empty());
    }
  }

  void notifyDecodingSuccess(StreamFramePtr&& response) {
    ASSERT(!filter_->upstreamRequestsForTest().empty());

    auto upstream_request = filter_->upstreamRequestsForTest().begin()->get();

    EXPECT_CALL(*mock_client_codec_, decode(BufferStringEqual("test_1"), _))
        .WillOnce(Invoke([this, resp = std::make_shared<StreamFramePtr>(std::move(response))](
                             Buffer::Instance& buffer, bool) {
          buffer.drain(buffer.length());

          const bool end_stream = (*resp)->frameFlags().endStream();
          int pending_request_size = 0;
          if (config_->bindUpstreamConnection()) {
            pending_request_size =
                boundUpstreamConnection()->waitingResponseRequestsForTest().size();
          }

          client_cb_->onDecodingSuccess(std::move(*resp));

          if (config_->bindUpstreamConnection()) {
            EXPECT_EQ(pending_request_size - (end_stream ? 1 : 0),
                      boundUpstreamConnection()->waitingResponseRequestsForTest().size());
          }
        }));

    Buffer::OwnedImpl test_buffer;
    test_buffer.add("test_1");

    upstream_request->generic_upstream_->onUpstreamData(test_buffer, false);
  }

  void notifyDecodingFailure() {
    ASSERT(!filter_->upstreamRequestsForTest().empty());

    auto upstream_request = filter_->upstreamRequestsForTest().begin()->get();

    if (config_->bindUpstreamConnection()) {
      // If upstream connection binding is enabled, the downstream connection will be closed
      // when the upstream connection is closed.
      EXPECT_CALL(mock_downstream_connection_, close(Network::ConnectionCloseType::FlushWrite));
    }

    EXPECT_CALL(mock_upstream_connection_, close(Network::ConnectionCloseType::FlushWrite))
        .WillOnce(Invoke([upstream_request](Network::ConnectionCloseType) {
          // Mock clean up closing.
          upstream_request->generic_upstream_->onEvent(Network::ConnectionEvent::LocalClose);
        }));

    EXPECT_CALL(*mock_client_codec_, decode(BufferStringEqual("test_1"), _))
        .WillOnce(Invoke([&](Buffer::Instance& buffer, bool) {
          buffer.drain(buffer.length());
          client_cb_->onDecodingFailure();
        }));

    Buffer::OwnedImpl test_buffer;
    test_buffer.add("test_1");

    upstream_request->generic_upstream_->onUpstreamData(test_buffer, false);
  }

  /**
   * Kick off a new upstream request.
   */
  void kickOffNewUpstreamRequest() {
    EXPECT_CALL(mock_filter_callback_, routeEntry()).WillOnce(Return(&mock_route_entry_));

    const std::string cluster_name = "cluster_0";

    EXPECT_CALL(mock_route_entry_, clusterName()).WillRepeatedly(ReturnRef(cluster_name));
    factory_context_.server_factory_context_.cluster_manager_.initializeThreadLocalClusters(
        {cluster_name});

    if (boundUpstreamConnection() == nullptr) {
      // Upstream binding is disabled or not set up yet, try to create a new connection.
      expectCreateConnection();
    }

    if (with_tracing_) {
      EXPECT_CALL(mock_filter_callback_, tracingConfig())
          .WillOnce(Return(OptRef<const Tracing::Config>{tracing_config_}));
      EXPECT_CALL(active_span_, spawnChild_(_, "router observability_name egress", _))
          .WillOnce(Invoke([this](const Tracing::Config&, const std::string&, SystemTime) {
            child_span_ = new NiceMock<Tracing::MockSpan>();
            return child_span_;
          }));
    } else {
      EXPECT_CALL(mock_filter_callback_, tracingConfig())
          .WillOnce(Return(OptRef<const Tracing::Config>{}));
    }

    EXPECT_EQ(filter_->onStreamDecoded(*request_), FilterStatus::StopIteration);
    EXPECT_EQ(1, filter_->upstreamRequestsForTest().size());
  }

  void verifyMetadataMatchCriteria() {
    ProtobufWkt::Struct request_struct;
    ProtobufWkt::Value val;

    // Populate metadata like StreamInfo.setDynamicMetadata() would.
    auto& fields_map = *request_struct.mutable_fields();
    val.set_string_value("v3.1");
    fields_map["version"] = val;
    val.set_string_value("devel");
    fields_map["stage"] = val;
    val.set_string_value("1");
    fields_map["xkey_in_request"] = val;
    (*mock_stream_info_.metadata_
          .mutable_filter_metadata())[Envoy::Config::MetadataFilters::get().ENVOY_LB] =
        request_struct;

    auto match = filter_->metadataMatchCriteria()->metadataMatchCriteria();

    EXPECT_EQ(match.size(), 3);
    auto it = match.begin();

    // Note: metadataMatchCriteria() keeps its entries sorted, so the order for checks
    // below matters.

    EXPECT_EQ((*it)->name(), "stage");
    EXPECT_EQ((*it)->value().value().string_value(), "devel");
    it++;

    EXPECT_EQ((*it)->name(), "version");
    EXPECT_EQ((*it)->value().value().string_value(), "v3.1");
    it++;

    EXPECT_EQ((*it)->name(), "xkey_in_request");
    EXPECT_EQ((*it)->value().value().string_value(), "1");
  }

  NiceMock<Server::Configuration::MockFactoryContext> factory_context_;
  NiceMock<Envoy::Event::MockDispatcher> dispatcher_;

  NiceMock<MockDecoderFilterCallback> mock_filter_callback_;
  NiceMock<StreamInfo::MockStreamInfo> mock_stream_info_;

  NiceMock<Network::MockServerConnection> mock_downstream_connection_;
  NiceMock<Network::MockClientConnection> mock_upstream_connection_;

  NiceMock<MockCodecFactory> mock_codec_factory_;

  NiceMock<MockClientCodec>* mock_client_codec_{};

  ClientCodecCallbacks* client_cb_{};

  NiceMock<MockRouteEntry> mock_route_entry_;

  std::shared_ptr<Router::RouterConfig> config_;

  std::shared_ptr<Router::RouterFilter> filter_;
  std::unique_ptr<FakeStreamCodecFactory::FakeRequest> request_;

  NiceMock<Tracing::MockConfig> tracing_config_;
  NiceMock<Tracing::MockSpan> active_span_;
  NiceMock<Tracing::MockSpan>* child_span_{};
  bool with_tracing_{};
  bool creating_connection_{};
};

std::vector<TestParameters> getTestParameters() {
  std::vector<TestParameters> ret;

  ret.push_back({false, false});
  ret.push_back({true, true});

  return ret;
}

std::string testParameterToString(const testing::TestParamInfo<TestParameters>& params) {
  return fmt::format("with_tracing_{}_bind_upstream_{}",
                     params.param.with_tracing ? "true" : "false",
                     params.param.bind_upstream ? "true" : "false");
}

INSTANTIATE_TEST_SUITE_P(GenericRoute, RouterFilterTest, testing::ValuesIn(getTestParameters()),
                         testParameterToString);

TEST_P(RouterFilterTest, OnStreamDecodedAndNoRouteEntry) {
  setup();

  EXPECT_CALL(mock_filter_callback_, routeEntry()).WillOnce(Return(nullptr));
  EXPECT_CALL(mock_filter_callback_, sendLocalReply(_, _, _))
      .WillOnce(Invoke([](Status status, absl::string_view, ResponseUpdateFunction) {
        EXPECT_EQ(status.message(), "route_not_found");
      }));

  EXPECT_EQ(filter_->onStreamDecoded(*request_), FilterStatus::StopIteration);
  cleanUp();

  // Mock downstream closing.
  mock_downstream_connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);
}

TEST_P(RouterFilterTest, NoUpstreamCluster) {
  setup();

  EXPECT_CALL(mock_filter_callback_, routeEntry()).WillOnce(Return(&mock_route_entry_));

  const std::string cluster_name = "cluster_0";

  EXPECT_CALL(mock_route_entry_, clusterName()).WillRepeatedly(ReturnRef(cluster_name));

  // No upstream cluster.
  EXPECT_CALL(mock_filter_callback_, sendLocalReply(_, _, _))
      .WillOnce(Invoke([](Status status, absl::string_view, ResponseUpdateFunction) {
        EXPECT_EQ(status.message(), "cluster_not_found");
      }));

  filter_->onStreamDecoded(*request_);
  cleanUp();

  // Mock downstream closing.
  mock_downstream_connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);
}

TEST_P(RouterFilterTest, UpstreamClusterMaintainMode) {
  setup();

  EXPECT_CALL(mock_filter_callback_, routeEntry()).WillOnce(Return(&mock_route_entry_));

  const std::string cluster_name = "cluster_0";

  EXPECT_CALL(mock_route_entry_, clusterName()).WillRepeatedly(ReturnRef(cluster_name));

  factory_context_.server_factory_context_.cluster_manager_.initializeThreadLocalClusters(
      {cluster_name});

  // Maintain mode.
  EXPECT_CALL(*factory_context_.server_factory_context_.cluster_manager_.thread_local_cluster_
                   .cluster_.info_,
              maintenanceMode())
      .WillOnce(Return(true));
  EXPECT_CALL(mock_filter_callback_, sendLocalReply(_, _, _))
      .WillOnce(Invoke([](Status status, absl::string_view, ResponseUpdateFunction) {
        EXPECT_EQ(status.message(), "cluster_maintain_mode");
      }));

  filter_->onStreamDecoded(*request_);
  cleanUp();

  // Mock downstream closing.
  mock_downstream_connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);
}

TEST_P(RouterFilterTest, UpstreamClusterNoHealthyUpstream) {
  setup();

  EXPECT_CALL(mock_filter_callback_, routeEntry()).WillOnce(Return(&mock_route_entry_));

  const std::string cluster_name = "cluster_0";

  EXPECT_CALL(mock_route_entry_, clusterName()).WillRepeatedly(ReturnRef(cluster_name));

  factory_context_.server_factory_context_.cluster_manager_.initializeThreadLocalClusters(
      {cluster_name});

  // No conn pool.
  EXPECT_CALL(factory_context_.server_factory_context_.cluster_manager_.thread_local_cluster_,
              tcpConnPool(_, _))
      .WillOnce(Return(absl::nullopt));

  EXPECT_CALL(mock_filter_callback_, sendLocalReply(_, _, _))
      .WillOnce(Invoke([](Status status, absl::string_view, ResponseUpdateFunction) {
        EXPECT_EQ(status.message(), "no_healthy_upstream");
      }));

  filter_->onStreamDecoded(*request_);

  cleanUp();

  // Mock downstream closing.
  mock_downstream_connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);
}

TEST_P(RouterFilterTest, KickOffNormalUpstreamRequest) {
  setup();
  kickOffNewUpstreamRequest();

  cleanUp();

  // Mock downstream closing.
  mock_downstream_connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);
}

TEST_P(RouterFilterTest, UpstreamRequestResetBeforePoolCallback) {
  setup();
  kickOffNewUpstreamRequest();

  if (with_tracing_) {
    EXPECT_CALL(*child_span_, setTag(Tracing::Tags::get().Error, "true"));
    EXPECT_CALL(*child_span_, setTag(Tracing::Tags::get().ErrorReason, "local_reset"));
    EXPECT_CALL(*child_span_, setTag(Tracing::Tags::get().Component, "proxy"));
    EXPECT_CALL(*child_span_, setTag(Tracing::Tags::get().ResponseFlags, "-"));
    EXPECT_CALL(*child_span_, setTag(Tracing::Tags::get().UpstreamCluster, "fake_cluster"));
    EXPECT_CALL(*child_span_,
                setTag(Tracing::Tags::get().UpstreamClusterName, "observability_name"));

    EXPECT_CALL(*child_span_, finishSpan());
  }

  expectCancelConnect();

  EXPECT_CALL(mock_filter_callback_, sendLocalReply(_, _, _))
      .WillOnce(Invoke([this](Status status, absl::string_view, ResponseUpdateFunction) {
        EXPECT_EQ(0, filter_->upstreamRequestsForTest().size());
        EXPECT_EQ(status.message(), "local_reset");
      }));

  filter_->upstreamRequestsForTest().begin()->get()->resetStream(StreamResetReason::LocalReset);
  EXPECT_EQ(0, filter_->upstreamRequestsForTest().size());

  // Mock downstream closing.
  mock_downstream_connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);
}

TEST_P(RouterFilterTest, UpstreamRequestPoolFailureConnctionOverflow) {
  setup();
  kickOffNewUpstreamRequest();

  if (with_tracing_) {
    EXPECT_CALL(*child_span_, setTag(Tracing::Tags::get().UpstreamAddress, _));
    EXPECT_CALL(*child_span_, setTag(Tracing::Tags::get().PeerAddress, _));
    EXPECT_CALL(*child_span_, setTag(Tracing::Tags::get().Error, "true"));
    EXPECT_CALL(*child_span_, setTag(Tracing::Tags::get().ErrorReason, "overflow"));
    EXPECT_CALL(*child_span_, setTag(Tracing::Tags::get().Component, "proxy"));
    EXPECT_CALL(*child_span_, setTag(Tracing::Tags::get().ResponseFlags, "-"));
    EXPECT_CALL(*child_span_, setTag(Tracing::Tags::get().UpstreamCluster, "fake_cluster"));
    EXPECT_CALL(*child_span_,
                setTag(Tracing::Tags::get().UpstreamClusterName, "observability_name"));
    EXPECT_CALL(*child_span_, finishSpan());
  }

  EXPECT_CALL(mock_filter_callback_, sendLocalReply(_, _, _))
      .WillOnce(Invoke([](Status status, absl::string_view, ResponseUpdateFunction) {
        EXPECT_EQ(status.message(), "overflow");
      }));

  notifyPoolFailure(ConnectionPool::PoolFailureReason::Overflow);

  // Mock downstream closing.
  mock_downstream_connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);
}

TEST_P(RouterFilterTest, UpstreamRequestPoolFailureConnctionTimeout) {
  setup();
  kickOffNewUpstreamRequest();

  if (with_tracing_) {
    EXPECT_CALL(*child_span_, setTag(Tracing::Tags::get().UpstreamAddress, _));
    EXPECT_CALL(*child_span_, setTag(Tracing::Tags::get().PeerAddress, _));
    EXPECT_CALL(*child_span_, setTag(Tracing::Tags::get().Error, "true"));
    EXPECT_CALL(*child_span_, setTag(Tracing::Tags::get().ErrorReason, "connection_failure"));
    EXPECT_CALL(*child_span_, setTag(Tracing::Tags::get().Component, "proxy"));
    EXPECT_CALL(*child_span_, setTag(Tracing::Tags::get().ResponseFlags, "-"));
    EXPECT_CALL(*child_span_, setTag(Tracing::Tags::get().UpstreamCluster, "fake_cluster"));
    EXPECT_CALL(*child_span_,
                setTag(Tracing::Tags::get().UpstreamClusterName, "observability_name"));
    EXPECT_CALL(*child_span_, finishSpan());
  }

  EXPECT_CALL(mock_filter_callback_, sendLocalReply(_, _, _))
      .WillOnce(Invoke([](Status status, absl::string_view, ResponseUpdateFunction) {
        EXPECT_EQ(status.message(), "connection_failure");
      }));

  notifyPoolFailure(ConnectionPool::PoolFailureReason::RemoteConnectionFailure);

  // Mock downstream closing.
  mock_downstream_connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);
}

TEST_P(RouterFilterTest, UpstreamRequestPoolReadyAndExpectNoResponse) {
  setup(FrameFlags(StreamFlags(0, true, false, false), true));
  kickOffNewUpstreamRequest();

  EXPECT_CALL(mock_filter_callback_, completeDirectly()).WillOnce(Invoke([this]() -> void {
    EXPECT_EQ(0, filter_->upstreamRequestsForTest().size());
  }));

  EXPECT_CALL(*mock_client_codec_, encode(_, _))
      .WillOnce(Invoke([&](const StreamFrame&, EncodingCallbacks& callback) -> void {
        Buffer::OwnedImpl buffer;
        buffer.add("hello");
        // Expect no response.
        callback.onEncodingSuccess(buffer, true);
      }));

  if (with_tracing_) {
    // Request complete directly.
    EXPECT_CALL(*child_span_, injectContext(_, _));
    EXPECT_CALL(*child_span_, setTag(_, _)).Times(testing::AnyNumber());
    EXPECT_CALL(*child_span_, finishSpan());
  }

  notifyPoolReady();
  EXPECT_EQ(0, filter_->upstreamRequestsForTest().size());

  // Mock downstream closing.
  mock_downstream_connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);
}

TEST_P(RouterFilterTest, UpstreamRequestPoolReadyButConnectionErrorBeforeResponse) {
  setup();
  kickOffNewUpstreamRequest();

  auto upstream_request = filter_->upstreamRequestsForTest().begin()->get();

  EXPECT_CALL(*mock_client_codec_, encode(_, _))
      .WillOnce(Invoke([&](const StreamFrame&, EncodingCallbacks& callback) -> void {
        Buffer::OwnedImpl buffer;
        buffer.add("hello");
        // Expect response.
        callback.onEncodingSuccess(buffer, true);
      }));

  notifyPoolReady();

  EXPECT_NE(nullptr, upstream_request->generic_upstream_->connection().ptr());

  EXPECT_CALL(mock_filter_callback_, sendLocalReply(_, _, _))
      .WillOnce(Invoke([this](Status status, absl::string_view, ResponseUpdateFunction) {
        EXPECT_EQ(0, filter_->upstreamRequestsForTest().size());
        EXPECT_EQ(status.message(), "local_reset");
      }));

  // Mock connection close event.
  notifyConnectionClose(Network::ConnectionEvent::LocalClose);

  // Mock downstream closing.
  mock_downstream_connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);
}

TEST_P(RouterFilterTest, UpstreamRequestPoolReadyButConnectionTerminationBeforeResponse) {
  setup();
  kickOffNewUpstreamRequest();

  auto upstream_request = filter_->upstreamRequestsForTest().begin()->get();

  EXPECT_CALL(*mock_client_codec_, encode(_, _))
      .WillOnce(Invoke([&](const StreamFrame&, EncodingCallbacks& callback) -> void {
        Buffer::OwnedImpl buffer;
        buffer.add("hello");
        // Expect response.
        callback.onEncodingSuccess(buffer, true);
      }));

  notifyPoolReady();

  EXPECT_NE(nullptr, upstream_request->generic_upstream_->connection().ptr());

  EXPECT_CALL(mock_filter_callback_, sendLocalReply(_, _, _))
      .WillOnce(Invoke([this](Status status, absl::string_view, ResponseUpdateFunction) {
        EXPECT_EQ(0, filter_->upstreamRequestsForTest().size());
        EXPECT_EQ(status.message(), "connection_termination");
      }));

  // Mock connection close event.
  notifyConnectionClose(Network::ConnectionEvent::RemoteClose);

  // Mock downstream closing.
  mock_downstream_connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);
}

TEST_P(RouterFilterTest, UpstreamRequestPoolReadyButStreamDestroyBeforeResponse) {
  setup();
  kickOffNewUpstreamRequest();

  auto upstream_request = filter_->upstreamRequestsForTest().begin()->get();

  EXPECT_CALL(*mock_client_codec_, encode(_, _))
      .WillOnce(Invoke([&](const StreamFrame&, EncodingCallbacks& callback) -> void {
        Buffer::OwnedImpl buffer;
        buffer.add("hello");
        // Expect response.
        callback.onEncodingSuccess(buffer, true);
      }));

  notifyPoolReady();

  EXPECT_NE(nullptr, upstream_request->generic_upstream_->connection().ptr());

  expectUpstreamConnectionClose();

  filter_->onDestroy();
  // Do nothing for the second call.
  filter_->onDestroy();

  // Mock downstream closing.
  mock_downstream_connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);
}

TEST_P(RouterFilterTest, UpstreamRequestPoolReadyAndResponse) {
  setup();
  kickOffNewUpstreamRequest();

  auto upstream_request = filter_->upstreamRequestsForTest().begin()->get();

  EXPECT_CALL(*mock_client_codec_, encode(_, _))
      .WillOnce(Invoke([&](const StreamFrame&, EncodingCallbacks& callback) -> void {
        Buffer::OwnedImpl buffer;
        buffer.add("hello");
        // Expect response.
        callback.onEncodingSuccess(buffer, true);
      }));

  if (with_tracing_) {
    // Inject tracing context.
    EXPECT_CALL(*child_span_, injectContext(_, _));
  }

  notifyPoolReady();

  EXPECT_NE(nullptr, upstream_request->generic_upstream_->connection().ptr());

  if (with_tracing_) {
    EXPECT_CALL(*child_span_, setTag(_, _)).Times(testing::AnyNumber());
    EXPECT_CALL(*child_span_, finishSpan());
  }

  EXPECT_CALL(mock_filter_callback_, onResponseStart(_)).WillOnce(Invoke([this](ResponsePtr) {
    // When the response is sent to callback, the upstream request should be removed.
    EXPECT_EQ(0, filter_->upstreamRequestsForTest().size());
  }));

  auto response = std::make_unique<FakeStreamCodecFactory::FakeResponse>();
  notifyDecodingSuccess(std::move(response));

  // Mock downstream closing.
  mock_downstream_connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);
}

TEST_P(RouterFilterTest, UpstreamRequestPoolReadyAndResponseAndMultipleRequest) {
  for (size_t i = 0; i < 5; i++) {
    setup(FrameFlags(StreamFlags(i)));

    // Expect immediate encoding.
    if (GetParam().bind_upstream && i > 0) {
      EXPECT_CALL(*mock_client_codec_, encode(_, _))
          .WillOnce(Invoke([&](const StreamFrame&, EncodingCallbacks& callback) -> void {
            Buffer::OwnedImpl buffer;
            buffer.add("hello");
            // Expect response.
            callback.onEncodingSuccess(buffer, true);
          }));
    }

    kickOffNewUpstreamRequest();

    // Expect encoding after pool ready.
    if (!GetParam().bind_upstream || i == 0) {
      EXPECT_CALL(*mock_client_codec_, encode(_, _))
          .WillOnce(Invoke([&](const StreamFrame&, EncodingCallbacks& callback) -> void {
            Buffer::OwnedImpl buffer;
            buffer.add("hello");
            // Expect response.
            callback.onEncodingSuccess(buffer, true);
          }));
    }

    auto upstream_request = filter_->upstreamRequestsForTest().begin()->get();

    notifyPoolReady();

    EXPECT_NE(nullptr, upstream_request->generic_upstream_->connection().ptr());

    EXPECT_CALL(mock_filter_callback_, onResponseStart(_)).WillOnce(Invoke([this](ResponsePtr) {
      // When the response is sent to callback, the upstream request should be removed.
      EXPECT_EQ(0, filter_->upstreamRequestsForTest().size());
    }));

    auto response = std::make_unique<FakeStreamCodecFactory::FakeResponse>();
    response->stream_frame_flags_ = FrameFlags(StreamFlags(i));
    notifyDecodingSuccess(std::move(response));

    cleanUp();
  }
  // Mock downstream closing.
  mock_downstream_connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);
}

TEST_P(RouterFilterTest, UpstreamRequestPoolReadyAndResponseWithMultipleFrames) {
  // There are multiple frames in the request.
  setup(FrameFlags(StreamFlags(0, false, false, true), /*end_stream*/ false));
  kickOffNewUpstreamRequest();

  auto upstream_request = filter_->upstreamRequestsForTest().begin()->get();

  if (with_tracing_) {
    // Inject tracing context.
    EXPECT_CALL(*child_span_, injectContext(_, _));
  }

  auto frame_1 = std::make_unique<FakeStreamCodecFactory::FakeRequest>();
  frame_1->stream_frame_flags_ = FrameFlags(StreamFlags(0, false, false, true), false);

  // This only store the frame and does nothing else because the pool is not ready yet.
  filter_->onStreamFrame(std::move(frame_1));

  EXPECT_CALL(*mock_client_codec_, encode(_, _))
      .Times(2)
      .WillRepeatedly(Invoke([&](const StreamFrame&, EncodingCallbacks& callback) -> void {
        Buffer::OwnedImpl buffer;
        buffer.add("hello");
        // Expect response.
        callback.onEncodingSuccess(buffer, false);
      }));

  // This will trigger two frames to be sent.
  notifyPoolReady();
  EXPECT_NE(nullptr, upstream_request->generic_upstream_->connection().ptr());

  EXPECT_CALL(*mock_client_codec_, encode(_, _))
      .WillOnce(Invoke([&](const StreamFrame&, EncodingCallbacks& callback) -> void {
        Buffer::OwnedImpl buffer;
        buffer.add("hello");
        // Expect response.
        callback.onEncodingSuccess(buffer, true);
      }));

  // End stream is set to true by default.
  auto frame_2 = std::make_unique<FakeStreamCodecFactory::FakeRequest>();
  // This will trigger the last frame to be sent directly because connection is ready and other
  // frames are already sent.
  filter_->onStreamFrame(std::move(frame_2));

  if (with_tracing_) {
    EXPECT_CALL(*child_span_, setTag(_, _)).Times(testing::AnyNumber());
    EXPECT_CALL(*child_span_, finishSpan());
  }

  EXPECT_CALL(mock_filter_callback_, onResponseStart(_));
  EXPECT_CALL(mock_filter_callback_, onResponseFrame(_))
      .Times(2)
      .WillRepeatedly(Invoke([this](StreamFramePtr frame) {
        // When the entire response is sent to callback, the upstream request should be removed.
        if (frame->frameFlags().endStream()) {
          EXPECT_EQ(0, filter_->upstreamRequestsForTest().size());
        } else {
          EXPECT_EQ(1, filter_->upstreamRequestsForTest().size());
        }
      }));

  auto response = std::make_unique<FakeStreamCodecFactory::FakeResponse>();
  response->stream_frame_flags_ = FrameFlags(StreamFlags(0, false, false, false), false);
  notifyDecodingSuccess(std::move(response));

  auto response_frame_1 = std::make_unique<FakeStreamCodecFactory::FakeResponse>();
  response_frame_1->stream_frame_flags_ = FrameFlags(StreamFlags(0, false, false, false), false);
  notifyDecodingSuccess(std::move(response_frame_1));

  // End stream is set to true by default.
  auto response_frame_2 = std::make_unique<FakeStreamCodecFactory::FakeResponse>();
  notifyDecodingSuccess(std::move(response_frame_2));

  // Mock downstream closing.
  mock_downstream_connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);
}

TEST_P(RouterFilterTest, UpstreamRequestPoolReadyAndResponseWithDrainCloseSetInResponse) {
  setup();
  kickOffNewUpstreamRequest();

  auto upstream_request = filter_->upstreamRequestsForTest().begin()->get();

  EXPECT_CALL(*mock_client_codec_, encode(_, _))
      .WillOnce(Invoke([&](const StreamFrame&, EncodingCallbacks& callback) -> void {
        Buffer::OwnedImpl buffer;
        buffer.add("hello");
        // Expect response.
        callback.onEncodingSuccess(buffer, true);
      }));

  if (with_tracing_) {
    // Inject tracing context.
    EXPECT_CALL(*child_span_, injectContext(_, _));
  }

  notifyPoolReady();

  EXPECT_NE(nullptr, upstream_request->generic_upstream_->connection().ptr());

  EXPECT_CALL(mock_filter_callback_, onResponseStart(_)).WillOnce(Invoke([this](ResponsePtr) {
    // When the response is sent to callback, the upstream request should be removed.
    EXPECT_EQ(0, filter_->upstreamRequestsForTest().size());
  }));

  EXPECT_CALL(mock_upstream_connection_, close(Network::ConnectionCloseType::FlushWrite));

  auto response = std::make_unique<FakeStreamCodecFactory::FakeResponse>();
  response->stream_frame_flags_ = FrameFlags(StreamFlags(0, false, true, false), true);
  notifyDecodingSuccess(std::move(response));

  // Mock downstream closing.
  mock_downstream_connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);
}

TEST_P(RouterFilterTest, UpstreamRequestPoolReadyAndResponseDecodingFailure) {
  setup();
  kickOffNewUpstreamRequest();

  auto upstream_request = filter_->upstreamRequestsForTest().begin()->get();

  EXPECT_CALL(*mock_client_codec_, encode(_, _))
      .WillOnce(Invoke([&](const StreamFrame&, EncodingCallbacks& callback) -> void {
        Buffer::OwnedImpl buffer;
        buffer.add("hello");
        // Expect response.
        callback.onEncodingSuccess(buffer, true);
      }));

  notifyPoolReady();

  EXPECT_NE(nullptr, upstream_request->generic_upstream_->connection().ptr());

  EXPECT_CALL(mock_filter_callback_, sendLocalReply(_, _, _))
      .WillOnce(Invoke([this](Status status, absl::string_view, ResponseUpdateFunction) {
        EXPECT_EQ(0, filter_->upstreamRequestsForTest().size());
        // Decoding error of bound upstream connection will not be notified to every requests
        // and will be treated as local reset.
        EXPECT_TRUE(status.message() == "protocol_error" || status.message() == "local_reset");
      }));

  notifyDecodingFailure();

  // Mock downstream closing.
  mock_downstream_connection_.raiseEvent(Network::ConnectionEvent::RemoteClose);
}

TEST_P(RouterFilterTest, LoadBalancerContextDownstreamConnection) {
  setup();
  EXPECT_CALL(mock_filter_callback_, connection());
  filter_->downstreamConnection();
}

TEST_P(RouterFilterTest, LoadBalancerContextNoMetadataMatchCriteria) {
  setup();

  // No metadata match criteria by default.
  EXPECT_EQ(nullptr, filter_->metadataMatchCriteria());
}

TEST_P(RouterFilterTest, LoadBalancerContextMetadataMatchCriteria) {
  setup();
  verifyMetadataMatchCriteria();
}

} // namespace
} // namespace Router
} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
load(
    "//bazel:envoy_build_system.bzl",
    "envoy_cc_test",
    "envoy_contrib_package",
)

licenses(["notice"])  # Apache 2

envoy_contrib_package()

envoy_cc_test(
    name = "router_test",
    srcs = [
        "router_test.cc",
    ],
    deps = [
        "//contrib/generic_proxy/filters/network/source/router:router_lib",
        "//contrib/generic_proxy/filters/network/test:fake_codec_lib",
        "//contrib/generic_proxy/filters/network/test/mocks:codec_mocks",
        "//contrib/generic_proxy/filters/network/test/mocks:filter_mocks",
        "//contrib/generic_proxy/filters/network/test/mocks:route_mocks",
        "//source/common/buffer:buffer_lib",
        "//test/mocks/server:factory_context_mocks",
        "//test/test_common:registry_lib",
        "//test/test_common:utility_lib",
    ],
)

envoy_cc_test(
    name = "config_test",
    srcs = [
        "config_test.cc",
    ],
    deps = [
        "//contrib/generic_proxy/filters/network/source/router:config",
        "//contrib/generic_proxy/filters/network/test/mocks:filter_mocks",
        "//test/mocks/server:factory_context_mocks",
    ],
)
#pragma once

#include "envoy/config/typed_config.h"
#include "envoy/server/factory_context.h"

#include "contrib/generic_proxy/filters/network/source/interface/filter.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

using TypedExtensionConfig = envoy::config::core::v3::TypedExtensionConfig;

/**
 * Implemented by each generic filter and registered via Registry::registerFactory or the
 * convenience class RegisterFactory.
 */
class NamedFilterConfigFactory : public Config::TypedFactory {
public:
  virtual FilterFactoryCb
  createFilterFactoryFromProto(const Protobuf::Message& config, const std::string& stat_prefix,
                               Server::Configuration::FactoryContext& context) PURE;

  /**
   * @return ProtobufTypes::MessagePtr create empty route config proto message route specific
   * config.
   */
  virtual ProtobufTypes::MessagePtr createEmptyRouteConfigProto() PURE;

  /**
   * @return RouteSpecificFilterConfigConstSharedPtr allow the filter to pre-process per route
   * config. Returned object will be stored in the loaded route configuration.
   */
  virtual RouteSpecificFilterConfigConstSharedPtr
  createRouteSpecificFilterConfig(const Protobuf::Message&,
                                  Server::Configuration::ServerFactoryContext&,
                                  ProtobufMessage::ValidationVisitor&) PURE;

  std::string category() const override { return "envoy.generic_proxy.filters"; }

  /**
   * @return bool true if this filter must be the last filter in a filter chain, false otherwise.
   */
  virtual bool isTerminalFilter() PURE;

  /**
   * @return absl::Status validate the codec config to see if it is compatible with the filter.
   * If the codec config is not compatible with this filter, return an error status.
   */
  virtual absl::Status validateCodec(const TypedExtensionConfig& /*config*/) {
    return absl::OkStatus();
  }

  std::set<std::string> configTypes() override {
    auto config_types = TypedFactory::configTypes();

    if (auto message = createEmptyRouteConfigProto(); message != nullptr) {
      config_types.insert(createReflectableMessage(*message)->GetDescriptor()->full_name());
    }

    return config_types;
  }
};

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include <chrono>

#include "envoy/config/core/v3/base.pb.h"
#include "envoy/config/typed_metadata.h"
#include "envoy/rds/config.h"
#include "envoy/router/router.h"

#include "contrib/generic_proxy/filters/network/source/interface/stream.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

class RouteSpecificFilterConfig {
public:
  virtual ~RouteSpecificFilterConfig() = default;
};
using RouteSpecificFilterConfigConstSharedPtr = std::shared_ptr<const RouteSpecificFilterConfig>;

/**
 * Interface of typed metadata factory. Reuse the same interface as the HTTP's router filter because
 * part of these abstractions are protocol independent.
 */
using RouteTypedMetadataFactory = Envoy::Router::HttpRouteTypedMetadataFactory;

class RouteEntry {
public:
  virtual ~RouteEntry() = default;

  /**
   * @return absl::string_view the name of the route.
   */
  virtual absl::string_view name() const PURE;

  /**
   * @return const std::string& the name of the target cluster.
   */
  virtual const std::string& clusterName() const PURE;

  /**
   * Get route level per filter config by the filter name.
   */
  virtual const RouteSpecificFilterConfig* perFilterConfig(absl::string_view) const PURE;
  template <class T> const T* typedPerFilterConfig(absl::string_view name) const {
    return dynamic_cast<const T*>(perFilterConfig(name));
  }

  /**
   * @return const envoy::config::core::v3::Metadata& return the metadata provided in the config
   * for this route.
   */
  virtual const envoy::config::core::v3::Metadata& metadata() const PURE;

  /**
   * @return const Envoy::Config::TypedMetadata& return the typed metadata provided in the config
   * for this route.
   */
  virtual const Envoy::Config::TypedMetadata& typedMetadata() const PURE;
};
using RouteEntryConstSharedPtr = std::shared_ptr<const RouteEntry>;

class RouteMatcher : public Rds::Config {
public:
  virtual RouteEntryConstSharedPtr routeEntry(const Request& request) const PURE;
};
using RouteMatcherPtr = std::unique_ptr<RouteMatcher>;

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include <cstdint>
#include <functional>
#include <memory>
#include <string>

#include "envoy/common/pure.h"
#include "envoy/tracing/trace_context.h"

#include "absl/status/status.h"
#include "absl/strings/string_view.h"
#include "absl/types/optional.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

/**
 * Stream flags from request or response to control the behavior of the
 * generic proxy filter. This is mainly used as part of FrameFlags.
 * All these flags could be ignored for the simple ping-pong use case.
 */
class StreamFlags {
public:
  StreamFlags(uint64_t stream_id = 0, bool one_way_stream = false, bool drain_close = false,
              bool is_heartbeat = false)
      : stream_id_(stream_id), one_way_stream_(one_way_stream), drain_close_(drain_close),
        is_heartbeat_(is_heartbeat) {}

  /**
   * @return the stream id of the request or response. This is used to match the
   * downstream request with the upstream response.

   * NOTE: In most cases, the stream id is not needed and will be ignored completely.
   * The stream id is only used when we can't match the downstream request
   * with the upstream response by the active stream instance self directly.
   * For example, when the multiple downstream requests are multiplexed into one
   * upstream connection.
   */
  uint64_t streamId() const { return stream_id_; }

  /**
   * @return whether the stream is one way stream. If request is one way stream, the
   * generic proxy filter will not wait for the response from the upstream.
   */
  bool oneWayStream() const { return one_way_stream_; }

  /**
   * @return whether the downstream/upstream connection should be drained after
   * current active stream are finished.
   */
  bool drainClose() const { return drain_close_; }

  /**
   * @return whether the current request/response is a heartbeat request/response.
   * NOTE: It would be better to handle heartbeat request/response by another L4
   * filter. Then the generic proxy filter can be used for the simple ping-pong
   * use case.
   */
  bool isHeartbeat() const { return is_heartbeat_; }

private:
  uint64_t stream_id_{0};

  bool one_way_stream_{false};
  bool drain_close_{false};
  bool is_heartbeat_{false};
};

/**
 * Flags of stream frame. This is used to control the behavior of the generic proxy filter.
 * All these flags could be ignored for the simple ping-pong use case.
 */
class FrameFlags {
public:
  /**
   * Construct FrameFlags with stream flags and end stream flag. The stream flags MUST be
   * same for all frames of the same stream.
   * @param stream_flags StreamFlags of the stream.
   * @param end_stream whether the current frame is the last frame of the request or response.
   * @param frame_tags frame tags of the current frame. The meaning of the frame tags is
   * application protocol specific.
   */
  FrameFlags(StreamFlags stream_flags = StreamFlags(), bool end_stream = true,
             uint32_t frame_tags = 0)
      : stream_flags_(stream_flags), end_stream_(end_stream), frame_tags_(frame_tags) {}

  /**
   * Get flags of stream that the frame belongs to. The flags MUST be same for all frames of the
   * same stream. Copy semantics is used because the flags are lightweight (only 16 bytes for now).
   * @return StreamFlags of the stream.
   */
  StreamFlags streamFlags() const { return stream_flags_; }

  /**
   * @return whether the current frame is the last frame of the request or response.
   */
  bool endStream() const { return end_stream_; }

  /**
   * @return frame tags of the current frame. The meaning of the frame tags is application
   * protocol specific. This allows the creator of the frame to attach additional information to the
   * frame and get it by the receiver of the frame without parsing the frame payload or dynamic
   * cast.
   * For example, the frame tags could be used to indicate the type of the frame by the server
   * codec. Then the client codec could get the frame type without dynamic cast.
   */
  uint32_t frameTags() const { return frame_tags_; }

private:
  StreamFlags stream_flags_{};

  // Default to true for backward compatibility.
  bool end_stream_{true};
  uint32_t frame_tags_{};
};

/**
 * Stream frame interface. This is used to represent the stream frame of request or response.
 */
class StreamFrame {
public:
  virtual ~StreamFrame() = default;

  /**
   * Get stream frame flags of current frame. The default implementation returns empty flags
   * that could be used for the simple ping-pong use case.
   * @return FrameFlags of the current frame.
   */
  virtual FrameFlags frameFlags() const { return {}; }
};

using StreamFramePtr = std::unique_ptr<StreamFrame>;
using StreamFrameSharedPtr = std::shared_ptr<StreamFrame>;

class StreamBase : public StreamFrame {
public:
  using IterateCallback = std::function<bool(absl::string_view key, absl::string_view val)>;

  /**
   * Get application protocol of generic stream.
   *
   * @return A string view representing the application protocol of the generic stream behind
   * the context.
   */
  virtual absl::string_view protocol() const PURE;

  /**
   * Iterate over all generic stream metadata entries.
   *
   * @param callback supplies the iteration callback.
   */
  virtual void forEach(IterateCallback /*callback*/) const {};

  /**
   * Get generic stream metadata value by key.
   *
   * @param key The metadata key of string view type.
   * @return The optional metadata value of string_view type.
   */
  virtual absl::optional<absl::string_view> get(absl::string_view /*key*/) const { return {}; }

  /**
   * Set new generic stream metadata key/value pair.
   *
   * @param key The metadata key of string view type.
   * @param val The metadata value of string view type.
   */
  virtual void set(absl::string_view /*key*/, absl::string_view /*val*/) {}

  /**
   * Erase generic stream metadata by key.
   * @param key The metadata key of string view type.
   */
  virtual void erase(absl::string_view /*key*/) {}

  // Used for matcher.
  static constexpr absl::string_view name() { return "generic_proxy"; }
};

/**
 * Interface of generic request. This is derived from StreamFrame that contains the request
 * specific information. First frame of the request MUST be a StreamRequest.
 *
 * NOTE: using interface that provided by the TraceContext as the interface of generic request here
 * to simplify the tracing integration. This is not a good design. This should be changed in the
 * future.
 */
class StreamRequest : public StreamBase {
public:
  /**
   * Get request host.
   *
   * @return The host of generic request. The meaning of the return value may be different For
   * different application protocols. It typically should be domain, VIP, or service name that
   * used to represents target service instances.
   */
  virtual absl::string_view host() const { return {}; }

  /**
   * Get request path.
   *
   * @return The path of generic request. The meaning of the return value may be different For
   * different application protocols. It typically should be RPC service name that used to
   * represents set of method or functionality provided by target service.
   */
  virtual absl::string_view path() const { return {}; }

  /**
   * Get request method.
   *
   * @return The method of generic request. The meaning of the return value may be different For
   * different application protocols.
   */
  virtual absl::string_view method() const { return {}; }
};

using StreamRequestPtr = std::unique_ptr<StreamRequest>;
using StreamRequestSharedPtr = std::shared_ptr<StreamRequest>;
// Alias for backward compatibility.
using Request = StreamRequest;
using RequestPtr = std::unique_ptr<Request>;
using RequestSharedPtr = std::shared_ptr<Request>;

enum class Event {
  Timeout,
  ConnectionTimeout,
  ConnectionClosed,
  LocalConnectionClosed,
  ConnectionFailure,
};

/**
 * The Status type is used by the generic proxy to indicate statuses or error types
 * to the application protocol codec. This is application protocol independent.
 */
using Status = absl::Status;
using StatusCode = absl::StatusCode;

/**
 * Generic stream status. The Status is used by the application protocol codec to
 * indicate the status of the response. The meaning of status code is application
 * protocol specific.
 */
struct StreamStatus {
public:
  StreamStatus() = default;
  StreamStatus(int code, bool ok) : code_(code), ok_(ok) {}

  // Returns true if the status indicates success. This will be used for tracing, logging
  // or stats purposes.
  ABSL_MUST_USE_RESULT bool ok() const { return ok_; }

  // Returns the status code value. The code will be used for tracing, logging or stats
  // purposes. The specific code value is application protocol specific.
  ABSL_MUST_USE_RESULT int code() const { return code_; }

private:
  int code_{};
  bool ok_{true};
};

/**
 * Interface of generic response. This is derived from StreamFrame that contains the response
 * specific information. First frame of the response MUST be a StreamResponse.
 */
class StreamResponse : public StreamBase {
public:
  /**
   * Get response status.
   *
   * @return generic response status.
   */
  virtual StreamStatus status() const { return {}; }
};

using StreamResponsePtr = std::unique_ptr<StreamResponse>;
using StreamResponseSharedPtr = std::shared_ptr<StreamResponse>;
// Alias for backward compatibility.
using Response = StreamResponse;
using ResponsePtr = std::unique_ptr<Response>;
using ResponseSharedPtr = std::shared_ptr<Response>;

template <class T> class StreamFramePtrHelper {
public:
  StreamFramePtrHelper(StreamFramePtr frame) {
    auto frame_ptr = frame.release();

    auto typed_frame_ptr = dynamic_cast<T*>(frame_ptr);

    if (typed_frame_ptr == nullptr) {
      // If the frame is not the expected type, wrap it
      // in the original StreamFramePtr.
      frame_ = StreamFramePtr{frame_ptr};
    } else {
      // If the frame is the expected type, wrap it
      // in the typed frame unique pointer.
      typed_frame_ = std::unique_ptr<T>{typed_frame_ptr};
    }
  }

  StreamFramePtr frame_;
  std::unique_ptr<T> typed_frame_;
};

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include "envoy/buffer/buffer.h"
#include "envoy/config/typed_config.h"
#include "envoy/network/filter.h"
#include "envoy/server/factory_context.h"

#include "contrib/generic_proxy/filters/network/source/interface/codec_callbacks.h"
#include "contrib/generic_proxy/filters/network/source/interface/stream.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

/**
 * Server codec that used to decode downstream request and encode upstream response.
 * This codec is used by downstream connection.
 */
class ServerCodec {
public:
  virtual ~ServerCodec() = default;

  /**
   * Set callbacks of server codec.
   * @param callbacks callbacks of server codec. This callback will have same lifetime
   * as the server codec.
   */
  virtual void setCodecCallbacks(ServerCodecCallbacks& callbacks) PURE;

  /**
   * Decode request frame from downstream connection.
   * @param buffer data to decode.
   * @param end_stream whether this is the last data of the downstream connection.
   */
  virtual void decode(Buffer::Instance& buffer, bool end_stream) PURE;

  /**
   * Encode response frame.
   * @param frame response frame to encode.
   * @param callbacks callbacks of encoding. This callback should be used to notify the
   * generic proxy filter that the response is encoded and should be called only once.
   */
  virtual void encode(const StreamFrame& frame, EncodingCallbacks& callbacks) PURE;

  /**
   * Create a response frame with specified status and flags.
   * @param status status of the response.
   * @param data any data that generic proxy filter wants to tell the codec.
   * @param request origin request that the response is created for.
   */
  virtual ResponsePtr respond(Status status, absl::string_view data, const Request& request) PURE;
};

/**
 * Client codec that used to decode upstream response and encode downstream request.
 * This codec is used by upstream connection.
 */
class ClientCodec {
public:
  virtual ~ClientCodec() = default;

  /**
   * Set callbacks of client codec.
   * @param callbacks callbacks of client codec. This callback will have same lifetime
   * as the client codec.
   */
  virtual void setCodecCallbacks(ClientCodecCallbacks& callbacks) PURE;

  /**
   * Decode response frame from upstream connection.
   * @param buffer data to decode.
   * @param end_stream whether this is the last data of the upstream connection.
   */
  virtual void decode(Buffer::Instance& buffer, bool end_stream) PURE;

  /**
   * Encode request frame.
   * @param frame request frame to encode.
   * @param callbacks callbacks of encoding. This callbacks should be used to notify the
   * generic proxy filter that the request is encoded and should be called only once.
   */
  virtual void encode(const StreamFrame& frame, EncodingCallbacks& callbacks) PURE;
};

using ServerCodecPtr = std::unique_ptr<ServerCodec>;
using ClientCodecPtr = std::unique_ptr<ClientCodec>;

/**
 * Factory used to create generic stream encoder and decoder. If the developer wants to add
 * new protocol support to this proxy, they need to implement the corresponding codec factory for
 * the corresponding protocol.
 */
class CodecFactory {
public:
  virtual ~CodecFactory() = default;

  /**
   * Create a server codec instance.
   */
  virtual ServerCodecPtr createServerCodec() const PURE;

  /**
   * Create a client codec instance.
   */
  virtual ClientCodecPtr createClientCodec() const PURE;
};

using CodecFactoryPtr = std::unique_ptr<CodecFactory>;

class FilterConfig;
using FilterConfigSharedPtr = std::shared_ptr<FilterConfig>;

/**
 * Custom read filter factory for generic proxy.
 */
class ProxyFactory {
public:
  virtual ~ProxyFactory() = default;

  /**
   * Create a custom proxy instance.
   * @param filter_manager the filter manager of the network filter chain.
   * @param filter_config supplies the read filter config.
   */
  virtual void createProxy(Network::FilterManager& filter_manager,
                           const FilterConfigSharedPtr& filter_config) const PURE;
};
using ProxyFactoryPtr = std::unique_ptr<ProxyFactory>;

/**
 * Factory config for codec factory. This class is used to register and create codec factories.
 */
class CodecFactoryConfig : public Envoy::Config::TypedFactory {
public:
  /**
   * Create a codec factory. This should never return nullptr.
   * @param config supplies the config.
   * @param context supplies the server context.
   * @return CodecFactoryPtr the codec factory.
   */
  virtual CodecFactoryPtr createCodecFactory(const Protobuf::Message&,
                                             Envoy::Server::Configuration::FactoryContext&) PURE;

  /**
   * Create a optional custom proxy factory.
   * @param config supplies the config.
   * @param context supplies the server context.
   * @return ProxyFactoryPtr the proxy factory to create generic proxy instance or nullptr if no
   * custom proxy is needed and the default generic proxy will be used.
   */
  virtual ProxyFactoryPtr createProxyFactory(const Protobuf::Message&,
                                             Envoy::Server::Configuration::FactoryContext&) {
    return nullptr;
  }

  std::string category() const override { return "envoy.generic_proxy.codecs"; }
};

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include "envoy/tracing/trace_config.h"
#include "envoy/tracing/tracer.h"

#include "contrib/generic_proxy/filters/network/source/access_log.h"
#include "contrib/generic_proxy/filters/network/source/interface/codec.h"
#include "contrib/generic_proxy/filters/network/source/interface/filter.h"
#include "contrib/generic_proxy/filters/network/source/interface/route.h"
#include "contrib/generic_proxy/filters/network/source/stats.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

/**
 * Filter config interface for generic proxy read filter.
 */
class FilterConfig : public FilterChainFactory {
public:
  /**
   * Get route entry by generic request.
   * @param request request.
   * @return RouteEntryConstSharedPtr route entry.
   */
  virtual RouteEntryConstSharedPtr routeEntry(const Request& request) const PURE;

  /**
   * Get codec factory for  decoding/encoding of request/response.
   * @return CodecFactory codec factory.
   */
  virtual const CodecFactory& codecFactory() const PURE;

  /**
   * @return const Network::DrainDecision& a drain decision that filters can use to
   * determine if they should be doing graceful closes on connections when possible.
   */
  virtual const Network::DrainDecision& drainDecision() const PURE;

  /**
   *  @return Tracing::Tracer tracing provider to use.
   */
  virtual OptRef<Tracing::Tracer> tracingProvider() const PURE;

  /**
   * @return connection manager tracing config.
   */
  virtual OptRef<const Tracing::ConnectionManagerTracingConfig> tracingConfig() const PURE;

  /**
   * @return stats to use.
   */
  virtual GenericFilterStats& stats() PURE;

  /**
   * @return code or flags stats name to use.
   */
  virtual const CodeOrFlags& codeOrFlags() const PURE;

  /**
   * @return const std::vector<AccessLogInstanceSharedPtr>& access logs.
   */
  virtual const std::vector<AccessLogInstanceSharedPtr>& accessLogs() const PURE;
};

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include "envoy/buffer/buffer.h"
#include "envoy/common/optref.h"
#include "envoy/network/connection.h"
#include "envoy/network/drain_decision.h"

#include "contrib/generic_proxy/filters/network/source/interface/stream.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

/**
 * Callbacks of ServerCodec.
 */
class ServerCodecCallbacks {
public:
  virtual ~ServerCodecCallbacks() = default;
  /**
   * If request decoding success then this method will be called.
   * @param frame request frame from decoding. Frist frame should be StreamRequest
   * frame.
   * NOTE: This method will be called multiple times for the multiple frames request.
   * FrameFlags and embedded StreamFlags could be used to correlate frames of same
   * request.
   */
  virtual void onDecodingSuccess(StreamFramePtr frame) PURE;

  /**
   * If request decoding failure then this method will be called.
   */
  virtual void onDecodingFailure() PURE;

  /**
   * Write specified data to the downstream connection. This is could be used to write
   * some raw binary to peer before the onDecodingSuccess()/onDecodingFailure() is
   * called. By this way, when some special data is received from peer, the custom
   * codec could handle it directly and write some reply to peer without notifying
   * the generic proxy filter.
   * @param buffer data to write.
   */
  virtual void writeToConnection(Buffer::Instance& buffer) PURE;

  /**
   * @return the downstream connection that the request is received from. This gives
   * the custom codec the full power to control the downstream connection.
   */
  virtual OptRef<Network::Connection> connection() PURE;
};

/**
 * Callbacks of ClientCodec.
 */
class ClientCodecCallbacks {
public:
  virtual ~ClientCodecCallbacks() = default;

  /**
   * If response decoding success then this method will be called.
   * @param frame response frame from decoding. Frist frame should be StreamResponse
   * frame.
   * NOTE: This method will be called multiple times for the multiple frames response.
   * FrameFlags and embedded StreamFlags could be used to correlate frames of same
   * request. And the StreamFlags could also be used to correlate the response with
   * the request.
   */
  virtual void onDecodingSuccess(StreamFramePtr frame) PURE;

  /**
   * If response decoding failure then this method will be called.
   */
  virtual void onDecodingFailure() PURE;

  /**
   * Write specified data to the upstream connection. This is could be used to write
   * some raw binary to peer before the onDecodingSuccess()/onDecodingFailure() is
   * called. By this way, when some special data is received from peer, the custom
   * codec could handle it directly and write some reply to peer without notifying
   * the generic proxy filter.
   * @param buffer data to write.
   */
  virtual void writeToConnection(Buffer::Instance& buffer) PURE;

  /**
   * @return the upstream connection that the response is received from. This gives
   * the custom codec the full power to control the upstream connection.
   */
  virtual OptRef<Network::Connection> connection() PURE;
};

/**
 * Callback of request/response frame.
 */
class EncodingCallbacks {
public:
  virtual ~EncodingCallbacks() = default;

  /**
   * If encoding success then this method will be called to notify the generic proxy.
   * @param buffer encoding result buffer.
   * @param end_stream if last frame is encoded.
   */
  virtual void onEncodingSuccess(Buffer::Instance& buffer, bool end_stream) PURE;
};

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
load(
    "//bazel:envoy_build_system.bzl",
    "envoy_cc_library",
    "envoy_contrib_package",
)

licenses(["notice"])  # Apache 2

envoy_contrib_package()

envoy_cc_library(
    name = "stream_interface",
    hdrs = [
        "stream.h",
    ],
    deps = [
        "//envoy/tracing:trace_context_interface",
    ],
)

envoy_cc_library(
    name = "codec_callbacks_interface",
    hdrs = [
        "codec_callbacks.h",
    ],
    deps = [
        ":stream_interface",
        "//envoy/buffer:buffer_interface",
        "//envoy/network:drain_decision_interface",
    ],
)

envoy_cc_library(
    name = "codec_interface",
    hdrs = [
        "codec.h",
    ],
    deps = [
        ":codec_callbacks_interface",
        ":stream_interface",
        "//envoy/buffer:buffer_interface",
        "//envoy/config:typed_config_interface",
        "//envoy/network:filter_interface",
        "//envoy/server:factory_context_interface",
    ],
)

envoy_cc_library(
    name = "filter_interface",
    hdrs = [
        "filter.h",
    ],
    deps = [
        ":codec_interface",
        ":route_interface",
        ":stream_interface",
    ],
)

envoy_cc_library(
    name = "route_interface",
    hdrs = [
        "route.h",
    ],
    deps = [
        ":stream_interface",
        "//envoy/config:typed_metadata_interface",
        "//envoy/event:dispatcher_interface",
        "//envoy/network:connection_interface",
        "//envoy/rds:rds_config_interface",
        "//envoy/router:router_interface",
        "//envoy/stream_info:stream_info_interface",
        "@envoy_api//envoy/config/core/v3:pkg_cc_proto",
    ],
)

envoy_cc_library(
    name = "config_interface",
    hdrs = [
        "config.h",
    ],
    deps = [
        ":filter_interface",
        "//envoy/config:typed_config_interface",
        "//envoy/server:factory_context_interface",
    ],
)

envoy_cc_library(
    name = "proxy_config_interface",
    hdrs = [
        "proxy_config.h",
    ],
    deps = [
        ":codec_interface",
        ":filter_interface",
        ":route_interface",
        "//contrib/generic_proxy/filters/network/source:access_log_lib",
        "//envoy/tracing:trace_config_interface",
        "//envoy/tracing:tracer_interface",
    ],
)
#pragma once

#include "envoy/event/dispatcher.h"
#include "envoy/network/connection.h"
#include "envoy/stream_info/stream_info.h"

#include "contrib/generic_proxy/filters/network/source/interface/codec.h"
#include "contrib/generic_proxy/filters/network/source/interface/route.h"
#include "contrib/generic_proxy/filters/network/source/interface/stream.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

using ResponseUpdateFunction = std::function<void(Response&)>;

/**
 * StreamFrameHandler to handle the frames from the stream (if exists).
 */
class StreamFrameHandler {
public:
  virtual ~StreamFrameHandler() = default;

  /**
   * Handle the frame from the stream.
   * @param frame frame from the stream.
   */
  virtual void onStreamFrame(StreamFramePtr frame) PURE;
};

/**
 * The stream filter callbacks are passed to all filters to use for writing response data and
 * interacting with the underlying stream in general.
 */
class StreamFilterCallbacks {
public:
  virtual ~StreamFilterCallbacks() = default;

  /**
   * @return Event::Dispatcher& the thread local dispatcher for allocating timers, etc.
   */
  virtual Envoy::Event::Dispatcher& dispatcher() PURE;

  /**
   * @return const CodecFactory& the downstream codec factory used to create request/response
   * decoder/encoder.
   */
  virtual const CodecFactory& downstreamCodec() PURE;

  /**
   * @return const RouteEntry* cached route entry for current request.
   */
  virtual const RouteEntry* routeEntry() const PURE;

  /**
   * @return const RouteSpecificFilterConfig* route level per filter config. The filter config
   * name will be used to get the config.
   */
  virtual const RouteSpecificFilterConfig* perFilterConfig() const PURE;

  /**
   * @return StreamInfo::StreamInfo& the stream info object associated with the stream.
   */
  virtual const StreamInfo::StreamInfo& streamInfo() const PURE;
  virtual StreamInfo::StreamInfo& streamInfo() PURE;

  /**
   * @return Tracing::Span& the active span associated with the stream.
   */
  virtual Tracing::Span& activeSpan() PURE;

  /**
   * @return const Tracing::Config& the tracing configuration.
   */
  virtual OptRef<const Tracing::Config> tracingConfig() const PURE;

  /**
   * @return const Network::Connection* downstream connection.
   */
  virtual const Network::Connection* connection() const PURE;
};

class DecoderFilterCallback : public virtual StreamFilterCallbacks {
public:
  /**
   * Send local reply directly to the downstream for the current request. Note encoder filters
   * will be skipped for the local reply for now.
   * @param status supplies the protocol independent response status to the codec to create
   * actual response frame or message. Note the actual response code may be different with code
   * in the status. For example, if the status is Protocol::Status::Ok, the actual response code
   * may be 200 for HTTP/1.1 or 20 for Dubbo.
   * The status message will be used as response code details and could be logged.
   * @param data supplies the additional data to the codec to create actual response frame or
   * message. This could be anything and is optional.
   * @param cb supplies the callback to update the response. This is optional and could be nullptr.
   */
  virtual void sendLocalReply(Status status, absl::string_view data = {},
                              ResponseUpdateFunction cb = {}) PURE;

  virtual void continueDecoding() PURE;

  /**
   * Called when the upstream response frame is received. This should only be called once.
   * @param response supplies the upstream response frame.
   */
  virtual void onResponseStart(StreamResponsePtr response) PURE;

  /**
   * Called when the upstream response frame is received. This should only be called once.
   * @param frame supplies the upstream frame.
   */
  virtual void onResponseFrame(StreamFramePtr frame) PURE;

  /**
   * Register a request frames handler to used to handle the request frames (except the special
   * StreamRequest frame).
   * This handler will be Called when the filter chain is completed.
   * @param handler supplies the request frames handler.
   *
   * TODO(wbpcode): this is used by the terminal filter the handle the request frames because
   * the filter chain doesn't support to handle extra frames. We should remove this when the
   * filter chain supports to handle extra frames.
   */
  virtual void setRequestFramesHandler(StreamFrameHandler& handler) PURE;

  virtual void completeDirectly() PURE;
};

class EncoderFilterCallback : public virtual StreamFilterCallbacks {
public:
  virtual void continueEncoding() PURE;
};

enum class FilterStatus { Continue, StopIteration };

class DecoderFilter {
public:
  virtual ~DecoderFilter() = default;

  virtual void onDestroy() PURE;

  virtual void setDecoderFilterCallbacks(DecoderFilterCallback& callbacks) PURE;
  virtual FilterStatus onStreamDecoded(StreamRequest& request) PURE;
};

class EncoderFilter {
public:
  virtual ~EncoderFilter() = default;

  virtual void onDestroy() PURE;

  virtual void setEncoderFilterCallbacks(EncoderFilterCallback& callbacks) PURE;
  virtual FilterStatus onStreamEncoded(StreamResponse& response) PURE;
};

class StreamFilter : public DecoderFilter, public EncoderFilter {};

using DecoderFilterSharedPtr = std::shared_ptr<DecoderFilter>;
using EncoderFilterSharedPtr = std::shared_ptr<EncoderFilter>;
using StreamFilterSharedPtr = std::shared_ptr<StreamFilter>;

class FilterChainFactoryCallbacks {
public:
  virtual ~FilterChainFactoryCallbacks() = default;

  /**
   * Add a decoder filter that is used when reading connection data.
   * @param filter supplies the filter to add.
   */
  virtual void addDecoderFilter(DecoderFilterSharedPtr filter) PURE;

  /**
   * Add a encoder filter that is used when writing connection data.
   * @param filter supplies the filter to add.
   */
  virtual void addEncoderFilter(EncoderFilterSharedPtr filter) PURE;

  /**
   * Add a decoder/encoder filter that is used both when reading and writing connection data.
   * @param filter supplies the filter to add.
   */
  virtual void addFilter(StreamFilterSharedPtr filter) PURE;
};

using FilterFactoryCb = std::function<void(FilterChainFactoryCallbacks& callbacks)>;

/**
 * Simple struct of additional contextual information of filter, e.g. filter config name
 * from configuration.
 */
struct FilterContext {
  // The name of the filter configuration that used to create related filter factory function.
  // This could be any legitimate non-empty string.
  // This config name will have longger lifetime than any related filter instance. So string
  // view could be used here safely.
  absl::string_view config_name;
};

/**
 * The filter chain manager is provided by the connection manager to the filter chain factory.
 * The filter chain factory will post the filter factory context and filter factory to the
 * filter chain manager to create filter and construct HTTP stream filter chain.
 */
class FilterChainManager {
public:
  virtual ~FilterChainManager() = default;

  /**
   * Post filter factory context and filter factory to the filter chain manager. The filter
   * chain manager will create filter instance based on the context and factory internally.
   * @param context supplies additional contextual information of filter factory.
   * @param factory factory function used to create filter instances.
   */
  virtual void applyFilterFactoryCb(FilterContext context, FilterFactoryCb& factory) PURE;
};

/**
 * A FilterChainFactory is used by a connection manager to create a stream level filter chain
 * when a new stream is created. Typically it would be implemented by a configuration engine
 * that would install a set of filters that are able to process an application scenario on top of a
 * stream of generic requests.
 */
class FilterChainFactory {
public:
  virtual ~FilterChainFactory() = default;

  /**
   * Called when a new HTTP stream is created on the connection.
   * @param manager supplies the "sink" that is used for actually creating the filter chain. @see
   *                FilterChainManager.
   */
  virtual void createFilterChain(FilterChainManager& manager) PURE;
};

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include "source/common/buffer/buffer_impl.h"

#include "contrib/envoy/extensions/filters/network/generic_proxy/codecs/kafka/v3/kafka.pb.h"
#include "contrib/generic_proxy/filters/network/source/interface/codec.h"
#include "contrib/kafka/filters/network/source/request_codec.h"
#include "contrib/kafka/filters/network/source/response_codec.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {
namespace Codec {
namespace Kafka {

using ProtoConfig =
    envoy::extensions::filters::network::generic_proxy::codecs::kafka::v3::KafkaCodecConfig;

class KafkaRequestFrame : public GenericProxy::StreamRequest {
public:
  KafkaRequestFrame(NetworkFilters::Kafka::AbstractRequestSharedPtr request)
      : request_(std::move(request)) {
    ASSERT(request_ != nullptr);
  }

  FrameFlags frameFlags() const override {
    if (request_ == nullptr) {
      return FrameFlags{};
    }
    return FrameFlags{
        StreamFlags{static_cast<uint64_t>(request_->request_header_.correlation_id_)}};
  }

  absl::string_view protocol() const override { return "kafka"; }

  NetworkFilters::Kafka::AbstractRequestSharedPtr request_;
};

class KafkaResponseFrame : public GenericProxy::StreamResponse {
public:
  KafkaResponseFrame(NetworkFilters::Kafka::AbstractResponseSharedPtr response)
      : response_(std::move(response)) {}

  FrameFlags frameFlags() const override {
    if (response_ == nullptr) {
      return FrameFlags{};
    }
    return FrameFlags{StreamFlags{static_cast<uint64_t>(response_->metadata_.correlation_id_)}};
  }

  absl::string_view protocol() const override { return "kafka"; }

  NetworkFilters::Kafka::AbstractResponseSharedPtr response_;
};

class KafkaRequestCallbacks : public NetworkFilters::Kafka::RequestCallback,
                              public Envoy::Logger::Loggable<Envoy::Logger::Id::kafka> {
public:
  KafkaRequestCallbacks(GenericProxy::ServerCodecCallbacks& callbacks) : callbacks_(callbacks) {}

  void onMessage(NetworkFilters::Kafka::AbstractRequestSharedPtr request) override {
    ENVOY_CONN_LOG(debug, "Kafka codec: new request from downstream client",
                   callbacks_.connection().ref());
    callbacks_.onDecodingSuccess(std::make_unique<KafkaRequestFrame>(std::move(request)));
  }

  void onFailedParse(NetworkFilters::Kafka::RequestParseFailureSharedPtr) override {
    ENVOY_CONN_LOG(debug, "Kafka codec: failed to parse request from downstream client",
                   callbacks_.connection().ref());
    callbacks_.onDecodingFailure();
  }

  GenericProxy::ServerCodecCallbacks& callbacks_;
};

class KafkaResponseCallbacks : public NetworkFilters::Kafka::ResponseCallback,
                               public Envoy::Logger::Loggable<Envoy::Logger::Id::kafka> {
public:
  KafkaResponseCallbacks(GenericProxy::ClientCodecCallbacks& callbacks) : callbacks_(callbacks) {}

  void onMessage(NetworkFilters::Kafka::AbstractResponseSharedPtr response) override {
    ENVOY_CONN_LOG(debug, "Kafka codec: new response from upstream server",
                   callbacks_.connection().ref());
    callbacks_.onDecodingSuccess(std::make_unique<KafkaResponseFrame>(std::move(response)));
  }

  void onFailedParse(NetworkFilters::Kafka::ResponseMetadataSharedPtr) override {
    ENVOY_CONN_LOG(debug, "Kafka codec: failed to parse response from upstream server",
                   callbacks_.connection().ref());
    callbacks_.onDecodingFailure();
  }

private:
  GenericProxy::ClientCodecCallbacks& callbacks_;
};

class KafkaServerCodec : public GenericProxy::ServerCodec,
                         public Envoy::Logger::Loggable<Envoy::Logger::Id::kafka> {
public:
  KafkaServerCodec();

  void setCodecCallbacks(GenericProxy::ServerCodecCallbacks& callbacks) override;
  void decode(Envoy::Buffer::Instance& buffer, bool end_stream) override;
  void encode(const GenericProxy::StreamFrame& frame,
              GenericProxy::EncodingCallbacks& callbacks) override;
  GenericProxy::ResponsePtr respond(absl::Status, absl::string_view,
                                    const GenericProxy::Request&) override;

  Envoy::Buffer::OwnedImpl request_buffer_;
  Envoy::Buffer::OwnedImpl response_buffer_;

  NetworkFilters::Kafka::RequestDecoderSharedPtr request_decoder_;
  NetworkFilters::Kafka::ResponseEncoder response_encoder_;

  std::shared_ptr<KafkaRequestCallbacks> request_callbacks_;
};

class KafkaClientCodec : public GenericProxy::ClientCodec,
                         public Envoy::Logger::Loggable<Envoy::Logger::Id::kafka> {
public:
  KafkaClientCodec();

  void setCodecCallbacks(GenericProxy::ClientCodecCallbacks& callbacks) override;
  void decode(Envoy::Buffer::Instance& buffer, bool end_stream) override;
  void encode(const GenericProxy::StreamFrame& frame,
              GenericProxy::EncodingCallbacks& callbacks) override;

  Envoy::Buffer::OwnedImpl request_buffer_;
  Envoy::Buffer::OwnedImpl response_buffer_;

  NetworkFilters::Kafka::ResponseDecoderSharedPtr response_decoder_;
  NetworkFilters::Kafka::RequestEncoder request_encoder_;

  std::shared_ptr<KafkaResponseCallbacks> response_callbacks_;
};

class KafkaCodecFactory : public GenericProxy::CodecFactory {
public:
  GenericProxy::ClientCodecPtr createClientCodec() const override {
    return std::make_unique<KafkaClientCodec>();
  }

  GenericProxy::ServerCodecPtr createServerCodec() const override {
    return std::make_unique<KafkaServerCodec>();
  }
};

class KafkaCodecFactoryConfig : public GenericProxy::CodecFactoryConfig {
public:
  // CodecFactoryConfig
  GenericProxy::CodecFactoryPtr
  createCodecFactory(const Envoy::Protobuf::Message& config,
                     Envoy::Server::Configuration::FactoryContext& context) override;
  std::string name() const override { return "envoy.generic_proxy.codecs.kafka"; }
  Envoy::ProtobufTypes::MessagePtr createEmptyConfigProto() override {
    return std::make_unique<ProtoConfig>();
  }
};

} // namespace Kafka
} // namespace Codec
} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
load(
    "//bazel:envoy_build_system.bzl",
    "envoy_cc_contrib_extension",
    "envoy_contrib_package",
)

licenses(["notice"])  # Apache 2

envoy_contrib_package()

envoy_cc_contrib_extension(
    name = "config",
    srcs = [
        "config.cc",
    ],
    hdrs = [
        "config.h",
    ],
    deps = [
        "//contrib/generic_proxy/filters/network/source/interface:codec_interface",
        "//contrib/kafka/filters/network/source:kafka_request_codec_lib",
        "//contrib/kafka/filters/network/source:kafka_response_codec_lib",
        "@envoy_api//contrib/envoy/extensions/filters/network/generic_proxy/codecs/kafka/v3:pkg_cc_proto",
    ],
)
#include "contrib/generic_proxy/filters/network/source/codecs/kafka/config.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {
namespace Codec {
namespace Kafka {

KafkaServerCodec::KafkaServerCodec() : response_encoder_(response_buffer_) {}

void KafkaServerCodec::setCodecCallbacks(GenericProxy::ServerCodecCallbacks& callbacks) {
  request_callbacks_ = std::make_shared<KafkaRequestCallbacks>(callbacks);
  request_decoder_ = std::make_shared<NetworkFilters::Kafka::RequestDecoder>(
      std::vector<NetworkFilters::Kafka::RequestCallbackSharedPtr>{request_callbacks_});
}

void KafkaServerCodec::decode(Envoy::Buffer::Instance& buffer, bool) {
  request_buffer_.move(buffer);
  request_decoder_->onData(request_buffer_);
  // All data has been consumed, so we can drain the buffer.
  request_buffer_.drain(request_buffer_.length());
}

void KafkaServerCodec::encode(const GenericProxy::StreamFrame& frame,
                              GenericProxy::EncodingCallbacks& callbacks) {
  auto* typed_response = dynamic_cast<const KafkaResponseFrame*>(&frame);
  if (typed_response == nullptr) {
    ENVOY_LOG(error, "Kafka codec: invalid response frame type and cannot encode");
    return;
  }
  if (typed_response->response_ != nullptr) {
    response_encoder_.encode(*typed_response->response_);
  } else {
    ENVOY_LOG(error, "Kafka codec: invalid empty response frame type and close connection");
    request_callbacks_->callbacks_.connection()->close(Network::ConnectionCloseType::FlushWrite);
    return;
  }
  callbacks.onEncodingSuccess(response_buffer_, true);
  // All data should be consumed by the generic proxy and send to the network.
  ASSERT(response_buffer_.length() == 0);
}
GenericProxy::ResponsePtr KafkaServerCodec::respond(absl::Status, absl::string_view,
                                                    const GenericProxy::Request&) {
  return std::make_unique<KafkaResponseFrame>(nullptr);
};

KafkaClientCodec::KafkaClientCodec() : request_encoder_(request_buffer_) {}

void KafkaClientCodec::setCodecCallbacks(GenericProxy::ClientCodecCallbacks& callbacks) {
  response_callbacks_ = std::make_shared<KafkaResponseCallbacks>(callbacks);
  response_decoder_ = std::make_shared<NetworkFilters::Kafka::ResponseDecoder>(
      std::vector<NetworkFilters::Kafka::ResponseCallbackSharedPtr>{response_callbacks_});
}

void KafkaClientCodec::decode(Envoy::Buffer::Instance& buffer, bool) {
  response_buffer_.move(buffer);
  response_decoder_->onData(response_buffer_);
  // All data has been consumed, so we can drain the buffer.
  response_buffer_.drain(response_buffer_.length());
}

void KafkaClientCodec::encode(const GenericProxy::StreamFrame& frame,
                              GenericProxy::EncodingCallbacks& callbacks) {
  auto* typed_request = dynamic_cast<const KafkaRequestFrame*>(&frame);
  if (typed_request == nullptr) {
    ENVOY_LOG(error, "Kafka codec: invalid request frame type and cannot encode");
    return;
  }
  response_decoder_->expectResponse(typed_request->request_->request_header_.correlation_id_,
                                    typed_request->request_->request_header_.api_key_,
                                    typed_request->request_->request_header_.api_version_);
  request_encoder_.encode(*typed_request->request_);
  callbacks.onEncodingSuccess(request_buffer_, true);
  // All data should be consumed by the generic proxy and send to the network.
  ASSERT(request_buffer_.length() == 0);
}

CodecFactoryPtr
KafkaCodecFactoryConfig::createCodecFactory(const Protobuf::Message&,
                                            Envoy::Server::Configuration::FactoryContext&) {
  return std::make_unique<KafkaCodecFactory>();
}

REGISTER_FACTORY(KafkaCodecFactoryConfig, CodecFactoryConfig);

} // namespace Kafka
} // namespace Codec
} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include <memory>

#include "source/common/common/logger.h"
#include "source/extensions/common/dubbo/codec.h"

#include "contrib/envoy/extensions/filters/network/generic_proxy/codecs/dubbo/v3/dubbo.pb.h"
#include "contrib/envoy/extensions/filters/network/generic_proxy/codecs/dubbo/v3/dubbo.pb.validate.h"
#include "contrib/generic_proxy/filters/network/source/interface/codec.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {
namespace Codec {
namespace Dubbo {

using ProtoConfig =
    envoy::extensions::filters::network::generic_proxy::codecs::dubbo::v3::DubboCodecConfig;

static constexpr absl::string_view DubboProtocolName = "dubbo";

class DubboRequest : public Request {
public:
  DubboRequest(Common::Dubbo::MessageMetadataSharedPtr inner_request)
      : inner_metadata_(std::move(inner_request)) {
    ASSERT(inner_metadata_ != nullptr);
    ASSERT(inner_metadata_->hasContext());
    ASSERT(inner_metadata_->hasRequest());
  }

  // Request
  absl::string_view protocol() const override { return DubboProtocolName; }
  void forEach(IterateCallback callback) const override;
  absl::optional<absl::string_view> get(absl::string_view key) const override;
  void set(absl::string_view key, absl::string_view val) override;
  absl::string_view host() const override { return inner_metadata_->request().serviceName(); }
  absl::string_view path() const override { return inner_metadata_->request().serviceName(); }
  absl::string_view method() const override { return inner_metadata_->request().methodName(); }
  void erase(absl::string_view key) override;

  // StreamFrame
  FrameFlags frameFlags() const override { return stream_frame_flags_; }

  FrameFlags stream_frame_flags_;

  Common::Dubbo::MessageMetadataSharedPtr inner_metadata_;
};

class DubboResponse : public Response {
public:
  DubboResponse(Common::Dubbo::MessageMetadataSharedPtr inner_response)
      : inner_metadata_(std::move(inner_response)) {
    ASSERT(inner_metadata_ != nullptr);
    ASSERT(inner_metadata_->hasContext());
    ASSERT(inner_metadata_->hasResponse());
    refreshStatus();
  }

  void refreshStatus();

  // Response.
  absl::string_view protocol() const override { return DubboProtocolName; }
  StreamStatus status() const override { return status_; }

  // StreamFrame
  FrameFlags frameFlags() const override { return stream_frame_flags_; }

  FrameFlags stream_frame_flags_;

  StreamStatus status_;
  Common::Dubbo::MessageMetadataSharedPtr inner_metadata_;
};

class DubboCodecBase : public Logger::Loggable<Logger::Id::connection> {
public:
  DubboCodecBase(Common::Dubbo::DubboCodecPtr codec);

  Common::Dubbo::DubboCodecPtr codec_;
};

template <class CodecType, class DecoderMessageType, class EncoderMessageType, class CallBackType>
class DubboDecoderBase : public DubboCodecBase, public CodecType {
public:
  using DubboCodecBase::DubboCodecBase;

  void setCodecCallbacks(CallBackType& callback) override { callback_ = &callback; }

  void decode(Buffer::Instance& buffer, bool) override {
    if (metadata_ == nullptr) {
      metadata_ = std::make_shared<Common::Dubbo::MessageMetadata>();
    }

    try {
      Common::Dubbo::DecodeStatus decode_status{Common::Dubbo::DecodeStatus::Success};
      if (!metadata_->hasContext()) {
        ENVOY_LOG(debug, "Dubbo codec: try to decode new dubbo request/response header");
        decode_status = codec_->decodeHeader(buffer, *metadata_);
      }

      if (decode_status == Common::Dubbo::DecodeStatus::Success) {
        ASSERT(metadata_->hasContext());
        ENVOY_LOG(debug, "Dubbo codec: try to decode new dubbo request/response body");
        decode_status = codec_->decodeData(buffer, *metadata_);
      }

      if (decode_status == Common::Dubbo::DecodeStatus::Failure) {
        ENVOY_LOG(warn, "Dubbo codec: unexpected decoding error");
        metadata_.reset();
        callback_->onDecodingFailure();
        return;
      }

      if (decode_status == Common::Dubbo::DecodeStatus::Waiting) {
        ENVOY_LOG(debug, "Dubbo codec: waiting for more input data");
        return;
      }

      ASSERT(decode_status == Common::Dubbo::DecodeStatus::Success);

      auto message = std::make_unique<DecoderMessageType>(metadata_);
      message->stream_frame_flags_ = {{static_cast<uint64_t>(metadata_->requestId()),
                                       !metadata_->context().isTwoWay(), false,
                                       metadata_->context().heartbeat()},
                                      true};
      callback_->onDecodingSuccess(std::move(message));
      metadata_.reset();
    } catch (const EnvoyException& error) {
      ENVOY_LOG(warn, "Dubbo codec: decoding error: {}", error.what());
      metadata_.reset();
      callback_->onDecodingFailure();
    }
  }

  void encode(const StreamFrame& frame, EncodingCallbacks& callbacks) override {
    ASSERT(dynamic_cast<const EncoderMessageType*>(&frame) != nullptr);
    const auto* typed_message = static_cast<const EncoderMessageType*>(&frame);

    Buffer::OwnedImpl buffer;
    codec_->encode(buffer, *typed_message->inner_metadata_);
    callbacks.onEncodingSuccess(buffer, true);
  }

  Common::Dubbo::MessageMetadataSharedPtr metadata_;
  CallBackType* callback_{};
};

class DubboServerCodec
    : public DubboDecoderBase<ServerCodec, DubboRequest, DubboResponse, ServerCodecCallbacks> {
public:
  using DubboDecoderBase::DubboDecoderBase;

  ResponsePtr respond(absl::Status status, absl::string_view short_response_flags,
                      const Request& request) override;
};

class DubboClientCodec
    : public DubboDecoderBase<ClientCodec, DubboResponse, DubboRequest, ClientCodecCallbacks> {
public:
  using DubboDecoderBase::DubboDecoderBase;
};

class DubboCodecFactory : public CodecFactory {
public:
  ServerCodecPtr createServerCodec() const override {
    return std::make_unique<DubboServerCodec>(
        Common::Dubbo::DubboCodec::codecFromSerializeType(Common::Dubbo::SerializeType::Hessian2));
  }
  ClientCodecPtr createClientCodec() const override {
    return std::make_unique<DubboClientCodec>(
        Common::Dubbo::DubboCodec::codecFromSerializeType(Common::Dubbo::SerializeType::Hessian2));
  }
};

class DubboCodecFactoryConfig : public CodecFactoryConfig {
public:
  // CodecFactoryConfig
  CodecFactoryPtr
  createCodecFactory(const Protobuf::Message& config,
                     Envoy::Server::Configuration::FactoryContext& context) override;
  std::string name() const override { return "envoy.generic_proxy.codecs.dubbo"; }
  ProtobufTypes::MessagePtr createEmptyConfigProto() override {
    return std::make_unique<ProtoConfig>();
  }
};

} // namespace Dubbo
} // namespace Codec
} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
load(
    "//bazel:envoy_build_system.bzl",
    "envoy_cc_contrib_extension",
    "envoy_contrib_package",
)

licenses(["notice"])  # Apache 2

envoy_contrib_package()

envoy_cc_contrib_extension(
    name = "config",
    srcs = [
        "config.cc",
    ],
    hdrs = [
        "config.h",
    ],
    deps = [
        "//contrib/generic_proxy/filters/network/source/interface:codec_interface",
        "//source/extensions/common/dubbo:codec_lib",
        "@envoy_api//contrib/envoy/extensions/filters/network/generic_proxy/codecs/dubbo/v3:pkg_cc_proto",
    ],
)
#include "contrib/generic_proxy/filters/network/source/codecs/dubbo/config.h"

#include <memory>

#include "envoy/registry/registry.h"

#include "source/extensions/common/dubbo/message_impl.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {
namespace Codec {
namespace Dubbo {

namespace {

constexpr absl::string_view VERSION_KEY = "version";

Common::Dubbo::ResponseStatus genericStatusToStatus(StatusCode code) {
  switch (code) {
  case StatusCode::kOk:
    return Common::Dubbo::ResponseStatus::Ok;
  case StatusCode::kInvalidArgument:
    return Common::Dubbo::ResponseStatus::BadRequest;
  default:
    return Common::Dubbo::ResponseStatus::ServerError;
  }
}

} // namespace

void DubboRequest::forEach(IterateCallback callback) const {
  const auto* typed_request =
      dynamic_cast<Common::Dubbo::RpcRequestImpl*>(&inner_metadata_->mutableRequest());
  ASSERT(typed_request != nullptr);

  for (const auto& pair : typed_request->attachment().attachment()) {
    ASSERT(pair.first != nullptr && pair.second != nullptr);

    if (pair.first->type() == Hessian2::Object::Type::String &&
        pair.second->type() == Hessian2::Object::Type::String) {
      ASSERT(pair.first->toString().has_value() && pair.second->toString().has_value());

      if (!callback(pair.first->toString().value().get(), pair.second->toString().value().get())) {
        break;
      }
    }
  }
}

absl::optional<absl::string_view> DubboRequest::get(absl::string_view key) const {
  if (key == VERSION_KEY) {
    return inner_metadata_->request().serviceVersion();
  }
  const auto* typed_request =
      dynamic_cast<Common::Dubbo::RpcRequestImpl*>(&inner_metadata_->mutableRequest());
  ASSERT(typed_request != nullptr);

  return typed_request->attachment().lookup(key);
}

void DubboRequest::set(absl::string_view key, absl::string_view val) {
  auto* typed_request =
      dynamic_cast<Common::Dubbo::RpcRequestImpl*>(&inner_metadata_->mutableRequest());
  ASSERT(typed_request != nullptr);

  typed_request->mutableAttachment()->insert(key, val);
}

void DubboRequest::erase(absl::string_view key) {
  auto* typed_request =
      dynamic_cast<Common::Dubbo::RpcRequestImpl*>(&inner_metadata_->mutableRequest());
  ASSERT(typed_request != nullptr);

  typed_request->mutableAttachment()->remove(key);
}

void DubboResponse::refreshStatus() {
  ASSERT(inner_metadata_ != nullptr);
  ASSERT(inner_metadata_->hasResponse() && inner_metadata_->hasResponseStatus());

  using Common::Dubbo::RpcResponseType;

  const auto status = inner_metadata_->context().responseStatus();
  const auto optional_type = inner_metadata_->response().responseType();

  // The final status is not ok if the response status is not ResponseStatus::Ok
  // anyway.
  bool response_ok = (status == Common::Dubbo::ResponseStatus::Ok);

  // The final status is not ok if the response type is ResponseWithException or
  // ResponseWithExceptionWithAttachments even if the response status is Ok.
  if (status == Common::Dubbo::ResponseStatus::Ok) {
    ASSERT(optional_type.has_value());
    auto type = optional_type.value_or(RpcResponseType::ResponseWithException);
    if (type == RpcResponseType::ResponseWithException ||
        type == RpcResponseType::ResponseWithExceptionWithAttachments) {
      response_ok = false;
    }
  }

  status_ = StreamStatus(static_cast<uint8_t>(status), response_ok);
}

DubboCodecBase::DubboCodecBase(Common::Dubbo::DubboCodecPtr codec) : codec_(std::move(codec)) {}

ResponsePtr DubboServerCodec::respond(Status status, absl::string_view,
                                      const Request& origin_request) {
  const auto* typed_request = dynamic_cast<const DubboRequest*>(&origin_request);
  ASSERT(typed_request != nullptr);

  Common::Dubbo::ResponseStatus response_status = genericStatusToStatus(status.code());

  absl::optional<Common::Dubbo::RpcResponseType> optional_type;
  absl::string_view content;

  if (response_status == Common::Dubbo::ResponseStatus::Ok) {
    optional_type.emplace(Common::Dubbo::RpcResponseType::ResponseWithException);
    content = "exception_via_proxy";
  } else {
    content = status.message();
  }

  return std::make_unique<DubboResponse>(Common::Dubbo::DirectResponseUtil::localResponse(
      *typed_request->inner_metadata_, response_status, optional_type, content));
}

CodecFactoryPtr
DubboCodecFactoryConfig::createCodecFactory(const Protobuf::Message&,
                                            Envoy::Server::Configuration::FactoryContext&) {
  return std::make_unique<DubboCodecFactory>();
}

REGISTER_FACTORY(DubboCodecFactoryConfig, CodecFactoryConfig);

} // namespace Dubbo
} // namespace Codec
} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/generic_proxy/filters/network/source/match.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

REGISTER_FACTORY(ServiceMatchDataInputFactory, Matcher::DataInputFactory<Request>);

REGISTER_FACTORY(HostMatchDataInputFactory, Matcher::DataInputFactory<Request>);

REGISTER_FACTORY(PathMatchDataInputFactory, Matcher::DataInputFactory<Request>);

REGISTER_FACTORY(MethodMatchDataInputFactory, Matcher::DataInputFactory<Request>);

REGISTER_FACTORY(PropertyMatchDataInputFactory, Matcher::DataInputFactory<Request>);

REGISTER_FACTORY(RequestMatchDataInputFactory, Matcher::DataInputFactory<Request>);

using StringMatcherImpl = Matchers::StringMatcherImpl<StringMatcherProto>;

RequestMatchInputMatcher::RequestMatchInputMatcher(const RequestMatcherProto& proto_config) {

  if (proto_config.has_host()) {
    host_ = std::make_unique<StringMatcherImpl>(proto_config.host());
  }
  if (proto_config.has_path()) {
    path_ = std::make_unique<StringMatcherImpl>(proto_config.path());
  }
  if (proto_config.has_method()) {
    method_ = std::make_unique<StringMatcherImpl>(proto_config.method());
  }

  for (const auto& property : proto_config.properties()) {
    properties_.push_back(
        {property.name(), std::make_unique<StringMatcherImpl>(property.string_match())});
  }
}

bool RequestMatchInputMatcher::match(const Matcher::MatchingDataType& input) {
  if (!absl::holds_alternative<std::shared_ptr<Matcher::CustomMatchData>>(input)) {
    return false;
  }

  const auto* typed_data = dynamic_cast<const RequestMatchData*>(
      absl::get<std::shared_ptr<Matcher::CustomMatchData>>(input).get());

  if (typed_data == nullptr) {
    return false;
  }

  return match(typed_data->request());
}

bool RequestMatchInputMatcher::match(const Request& request) {
  // TODO(wbpcode): may add more debug log for request match?
  if (host_ != nullptr) {
    if (!host_->match(request.host())) {
      // Host does not match.
      return false;
    }
  }

  if (path_ != nullptr) {
    if (!path_->match(request.path())) {
      // Path does not match.
      return false;
    }
  }

  if (method_ != nullptr) {
    if (!method_->match(request.method())) {
      // Method does not match.
      return false;
    }
  }

  for (const auto& property : properties_) {
    if (auto val = request.get(property.first); val.has_value()) {
      if (!property.second->match(val.value())) {
        // Property does not match.
        return false;
      }
    } else {
      // Property does not exist.
      return false;
    }
  }

  // All matchers passed.
  return true;
}

Matcher::InputMatcherFactoryCb RequestMatchDataInputMatcherFactory::createInputMatcherFactoryCb(
    const Protobuf::Message& config, Server::Configuration::ServerFactoryContext& factory_context) {
  const auto& proto_config = MessageUtil::downcastAndValidate<const RequestMatcherProto&>(
      config, factory_context.messageValidationVisitor());

  return [proto_config]() -> Matcher::InputMatcherPtr {
    return std::make_unique<RequestMatchInputMatcher>(proto_config);
  };
}

REGISTER_FACTORY(RequestMatchDataInputMatcherFactory, Matcher::InputMatcherFactory);

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include "envoy/registry/registry.h"

#include "source/extensions/filters/network/common/factory_base.h"

#include "contrib/envoy/extensions/filters/network/generic_proxy/v3/generic_proxy.pb.h"
#include "contrib/envoy/extensions/filters/network/generic_proxy/v3/generic_proxy.pb.validate.h"
#include "contrib/generic_proxy/filters/network/source/interface/config.h"
#include "contrib/generic_proxy/filters/network/source/proxy.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

class Factory : public Envoy::Extensions::NetworkFilters::Common::FactoryBase<ProxyConfig> {
public:
  Factory() : FactoryBase(Filter::name(), true) {}

  Envoy::Network::FilterFactoryCb
  createFilterFactoryFromProtoTyped(const ProxyConfig& proto_config,
                                    Envoy::Server::Configuration::FactoryContext& context) override;

  static std::pair<CodecFactoryPtr, ProxyFactoryPtr>
  factoriesFromProto(const TypedExtensionConfig& codec_config,
                     Server::Configuration::FactoryContext& context);

  static Rds::RouteConfigProviderSharedPtr
  routeConfigProviderFromProto(const ProxyConfig& config,
                               Server::Configuration::FactoryContext& context,
                               RouteConfigProviderManager& route_config_provider_manager);

  static std::vector<NamedFilterFactoryCb>
  filtersFactoryFromProto(const ProtobufWkt::RepeatedPtrField<TypedExtensionConfig>& filters,
                          const TypedExtensionConfig& codec_config, const std::string stats_prefix,
                          Server::Configuration::FactoryContext& context);
};

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include "contrib/generic_proxy/filters/network/source/file_access_log.h"
#include "contrib/generic_proxy/filters/network/source/interface/stream.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

struct FormatterContext {
  const Request* request_{};
  const Response* response_{};

  static constexpr absl::string_view category() { return "generic_proxy"; }
};

// Formatter for generic proxy.
using Formatter = Formatter::FormatterBase<FormatterContext>;
using FormatterProvider = Envoy::Formatter::FormatterProviderBase<FormatterContext>;
using FormatterProviderPtr = std::unique_ptr<FormatterProvider>;
using CommandParser = Envoy::Formatter::CommandParserBase<FormatterContext>;
using CommandParserFactory = Envoy::Formatter::CommandParserFactoryBase<FormatterContext>;
using BuiltInCommandParsers = Envoy::Formatter::BuiltInCommandParsersBase<FormatterContext>;

// Access log for generic proxy.
using AccessLogFilter = AccessLog::FilterBase<FormatterContext>;
using AccessLogFilterPtr = std::unique_ptr<AccessLogFilter>;
using AccessLogFilterFactory = AccessLog::ExtensionFilterFactoryBase<FormatterContext>;
using AccessLogInstance = AccessLog::InstanceBase<FormatterContext>;
using AccessLogInstanceSharedPtr = std::shared_ptr<AccessLogInstance>;
using AccessLogInstanceFactory = AccessLog::AccessLogInstanceFactoryBase<FormatterContext>;

// File access log for generic proxy.
using FileAccessLog = FileAccessLogBase<FormatterContext>;
using FileAccessLogFactory = FileAccessLogFactoryBase<FormatterContext>;

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include <functional>

#include "envoy/config/core/v3/base.pb.h"
#include "envoy/config/route/v3/route_components.pb.h"
#include "envoy/config/typed_metadata.h"
#include "envoy/server/factory_context.h"

#include "source/common/common/matchers.h"
#include "source/common/config/metadata.h"
#include "source/common/http/header_utility.h"
#include "source/common/matcher/matcher.h"

#include "contrib/envoy/extensions/filters/network/generic_proxy/action/v3/action.pb.h"
#include "contrib/envoy/extensions/filters/network/generic_proxy/action/v3/action.pb.validate.h"
#include "contrib/envoy/extensions/filters/network/generic_proxy/v3/route.pb.h"
#include "contrib/envoy/extensions/filters/network/generic_proxy/v3/route.pb.validate.h"
#include "contrib/generic_proxy/filters/network/source/interface/route.h"
#include "contrib/generic_proxy/filters/network/source/interface/stream.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

using ProtoRouteAction =
    envoy::extensions::filters::network::generic_proxy::action::v3::RouteAction;
using ProtoRouteConfiguration =
    envoy::extensions::filters::network::generic_proxy::v3::RouteConfiguration;
using ProtoVirtualHost = envoy::extensions::filters::network::generic_proxy::v3::VirtualHost;

class RouteEntryImpl : public RouteEntry {
public:
  RouteEntryImpl(const ProtoRouteAction& route,
                 Envoy::Server::Configuration::ServerFactoryContext& context);

  // RouteEntry
  absl::string_view name() const override { return name_; }
  const std::string& clusterName() const override { return cluster_name_; }
  const RouteSpecificFilterConfig* perFilterConfig(absl::string_view name) const override {
    auto iter = per_filter_configs_.find(name);
    return iter != per_filter_configs_.end() ? iter->second.get() : nullptr;
  }
  const envoy::config::core::v3::Metadata& metadata() const override { return metadata_; }

  const Envoy::Config::TypedMetadata& typedMetadata() const override { return typed_metadata_; };

  RouteSpecificFilterConfigConstSharedPtr
  createRouteSpecificFilterConfig(const std::string& name, const ProtobufWkt::Any& typed_config,
                                  Server::Configuration::ServerFactoryContext& factory_context,
                                  ProtobufMessage::ValidationVisitor& validator);

private:
  static const uint64_t DEFAULT_ROUTE_TIMEOUT_MS = 15000;

  std::string name_;
  std::string cluster_name_;

  const envoy::config::core::v3::Metadata metadata_;
  const Envoy::Config::TypedMetadataImpl<RouteTypedMetadataFactory> typed_metadata_;

  absl::flat_hash_map<std::string, RouteSpecificFilterConfigConstSharedPtr> per_filter_configs_;
};
using RouteEntryImplConstSharedPtr = std::shared_ptr<const RouteEntryImpl>;

struct RouteActionContext {
  Server::Configuration::ServerFactoryContext& factory_context;
};

// Action used with the matching tree to specify route to use for an incoming stream.
class RouteMatchAction : public Matcher::ActionBase<ProtoRouteAction> {
public:
  explicit RouteMatchAction(RouteEntryConstSharedPtr route) : route_(std::move(route)) {}

  RouteEntryConstSharedPtr route() const { return route_; }

private:
  RouteEntryConstSharedPtr route_;
};

class RouteActionValidationVisitor : public Matcher::MatchTreeValidationVisitor<Request> {
public:
  absl::Status performDataInputValidation(const Matcher::DataInputFactory<Request>&,
                                          absl::string_view) override {
    return absl::OkStatus();
  }
};

// Registered factory for RouteMatchAction.
class RouteMatchActionFactory : public Matcher::ActionFactory<RouteActionContext> {
public:
  Matcher::ActionFactoryCb
  createActionFactoryCb(const Protobuf::Message& config, RouteActionContext& context,
                        ProtobufMessage::ValidationVisitor& validation_visitor) override;
  std::string name() const override { return "envoy.matching.action.generic_proxy.route"; }
  ProtobufTypes::MessagePtr createEmptyConfigProto() override {
    return std::make_unique<ProtoRouteAction>();
  }
};

class NullRouteMatcherImpl : public RouteMatcher {
public:
  // RouteMatcher
  RouteEntryConstSharedPtr routeEntry(const Request&) const override { return nullptr; }
};

class VirtualHostImpl : Logger::Loggable<Envoy::Logger::Id::filter> {
public:
  VirtualHostImpl(const ProtoVirtualHost& virtual_host_config,
                  Envoy::Server::Configuration::ServerFactoryContext& context,
                  bool validate_clusters_default = false);

  RouteEntryConstSharedPtr routeEntry(const Request& request) const;
  absl::string_view name() const { return name_; }

private:
  std::string name_;
  Matcher::MatchTreeSharedPtr<Request> matcher_;
};
using VirtualHostSharedPtr = std::shared_ptr<VirtualHostImpl>;

class RouteMatcherImpl : public RouteMatcher, Logger::Loggable<Envoy::Logger::Id::filter> {
public:
  RouteMatcherImpl(const ProtoRouteConfiguration& route_config,
                   Envoy::Server::Configuration::ServerFactoryContext& context,
                   bool validate_clusters_default = false);

  RouteEntryConstSharedPtr routeEntry(const Request& request) const override;

  absl::string_view name() const { return name_; }

private:
  using WildcardVirtualHosts =
      std::map<int64_t, absl::flat_hash_map<std::string, VirtualHostSharedPtr>, std::greater<>>;
  using SubstringFunction = std::function<absl::string_view(absl::string_view, int)>;
  const VirtualHostImpl* findWildcardVirtualHost(absl::string_view host,
                                                 const WildcardVirtualHosts& wildcard_virtual_hosts,
                                                 SubstringFunction substring_function) const;

  const VirtualHostImpl* findVirtualHost(const Request& request) const;

  std::string name_;

  absl::flat_hash_map<std::string, VirtualHostSharedPtr> virtual_hosts_;
  // std::greater as a minor optimization to iterate from more to less specific
  //
  // A note on using an unordered_map versus a vector of (string, VirtualHostSharedPtr) pairs:
  //
  // Based on local benchmarks, each vector entry costs around 20ns for recall and (string)
  // comparison with a fixed cost of about 25ns. For unordered_map, the empty map costs about 65ns
  // and climbs to about 110ns once there are any entries.
  //
  // The break-even is 4 entries.
  WildcardVirtualHosts wildcard_virtual_host_suffixes_;
  WildcardVirtualHosts wildcard_virtual_host_prefixes_;

  VirtualHostSharedPtr default_virtual_host_;
};

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include <memory>

#include "source/common/rds/common/route_config_provider_manager_impl.h"

#include "contrib/envoy/extensions/filters/network/generic_proxy/v3/generic_proxy.pb.h"
#include "contrib/envoy/extensions/filters/network/generic_proxy/v3/generic_proxy.pb.validate.h"
#include "contrib/envoy/extensions/filters/network/generic_proxy/v3/route.pb.h"
#include "contrib/envoy/extensions/filters/network/generic_proxy/v3/route.pb.validate.h"
#include "contrib/generic_proxy/filters/network/source/route.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

using RouteConfigProviderManagerImpl = Rds::Common::RouteConfigProviderManagerImpl<
    envoy::extensions::filters::network::generic_proxy::v3::GenericRds,
    envoy::extensions::filters::network::generic_proxy::v3::RouteConfiguration, 1, RouteMatcherImpl,
    NullRouteMatcherImpl>;

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#pragma once

#include "envoy/access_log/access_log.h"
#include "envoy/access_log/access_log_config.h"
#include "envoy/extensions/access_loggers/file/v3/file.pb.h"
#include "envoy/extensions/access_loggers/file/v3/file.pb.validate.h"

#include "source/common/common/utility.h"
#include "source/common/formatter/substitution_format_string.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

template <class Context> class FileAccessLogBase : public AccessLog::InstanceBase<Context> {
public:
  FileAccessLogBase(const Filesystem::FilePathAndType& access_log_file_info,
                    AccessLog::FilterBasePtr<Context>&& filter,
                    Formatter::FormatterBasePtr<Context>&& formatter,
                    AccessLog::AccessLogManager& log_manager)
      : filter_(std::move(filter)), formatter_(std::move(formatter)) {
    log_file_ = log_manager.createAccessLog(access_log_file_info);
  }

  void log(const Context& context, const StreamInfo::StreamInfo& stream_info) override {
    if (filter_ != nullptr && !filter_->evaluate(context, stream_info)) {
      return;
    }
    log_file_->write(formatter_->formatWithContext(context, stream_info));
  }

private:
  AccessLog::AccessLogFileSharedPtr log_file_;
  AccessLog::FilterBasePtr<Context> filter_;
  Formatter::FormatterBasePtr<Context> formatter_;
};

template <class Context>
class FileAccessLogFactoryBase : public AccessLog::AccessLogInstanceFactoryBase<Context> {
public:
  FileAccessLogFactoryBase()
      : name_(fmt::format("envoy.{}.access_loggers.file", Context::category())) {}

  AccessLog::InstanceBaseSharedPtr<Context>
  createAccessLogInstance(const Protobuf::Message& config,
                          AccessLog::FilterBasePtr<Context>&& filter,
                          Server::Configuration::FactoryContext& context) override {
    const auto& typed_config = MessageUtil::downcastAndValidate<
        const envoy::extensions::access_loggers::file::v3::FileAccessLog&>(
        config, context.messageValidationVisitor());

    Formatter::FormatterBasePtr<Context> formatter;

    switch (typed_config.access_log_format_case()) {
    case envoy::extensions::access_loggers::file::v3::FileAccessLog::AccessLogFormatCase::kFormat:
      if (typed_config.format().empty()) {
        formatter = getDefaultFormatter();
      } else {
        envoy::config::core::v3::SubstitutionFormatString sff_config;
        sff_config.mutable_text_format_source()->set_inline_string(typed_config.format());
        formatter =
            Formatter::SubstitutionFormatStringUtils::fromProtoConfig<Context>(sff_config, context);
      }
      break;
    case envoy::extensions::access_loggers::file::v3::FileAccessLog::AccessLogFormatCase::
        kJsonFormat:
      formatter = Formatter::SubstitutionFormatStringUtils::createJsonFormatter<Context>(
          typed_config.json_format(), false, false, false);
      break;
    case envoy::extensions::access_loggers::file::v3::FileAccessLog::AccessLogFormatCase::
        kTypedJsonFormat: {
      envoy::config::core::v3::SubstitutionFormatString sff_config;
      *sff_config.mutable_json_format() = typed_config.typed_json_format();
      formatter =
          Formatter::SubstitutionFormatStringUtils::fromProtoConfig<Context>(sff_config, context);
      break;
    }
    case envoy::extensions::access_loggers::file::v3::FileAccessLog::AccessLogFormatCase::
        kLogFormat:
      formatter = Formatter::SubstitutionFormatStringUtils::fromProtoConfig<Context>(
          typed_config.log_format(), context);
      break;
    case envoy::extensions::access_loggers::file::v3::FileAccessLog::AccessLogFormatCase::
        ACCESS_LOG_FORMAT_NOT_SET:
      formatter = getDefaultFormatter();
      break;
    }
    if (formatter == nullptr) {
      ExceptionUtil::throwEnvoyException(
          "Access log: no format and no default format for file access log");
    }

    Filesystem::FilePathAndType file_info{Filesystem::DestinationType::File, typed_config.path()};
    return std::make_shared<FileAccessLogBase<Context>>(
        file_info, std::move(filter), std::move(formatter),
        context.serverFactoryContext().accessLogManager());
  }

  ProtobufTypes::MessagePtr createEmptyConfigProto() override {
    return ProtobufTypes::MessagePtr{
        new envoy::extensions::access_loggers::file::v3::FileAccessLog()};
  }

  std::string name() const override { return name_; }

protected:
  virtual Formatter::FormatterBasePtr<Context> getDefaultFormatter() const { return nullptr; }

private:
  const std::string name_;
};

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/generic_proxy/filters/network/source/upstream.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

UpstreamConnection::~UpstreamConnection() {
  // Do clean up here again to ensure the cleanUp is called. This is safe to call
  // multiple times because of the is_cleand_up_ flag.
  this->cleanUp(true);
}

void UpstreamConnection::initialize() {
  if (!initialized_) {
    initialized_ = true;
    newConnection();
  }
}

void UpstreamConnection::cleanUp(bool close_connection) {
  // If the cleanUp is called multiple times, just return.
  if (is_cleaned_up_) {
    return;
  }

  ENVOY_LOG(debug, "generic proxy upstream manager: clean up upstream connection");
  // Set is_cleaned_up_ flag to true to avoid double clean up.
  is_cleaned_up_ = true;

  if (close_connection && owned_conn_data_ != nullptr) {
    ENVOY_LOG(debug, "generic proxy upstream request: close upstream connection");
    ASSERT(tcp_pool_handle_ == nullptr);
    owned_conn_data_->connection().close(Network::ConnectionCloseType::FlushWrite);
  }
  owned_conn_data_.reset();

  if (tcp_pool_handle_ != nullptr) {
    ENVOY_LOG(debug, "generic proxy upstream manager: cacel upstream connection");

    ASSERT(owned_conn_data_ == nullptr);
    tcp_pool_handle_->cancel(Tcp::ConnectionPool::CancelPolicy::Default);
    tcp_pool_handle_ = nullptr;
  }
}

void UpstreamConnection::onUpstreamData(Buffer::Instance& data, bool end_stream) {
  ASSERT(!is_cleaned_up_);

  if (data.length() == 0) {
    return;
  }

  client_codec_->decode(data, end_stream);
}

void UpstreamConnection::onPoolFailure(ConnectionPool::PoolFailureReason reason,
                                       absl::string_view transport_failure_reason,
                                       Upstream::HostDescriptionConstSharedPtr host) {
  ENVOY_LOG(debug, "generic proxy upstream manager: on upstream connection failure (host: {})",
            host != nullptr ? host->address()->asStringView() : absl::string_view{});

  tcp_pool_handle_ = nullptr;
  upstream_host_ = std::move(host);

  onPoolFailureImpl(reason, transport_failure_reason);
}

void UpstreamConnection::onPoolReady(Tcp::ConnectionPool::ConnectionDataPtr&& conn_data,
                                     Upstream::HostDescriptionConstSharedPtr host) {
  ASSERT(host != nullptr);
  ENVOY_LOG(debug, "generic proxy upstream manager: on upstream connection ready (host: {})",
            host->address()->asStringView());

  tcp_pool_handle_ = nullptr;
  upstream_host_ = std::move(host);

  owned_conn_data_ = std::move(conn_data);
  owned_conn_data_->addUpstreamCallbacks(*this);

  onPoolSuccessImpl();
}

void UpstreamConnection::onEvent(Network::ConnectionEvent event) { onEventImpl(event); }

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/generic_proxy/filters/network/source/stats.h"

#include "source/common/stream_info/utility.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

constexpr uint32_t MaxCodeValue = 999;

CodeOrFlags::CodeOrFlags(Server::Configuration::ServerFactoryContext& context)
    : pool_(context.scope().symbolTable()) {

  // Only 0-999 are valid status codes for now. This should be enough for all practical purposes.
  // And because this should be global singleton, it's fine to preallocate all of them.
  for (uint32_t i = 0; i <= MaxCodeValue; ++i) {
    code_stat_names_.push_back(pool_.add(std::to_string(i)));
  }

  for (const auto& flag : StreamInfo::ResponseFlagUtils::ALL_RESPONSE_STRINGS_FLAGS) {
    flag_stat_names_.emplace(flag.second, pool_.add(flag.first.short_string_));
  }

  unknown_code_or_flag_ = pool_.add("-");
}

Stats::StatName CodeOrFlags::statNameFromCode(uint32_t code) const {
  if (code <= MaxCodeValue) {
    return code_stat_names_[code];
  }
  return unknown_code_or_flag_;
}

Stats::StatName CodeOrFlags::statNameFromFlag(StreamInfo::ResponseFlag flag) const {
  const auto iter = flag_stat_names_.find(flag);
  if (iter != flag_stat_names_.end()) {
    return iter->second;
  }
  return unknown_code_or_flag_;
}

absl::InlinedVector<StreamInfo::ResponseFlag, 2>
getResponseFlags(const StreamInfo::StreamInfo& info) {
  if (info.responseFlags() == 0) {
    return {};
  }

  absl::InlinedVector<StreamInfo::ResponseFlag, 2> flags;

  for (const auto& flag : StreamInfo::ResponseFlagUtils::ALL_RESPONSE_STRINGS_FLAGS) {
    if (info.hasResponseFlag(flag.second)) {
      flags.push_back(flag.second);
    }
  }
  return flags;
}

void GenericFilterStatsHelper::onRequestReset() { stats_.downstream_rq_reset_.inc(); }

void GenericFilterStatsHelper::onRequestDecodingError() {
  stats_.downstream_rq_decoding_error_.inc();
}

void GenericFilterStatsHelper::onRequest() {
  stats_.downstream_rq_total_.inc();
  stats_.downstream_rq_active_.inc();
}
void GenericFilterStatsHelper::onRequestComplete(const StreamInfo::StreamInfo& info,
                                                 bool local_reply, bool error_reply) {
  stats_.downstream_rq_active_.dec();

  if (local_reply) {
    stats_.downstream_rq_local_.inc();
  }
  if (error_reply) {
    stats_.downstream_rq_error_.inc();
  }

  // Record request time.
  auto rq_time_ms = info.requestComplete();
  if (rq_time_ms.has_value()) {
    stats_.downstream_rq_time_.recordValue(
        std::chrono::duration_cast<std::chrono::milliseconds>(rq_time_ms.value()).count());
  }

  // Record request tx time.
  StreamInfo::TimingUtility timing(info);
  auto rq_tx_time_us = timing.lastUpstreamTxByteSent();
  if (rq_tx_time_us.has_value()) {
    stats_.downstream_rq_tx_time_.recordValue(
        std::chrono::duration_cast<std::chrono::microseconds>(rq_tx_time_us.value()).count());
  }

  const auto response_code = info.responseCode().value_or(0);
  const auto response_flags = getResponseFlags(info);

  if (last_code_counter_.second.has_value() && response_code == last_code_counter_.first) {
    last_code_counter_.second->inc();
  } else {
    auto name_storage =
        stats_scope_.symbolTable().join({stats_.stats_prefix_, stats_.downstream_rq_code_,
                                         code_or_flag_.statNameFromCode(response_code)});
    last_code_counter_ = {response_code,
                          stats_scope_.counterFromStatName(Stats::StatName{name_storage.get()})};
    last_code_counter_.second->inc();
  }

  for (const auto& flag : response_flags) {
    if (last_flag_counter_.second.has_value() && flag == last_flag_counter_.first) {
      last_flag_counter_.second->inc();
    } else {
      auto name_storage = stats_scope_.symbolTable().join(
          {stats_.stats_prefix_, stats_.downstream_rq_flag_, code_or_flag_.statNameFromFlag(flag)});

      last_flag_counter_ = {flag,
                            stats_scope_.counterFromStatName(Stats::StatName{name_storage.get()})};
      last_flag_counter_.second->inc();
    }
  }
}

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions
} // namespace Envoy
#include "contrib/generic_proxy/filters/network/source/access_log.h"

#include "envoy/registry/registry.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

class StringValueFormatterProvider : public FormatterProvider {
public:
  using ValueExtractor = std::function<absl::optional<std::string>(const FormatterContext&,
                                                                   const StreamInfo::StreamInfo&)>;

  StringValueFormatterProvider(ValueExtractor f, absl::optional<size_t> max_length = absl::nullopt)
      : value_extractor_(f), max_length_(max_length) {}

  // FormatterProvider
  absl::optional<std::string>
  formatWithContext(const FormatterContext& context,
                    const StreamInfo::StreamInfo& stream_info) const override {
    auto optional_str = value_extractor_(context, stream_info);
    if (!optional_str) {
      return absl::nullopt;
    }
    if (max_length_.has_value()) {
      if (optional_str->length() > max_length_.value()) {
        optional_str->resize(max_length_.value());
      }
    }
    return optional_str;
  }
  ProtobufWkt::Value
  formatValueWithContext(const FormatterContext& context,
                         const StreamInfo::StreamInfo& stream_info) const override {
    return ValueUtil::optionalStringValue(formatWithContext(context, stream_info));
  }

private:
  ValueExtractor value_extractor_;
  absl::optional<size_t> max_length_;
};

class GenericStatusCodeFormatterProvider : public FormatterProvider {
public:
  GenericStatusCodeFormatterProvider() = default;

  // FormatterProvider
  absl::optional<std::string> formatWithContext(const FormatterContext& context,
                                                const StreamInfo::StreamInfo&) const override {
    if (context.response_ == nullptr) {
      return absl::nullopt;
    }

    const int code = context.response_->status().code();
    return std::to_string(code);
  }
  ProtobufWkt::Value formatValueWithContext(const FormatterContext& context,
                                            const StreamInfo::StreamInfo&) const override {
    if (context.response_ == nullptr) {
      return ValueUtil::nullValue();
    }

    const int code = context.response_->status().code();
    return ValueUtil::numberValue(code);
  }
};

class SimpleCommandParser : public CommandParser {
public:
  using ProviderFunc =
      std::function<FormatterProviderPtr(absl::string_view, absl::optional<size_t> max_length)>;
  using ProviderFuncTable = absl::flat_hash_map<std::string, ProviderFunc>;

  // CommandParser
  FormatterProviderPtr parse(const std::string& command, const std::string& command_arg,
                             absl::optional<size_t>& max_length) const override {
    const auto& provider_func_table = providerFuncTable();
    const auto func_iter = provider_func_table.find(std::string(command));
    if (func_iter == provider_func_table.end()) {
      return nullptr;
    }
    return func_iter->second(command_arg, max_length);
  }

private:
  static const ProviderFuncTable& providerFuncTable() {
    CONSTRUCT_ON_FIRST_USE(
        ProviderFuncTable,
        {
            {"METHOD",
             [](absl::string_view, absl::optional<size_t>) -> FormatterProviderPtr {
               return std::make_unique<StringValueFormatterProvider>(
                   [](const FormatterContext& context,
                      const StreamInfo::StreamInfo&) -> absl::optional<std::string> {
                     if (context.request_) {
                       return std::string(context.request_->method());
                     }
                     return absl::nullopt;
                   });
             }},
            {"HOST",
             [](absl::string_view, absl::optional<size_t>) -> FormatterProviderPtr {
               return std::make_unique<StringValueFormatterProvider>(
                   [](const FormatterContext& context,
                      const StreamInfo::StreamInfo&) -> absl::optional<std::string> {
                     if (context.request_) {
                       return std::string(context.request_->host());
                     }
                     return absl::nullopt;
                   });
             }},
            {"PATH",
             [](absl::string_view, absl::optional<size_t>) -> FormatterProviderPtr {
               return std::make_unique<StringValueFormatterProvider>(
                   [](const FormatterContext& context,
                      const StreamInfo::StreamInfo&) -> absl::optional<std::string> {
                     if (context.request_) {
                       return std::string(context.request_->path());
                     }
                     return absl::nullopt;
                   });
             }},
            {"PROTOCOL",
             [](absl::string_view, absl::optional<size_t>) -> FormatterProviderPtr {
               return std::make_unique<StringValueFormatterProvider>(
                   [](const FormatterContext& context,
                      const StreamInfo::StreamInfo&) -> absl::optional<std::string> {
                     if (context.request_) {
                       return std::string(context.request_->protocol());
                     }
                     return absl::nullopt;
                   });
             }},
            {"REQUEST_PROPERTY",
             [](absl::string_view command_arg, absl::optional<size_t>) -> FormatterProviderPtr {
               return std::make_unique<StringValueFormatterProvider>(
                   [key = std::string(command_arg)](
                       const FormatterContext& context,
                       const StreamInfo::StreamInfo&) -> absl::optional<std::string> {
                     if (!context.request_) {
                       return absl::nullopt;
                     }
                     auto optional_view = context.request_->get(key);
                     if (!optional_view.has_value()) {
                       return absl::nullopt;
                     }
                     return std::string(optional_view.value());
                   });
             }},
            {"RESPONSE_PROPERTY",
             [](absl::string_view command_arg, absl::optional<size_t>) -> FormatterProviderPtr {
               return std::make_unique<StringValueFormatterProvider>(
                   [key = std::string(command_arg)](
                       const FormatterContext& context,
                       const StreamInfo::StreamInfo&) -> absl::optional<std::string> {
                     if (!context.response_) {
                       return absl::nullopt;
                     }
                     auto optional_view = context.response_->get(key);
                     if (!optional_view.has_value()) {
                       return absl::nullopt;
                     }
                     return std::string(optional_view.value());
                   });
             }},
            // A formatter for the response status code. This supports the case where the response
            // code is minus value and will override the common RESPONSE_CODE formatter for generic
            // proxy.
            {"RESPONSE_CODE",
             [](absl::string_view, absl::optional<size_t>) -> FormatterProviderPtr {
               return std::make_unique<GenericStatusCodeFormatterProvider>();
             }},
        });
  }
};

// Register the access log for the FormatterContext.
REGISTER_FACTORY(FileAccessLogFactory, AccessLogInstanceFactory);

} // namespace GenericProxy
} // namespace NetworkFilters
} // namespace Extensions

namespace Formatter {

using FormatterContext = Extensions::NetworkFilters::GenericProxy::FormatterContext;
using SimpleCommandParser = Extensions::NetworkFilters::GenericProxy::SimpleCommandParser;
// Regiter the built-in command parsers for the FormatterContext.
REGISTER_BUILT_IN_COMMAND_PARSER(FormatterContext, SimpleCommandParser);

} // namespace Formatter

} // namespace Envoy
#include "contrib/generic_proxy/filters/network/source/route.h"

#include <memory>

#include "envoy/config/route/v3/route_components.pb.h"

#include "source/common/common/assert.h"
#include "source/common/common/matchers.h"
#include "source/common/config/utility.h"

#include "contrib/generic_proxy/filters/network/source/interface/config.h"
#include "contrib/generic_proxy/filters/network/source/interface/route.h"
#include "interface/stream.h"

namespace Envoy {
namespace Extensions {
namespace NetworkFilters {
namespace GenericProxy {

RouteSpecificFilterConfigConstSharedPtr RouteEntryImpl::createRouteSpecificFilterConfig(
    const std::string& name, const ProtobufWkt::Any& typed_config,
    Server::Configuration::ServerFactoryContext& factory_context,
    ProtobufMessage::ValidationVisitor& validator) {

  auto* factory = Config::Utility::getFactoryByType<NamedFilterConfigFactory>(typed_config);
  if (factory == nullptr) {
    if (!Runtime::runtimeFeatureEnabled("envoy.reloadable_features.no_extension_lookup_by_name")) {
      factory = Config::Utility::getFactoryByName<NamedFilterConfigFactory>(name);
    }
  }

  if (factory == nullptr) {
    ExceptionUtil::throwEnvoyException(
        fmt::format("Didn't find a registered implementation for '{}' with type URL: '{}'", name,
                    Config::Utility::getFactoryType(typed_config)));
  }

  ProtobufTypes::MessagePtr message = factory->createEmptyRouteConfigProto();
  if (message == nullptr) {
    return nullptr;
  }

  Envoy::Config::Utility::translateOpaqueConfig(typed_config, validator, *message);
  return factory->createRouteSpecificFilterConfig(*message, factory_context, validator);
}

RouteEntryImpl::RouteEntryImpl(const ProtoRouteAction& route_action,
                               Envoy::Server::Configuration::ServerFactoryContext& context)
    : name_(route_action.name()), cluster_name_(route_action.cluster()),
      metadata_(route_action.metadata()), typed_metadata_(metadata_) {

  for (const auto& proto_filter_config : route_action.per_filter_config()) {
    auto route_config =
        createRouteSpecificFilterConfig(proto_filter_config.first, proto_filter_config.second,
                                        context, context.messageValidationVisitor());
    if (route_config != nullptr) {
      per_filter_configs_.emplace(proto_filter_config.first, std::move(route_config));
    }
  }
}

Matcher::ActionFactoryCb RouteMatchActionFactory::createActionFactoryCb(
    const Protobuf::Message& config, RouteActionContext& context,
    ProtobufMessage::ValidationVisitor& validation_visitor) {
  const auto& route_action =
      MessageUtil::downcastAndValidate<const ProtoRouteAction&>(config, validation_visitor);
  auto route = std::make_shared<RouteEntryImpl>(route_action, context.factory_context);
  return [route]() { return std::make_unique<RouteMatchAction>(route); };
}
REGISTER_FACTORY(RouteMatchActionFactory, Matcher::ActionFactory<RouteActionContext>);

VirtualHostImpl::VirtualHostImpl(const ProtoVirtualHost& virtual_host_config,
                                 Envoy::Server::Configuration::ServerFactoryContext& context, bool)
    : name_(virtual_host_config.name()) {
  RouteActionValidationVisitor validation_visitor;
  RouteActionContext action_context{context};

  Matcher::MatchTreeFactory<Request, RouteActionContext> factory(action_context, context,
                                                                 validation_visitor);

  matcher_ = factory.create(virtual_host_config.routes())();

  if (!validation_visitor.errors().empty()) {
    throw EnvoyException(fmt::format("requirement violation while creating route match tree: {}",
                                     validation_visitor.errors()[0]));
  }
}

RouteEntryConstSharedPtr VirtualHostImpl::routeEntry(const Request& request) const {
  auto match = Matcher::evaluateMatch<Request>(*matcher_, request);

  if (match.result_) {
    auto action = match.result_();

    // The only possible action that can be used within the route matching context
    // is the RouteMatchAction, so this must be true.
    ASSERT(action->typeUrl() == RouteMatchAction::staticTypeUrl());
    ASSERT(dynamic_cast<RouteMatchAction*>(action.get()));
    const RouteMatchAction& route_action = static_cast<const RouteMatchAction&>(*action);

    return route_action.route();
  }

  ENVOY_LOG(debug, "failed to match incoming request: {}",
            static_cast<uint32_t>(match.match_state_));
  return nullptr;
}

RouteMatcherImpl::RouteMatcherImpl(const ProtoRouteConfiguration& route_config,
                                   Envoy::Server::Configuration::ServerFactoryContext& context,
                                   bool validate_clusters)
    : name_(route_config.name()) {
  constexpr absl::string_view wildcard_flag{"*"};

  // TODO(wbpcode): maybe share the same code with common/router/config_impl.cc by using template.
  for (const auto& virtual_host_config : route_config.virtual_hosts()) {
    VirtualHostSharedPtr virtual_host =
        std::make_shared<VirtualHostImpl>(virtual_host_config, context, validate_clusters);
    for (const std::string& host_name : virtual_host_config.hosts()) {
      if (host_name.empty()) {
        throw EnvoyException(
            fmt::format("Invalid empty host name in route {}", route_config.name()));
      }

      absl::string_view host_name_view{host_name};
      bool duplicate_found = false;
      if (wildcard_flag == host_name_view) {
        // Catch all virtual host.
        if (default_virtual_host_ != nullptr) {
          throw EnvoyException(fmt::format("Only a single wildcard domain is permitted in route {}",
                                           route_config.name()));
        }
        default_virtual_host_ = virtual_host;
      } else if (absl::StartsWith(host_name_view, wildcard_flag)) {
        duplicate_found = !wildcard_virtual_host_suffixes_[host_name_view.size() - 1]
                               .emplace(host_name_view.substr(1), virtual_host)
                               .second;
      } else if (absl::EndsWith(host_name_view, wildcard_flag)) {
        duplicate_found =
            !wildcard_virtual_host_prefixes_[host_name_view.size() - 1]
                 .emplace(host_name_view.substr(0, host_name_view.size() - 1), virtual_host)
                 .second;
      } else {
        duplicate_found = !virtual_hosts_.emplace(host_name_view, virtual_host).second;
      }
      if (duplicate_found) {
        throw EnvoyException(fmt::format("Only unique values for host are permitted. Duplicate "
                                         "entry of domain {} in route {}",
                                         host_name_view, route_config.name()));
      }
    }
  }

  // 'routes' is supported for backwards compatibility. It will be used as default virtual host
  // if no catch-all virtual host is specified.
  if (route_config.has_routes()) {
    if (default_virtual_host_ == nullptr) {
      ProtoVirtualHost proto_virtual_host;
      proto_virtual_host.mutable_routes()->MergeFrom(route_config.routes());
      default_virtual_host_ =
          std::make_shared<VirtualHostImpl>(proto_virtual_host, context, validate_clusters);
    } else {
      throw EnvoyException(fmt::format("'routes' cannot be specified at the same time as a "
                                  